2024-10-24T13:18:06.204578481Z I1024 13:18:06.204426       1 cmd.go:250] Using service-serving-cert provided certificates
2024-10-24T13:18:06.204578481Z I1024 13:18:06.204542       1 leaderelection.go:121] The leader election gives 4 retries and allows for 30s of clock skew. The kube-apiserver downtime tolerance is 78s. Worst non-graceful lease acquisition is 2m43s. Worst graceful lease acquisition is {26s}.
2024-10-24T13:18:06.205261731Z I1024 13:18:06.205202       1 observer_polling.go:159] Starting file observer
2024-10-24T13:19:00.554452955Z I1024 13:19:00.554379       1 builder.go:298] kube-apiserver-operator version v4.0.0-alpha.0-2044-gdf3657c-df3657cc2
2024-10-24T13:19:01.037245407Z I1024 13:19:01.037144       1 secure_serving.go:57] Forcing use of http/1.1 only
2024-10-24T13:19:01.037245407Z W1024 13:19:01.037214       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256' detected.
2024-10-24T13:19:01.037245407Z W1024 13:19:01.037223       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256' detected.
2024-10-24T13:19:01.037245407Z W1024 13:19:01.037235       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_128_GCM_SHA256' detected.
2024-10-24T13:19:01.037245407Z W1024 13:19:01.037240       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_256_GCM_SHA384' detected.
2024-10-24T13:19:01.037284377Z W1024 13:19:01.037244       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_128_CBC_SHA' detected.
2024-10-24T13:19:01.037284377Z W1024 13:19:01.037249       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_256_CBC_SHA' detected.
2024-10-24T13:19:01.047138836Z I1024 13:19:01.047100       1 leaderelection.go:254] attempting to acquire leader lease openshift-kube-apiserver-operator/kube-apiserver-operator-lock...
2024-10-24T13:19:01.048552426Z I1024 13:19:01.048518       1 requestheader_controller.go:172] Starting RequestHeaderAuthRequestController
2024-10-24T13:19:01.048596916Z I1024 13:19:01.048569       1 shared_informer.go:313] Waiting for caches to sync for RequestHeaderAuthRequestController
2024-10-24T13:19:01.048639196Z I1024 13:19:01.048583       1 configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2024-10-24T13:19:01.048639196Z I1024 13:19:01.048626       1 configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2024-10-24T13:19:01.048651796Z I1024 13:19:01.048641       1 shared_informer.go:313] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-10-24T13:19:01.048818406Z I1024 13:19:01.048642       1 shared_informer.go:313] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-10-24T13:19:01.049058816Z I1024 13:19:01.049022       1 dynamic_serving_content.go:135] "Starting controller" name="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key"
2024-10-24T13:19:01.049254316Z I1024 13:19:01.049056       1 secure_serving.go:213] Serving securely on [::]:8443
2024-10-24T13:19:01.049254316Z I1024 13:19:01.049074       1 tlsconfig.go:243] "Starting DynamicServingCertificateController"
2024-10-24T13:19:01.149740005Z I1024 13:19:01.149660       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-10-24T13:19:01.149952955Z I1024 13:19:01.149873       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-10-24T13:19:01.150152654Z I1024 13:19:01.150109       1 shared_informer.go:320] Caches are synced for RequestHeaderAuthRequestController
2024-10-24T13:21:42.752461631Z I1024 13:21:42.752391       1 leaderelection.go:268] successfully acquired lease openshift-kube-apiserver-operator/kube-apiserver-operator-lock
2024-10-24T13:21:42.752854311Z I1024 13:21:42.752506       1 event.go:377] Event(v1.ObjectReference{Kind:"Lease", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator-lock", UID:"4ae29599-1ac2-4955-b398-22769183a220", APIVersion:"coordination.k8s.io/v1", ResourceVersion:"22492", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' kube-apiserver-operator-749f4b99b7-fqnd2_abd6523a-0958-42d6-b47e-3ea5745d2a3c became leader
2024-10-24T13:21:42.753582611Z I1024 13:21:42.753536       1 simple_featuregate_reader.go:171] Starting feature-gate-detector
2024-10-24T13:21:42.764589531Z I1024 13:21:42.764530       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'FeatureGatesInitialized' FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AWSEFSDriverVolumeMetrics", "AdminNetworkPolicy", "AlibabaPlatform", "AzureWorkloadIdentity", "BareMetalLoadBalancer", "BuildCSIVolumes", "ChunkSizeMiB", "CloudDualStackNodeIPs", "DisableKubeletCloudCredentialProviders", "GCPLabelsTags", "HardwareSpeed", "IngressControllerLBSubnetsAWS", "KMSv1", "ManagedBootImages", "MetricsServer", "MultiArchInstallAWS", "MultiArchInstallGCP", "NetworkDiagnosticsConfig", "NetworkLiveMigration", "NodeDisruptionPolicy", "OpenShiftPodSecurityAdmission", "PrivateHostedZoneAWS", "SetEIPForNLBIngressController", "VSphereControlPlaneMachineSet", "VSphereDriverConfiguration", "VSphereStaticIPs", "ValidatingAdmissionPolicy"}, Disabled:[]v1.FeatureGateName{"AWSClusterHostedDNS", "AdditionalRoutingCapabilities", "AutomatedEtcdBackup", "BootcNodeManagement", "CSIDriverSharedResource", "ClusterAPIInstall", "ClusterAPIInstallIBMCloud", "ClusterMonitoringConfig", "DNSNameResolver", "DynamicResourceAllocation", "EtcdBackendQuota", "EventedPLEG", "Example", "ExternalOIDC", "GCPClusterHostedDNS", "GatewayAPI", "ImageStreamImportMode", "IngressControllerDynamicConfigurationManager", "InsightsConfig", "InsightsConfigAPI", "InsightsOnDemandDataGather", "InsightsRuntimeExtractor", "MachineAPIMigration", "MachineAPIOperatorDisableMachineHealthCheckController", "MachineAPIProviderOpenStack", "MachineConfigNodes", "ManagedBootImagesAWS", "MaxUnavailableStatefulSet", "MetricsCollectionProfiles", "MixedCPUsAllocation", "MultiArchInstallAzure", "NetworkSegmentation", "NewOLM", "NodeSwap", "OVNObservability", "OnClusterBuild", "PersistentIPsForVirtualization", "PinnedImages", "PlatformOperators", "ProcMountType", "RouteAdvertisements", "RouteExternalCertificate", "ServiceAccountTokenNodeBinding", "SignatureStores", "SigstoreImageVerification", "TranslateStreamCloseWebsocketRequests", "UpgradeStatus", "UserNamespacesPodSecurityStandards", "UserNamespacesSupport", "VSphereMultiNetworks", "VSphereMultiVCenters", "VolumeGroupSnapshot"}}
2024-10-24T13:21:42.764709561Z I1024 13:21:42.764529       1 starter.go:164] FeatureGates initialized: knownFeatureGates=[AWSEFSDriverVolumeMetrics AdminNetworkPolicy AlibabaPlatform AzureWorkloadIdentity BareMetalLoadBalancer BuildCSIVolumes ChunkSizeMiB CloudDualStackNodeIPs DisableKubeletCloudCredentialProviders GCPLabelsTags HardwareSpeed IngressControllerLBSubnetsAWS KMSv1 ManagedBootImages MetricsServer MultiArchInstallAWS MultiArchInstallGCP NetworkDiagnosticsConfig NetworkLiveMigration NodeDisruptionPolicy OpenShiftPodSecurityAdmission PrivateHostedZoneAWS SetEIPForNLBIngressController VSphereControlPlaneMachineSet VSphereDriverConfiguration VSphereStaticIPs ValidatingAdmissionPolicy AWSClusterHostedDNS AdditionalRoutingCapabilities AutomatedEtcdBackup BootcNodeManagement CSIDriverSharedResource ClusterAPIInstall ClusterAPIInstallIBMCloud ClusterMonitoringConfig DNSNameResolver DynamicResourceAllocation EtcdBackendQuota EventedPLEG Example ExternalOIDC GCPClusterHostedDNS GatewayAPI ImageStreamImportMode IngressControllerDynamicConfigurationManager InsightsConfig InsightsConfigAPI InsightsOnDemandDataGather InsightsRuntimeExtractor MachineAPIMigration MachineAPIOperatorDisableMachineHealthCheckController MachineAPIProviderOpenStack MachineConfigNodes ManagedBootImagesAWS MaxUnavailableStatefulSet MetricsCollectionProfiles MixedCPUsAllocation MultiArchInstallAzure NetworkSegmentation NewOLM NodeSwap OVNObservability OnClusterBuild PersistentIPsForVirtualization PinnedImages PlatformOperators ProcMountType RouteAdvertisements RouteExternalCertificate ServiceAccountTokenNodeBinding SignatureStores SigstoreImageVerification TranslateStreamCloseWebsocketRequests UpgradeStatus UserNamespacesPodSecurityStandards UserNamespacesSupport VSphereMultiNetworks VSphereMultiVCenters VolumeGroupSnapshot]
2024-10-24T13:21:42.812082933Z I1024 13:21:42.812046       1 base_controller.go:68] Waiting for caches to sync for SCCReconcileController
2024-10-24T13:21:42.819183334Z I1024 13:21:42.819113       1 base_controller.go:68] Waiting for caches to sync for MissingStaticPodController
2024-10-24T13:21:42.819220003Z I1024 13:21:42.819190       1 base_controller.go:68] Waiting for caches to sync for kube-apiserver
2024-10-24T13:21:42.819591573Z I1024 13:21:42.819568       1 base_controller.go:68] Waiting for caches to sync for TargetConfigController
2024-10-24T13:21:42.819675563Z I1024 13:21:42.819651       1 base_controller.go:68] Waiting for caches to sync for NodeKubeconfigController
2024-10-24T13:21:42.819771354Z I1024 13:21:42.819734       1 base_controller.go:68] Waiting for caches to sync for ConfigObserver
2024-10-24T13:21:42.820076724Z I1024 13:21:42.819988       1 base_controller.go:68] Waiting for caches to sync for PodSecurityReadinessController
2024-10-24T13:21:42.820145903Z I1024 13:21:42.820121       1 base_controller.go:74] Caches are synced for PodSecurityReadinessController 
2024-10-24T13:21:42.820196913Z I1024 13:21:42.820172       1 base_controller.go:111] Starting #1 worker of PodSecurityReadinessController controller ...
2024-10-24T13:21:42.820298303Z I1024 13:21:42.820232       1 base_controller.go:68] Waiting for caches to sync for highCPUUsageAlertController
2024-10-24T13:21:42.820630144Z I1024 13:21:42.820602       1 base_controller.go:68] Waiting for caches to sync for KubeAPIServerStaticResources-StaticResources
2024-10-24T13:21:42.820697093Z I1024 13:21:42.820658       1 base_controller.go:68] Waiting for caches to sync for EncryptionConditionController
2024-10-24T13:21:42.820697093Z I1024 13:21:42.820692       1 base_controller.go:68] Waiting for caches to sync for CertRotationTimeUpgradeableController
2024-10-24T13:21:42.820803713Z I1024 13:21:42.820722       1 termination_observer.go:145] Starting TerminationObserver
2024-10-24T13:21:42.820803713Z I1024 13:21:42.820797       1 base_controller.go:68] Waiting for caches to sync for EventWatchController
2024-10-24T13:21:42.820858443Z I1024 13:21:42.820830       1 base_controller.go:68] Waiting for caches to sync for BoundSATokenSignerController
2024-10-24T13:21:42.820858443Z I1024 13:21:42.820852       1 base_controller.go:68] Waiting for caches to sync for auditPolicyController
2024-10-24T13:21:42.820898714Z I1024 13:21:42.820869       1 base_controller.go:68] Waiting for caches to sync for EncryptionKeyController
2024-10-24T13:21:42.820898714Z I1024 13:21:42.820893       1 base_controller.go:68] Waiting for caches to sync for EncryptionStateController
2024-10-24T13:21:42.820911174Z I1024 13:21:42.820905       1 base_controller.go:68] Waiting for caches to sync for EncryptionPruneController
2024-10-24T13:21:42.820931603Z I1024 13:21:42.820918       1 base_controller.go:68] Waiting for caches to sync for EncryptionMigrationController
2024-10-24T13:21:42.820942393Z I1024 13:21:42.820933       1 base_controller.go:68] Waiting for caches to sync for WorkerLatencyProfile
2024-10-24T13:21:42.820984113Z I1024 13:21:42.820954       1 base_controller.go:68] Waiting for caches to sync for ConnectivityCheckController
2024-10-24T13:21:42.820998373Z I1024 13:21:42.820981       1 base_controller.go:68] Waiting for caches to sync for KubeletVersionSkewController
2024-10-24T13:21:42.821097813Z I1024 13:21:42.821050       1 base_controller.go:68] Waiting for caches to sync for ServiceAccountIssuerController
2024-10-24T13:21:42.821097813Z I1024 13:21:42.821087       1 base_controller.go:68] Waiting for caches to sync for webhookSupportabilityController
2024-10-24T13:21:42.821237804Z I1024 13:21:42.821207       1 certrotationcontroller.go:819] Starting CertRotation
2024-10-24T13:21:42.821285133Z I1024 13:21:42.821270       1 certrotationcontroller.go:784] Waiting for CertRotation
2024-10-24T13:21:42.821342943Z I1024 13:21:42.821313       1 base_controller.go:68] Waiting for caches to sync for kube-apiserver-StaticPodState
2024-10-24T13:21:42.821402003Z I1024 13:21:42.820632       1 base_controller.go:68] Waiting for caches to sync for RemoveStaleConditionsController
2024-10-24T13:21:42.821476423Z I1024 13:21:42.821388       1 base_controller.go:68] Waiting for caches to sync for PruneController
2024-10-24T13:21:42.821906214Z I1024 13:21:42.821398       1 base_controller.go:68] Waiting for caches to sync for StartupMonitorPodCondition
2024-10-24T13:21:42.821970134Z I1024 13:21:42.821296       1 base_controller.go:68] Waiting for caches to sync for kube-apiserver-InstallerState
2024-10-24T13:21:42.822066974Z I1024 13:21:42.821216       1 base_controller.go:68] Waiting for caches to sync for RevisionController
2024-10-24T13:21:42.822066974Z I1024 13:21:42.821408       1 base_controller.go:68] Waiting for caches to sync for StaticPodStateFallback
2024-10-24T13:21:42.822066974Z I1024 13:21:42.821419       1 base_controller.go:68] Waiting for caches to sync for kube-apiserver-Node
2024-10-24T13:21:42.822066974Z I1024 13:21:42.821423       1 base_controller.go:68] Waiting for caches to sync for kube-apiserver-Installer
2024-10-24T13:21:42.822066974Z I1024 13:21:42.821458       1 base_controller.go:68] Waiting for caches to sync for StatusSyncer_kube-apiserver
2024-10-24T13:21:42.822066974Z I1024 13:21:42.821537       1 base_controller.go:68] Waiting for caches to sync for GuardController
2024-10-24T13:21:42.822090823Z I1024 13:21:42.821556       1 base_controller.go:68] Waiting for caches to sync for UnsupportedConfigOverridesController
2024-10-24T13:21:42.822090823Z I1024 13:21:42.821570       1 base_controller.go:68] Waiting for caches to sync for LoggingSyncer
2024-10-24T13:21:42.822090823Z I1024 13:21:42.821780       1 base_controller.go:68] Waiting for caches to sync for BackingResourceController-StaticResources
2024-10-24T13:21:42.912323037Z I1024 13:21:42.912254       1 base_controller.go:74] Caches are synced for SCCReconcileController 
2024-10-24T13:21:42.912323037Z I1024 13:21:42.912283       1 base_controller.go:111] Starting #1 worker of SCCReconcileController controller ...
2024-10-24T13:21:42.920936057Z I1024 13:21:42.920877       1 base_controller.go:74] Caches are synced for EventWatchController 
2024-10-24T13:21:42.920936057Z I1024 13:21:42.920918       1 base_controller.go:111] Starting #1 worker of EventWatchController controller ...
2024-10-24T13:21:42.921284028Z I1024 13:21:42.921254       1 base_controller.go:74] Caches are synced for ServiceAccountIssuerController 
2024-10-24T13:21:42.921284028Z I1024 13:21:42.921265       1 base_controller.go:111] Starting #1 worker of ServiceAccountIssuerController controller ...
2024-10-24T13:21:42.922240327Z I1024 13:21:42.922186       1 base_controller.go:74] Caches are synced for RemoveStaleConditionsController 
2024-10-24T13:21:42.922240327Z I1024 13:21:42.922226       1 base_controller.go:111] Starting #1 worker of RemoveStaleConditionsController controller ...
2024-10-24T13:21:42.922240327Z I1024 13:21:42.922230       1 base_controller.go:74] Caches are synced for UnsupportedConfigOverridesController 
2024-10-24T13:21:42.922268157Z I1024 13:21:42.922244       1 base_controller.go:111] Starting #1 worker of UnsupportedConfigOverridesController controller ...
2024-10-24T13:21:42.922280177Z I1024 13:21:42.922267       1 base_controller.go:74] Caches are synced for LoggingSyncer 
2024-10-24T13:21:42.922290217Z I1024 13:21:42.922281       1 base_controller.go:111] Starting #1 worker of LoggingSyncer controller ...
2024-10-24T13:21:42.956542408Z I1024 13:21:42.956450       1 reflector.go:368] Caches populated for *v1.OAuth from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:43.010009870Z I1024 13:21:43.009943       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:43.096454254Z I1024 13:21:43.096367       1 reflector.go:368] Caches populated for *v1.CustomResourceDefinition from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:43.121253955Z I1024 13:21:43.121182       1 base_controller.go:74] Caches are synced for webhookSupportabilityController 
2024-10-24T13:21:43.121253955Z I1024 13:21:43.121234       1 base_controller.go:111] Starting #1 worker of webhookSupportabilityController controller ...
2024-10-24T13:21:43.167092617Z I1024 13:21:43.166982       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:43.203124368Z I1024 13:21:43.203055       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:43.222958909Z I1024 13:21:43.222911       1 base_controller.go:74] Caches are synced for StatusSyncer_kube-apiserver 
2024-10-24T13:21:43.222958909Z I1024 13:21:43.222935       1 base_controller.go:111] Starting #1 worker of StatusSyncer_kube-apiserver controller ...
2024-10-24T13:21:43.223699679Z I1024 13:21:43.223670       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"BackingResourceControllerDegraded: \"manifests/installer-sa.yaml\" (string): rpc error: code = Unknown desc = malformed header: missing HTTP content-type\nBackingResourceControllerDegraded: \nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-apiserver)\nKubeAPIServerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/kube-apiserver-pod\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps kube-apiserver-pod)","reason":"BackingResourceController_SyncError::GuardController_SyncError::KubeAPIServerStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:33Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:21:43.227815719Z W1024 13:21:43.227712       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.254.42:8443: connect: connection refused
2024-10-24T13:21:43.395030675Z I1024 13:21:43.394951       1 reflector.go:368] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:43.421147196Z I1024 13:21:43.421075       1 base_controller.go:74] Caches are synced for ConnectivityCheckController 
2024-10-24T13:21:43.421147196Z I1024 13:21:43.421118       1 base_controller.go:111] Starting #1 worker of ConnectivityCheckController controller ...
2024-10-24T13:21:43.421219856Z I1024 13:21:43.421189       1 base_controller.go:74] Caches are synced for highCPUUsageAlertController 
2024-10-24T13:21:43.421219856Z I1024 13:21:43.421214       1 base_controller.go:111] Starting #1 worker of highCPUUsageAlertController controller ...
2024-10-24T13:21:43.421549986Z I1024 13:21:43.421511       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:21:43.421637236Z I1024 13:21:43.421591       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2024-10-24T13:21:43.421652956Z I1024 13:21:43.421633       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX
2024-10-24T13:21:43.421652956Z I1024 13:21:43.421645       1 internalloadbalancer.go:27] syncing internal loadbalancer hostnames: api-int.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX
2024-10-24T13:21:43.421687016Z I1024 13:21:43.421652       1 certrotationcontroller.go:802] Finished waiting for CertRotation
2024-10-24T13:21:43.421698586Z I1024 13:21:43.421685       1 base_controller.go:68] Waiting for caches to sync for CertRotationController
2024-10-24T13:21:43.421698586Z I1024 13:21:43.421690       1 base_controller.go:68] Waiting for caches to sync for CertRotationController
2024-10-24T13:21:43.421709066Z I1024 13:21:43.421700       1 base_controller.go:68] Waiting for caches to sync for CertRotationController
2024-10-24T13:21:43.421718916Z I1024 13:21:43.421710       1 base_controller.go:68] Waiting for caches to sync for CertRotationController
2024-10-24T13:21:43.421718916Z I1024 13:21:43.421713       1 base_controller.go:68] Waiting for caches to sync for CertRotationController
2024-10-24T13:21:43.421732896Z I1024 13:21:43.421723       1 base_controller.go:68] Waiting for caches to sync for CertRotationController
2024-10-24T13:21:43.421732896Z I1024 13:21:43.421692       1 base_controller.go:74] Caches are synced for CertRotationController 
2024-10-24T13:21:43.421742796Z I1024 13:21:43.421737       1 base_controller.go:111] Starting #1 worker of CertRotationController controller ...
2024-10-24T13:21:43.421802347Z I1024 13:21:43.421740       1 base_controller.go:68] Waiting for caches to sync for CertRotationController
2024-10-24T13:21:43.421802347Z I1024 13:21:43.421764       1 base_controller.go:74] Caches are synced for CertRotationController 
2024-10-24T13:21:43.421802347Z I1024 13:21:43.421770       1 base_controller.go:111] Starting #1 worker of CertRotationController controller ...
2024-10-24T13:21:43.421802347Z I1024 13:21:43.421772       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2024-10-24T13:21:43.421802347Z I1024 13:21:43.421795       1 base_controller.go:68] Waiting for caches to sync for CertRotationController
2024-10-24T13:21:43.421820916Z I1024 13:21:43.421725       1 base_controller.go:68] Waiting for caches to sync for CertRotationController
2024-10-24T13:21:43.421820916Z I1024 13:21:43.421810       1 base_controller.go:68] Waiting for caches to sync for CertRotationController
2024-10-24T13:21:43.421831256Z I1024 13:21:43.421825       1 base_controller.go:68] Waiting for caches to sync for CertRotationController
2024-10-24T13:21:43.421840716Z I1024 13:21:43.421824       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX
2024-10-24T13:21:43.421840716Z I1024 13:21:43.421802       1 base_controller.go:74] Caches are synced for CertRotationController 
2024-10-24T13:21:43.421871307Z I1024 13:21:43.421847       1 base_controller.go:111] Starting #1 worker of CertRotationController controller ...
2024-10-24T13:21:43.422551697Z I1024 13:21:43.421732       1 base_controller.go:68] Waiting for caches to sync for CertRotationController
2024-10-24T13:21:43.460848888Z I1024 13:21:43.460788       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:43.491638289Z I1024 13:21:43.491591       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:21:43.521901290Z I1024 13:21:43.521831       1 base_controller.go:74] Caches are synced for WorkerLatencyProfile 
2024-10-24T13:21:43.521901290Z I1024 13:21:43.521868       1 base_controller.go:111] Starting #1 worker of WorkerLatencyProfile controller ...
2024-10-24T13:21:43.521939911Z I1024 13:21:43.521901       1 base_controller.go:74] Caches are synced for PruneController 
2024-10-24T13:21:43.521939911Z I1024 13:21:43.521925       1 base_controller.go:111] Starting #1 worker of PruneController controller ...
2024-10-24T13:21:43.534582491Z I1024 13:21:43.534555       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:21:43.561068012Z I1024 13:21:43.560992       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:43.597799383Z I1024 13:21:43.597737       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:21:43.617148684Z I1024 13:21:43.617086       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:43.620416624Z I1024 13:21:43.620379       1 base_controller.go:74] Caches are synced for NodeKubeconfigController 
2024-10-24T13:21:43.620416624Z I1024 13:21:43.620399       1 base_controller.go:111] Starting #1 worker of NodeKubeconfigController controller ...
2024-10-24T13:21:43.621133854Z I1024 13:21:43.621074       1 base_controller.go:74] Caches are synced for BoundSATokenSignerController 
2024-10-24T13:21:43.621133854Z I1024 13:21:43.621100       1 base_controller.go:111] Starting #1 worker of BoundSATokenSignerController controller ...
2024-10-24T13:21:43.621133854Z I1024 13:21:43.621082       1 base_controller.go:74] Caches are synced for auditPolicyController 
2024-10-24T13:21:43.621133854Z I1024 13:21:43.621124       1 base_controller.go:111] Starting #1 worker of auditPolicyController controller ...
2024-10-24T13:21:43.621270434Z I1024 13:21:43.621226       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "auditPolicyController" resync interval is set to 10s which might lead to client request throttling
2024-10-24T13:21:43.622691004Z I1024 13:21:43.622640       1 base_controller.go:74] Caches are synced for CertRotationController 
2024-10-24T13:21:43.622691004Z I1024 13:21:43.622658       1 base_controller.go:111] Starting #1 worker of CertRotationController controller ...
2024-10-24T13:21:43.622691004Z I1024 13:21:43.622659       1 base_controller.go:74] Caches are synced for CertRotationController 
2024-10-24T13:21:43.622691004Z I1024 13:21:43.622672       1 base_controller.go:111] Starting #1 worker of CertRotationController controller ...
2024-10-24T13:21:43.622691004Z I1024 13:21:43.622679       1 base_controller.go:74] Caches are synced for RevisionController 
2024-10-24T13:21:43.622721784Z I1024 13:21:43.622689       1 base_controller.go:111] Starting #1 worker of RevisionController controller ...
2024-10-24T13:21:43.622721784Z I1024 13:21:43.622706       1 base_controller.go:74] Caches are synced for CertRotationController 
2024-10-24T13:21:43.622721784Z I1024 13:21:43.622712       1 base_controller.go:111] Starting #1 worker of CertRotationController controller ...
2024-10-24T13:21:43.623331074Z I1024 13:21:43.623289       1 base_controller.go:74] Caches are synced for CertRotationController 
2024-10-24T13:21:43.623331074Z I1024 13:21:43.623310       1 base_controller.go:111] Starting #1 worker of CertRotationController controller ...
2024-10-24T13:21:43.624097414Z I1024 13:21:43.624063       1 base_controller.go:74] Caches are synced for CertRotationController 
2024-10-24T13:21:43.624097414Z I1024 13:21:43.624077       1 base_controller.go:74] Caches are synced for CertRotationController 
2024-10-24T13:21:43.624097414Z I1024 13:21:43.624087       1 base_controller.go:111] Starting #1 worker of CertRotationController controller ...
2024-10-24T13:21:43.624097414Z I1024 13:21:43.624087       1 base_controller.go:74] Caches are synced for CertRotationController 
2024-10-24T13:21:43.624124964Z I1024 13:21:43.624098       1 base_controller.go:111] Starting #1 worker of CertRotationController controller ...
2024-10-24T13:21:43.624124964Z I1024 13:21:43.624079       1 base_controller.go:111] Starting #1 worker of CertRotationController controller ...
2024-10-24T13:21:43.624124964Z I1024 13:21:43.624068       1 base_controller.go:74] Caches are synced for CertRotationController 
2024-10-24T13:21:43.624124964Z I1024 13:21:43.624118       1 base_controller.go:111] Starting #1 worker of CertRotationController controller ...
2024-10-24T13:21:43.646454035Z I1024 13:21:43.646422       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:21:43.677689286Z I1024 13:21:43.675514       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:21:43.721711378Z I1024 13:21:43.720759       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:21:43.776563630Z I1024 13:21:43.775497       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:21:43.788211531Z I1024 13:21:43.787848       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]" to "BackingResourceControllerDegraded: \"manifests/installer-sa.yaml\" (string): rpc error: code = Unknown desc = malformed header: missing HTTP content-type\nBackingResourceControllerDegraded: \nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-apiserver)\nKubeAPIServerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/kube-apiserver-pod\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps kube-apiserver-pod)",Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 7",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 7"
2024-10-24T13:21:43.808684041Z I1024 13:21:43.808619       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:43.818986002Z I1024 13:21:43.818929       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:21:43.862667503Z I1024 13:21:43.862617       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:21:43.878908154Z I1024 13:21:43.877310       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:21:43.998770608Z I1024 13:21:43.998708       1 request.go:700] Waited for 1.182064995s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/configmaps?limit=500&resourceVersion=0
2024-10-24T13:21:44.018371449Z I1024 13:21:44.018316       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:44.022200840Z I1024 13:21:44.022154       1 base_controller.go:74] Caches are synced for CertRotationController 
2024-10-24T13:21:44.022200840Z I1024 13:21:44.022187       1 base_controller.go:111] Starting #1 worker of CertRotationController controller ...
2024-10-24T13:21:44.212211777Z I1024 13:21:44.212138       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:44.231597387Z W1024 13:21:44.231504       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.254.42:8443: connect: connection refused
2024-10-24T13:21:44.403509644Z I1024 13:21:44.403451       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:44.421117425Z I1024 13:21:44.421073       1 base_controller.go:74] Caches are synced for KubeletVersionSkewController 
2024-10-24T13:21:44.421117425Z I1024 13:21:44.421100       1 base_controller.go:111] Starting #1 worker of KubeletVersionSkewController controller ...
2024-10-24T13:21:44.422375135Z I1024 13:21:44.422319       1 base_controller.go:74] Caches are synced for kube-apiserver-Node 
2024-10-24T13:21:44.422375135Z I1024 13:21:44.422340       1 base_controller.go:111] Starting #1 worker of kube-apiserver-Node controller ...
2024-10-24T13:21:44.457889777Z I1024 13:21:44.457854       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:21:44.601495122Z I1024 13:21:44.601438       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:44.622480273Z I1024 13:21:44.622443       1 base_controller.go:74] Caches are synced for BackingResourceController-StaticResources 
2024-10-24T13:21:44.622542943Z I1024 13:21:44.622526       1 base_controller.go:111] Starting #1 worker of BackingResourceController-StaticResources controller ...
2024-10-24T13:21:44.801406630Z I1024 13:21:44.801358       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:44.820114230Z I1024 13:21:44.820074       1 base_controller.go:74] Caches are synced for TargetConfigController 
2024-10-24T13:21:44.820114230Z I1024 13:21:44.820095       1 base_controller.go:111] Starting #1 worker of TargetConfigController controller ...
2024-10-24T13:21:44.821316881Z I1024 13:21:44.821271       1 base_controller.go:74] Caches are synced for CertRotationTimeUpgradeableController 
2024-10-24T13:21:44.821316881Z I1024 13:21:44.821305       1 base_controller.go:111] Starting #1 worker of CertRotationTimeUpgradeableController controller ...
2024-10-24T13:21:45.005704327Z I1024 13:21:45.001925       1 request.go:700] Waited for 2.184735134s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?limit=500&resourceVersion=0
2024-10-24T13:21:45.007203168Z I1024 13:21:45.007125       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:45.019606698Z I1024 13:21:45.019557       1 base_controller.go:74] Caches are synced for MissingStaticPodController 
2024-10-24T13:21:45.019606698Z I1024 13:21:45.019583       1 base_controller.go:111] Starting #1 worker of MissingStaticPodController controller ...
2024-10-24T13:21:45.020822028Z I1024 13:21:45.020727       1 base_controller.go:74] Caches are synced for EncryptionConditionController 
2024-10-24T13:21:45.020822028Z I1024 13:21:45.020804       1 base_controller.go:111] Starting #1 worker of EncryptionConditionController controller ...
2024-10-24T13:21:45.020961678Z I1024 13:21:45.020921       1 base_controller.go:74] Caches are synced for EncryptionKeyController 
2024-10-24T13:21:45.021064468Z I1024 13:21:45.021002       1 base_controller.go:74] Caches are synced for EncryptionPruneController 
2024-10-24T13:21:45.021172438Z I1024 13:21:45.021145       1 base_controller.go:111] Starting #1 worker of EncryptionPruneController controller ...
2024-10-24T13:21:45.021193248Z I1024 13:21:45.021020       1 base_controller.go:111] Starting #1 worker of EncryptionKeyController controller ...
2024-10-24T13:21:45.021253828Z I1024 13:21:45.020970       1 base_controller.go:74] Caches are synced for EncryptionMigrationController 
2024-10-24T13:21:45.021328408Z I1024 13:21:45.021302       1 base_controller.go:111] Starting #1 worker of EncryptionMigrationController controller ...
2024-10-24T13:21:45.021379848Z I1024 13:21:45.020938       1 base_controller.go:74] Caches are synced for EncryptionStateController 
2024-10-24T13:21:45.021432998Z I1024 13:21:45.021412       1 base_controller.go:111] Starting #1 worker of EncryptionStateController controller ...
2024-10-24T13:21:45.021916758Z I1024 13:21:45.021862       1 base_controller.go:74] Caches are synced for kube-apiserver-StaticPodState 
2024-10-24T13:21:45.021991468Z I1024 13:21:45.021975       1 base_controller.go:111] Starting #1 worker of kube-apiserver-StaticPodState controller ...
2024-10-24T13:21:45.022142828Z I1024 13:21:45.022100       1 base_controller.go:74] Caches are synced for GuardController 
2024-10-24T13:21:45.022142828Z I1024 13:21:45.022118       1 base_controller.go:111] Starting #1 worker of GuardController controller ...
2024-10-24T13:21:45.022302578Z I1024 13:21:45.022271       1 base_controller.go:74] Caches are synced for StaticPodStateFallback 
2024-10-24T13:21:45.022471188Z I1024 13:21:45.022426       1 base_controller.go:111] Starting #1 worker of StaticPodStateFallback controller ...
2024-10-24T13:21:45.022471188Z I1024 13:21:45.022288       1 base_controller.go:74] Caches are synced for StartupMonitorPodCondition 
2024-10-24T13:21:45.022471188Z I1024 13:21:45.022459       1 base_controller.go:111] Starting #1 worker of StartupMonitorPodCondition controller ...
2024-10-24T13:21:45.022497968Z I1024 13:21:45.022298       1 base_controller.go:74] Caches are synced for kube-apiserver-Installer 
2024-10-24T13:21:45.022497968Z I1024 13:21:45.022484       1 base_controller.go:111] Starting #1 worker of kube-apiserver-Installer controller ...
2024-10-24T13:21:45.022620258Z I1024 13:21:45.022307       1 base_controller.go:74] Caches are synced for kube-apiserver-InstallerState 
2024-10-24T13:21:45.022673958Z I1024 13:21:45.022659       1 base_controller.go:111] Starting #1 worker of kube-apiserver-InstallerState controller ...
2024-10-24T13:21:45.206123845Z I1024 13:21:45.206054       1 reflector.go:368] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:45.220509506Z I1024 13:21:45.220440       1 base_controller.go:74] Caches are synced for ConfigObserver 
2024-10-24T13:21:45.220509506Z I1024 13:21:45.220472       1 base_controller.go:111] Starting #1 worker of ConfigObserver controller ...
2024-10-24T13:21:45.401517823Z I1024 13:21:45.401450       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:45.603222941Z I1024 13:21:45.603151       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:45.619598451Z I1024 13:21:45.619519       1 base_controller.go:74] Caches are synced for kube-apiserver 
2024-10-24T13:21:45.619598451Z I1024 13:21:45.619550       1 base_controller.go:111] Starting #1 worker of kube-apiserver controller ...
2024-10-24T13:21:45.801003878Z I1024 13:21:45.800932       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:45.820814499Z I1024 13:21:45.820739       1 base_controller.go:74] Caches are synced for KubeAPIServerStaticResources-StaticResources 
2024-10-24T13:21:45.820814499Z I1024 13:21:45.820776       1 base_controller.go:111] Starting #1 worker of KubeAPIServerStaticResources-StaticResources controller ...
2024-10-24T13:21:46.198908033Z I1024 13:21:46.198849       1 request.go:700] Waited for 2.5778072s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:21:46.267791466Z I1024 13:21:46.267711       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:21:46.613592609Z W1024 13:21:46.613521       1 dynamic_operator_client.go:355] .status.conditions["BackingResourceControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:21:46.649436991Z I1024 13:21:46.649370       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:21:46.651249260Z I1024 13:21:46.651203       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-apiserver)\nKubeAPIServerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/kube-apiserver-pod\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps kube-apiserver-pod)","reason":"GuardController_SyncError::KubeAPIServerStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:33Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:21:46.668421201Z I1024 13:21:46.667996       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "BackingResourceControllerDegraded: \"manifests/installer-sa.yaml\" (string): rpc error: code = Unknown desc = malformed header: missing HTTP content-type\nBackingResourceControllerDegraded: \nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-apiserver)\nKubeAPIServerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/kube-apiserver-pod\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps kube-apiserver-pod)" to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-apiserver)\nKubeAPIServerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/kube-apiserver-pod\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps kube-apiserver-pod)"
2024-10-24T13:21:47.199200172Z I1024 13:21:47.199110       1 request.go:700] Waited for 2.176634084s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:21:48.399508688Z I1024 13:21:48.399461       1 request.go:700] Waited for 2.186709924s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:21:49.405742087Z E1024 13:21:49.405680       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:49.405742087Z E1024 13:21:49.405710       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:49.407718226Z E1024 13:21:49.407674       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:49.598948014Z I1024 13:21:49.598890       1 request.go:700] Waited for 1.792655259s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:50.799257770Z I1024 13:21:50.799193       1 request.go:700] Waited for 1.792309979s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-10-24T13:21:51.700277985Z W1024 13:21:51.700216       1 dynamic_operator_client.go:355] .status.conditions["KubeAPIServerStaticResourcesDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:21:51.735042126Z I1024 13:21:51.735004       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:21:51.736534656Z I1024 13:21:51.736496       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nTargetConfigControllerDegraded: \"configmap/kube-apiserver-pod\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps kube-apiserver-pod)","reason":"GuardController_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:33Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:21:51.755392147Z I1024 13:21:51.755312       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-apiserver)\nKubeAPIServerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/kube-apiserver-pod\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps kube-apiserver-pod)" to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nTargetConfigControllerDegraded: \"configmap/kube-apiserver-pod\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps kube-apiserver-pod)"
2024-10-24T13:21:51.998911616Z I1024 13:21:51.998854       1 request.go:700] Waited for 1.192697275s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-10-24T13:21:52.371062210Z I1024 13:21:52.370985       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveInternalRegistryHostnameChanged' Internal registry hostname changed to "image-registry.openshift-image-registry.svc:5000"
2024-10-24T13:21:52.375401971Z I1024 13:21:52.375314       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-10-24T13:21:52.375401971Z   	"admission":          map[string]any{"pluginConfig": map[string]any{"PodSecurity": map[string]any{"configuration": map[string]any{"defaults": map[string]any{"audit": string("restricted"), "audit-version": string("latest"), "enforce": string("restricted"), "enforce-version": string("latest"), ...}}}, "network.openshift.io/ExternalIPRanger": map[string]any{"configuration": map[string]any{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]any{"configuration": map[string]any{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []any{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2024-10-24T13:21:52.375401971Z   	"apiServerArguments": map[string]any{"api-audiences": []any{string("https://kubernetes.default.svc")}, "authentication-token-webhook-config-file": []any{string("/etc/kubernetes/static-pod-resources/secrets/webhook-authenticat"...)}, "authentication-token-webhook-version": []any{string("v1")}, "etcd-servers": []any{string("https://10.0.0.3:2379"), string("https://10.0.0.4:2379"), string("https://10.0.0.5:2379"), string("https://10.0.0.6:2379"), ...}, ...},
2024-10-24T13:21:52.375401971Z   	"corsAllowedOrigins": []any{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2024-10-24T13:21:52.375401971Z + 	"imagePolicyConfig": map[string]any{
2024-10-24T13:21:52.375401971Z + 		"internalRegistryHostname": string("image-registry.openshift-image-registry.svc:5000"),
2024-10-24T13:21:52.375401971Z + 	},
2024-10-24T13:21:52.375401971Z   	"servicesSubnet": string("172.30.0.0/16"),
2024-10-24T13:21:52.375401971Z   	"servingInfo":    map[string]any{"bindAddress": string("0.0.0.0:6443"), "bindNetwork": string("tcp4"), "cipherSuites": []any{string("TLS_AES_128_GCM_SHA256"), string("TLS_AES_256_GCM_SHA384"), string("TLS_CHACHA20_POLY1305_SHA256"), string("TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"), ...}, "minTLSVersion": string("VersionTLS12"), ...},
2024-10-24T13:21:52.375401971Z   }
2024-10-24T13:21:52.430352123Z E1024 13:21:52.430270       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:52.430352123Z E1024 13:21:52.430313       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:52.432839253Z E1024 13:21:52.432798       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:52.442046503Z W1024 13:21:52.441950       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.254.42:8443: connect: connection refused
2024-10-24T13:21:52.476019045Z I1024 13:21:52.475951       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:21:53.198653022Z I1024 13:21:53.198591       1 request.go:700] Waited for 1.462068956s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:21:53.444912171Z W1024 13:21:53.444839       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.254.42:8443: connect: connection refused
2024-10-24T13:21:54.199732181Z I1024 13:21:54.199662       1 request.go:700] Waited for 2.190611414s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-10-24T13:21:54.863108276Z I1024 13:21:54.863029       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-apiserver because it was missing
2024-10-24T13:21:55.399068396Z I1024 13:21:55.399017       1 request.go:700] Waited for 2.155848853s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:21:55.471600039Z I1024 13:21:55.471410       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:21:55.571525863Z W1024 13:21:55.571409       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.254.42:8443: connect: connection refused
2024-10-24T13:21:56.576673722Z W1024 13:21:56.576586       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.254.42:8443: connect: connection refused
2024-10-24T13:21:56.599000412Z I1024 13:21:56.598850       1 request.go:700] Waited for 2.141438432s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:56.669679305Z I1024 13:21:56.669617       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:21:56.670671045Z I1024 13:21:56.670648       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:21:56.830903881Z E1024 13:21:56.830804       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:56.830903881Z E1024 13:21:56.830838       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:56.833426721Z E1024 13:21:56.833339       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:57.013890488Z I1024 13:21:57.013817       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:21:57.799174138Z I1024 13:21:57.799112       1 request.go:700] Waited for 1.941496494s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-7-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:58.300369498Z I1024 13:21:58.300313       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:21:58.318815688Z I1024 13:21:58.318363       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:21:58.473855994Z I1024 13:21:58.473728       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:21:58.476189354Z I1024 13:21:58.476073       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:33Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:21:58.499533355Z I1024 13:21:58.499428       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nTargetConfigControllerDegraded: \"configmap/kube-apiserver-pod\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps kube-apiserver-pod)" to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:58.674586712Z W1024 13:21:58.674514       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.254.42:8443: connect: connection refused
2024-10-24T13:21:58.999335395Z I1024 13:21:58.999262       1 request.go:700] Waited for 1.982507446s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:21:59.678336450Z W1024 13:21:59.678238       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.254.42:8443: connect: connection refused
2024-10-24T13:21:59.999459243Z I1024 13:21:59.999404       1 request.go:700] Waited for 1.525927739s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:22:01.018488452Z E1024 13:22:01.018413       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:01.018488452Z E1024 13:22:01.018456       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:01.020250652Z E1024 13:22:01.020188       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:01.021828592Z E1024 13:22:01.021792       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:01.021828592Z E1024 13:22:01.021824       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:01.199355929Z I1024 13:22:01.199310       1 request.go:700] Waited for 2.190884084s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:01.864392954Z I1024 13:22:01.864307       1 core.go:352] ConfigMap "openshift-kube-apiserver/config" changes: {"apiVersion":"v1","data":{"config.yaml":"{\"admission\":{\"pluginConfig\":{\"PodSecurity\":{\"configuration\":{\"apiVersion\":\"pod-security.admission.config.k8s.io/v1\",\"defaults\":{\"audit\":\"restricted\",\"audit-version\":\"latest\",\"enforce\":\"restricted\",\"enforce-version\":\"latest\",\"warn\":\"restricted\",\"warn-version\":\"latest\"},\"exemptions\":{\"usernames\":[\"system:serviceaccount:openshift-infra:build-controller\"]},\"kind\":\"PodSecurityConfiguration\"}},\"network.openshift.io/ExternalIPRanger\":{\"configuration\":{\"allowIngressIP\":false,\"apiVersion\":\"network.openshift.io/v1\",\"externalIPNetworkCIDRs\":null,\"kind\":\"ExternalIPRangerAdmissionConfig\"},\"location\":\"\"},\"network.openshift.io/RestrictedEndpointsAdmission\":{\"configuration\":{\"apiVersion\":\"network.openshift.io/v1\",\"kind\":\"RestrictedEndpointsAdmissionConfig\",\"restrictedCIDRs\":[\"10.128.0.0/14\",\"172.30.0.0/16\"]}}}},\"apiServerArguments\":{\"allow-privileged\":[\"true\"],\"anonymous-auth\":[\"true\"],\"api-audiences\":[\"https://kubernetes.default.svc\"],\"audit-log-format\":[\"json\"],\"audit-log-maxbackup\":[\"10\"],\"audit-log-maxsize\":[\"200\"],\"audit-log-path\":[\"/var/log/kube-apiserver/audit.log\"],\"audit-policy-file\":[\"/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-audit-policies/policy.yaml\"],\"authentication-token-webhook-config-file\":[\"/etc/kubernetes/static-pod-resources/secrets/webhook-authenticator/kubeConfig\"],\"authentication-token-webhook-version\":[\"v1\"],\"authorization-mode\":[\"Scope\",\"SystemMasters\",\"RBAC\",\"Node\"],\"client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/client-ca/ca-bundle.crt\"],\"enable-admission-plugins\":[\"CertificateApproval\",\"CertificateSigning\",\"CertificateSubjectRestriction\",\"DefaultIngressClass\",\"DefaultStorageClass\",\"DefaultTolerationSeconds\",\"LimitRanger\",\"MutatingAdmissionWebhook\",\"NamespaceLifecycle\",\"NodeRestriction\",\"OwnerReferencesPermissionEnforcement\",\"PersistentVolumeClaimResize\",\"PodNodeSelector\",\"PodTolerationRestriction\",\"Priority\",\"ResourceQuota\",\"RuntimeClass\",\"ServiceAccount\",\"StorageObjectInUseProtection\",\"TaintNodesByCondition\",\"ValidatingAdmissionWebhook\",\"ValidatingAdmissionPolicy\",\"authorization.openshift.io/RestrictSubjectBindings\",\"authorization.openshift.io/ValidateRoleBindingRestriction\",\"config.openshift.io/DenyDeleteClusterConfiguration\",\"config.openshift.io/ValidateAPIServer\",\"config.openshift.io/ValidateAuthentication\",\"config.openshift.io/ValidateConsole\",\"config.openshift.io/ValidateFeatureGate\",\"config.openshift.io/ValidateImage\",\"config.openshift.io/ValidateOAuth\",\"config.openshift.io/ValidateProject\",\"config.openshift.io/ValidateScheduler\",\"image.openshift.io/ImagePolicy\",\"network.openshift.io/ExternalIPRanger\",\"network.openshift.io/RestrictedEndpointsAdmission\",\"quota.openshift.io/ClusterResourceQuota\",\"quota.openshift.io/ValidateClusterResourceQuota\",\"route.openshift.io/IngressAdmission\",\"scheduling.openshift.io/OriginPodNodeEnvironment\",\"security.openshift.io/DefaultSecurityContextConstraints\",\"security.openshift.io/SCCExecRestrictions\",\"security.openshift.io/SecurityContextConstraint\",\"security.openshift.io/ValidateSecurityContextConstraints\",\"storage.openshift.io/CSIInlineVolumeSecurity\"],\"enable-aggregator-routing\":[\"true\"],\"enable-logs-handler\":[\"false\"],\"endpoint-reconciler-type\":[\"lease\"],\"etcd-cafile\":[\"/etc/kubernetes/static-pod-resources/configmaps/etcd-serving-ca/ca-bundle.crt\"],\"etcd-certfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.crt\"],\"etcd-healthcheck-timeout\":[\"9s\"],\"etcd-keyfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.key\"],\"etcd-prefix\":[\"kubernetes.io\"],\"etcd-readycheck-timeout\":[\"9s\"],\"etcd-servers\":[\"https://10.0.0.3:2379\",\"https://10.0.0.4:2379\",\"https://10.0.0.5:2379\",\"https://10.0.0.6:2379\",\"https://localhost:2379\"],\"event-ttl\":[\"3h\"],\"feature-gates\":[\"AWSEFSDriverVolumeMetrics=true\",\"AdminNetworkPolicy=true\",\"AlibabaPlatform=true\",\"AzureWorkloadIdentity=true\",\"BareMetalLoadBalancer=true\",\"BuildCSIVolumes=true\",\"ChunkSizeMiB=true\",\"CloudDualStackNodeIPs=true\",\"DisableKubeletCloudCredentialProviders=true\",\"GCPLabelsTags=true\",\"HardwareSpeed=true\",\"IngressControllerLBSubnetsAWS=true\",\"KMSv1=true\",\"ManagedBootImages=true\",\"MetricsServer=true\",\"MultiArchInstallAWS=true\",\"MultiArchInstallGCP=true\",\"NetworkDiagnosticsConfig=true\",\"NetworkLiveMigration=true\",\"NodeDisruptionPolicy=true\",\"OpenShiftPodSecurityAdmission=true\",\"PrivateHostedZoneAWS=true\",\"SetEIPForNLBIngressController=true\",\"VSphereControlPlaneMachineSet=true\",\"VSphereDriverConfiguration=true\",\"VSphereStaticIPs=true\",\"ValidatingAdmissionPolicy=true\",\"AWSClusterHostedDNS=false\",\"AdditionalRoutingCapabilities=false\",\"AutomatedEtcdBackup=false\",\"BootcNodeManagement=false\",\"CSIDriverSharedResource=false\",\"ClusterAPIInstall=false\",\"ClusterAPIInstallIBMCloud=false\",\"ClusterMonitoringConfig=false\",\"DNSNameResolver=false\",\"DynamicResourceAllocation=false\",\"EtcdBackendQuota=false\",\"EventedPLEG=false\",\"Example=false\",\"ExternalOIDC=false\",\"GCPClusterHostedDNS=false\",\"GatewayAPI=false\",\"ImageStreamImportMode=false\",\"IngressControllerDynamicConfigurationManager=false\",\"InsightsConfig=false\",\"InsightsConfigAPI=false\",\"InsightsOnDemandDataGather=false\",\"InsightsRuntimeExtractor=false\",\"MachineAPIMigration=false\",\"MachineAPIOperatorDisableMachineHealthCheckController=false\",\"MachineAPIProviderOpenStack=false\",\"MachineConfigNodes=false\",\"ManagedBootImagesAWS=false\",\"MaxUnavailableStatefulSet=false\",\"MetricsCollectionProfiles=false\",\"MixedCPUsAllocation=false\",\"MultiArchInstallAzure=false\",\"NetworkSegmentation=false\",\"NewOLM=false\",\"NodeSwap=false\",\"OVNObservability=false\",\"OnClusterBuild=false\",\"PersistentIPsForVirtualization=false\",\"PinnedImages=false\",\"PlatformOperators=false\",\"ProcMountType=false\",\"RouteAdvertisements=false\",\"RouteExternalCertificate=false\",\"ServiceAccountTokenNodeBinding=false\",\"SignatureStores=false\",\"SigstoreImageVerification=false\",\"TranslateStreamCloseWebsocketRequests=false\",\"UpgradeStatus=false\",\"UserNamespacesPodSecurityStandards=false\",\"UserNamespacesSupport=false\",\"VSphereMultiNetworks=false\",\"VSphereMultiVCenters=false\",\"VolumeGroupSnapshot=false\"],\"goaway-chance\":[\"0\"],\"http2-max-streams-per-connection\":[\"2000\"],\"kubelet-certificate-authority\":[\"/etc/kubernetes/static-pod-resources/configmaps/kubelet-serving-ca/ca-bundle.crt\"],\"kubelet-client-certificate\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.crt\"],\"kubelet-client-key\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.key\"],\"kubelet-preferred-address-types\":[\"InternalIP\"],\"kubelet-read-only-port\":[\"0\"],\"kubernetes-service-node-port\":[\"0\"],\"max-mutating-requests-inflight\":[\"1000\"],\"max-requests-inflight\":[\"3000\"],\"min-request-timeout\":[\"3600\"],\"proxy-client-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.crt\"],\"proxy-client-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.key\"],\"requestheader-allowed-names\":[\"kube-apiserver-proxy\",\"system:kube-apiserver-proxy\",\"system:openshift-aggregator\"],\"requestheader-client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/aggregator-client-ca/ca-bundle.crt\"],\"requestheader-extra-headers-prefix\":[\"X-Remote-Extra-\"],\"requestheader-group-headers\":[\"X-Remote-Group\"],\"requestheader-username-headers\":[\"X-Remote-User\"],\"runtime-config\":[\"admissionregistration.k8s.io/v1beta1=true\"],\"send-retry-after-while-not-ready-once\":[\"false\"],\"service-account-issuer\":[\"https://kubernetes.default.svc\"],\"service-account-jwks-uri\":[\"https://api.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX:6443/openid/v1/jwks\"],\"service-account-lookup\":[\"true\"],\"service-account-signing-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/bound-service-account-signing-key/service-account.key\"],\"service-node-port-range\":[\"30000-32767\"],\"shutdown-delay-duration\":[\"70s\"],\"shutdown-send-retry-after\":[\"true\"],\"storage-backend\":[\"etcd3\"],\"storage-media-type\":[\"application/vnd.kubernetes.protobuf\"],\"strict-transport-security-directives\":[\"max-age=31536000,includeSubDomains,preload\"],\"tls-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\"],\"tls-private-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"]},\"apiVersion\":\"kubecontrolplane.config.openshift.io/v1\",\"authConfig\":{\"oauthMetadataFile\":\"\"},\"consolePublicURL\":\"\",\"corsAllowedOrigins\":[\"//127\\\\.0\\\\.0\\\\.1(:|$)\",\"//localhost(:|$)\"],\"imagePolicyConfig\":{\"internalRegistryHostname\":\"image-registry.openshift-image-registry.svc:5000\"},\"kind\":\"KubeAPIServerConfig\",\"projectConfig\":{\"defaultNodeSelector\":\"\"},\"serviceAccountPublicKeyFiles\":[\"/etc/kubernetes/static-pod-resources/configmaps/sa-token-signing-certs\",\"/etc/kubernetes/static-pod-resources/configmaps/bound-sa-token-signing-certs\"],\"servicesSubnet\":\"172.30.0.0/16\",\"servingInfo\":{\"bindAddress\":\"0.0.0.0:6443\",\"bindNetwork\":\"tcp4\",\"cipherSuites\":[\"TLS_AES_128_GCM_SHA256\",\"TLS_AES_256_GCM_SHA384\",\"TLS_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"],\"minTLSVersion\":\"VersionTLS12\",\"namedCertificates\":[{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.key\"}]}}"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:22:01.864893394Z I1024 13:22:01.864515       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/config -n openshift-kube-apiserver:
2024-10-24T13:22:01.864893394Z cause by changes in data.config.yaml
2024-10-24T13:22:01.870198154Z I1024 13:22:01.870148       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 8 triggered by "required configmap/config has changed"
2024-10-24T13:22:02.399068974Z I1024 13:22:02.399001       1 request.go:700] Waited for 1.156119174s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:02.986317877Z I1024 13:22:02.986261       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:22:03.599231531Z I1024 13:22:03.599126       1 request.go:700] Waited for 1.585943391s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:22:03.629218712Z I1024 13:22:03.629164       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:22:03.717951145Z I1024 13:22:03.717895       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:22:03.803431139Z I1024 13:22:03.803355       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:22:04.213427444Z E1024 13:22:04.213364       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:04.215927794Z E1024 13:22:04.214979       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:04.215927794Z E1024 13:22:04.215010       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:04.531787557Z I1024 13:22:04.531671       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-10-24T13:22:04.531787557Z   	"admission":          map[string]any{"pluginConfig": map[string]any{"PodSecurity": map[string]any{"configuration": map[string]any{"defaults": map[string]any{"audit": string("restricted"), "audit-version": string("latest"), "enforce": string("restricted"), "enforce-version": string("latest"), ...}}}, "network.openshift.io/ExternalIPRanger": map[string]any{"configuration": map[string]any{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]any{"configuration": map[string]any{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []any{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2024-10-24T13:22:04.531787557Z   	"apiServerArguments": map[string]any{"api-audiences": []any{string("https://kubernetes.default.svc")}, "authentication-token-webhook-config-file": []any{string("/etc/kubernetes/static-pod-resources/secrets/webhook-authenticat"...)}, "authentication-token-webhook-version": []any{string("v1")}, "etcd-servers": []any{string("https://10.0.0.3:2379"), string("https://10.0.0.4:2379"), string("https://10.0.0.5:2379"), string("https://10.0.0.6:2379"), ...}, ...},
2024-10-24T13:22:04.531787557Z + 	"authConfig": map[string]any{
2024-10-24T13:22:04.531787557Z + 		"oauthMetadataFile": string("/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/oauthMetadata"),
2024-10-24T13:22:04.531787557Z + 	},
2024-10-24T13:22:04.531787557Z   	"corsAllowedOrigins": []any{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2024-10-24T13:22:04.531787557Z   	"imagePolicyConfig":  map[string]any{"internalRegistryHostname": string("image-registry.openshift-image-registry.svc:5000")},
2024-10-24T13:22:04.531787557Z   	... // 2 identical entries
2024-10-24T13:22:04.531787557Z   }
2024-10-24T13:22:04.569395798Z I1024 13:22:04.569323       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:22:04.572678338Z I1024 13:22:04.572432       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-10-24T13:22:04.572678338Z   	"admission":          map[string]any{"pluginConfig": map[string]any{"PodSecurity": map[string]any{"configuration": map[string]any{"defaults": map[string]any{"audit": string("restricted"), "audit-version": string("latest"), "enforce": string("restricted"), "enforce-version": string("latest"), ...}}}, "network.openshift.io/ExternalIPRanger": map[string]any{"configuration": map[string]any{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]any{"configuration": map[string]any{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []any{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2024-10-24T13:22:04.572678338Z   	"apiServerArguments": map[string]any{"api-audiences": []any{string("https://kubernetes.default.svc")}, "authentication-token-webhook-config-file": []any{string("/etc/kubernetes/static-pod-resources/secrets/webhook-authenticat"...)}, "authentication-token-webhook-version": []any{string("v1")}, "etcd-servers": []any{string("https://10.0.0.3:2379"), string("https://10.0.0.4:2379"), string("https://10.0.0.5:2379"), string("https://10.0.0.6:2379"), ...}, ...},
2024-10-24T13:22:04.572678338Z + 	"authConfig": map[string]any{
2024-10-24T13:22:04.572678338Z + 		"oauthMetadataFile": string("/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/oauthMetadata"),
2024-10-24T13:22:04.572678338Z + 	},
2024-10-24T13:22:04.572678338Z   	"corsAllowedOrigins": []any{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2024-10-24T13:22:04.572678338Z   	"imagePolicyConfig":  map[string]any{"internalRegistryHostname": string("image-registry.openshift-image-registry.svc:5000")},
2024-10-24T13:22:04.572678338Z   	... // 2 identical entries
2024-10-24T13:22:04.572678338Z   }
2024-10-24T13:22:04.799298986Z I1024 13:22:04.799235       1 request.go:700] Waited for 1.81322574s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:22:05.413946620Z I1024 13:22:05.413165       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-8 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:05.998973202Z I1024 13:22:05.998922       1 request.go:700] Waited for 1.981664575s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T13:22:06.407289678Z I1024 13:22:06.407236       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:22:07.198770429Z I1024 13:22:07.198697       1 request.go:700] Waited for 1.992526006s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-10-24T13:22:07.414849097Z I1024 13:22:07.414786       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-8 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:08.217350587Z E1024 13:22:08.217301       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:08.399306834Z I1024 13:22:08.399218       1 request.go:700] Waited for 1.989568226s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:22:08.610535833Z I1024 13:22:08.610386       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/oauth-metadata -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:09.599202470Z I1024 13:22:09.599150       1 request.go:700] Waited for 2.184284963s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T13:22:09.631123822Z I1024 13:22:09.630957       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-8 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:10.600416619Z I1024 13:22:10.599404       1 request.go:700] Waited for 2.059432399s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T13:22:11.612634777Z I1024 13:22:11.612555       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/oauth-metadata-8 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:11.798573784Z I1024 13:22:11.798509       1 request.go:700] Waited for 1.903071862s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:12.006329713Z E1024 13:22:12.006283       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:12.006415072Z E1024 13:22:12.006390       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:12.008238003Z E1024 13:22:12.008194       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:12.799357793Z I1024 13:22:12.799277       1 request.go:700] Waited for 1.990506246s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-7-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:13.323505693Z I1024 13:22:13.322737       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:22:13.610930174Z I1024 13:22:13.610864       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-8 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:13.999546229Z I1024 13:22:13.999442       1 request.go:700] Waited for 1.989532706s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:22:15.198684595Z I1024 13:22:15.198629       1 request.go:700] Waited for 1.785869169s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-10-24T13:22:15.409019673Z I1024 13:22:15.408939       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-8 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:15.606410170Z E1024 13:22:15.606340       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:15.606410170Z E1024 13:22:15.606367       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:15.608413491Z E1024 13:22:15.608363       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:15.609907310Z E1024 13:22:15.609861       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:16.005071466Z I1024 13:22:16.005003       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:22:16.199067913Z I1024 13:22:16.199011       1 request.go:700] Waited for 1.588955681s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-7-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:22:16.814540347Z I1024 13:22:16.814435       1 core.go:352] ConfigMap "openshift-kube-apiserver/config" changes: {"apiVersion":"v1","data":{"config.yaml":"{\"admission\":{\"pluginConfig\":{\"PodSecurity\":{\"configuration\":{\"apiVersion\":\"pod-security.admission.config.k8s.io/v1\",\"defaults\":{\"audit\":\"restricted\",\"audit-version\":\"latest\",\"enforce\":\"restricted\",\"enforce-version\":\"latest\",\"warn\":\"restricted\",\"warn-version\":\"latest\"},\"exemptions\":{\"usernames\":[\"system:serviceaccount:openshift-infra:build-controller\"]},\"kind\":\"PodSecurityConfiguration\"}},\"network.openshift.io/ExternalIPRanger\":{\"configuration\":{\"allowIngressIP\":false,\"apiVersion\":\"network.openshift.io/v1\",\"externalIPNetworkCIDRs\":null,\"kind\":\"ExternalIPRangerAdmissionConfig\"},\"location\":\"\"},\"network.openshift.io/RestrictedEndpointsAdmission\":{\"configuration\":{\"apiVersion\":\"network.openshift.io/v1\",\"kind\":\"RestrictedEndpointsAdmissionConfig\",\"restrictedCIDRs\":[\"10.128.0.0/14\",\"172.30.0.0/16\"]}}}},\"apiServerArguments\":{\"allow-privileged\":[\"true\"],\"anonymous-auth\":[\"true\"],\"api-audiences\":[\"https://kubernetes.default.svc\"],\"audit-log-format\":[\"json\"],\"audit-log-maxbackup\":[\"10\"],\"audit-log-maxsize\":[\"200\"],\"audit-log-path\":[\"/var/log/kube-apiserver/audit.log\"],\"audit-policy-file\":[\"/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-audit-policies/policy.yaml\"],\"authentication-token-webhook-config-file\":[\"/etc/kubernetes/static-pod-resources/secrets/webhook-authenticator/kubeConfig\"],\"authentication-token-webhook-version\":[\"v1\"],\"authorization-mode\":[\"Scope\",\"SystemMasters\",\"RBAC\",\"Node\"],\"client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/client-ca/ca-bundle.crt\"],\"enable-admission-plugins\":[\"CertificateApproval\",\"CertificateSigning\",\"CertificateSubjectRestriction\",\"DefaultIngressClass\",\"DefaultStorageClass\",\"DefaultTolerationSeconds\",\"LimitRanger\",\"MutatingAdmissionWebhook\",\"NamespaceLifecycle\",\"NodeRestriction\",\"OwnerReferencesPermissionEnforcement\",\"PersistentVolumeClaimResize\",\"PodNodeSelector\",\"PodTolerationRestriction\",\"Priority\",\"ResourceQuota\",\"RuntimeClass\",\"ServiceAccount\",\"StorageObjectInUseProtection\",\"TaintNodesByCondition\",\"ValidatingAdmissionWebhook\",\"ValidatingAdmissionPolicy\",\"authorization.openshift.io/RestrictSubjectBindings\",\"authorization.openshift.io/ValidateRoleBindingRestriction\",\"config.openshift.io/DenyDeleteClusterConfiguration\",\"config.openshift.io/ValidateAPIServer\",\"config.openshift.io/ValidateAuthentication\",\"config.openshift.io/ValidateConsole\",\"config.openshift.io/ValidateFeatureGate\",\"config.openshift.io/ValidateImage\",\"config.openshift.io/ValidateOAuth\",\"config.openshift.io/ValidateProject\",\"config.openshift.io/ValidateScheduler\",\"image.openshift.io/ImagePolicy\",\"network.openshift.io/ExternalIPRanger\",\"network.openshift.io/RestrictedEndpointsAdmission\",\"quota.openshift.io/ClusterResourceQuota\",\"quota.openshift.io/ValidateClusterResourceQuota\",\"route.openshift.io/IngressAdmission\",\"scheduling.openshift.io/OriginPodNodeEnvironment\",\"security.openshift.io/DefaultSecurityContextConstraints\",\"security.openshift.io/SCCExecRestrictions\",\"security.openshift.io/SecurityContextConstraint\",\"security.openshift.io/ValidateSecurityContextConstraints\",\"storage.openshift.io/CSIInlineVolumeSecurity\"],\"enable-aggregator-routing\":[\"true\"],\"enable-logs-handler\":[\"false\"],\"endpoint-reconciler-type\":[\"lease\"],\"etcd-cafile\":[\"/etc/kubernetes/static-pod-resources/configmaps/etcd-serving-ca/ca-bundle.crt\"],\"etcd-certfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.crt\"],\"etcd-healthcheck-timeout\":[\"9s\"],\"etcd-keyfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.key\"],\"etcd-prefix\":[\"kubernetes.io\"],\"etcd-readycheck-timeout\":[\"9s\"],\"etcd-servers\":[\"https://10.0.0.3:2379\",\"https://10.0.0.4:2379\",\"https://10.0.0.5:2379\",\"https://10.0.0.6:2379\",\"https://localhost:2379\"],\"event-ttl\":[\"3h\"],\"feature-gates\":[\"AWSEFSDriverVolumeMetrics=true\",\"AdminNetworkPolicy=true\",\"AlibabaPlatform=true\",\"AzureWorkloadIdentity=true\",\"BareMetalLoadBalancer=true\",\"BuildCSIVolumes=true\",\"ChunkSizeMiB=true\",\"CloudDualStackNodeIPs=true\",\"DisableKubeletCloudCredentialProviders=true\",\"GCPLabelsTags=true\",\"HardwareSpeed=true\",\"IngressControllerLBSubnetsAWS=true\",\"KMSv1=true\",\"ManagedBootImages=true\",\"MetricsServer=true\",\"MultiArchInstallAWS=true\",\"MultiArchInstallGCP=true\",\"NetworkDiagnosticsConfig=true\",\"NetworkLiveMigration=true\",\"NodeDisruptionPolicy=true\",\"OpenShiftPodSecurityAdmission=true\",\"PrivateHostedZoneAWS=true\",\"SetEIPForNLBIngressController=true\",\"VSphereControlPlaneMachineSet=true\",\"VSphereDriverConfiguration=true\",\"VSphereStaticIPs=true\",\"ValidatingAdmissionPolicy=true\",\"AWSClusterHostedDNS=false\",\"AdditionalRoutingCapabilities=false\",\"AutomatedEtcdBackup=false\",\"BootcNodeManagement=false\",\"CSIDriverSharedResource=false\",\"ClusterAPIInstall=false\",\"ClusterAPIInstallIBMCloud=false\",\"ClusterMonitoringConfig=false\",\"DNSNameResolver=false\",\"DynamicResourceAllocation=false\",\"EtcdBackendQuota=false\",\"EventedPLEG=false\",\"Example=false\",\"ExternalOIDC=false\",\"GCPClusterHostedDNS=false\",\"GatewayAPI=false\",\"ImageStreamImportMode=false\",\"IngressControllerDynamicConfigurationManager=false\",\"InsightsConfig=false\",\"InsightsConfigAPI=false\",\"InsightsOnDemandDataGather=false\",\"InsightsRuntimeExtractor=false\",\"MachineAPIMigration=false\",\"MachineAPIOperatorDisableMachineHealthCheckController=false\",\"MachineAPIProviderOpenStack=false\",\"MachineConfigNodes=false\",\"ManagedBootImagesAWS=false\",\"MaxUnavailableStatefulSet=false\",\"MetricsCollectionProfiles=false\",\"MixedCPUsAllocation=false\",\"MultiArchInstallAzure=false\",\"NetworkSegmentation=false\",\"NewOLM=false\",\"NodeSwap=false\",\"OVNObservability=false\",\"OnClusterBuild=false\",\"PersistentIPsForVirtualization=false\",\"PinnedImages=false\",\"PlatformOperators=false\",\"ProcMountType=false\",\"RouteAdvertisements=false\",\"RouteExternalCertificate=false\",\"ServiceAccountTokenNodeBinding=false\",\"SignatureStores=false\",\"SigstoreImageVerification=false\",\"TranslateStreamCloseWebsocketRequests=false\",\"UpgradeStatus=false\",\"UserNamespacesPodSecurityStandards=false\",\"UserNamespacesSupport=false\",\"VSphereMultiNetworks=false\",\"VSphereMultiVCenters=false\",\"VolumeGroupSnapshot=false\"],\"goaway-chance\":[\"0\"],\"http2-max-streams-per-connection\":[\"2000\"],\"kubelet-certificate-authority\":[\"/etc/kubernetes/static-pod-resources/configmaps/kubelet-serving-ca/ca-bundle.crt\"],\"kubelet-client-certificate\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.crt\"],\"kubelet-client-key\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.key\"],\"kubelet-preferred-address-types\":[\"InternalIP\"],\"kubelet-read-only-port\":[\"0\"],\"kubernetes-service-node-port\":[\"0\"],\"max-mutating-requests-inflight\":[\"1000\"],\"max-requests-inflight\":[\"3000\"],\"min-request-timeout\":[\"3600\"],\"proxy-client-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.crt\"],\"proxy-client-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.key\"],\"requestheader-allowed-names\":[\"kube-apiserver-proxy\",\"system:kube-apiserver-proxy\",\"system:openshift-aggregator\"],\"requestheader-client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/aggregator-client-ca/ca-bundle.crt\"],\"requestheader-extra-headers-prefix\":[\"X-Remote-Extra-\"],\"requestheader-group-headers\":[\"X-Remote-Group\"],\"requestheader-username-headers\":[\"X-Remote-User\"],\"runtime-config\":[\"admissionregistration.k8s.io/v1beta1=true\"],\"send-retry-after-while-not-ready-once\":[\"false\"],\"service-account-issuer\":[\"https://kubernetes.default.svc\"],\"service-account-jwks-uri\":[\"https://api.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX:6443/openid/v1/jwks\"],\"service-account-lookup\":[\"true\"],\"service-account-signing-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/bound-service-account-signing-key/service-account.key\"],\"service-node-port-range\":[\"30000-32767\"],\"shutdown-delay-duration\":[\"70s\"],\"shutdown-send-retry-after\":[\"true\"],\"storage-backend\":[\"etcd3\"],\"storage-media-type\":[\"application/vnd.kubernetes.protobuf\"],\"strict-transport-security-directives\":[\"max-age=31536000,includeSubDomains,preload\"],\"tls-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\"],\"tls-private-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"]},\"apiVersion\":\"kubecontrolplane.config.openshift.io/v1\",\"authConfig\":{\"oauthMetadataFile\":\"/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/oauthMetadata\"},\"consolePublicURL\":\"\",\"corsAllowedOrigins\":[\"//127\\\\.0\\\\.0\\\\.1(:|$)\",\"//localhost(:|$)\"],\"imagePolicyConfig\":{\"internalRegistryHostname\":\"image-registry.openshift-image-registry.svc:5000\"},\"kind\":\"KubeAPIServerConfig\",\"projectConfig\":{\"defaultNodeSelector\":\"\"},\"serviceAccountPublicKeyFiles\":[\"/etc/kubernetes/static-pod-resources/configmaps/sa-token-signing-certs\",\"/etc/kubernetes/static-pod-resources/configmaps/bound-sa-token-signing-certs\"],\"servicesSubnet\":\"172.30.0.0/16\",\"servingInfo\":{\"bindAddress\":\"0.0.0.0:6443\",\"bindNetwork\":\"tcp4\",\"cipherSuites\":[\"TLS_AES_128_GCM_SHA256\",\"TLS_AES_256_GCM_SHA384\",\"TLS_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"],\"minTLSVersion\":\"VersionTLS12\",\"namedCertificates\":[{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.key\"}]}}"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:22:16.817314016Z I1024 13:22:16.817170       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/config -n openshift-kube-apiserver:
2024-10-24T13:22:16.817314016Z cause by changes in data.config.yaml
2024-10-24T13:22:17.014301314Z I1024 13:22:17.014218       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-8 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:17.199365681Z I1024 13:22:17.199290       1 request.go:700] Waited for 1.58908336s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:22:18.399213977Z I1024 13:22:18.399162       1 request.go:700] Waited for 1.57861716s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-10-24T13:22:18.609484115Z I1024 13:22:18.609418       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-8 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:18.805656622Z E1024 13:22:18.805592       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:18.809990923Z E1024 13:22:18.809822       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:18.815371793Z E1024 13:22:18.815317       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:19.598712063Z I1024 13:22:19.598662       1 request.go:700] Waited for 1.584679041s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:22:20.208832776Z I1024 13:22:20.208738       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-8 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:20.599045601Z I1024 13:22:20.598995       1 request.go:700] Waited for 1.530982428s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:22:21.799008097Z I1024 13:22:21.798949       1 request.go:700] Waited for 1.590244251s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T13:22:21.824521468Z I1024 13:22:21.824406       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-8 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:22.005479055Z E1024 13:22:22.005402       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:22.007117125Z E1024 13:22:22.007045       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:22.799249096Z I1024 13:22:22.799174       1 request.go:700] Waited for 1.583009001s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:22:23.413677289Z I1024 13:22:23.413591       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-8 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:23.799323204Z I1024 13:22:23.799258       1 request.go:700] Waited for 1.592912291s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T13:22:24.010799692Z I1024 13:22:24.010713       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:22:25.000653060Z I1024 13:22:25.000571       1 request.go:700] Waited for 1.586789591s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-8
2024-10-24T13:22:25.209118988Z E1024 13:22:25.209065       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:25.209210488Z E1024 13:22:25.209194       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:25.211557618Z E1024 13:22:25.211352       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:26.199354936Z I1024 13:22:26.199272       1 request.go:700] Waited for 1.590679741s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:22:26.619736252Z I1024 13:22:26.619679       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-8 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:27.398779062Z I1024 13:22:27.398676       1 request.go:700] Waited for 1.592420061s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-7-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:28.011263575Z I1024 13:22:28.011180       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-8 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:28.205411903Z E1024 13:22:28.205327       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:28.205411903Z E1024 13:22:28.205373       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:28.207519113Z E1024 13:22:28.207473       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:28.292121306Z I1024 13:22:28.292016       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:22:28.599010888Z I1024 13:22:28.598954       1 request.go:700] Waited for 1.390655473s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:29.217418542Z I1024 13:22:29.217337       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-8 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:29.599177716Z I1024 13:22:29.599079       1 request.go:700] Waited for 1.124912423s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:22:30.208745290Z I1024 13:22:30.208679       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 8 triggered by "required configmap/config has changed"
2024-10-24T13:22:30.210926539Z W1024 13:22:30.210859       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:22:30.210926539Z W1024 13:22:30.210883       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:22:30.244121871Z W1024 13:22:30.244041       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:22:30.244121871Z W1024 13:22:30.244102       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:22:30.245386561Z I1024 13:22:30.245343       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:22:30.272906562Z I1024 13:22:30.272856       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 9 triggered by "required configmap/config has changed"
2024-10-24T13:22:30.813389222Z I1024 13:22:30.813322       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:22:31.398873795Z I1024 13:22:31.398722       1 request.go:700] Waited for 1.188302235s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-7-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:22:32.399007653Z I1024 13:22:32.398935       1 request.go:700] Waited for 1.982817856s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:22:33.599019909Z I1024 13:22:33.598951       1 request.go:700] Waited for 1.982657826s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:33.812423638Z I1024 13:22:33.812341       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-9 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:34.010476715Z E1024 13:22:34.010402       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:34.010476715Z E1024 13:22:34.010445       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:34.012655655Z E1024 13:22:34.012603       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:34.021659395Z I1024 13:22:34.021350       1 termination_observer.go:236] Observed event "TerminationPreShutdownHooksFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0" (last termination at 2024-10-24 13:13:16 +0000 UTC) at 2024-10-24 13:22:34 +0000 UTC
2024-10-24T13:22:34.803176375Z I1024 13:22:34.803122       1 request.go:700] Waited for 1.789446338s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:22:35.621472967Z I1024 13:22:35.621408       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-9 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:35.998496091Z I1024 13:22:35.998434       1 request.go:700] Waited for 1.781811298s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:22:36.999370930Z I1024 13:22:36.999310       1 request.go:700] Waited for 2.187314703s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2024-10-24T13:22:37.819418551Z I1024 13:22:37.815483       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-9 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:38.007538638Z E1024 13:22:38.007447       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:38.007538638Z E1024 13:22:38.007479       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:38.009414968Z E1024 13:22:38.009315       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:38.198929765Z I1024 13:22:38.198819       1 request.go:700] Waited for 2.180892543s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:22:39.007326966Z I1024 13:22:39.007281       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:22:39.007326966Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:22:39.007326966Z  CurrentRevision: (int32) 0,
2024-10-24T13:22:39.007326966Z  TargetRevision: (int32) 8,
2024-10-24T13:22:39.007326966Z  LastFailedRevision: (int32) 0,
2024-10-24T13:22:39.007326966Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:22:39.007326966Z  LastFailedReason: (string) "",
2024-10-24T13:22:39.007326966Z  LastFailedCount: (int) 0,
2024-10-24T13:22:39.007326966Z  LastFallbackCount: (int) 0,
2024-10-24T13:22:39.007326966Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:22:39.007326966Z }
2024-10-24T13:22:39.007326966Z  because new revision pending
2024-10-24T13:22:39.009511567Z W1024 13:22:39.009461       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:22:39.009511567Z W1024 13:22:39.009487       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:22:39.009511567Z W1024 13:22:39.009494       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:22:39.009511567Z W1024 13:22:39.009500       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:22:39.009511567Z W1024 13:22:39.009506       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:22:39.051620818Z I1024 13:22:39.051559       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:22:39.052718848Z I1024 13:22:39.052670       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:33Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 8","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:22:39.069554949Z I1024 13:22:39.069473       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 7" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 8",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 7" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 8"
2024-10-24T13:22:39.104001220Z I1024 13:22:39.103941       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:22:39.199151144Z I1024 13:22:39.199080       1 request.go:700] Waited for 1.83552582s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-10-24T13:22:39.425133953Z I1024 13:22:39.425060       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-8-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:40.010650065Z I1024 13:22:40.010590       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/oauth-metadata-9 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:40.398743760Z I1024 13:22:40.398676       1 request.go:700] Waited for 2.180311714s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:22:41.599370856Z I1024 13:22:41.599310       1 request.go:700] Waited for 2.174338284s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:22:42.409489737Z I1024 13:22:42.409401       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-9 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:42.608098975Z E1024 13:22:42.608034       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:42.608098975Z E1024 13:22:42.608059       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:42.609836584Z E1024 13:22:42.609809       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:42.799005122Z I1024 13:22:42.798951       1 request.go:700] Waited for 2.383571732s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:22:43.998778088Z I1024 13:22:43.998657       1 request.go:700] Waited for 2.368316141s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:22:44.212321946Z I1024 13:22:44.212259       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-8-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:44.809292159Z I1024 13:22:44.809218       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-9 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:44.998806126Z I1024 13:22:44.998696       1 request.go:700] Waited for 2.387305262s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:22:45.998842075Z I1024 13:22:45.998768       1 request.go:700] Waited for 2.189880563s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:22:47.199264840Z I1024 13:22:47.199192       1 request.go:700] Waited for 2.389953441s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T13:22:47.215733321Z I1024 13:22:47.215656       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-9 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:47.408286038Z E1024 13:22:47.408209       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:47.408286038Z E1024 13:22:47.408247       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:47.410123639Z E1024 13:22:47.410075       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:48.007406341Z I1024 13:22:48.007336       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:22:48.007406341Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:22:48.007406341Z  CurrentRevision: (int32) 0,
2024-10-24T13:22:48.007406341Z  TargetRevision: (int32) 8,
2024-10-24T13:22:48.007406341Z  LastFailedRevision: (int32) 0,
2024-10-24T13:22:48.007406341Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:22:48.007406341Z  LastFailedReason: (string) "",
2024-10-24T13:22:48.007406341Z  LastFailedCount: (int) 0,
2024-10-24T13:22:48.007406341Z  LastFallbackCount: (int) 0,
2024-10-24T13:22:48.007406341Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:22:48.007406341Z }
2024-10-24T13:22:48.007406341Z  because new revision pending
2024-10-24T13:22:48.199347758Z I1024 13:22:48.199284       1 request.go:700] Waited for 2.392764082s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-10-24T13:22:48.813525762Z I1024 13:22:48.813460       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-8-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:49.199481617Z I1024 13:22:49.199399       1 request.go:700] Waited for 2.393720352s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:49.412226865Z I1024 13:22:49.412161       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-9 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:50.398793863Z I1024 13:22:50.398704       1 request.go:700] Waited for 2.182269454s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:22:51.399059481Z I1024 13:22:51.398994       1 request.go:700] Waited for 2.190482014s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:22:51.611187599Z I1024 13:22:51.611108       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-9 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:51.813887107Z E1024 13:22:51.813820       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:51.813887107Z E1024 13:22:51.813848       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:51.816097617Z E1024 13:22:51.816047       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:52.399187090Z I1024 13:22:52.399125       1 request.go:700] Waited for 2.191186095s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:53.599326676Z I1024 13:22:53.599256       1 request.go:700] Waited for 2.191754864s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:53.809088184Z I1024 13:22:53.809017       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-9 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:54.599402904Z I1024 13:22:54.599334       1 request.go:700] Waited for 2.192348284s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:55.798420080Z I1024 13:22:55.798346       1 request.go:700] Waited for 2.190629964s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:56.011908808Z I1024 13:22:56.011849       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-9 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:56.208189795Z E1024 13:22:56.208118       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:56.208189795Z E1024 13:22:56.208145       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:56.209870125Z E1024 13:22:56.209833       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:56.998546244Z I1024 13:22:56.998491       1 request.go:700] Waited for 2.188389912s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-10-24T13:22:57.999283737Z I1024 13:22:57.999212       1 request.go:700] Waited for 1.787611801s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:22:58.292634584Z I1024 13:22:58.290538       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:22:58.628213911Z I1024 13:22:58.628140       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-8-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:58.999320780Z I1024 13:22:58.999260       1 request.go:700] Waited for 1.785580201s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:22:59.623684984Z I1024 13:22:59.623592       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-9 -n openshift-kube-apiserver because it was missing
2024-10-24T13:22:59.758636728Z I1024 13:22:59.758559       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:22:59.807676079Z E1024 13:22:59.807628       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:59.807676079Z E1024 13:22:59.807652       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:59.809584679Z E1024 13:22:59.809513       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:59.811207639Z E1024 13:22:59.811154       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:59.811207639Z E1024 13:22:59.811191       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:00.198896538Z I1024 13:23:00.198833       1 request.go:700] Waited for 1.70815792s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:23:00.407249053Z I1024 13:23:00.407169       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 8, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:23:01.398977245Z I1024 13:23:01.398917       1 request.go:700] Waited for 1.991309516s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:01.612205270Z I1024 13:23:01.612059       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-9 -n openshift-kube-apiserver because it was missing
2024-10-24T13:23:02.399192519Z I1024 13:23:02.399136       1 request.go:700] Waited for 1.989669736s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:23:03.399444852Z I1024 13:23:03.399381       1 request.go:700] Waited for 1.983818356s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:23:03.613218367Z I1024 13:23:03.612173       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-9 -n openshift-kube-apiserver because it was missing
2024-10-24T13:23:03.810048251Z E1024 13:23:03.809985       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:04.599301329Z I1024 13:23:04.599234       1 request.go:700] Waited for 1.584905156s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:23:05.211048623Z I1024 13:23:05.210972       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 9 triggered by "required configmap/config has changed"
2024-10-24T13:23:05.212610244Z W1024 13:23:05.212552       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:23:05.212610244Z W1024 13:23:05.212576       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:23:05.246723005Z W1024 13:23:05.246659       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:23:05.246723005Z W1024 13:23:05.246691       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:23:05.251535184Z I1024 13:23:05.251482       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:23:05.799200097Z I1024 13:23:05.799110       1 request.go:700] Waited for 1.782005311s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:23:06.799193030Z I1024 13:23:06.799129       1 request.go:700] Waited for 1.792768171s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:07.504473787Z E1024 13:23:07.504397       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:07.504473787Z E1024 13:23:07.504431       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:07.506012827Z E1024 13:23:07.505973       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:07.999136578Z I1024 13:23:07.999091       1 request.go:700] Waited for 1.791182871s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-8-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:23:09.198742956Z I1024 13:23:09.198662       1 request.go:700] Waited for 1.191290117s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-8-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:23:09.256574167Z I1024 13:23:09.256519       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 8, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:23:10.008527475Z E1024 13:23:10.008473       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:10.008527475Z E1024 13:23:10.008494       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:10.010334475Z E1024 13:23:10.010302       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:10.398782264Z I1024 13:23:10.398693       1 request.go:700] Waited for 1.058342725s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:23:10.825684144Z E1024 13:23:10.825637       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:10.826630233Z I1024 13:23:10.826593       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-9-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-apiserver because it was missing
2024-10-24T13:23:11.998898161Z I1024 13:23:11.998835       1 request.go:700] Waited for 1.172687968s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:23:12.999252304Z I1024 13:23:12.999200       1 request.go:700] Waited for 1.388003562s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:23:13.208212649Z E1024 13:23:13.208150       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:13.209707579Z E1024 13:23:13.209663       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:13.613448358Z I1024 13:23:13.613397       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-9-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-apiserver because it was missing
2024-10-24T13:23:14.000035007Z I1024 13:23:13.999446       1 request.go:700] Waited for 1.392572642s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-8-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:23:15.198896485Z I1024 13:23:15.198828       1 request.go:700] Waited for 1.561741966s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:23:15.616339105Z I1024 13:23:15.616271       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:23:15.616339105Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:23:15.616339105Z  CurrentRevision: (int32) 0,
2024-10-24T13:23:15.616339105Z  TargetRevision: (int32) 9,
2024-10-24T13:23:15.616339105Z  LastFailedRevision: (int32) 0,
2024-10-24T13:23:15.616339105Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:23:15.616339105Z  LastFailedReason: (string) "",
2024-10-24T13:23:15.616339105Z  LastFailedCount: (int) 0,
2024-10-24T13:23:15.616339105Z  LastFallbackCount: (int) 0,
2024-10-24T13:23:15.616339105Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:23:15.616339105Z }
2024-10-24T13:23:15.616339105Z  because new revision pending
2024-10-24T13:23:15.618640845Z W1024 13:23:15.618592       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:23:15.618640845Z W1024 13:23:15.618620       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:23:15.618640845Z W1024 13:23:15.618627       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:23:15.618640845Z W1024 13:23:15.618632       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:23:15.618675104Z W1024 13:23:15.618637       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:23:15.664177616Z I1024 13:23:15.664122       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:23:15.664660196Z I1024 13:23:15.664619       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:33Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 9","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:23:15.687413886Z I1024 13:23:15.684086       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 8" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 9",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 8" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 9"
2024-10-24T13:23:15.713190807Z I1024 13:23:15.712838       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:23:16.199285768Z I1024 13:23:16.199204       1 request.go:700] Waited for 1.591546397s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:23:16.207772718Z E1024 13:23:16.207694       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:16.207772718Z E1024 13:23:16.207722       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:16.209842178Z E1024 13:23:16.209793       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:16.615401598Z I1024 13:23:16.615144       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-9-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-apiserver because it was missing
2024-10-24T13:23:17.399291336Z I1024 13:23:17.399234       1 request.go:700] Waited for 1.73500898s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:23:18.598828964Z I1024 13:23:18.598766       1 request.go:700] Waited for 2.189663431s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:23:19.598903027Z I1024 13:23:19.598837       1 request.go:700] Waited for 2.181116321s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:23:20.599006750Z I1024 13:23:20.598904       1 request.go:700] Waited for 2.191206411s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:23:20.607821030Z E1024 13:23:20.607727       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:20.607821030Z E1024 13:23:20.607782       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:20.609516930Z E1024 13:23:20.609475       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:21.798497227Z I1024 13:23:21.798428       1 request.go:700] Waited for 1.590305396s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-10-24T13:23:22.798593931Z I1024 13:23:22.798532       1 request.go:700] Waited for 1.588955296s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:23:23.608886019Z E1024 13:23:23.608828       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:23.608886019Z E1024 13:23:23.608855       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:23.610819409Z E1024 13:23:23.610790       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:23.999129318Z I1024 13:23:23.999061       1 request.go:700] Waited for 1.192033007s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:24.208111453Z I1024 13:23:24.208034       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:23:24.208111453Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:23:24.208111453Z  CurrentRevision: (int32) 0,
2024-10-24T13:23:24.208111453Z  TargetRevision: (int32) 9,
2024-10-24T13:23:24.208111453Z  LastFailedRevision: (int32) 0,
2024-10-24T13:23:24.208111453Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:23:24.208111453Z  LastFailedReason: (string) "",
2024-10-24T13:23:24.208111453Z  LastFailedCount: (int) 0,
2024-10-24T13:23:24.208111453Z  LastFallbackCount: (int) 0,
2024-10-24T13:23:24.208111453Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:23:24.208111453Z }
2024-10-24T13:23:24.208111453Z  because new revision pending
2024-10-24T13:23:25.199255666Z I1024 13:23:25.199188       1 request.go:700] Waited for 1.384714312s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-9-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:23:26.399452954Z I1024 13:23:26.399353       1 request.go:700] Waited for 1.906253245s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:23:26.807080983Z E1024 13:23:26.807021       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:26.807080983Z E1024 13:23:26.807057       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:26.809525623Z E1024 13:23:26.809495       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:27.401847317Z I1024 13:23:27.400878       1 request.go:700] Waited for 1.985267686s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:23:28.599446945Z I1024 13:23:28.599386       1 request.go:700] Waited for 1.992262486s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2024-10-24T13:23:29.798609012Z I1024 13:23:29.798531       1 request.go:700] Waited for 1.186790647s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-10-24T13:23:30.007695477Z E1024 13:23:30.007634       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:30.007695477Z E1024 13:23:30.007662       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:30.010039847Z E1024 13:23:30.009990       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:30.798724936Z I1024 13:23:30.798653       1 request.go:700] Waited for 1.111998185s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:23:31.425592260Z I1024 13:23:31.425515       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-9-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-apiserver because it was missing
2024-10-24T13:23:32.006847113Z I1024 13:23:32.006785       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 9, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:23:32.598694777Z I1024 13:23:32.598636       1 request.go:700] Waited for 1.171384947s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:23:33.599277010Z I1024 13:23:33.599213       1 request.go:700] Waited for 1.189149558s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:23:34.009615509Z E1024 13:23:34.009554       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:34.009615509Z E1024 13:23:34.009580       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:34.011733189Z E1024 13:23:34.011689       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:34.013631009Z E1024 13:23:34.013591       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:34.013670959Z E1024 13:23:34.013627       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:34.799273058Z I1024 13:23:34.799204       1 request.go:700] Waited for 1.188682117s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:23:36.209013390Z E1024 13:23:36.208940       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:37.207278363Z I1024 13:23:37.207221       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 9, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:23:37.607317253Z E1024 13:23:37.607227       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:37.607385022Z E1024 13:23:37.607315       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:37.609050342Z E1024 13:23:37.609010       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:38.608026196Z I1024 13:23:38.607962       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 9, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:23:43.292859085Z I1024 13:23:43.289373       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:23:44.628843426Z E1024 13:23:44.628795       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:44.641026356Z E1024 13:23:44.640958       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:44.656560506Z E1024 13:23:44.656491       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:44.682389827Z E1024 13:23:44.682313       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:44.727327788Z E1024 13:23:44.727278       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:44.812798330Z E1024 13:23:44.812728       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:45.026283725Z E1024 13:23:45.026218       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:45.228945139Z E1024 13:23:45.228879       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:45.624805958Z E1024 13:23:45.624711       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:46.007907957Z I1024 13:23:46.007802       1 termination_observer.go:236] Observed event "TerminationGracefulTerminationFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0" (last termination at 2024-10-24 13:13:16 +0000 UTC) at 2024-10-24 13:23:46 +0000 UTC
2024-10-24T13:23:46.228496762Z E1024 13:23:46.228396       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:46.425826327Z E1024 13:23:46.425729       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:47.029066721Z E1024 13:23:47.028999       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:47.224975395Z E1024 13:23:47.224917       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:47.828636679Z E1024 13:23:47.828560       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:48.225687638Z E1024 13:23:48.225627       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:48.438614433Z E1024 13:23:48.438528       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:49.024540916Z E1024 13:23:49.024483       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:49.628057681Z E1024 13:23:49.627985       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:49.825143795Z E1024 13:23:49.825070       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:50.027811830Z E1024 13:23:50.027735       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:50.426723839Z E1024 13:23:50.426657       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:50.825109298Z E1024 13:23:50.825043       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:51.038797873Z E1024 13:23:51.038720       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:51.824649781Z E1024 13:23:51.824587       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:52.227885211Z E1024 13:23:52.227819       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:52.834099265Z E1024 13:23:52.834015       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:23:52.834882044Z E1024 13:23:52.834777       1 leaderelection.go:436] error retrieving resource lock openshift-kube-apiserver-operator/kube-apiserver-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:53.038127539Z E1024 13:23:53.038062       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:53.224626953Z E1024 13:23:53.224570       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:53.428306558Z E1024 13:23:53.428257       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:54.427537661Z E1024 13:23:54.427466       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:54.629265676Z E1024 13:23:54.629214       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:55.026625105Z E1024 13:23:55.026549       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:55.227987000Z E1024 13:23:55.227919       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:55.424932125Z E1024 13:23:55.424874       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:55.837162704Z E1024 13:23:55.837078       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:56.227077763Z E1024 13:23:56.227011       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:57.027570461Z E1024 13:23:57.027515       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:57.227635636Z E1024 13:23:57.227566       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:57.828011680Z E1024 13:23:57.827945       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:58.239380399Z E1024 13:23:58.239294       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:58.627130608Z E1024 13:23:58.627064       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:58.825274393Z E1024 13:23:58.825202       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:59.623979021Z I1024 13:23:59.623914       1 request.go:700] Waited for 1.074044295s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T13:23:59.627620992Z E1024 13:23:59.627586       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:59.827391896Z E1024 13:23:59.827332       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:00.027922111Z E1024 13:24:00.027827       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:00.426983990Z E1024 13:24:00.426903       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:00.627524844Z E1024 13:24:00.627461       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:01.038575204Z E1024 13:24:01.038504       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:02.026522517Z E1024 13:24:02.026455       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:02.227708071Z E1024 13:24:02.227634       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:02.838390366Z E1024 13:24:02.838314       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:04.027687983Z E1024 13:24:04.027621       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:04.227310708Z E1024 13:24:04.227250       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:04.628793197Z E1024 13:24:04.628689       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:04.824428231Z E1024 13:24:04.824360       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:05.027925706Z E1024 13:24:05.027848       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:05.240195211Z E1024 13:24:05.240114       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:06.627564703Z E1024 13:24:06.627510       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:07.227085757Z E1024 13:24:07.227011       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:07.643144437Z E1024 13:24:07.643062       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:07.827272141Z E1024 13:24:07.827218       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:08.826924084Z E1024 13:24:08.826849       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:10.037995042Z E1024 13:24:10.037940       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:10.227987857Z E1024 13:24:10.227909       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:10.428407361Z E1024 13:24:10.428344       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:11.827412774Z E1024 13:24:11.827344       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:12.227314373Z E1024 13:24:12.227241       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:13.638026595Z E1024 13:24:13.637957       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:14.027460105Z E1024 13:24:14.027386       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:14.226985209Z E1024 13:24:14.226918       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:15.067324048Z E1024 13:24:15.067241       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:15.626203721Z E1024 13:24:15.626147       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:17.356111121Z E1024 13:24:17.356037       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:17.472735964Z E1024 13:24:17.472655       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:18.199695181Z E1024 13:24:18.199630       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:18.794561335Z E1024 13:24:18.794468       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:18.836800746Z E1024 13:24:18.836667       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:24:18.837506875Z E1024 13:24:18.837448       1 leaderelection.go:436] error retrieving resource lock openshift-kube-apiserver-operator/kube-apiserver-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:23.332641799Z E1024 13:24:23.332568       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:23.637510836Z E1024 13:24:23.637442       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:27.601685548Z E1024 13:24:27.601640       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:29.060552082Z E1024 13:24:29.060453       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:30.914196525Z E1024 13:24:30.914132       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:33.585875696Z E1024 13:24:33.585832       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:33.639253857Z E1024 13:24:33.639197       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:35.549722812Z E1024 13:24:35.549662       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:25:21.237278609Z I1024 13:25:21.237219       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:21.237859619Z I1024 13:25:21.237810       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:25:24.847613756Z I1024 13:25:24.847482       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:25.386273854Z I1024 13:25:25.386210       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:26.965271419Z I1024 13:25:26.965187       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:28.614530183Z I1024 13:25:28.614457       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:28.614949883Z I1024 13:25:28.614899       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:25:28.783201582Z I1024 13:25:28.783121       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:29.022445931Z I1024 13:25:29.022360       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:29.030429631Z I1024 13:25:29.030337       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:30.220206947Z I1024 13:25:30.220133       1 request.go:700] Waited for 1.157270516s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:25:31.629449842Z I1024 13:25:31.629386       1 installer_controller.go:506] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-0" for revision 9 for the 1st time because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:31.629449842Z W1024 13:23:53.148987       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:31.629449842Z W1024 13:24:03.148942       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:31.629449842Z W1024 13:24:13.149702       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:31.629449842Z W1024 13:24:23.148978       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:31.629449842Z W1024 13:24:33.149148       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:31.629449842Z W1024 13:24:33.150178       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:31.629449842Z F1024 13:24:33.150207       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:25:31.629532042Z I1024 13:25:31.629498       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:25:31.629532042Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:25:31.629532042Z  CurrentRevision: (int32) 0,
2024-10-24T13:25:31.629532042Z  TargetRevision: (int32) 9,
2024-10-24T13:25:31.629532042Z  LastFailedRevision: (int32) 9,
2024-10-24T13:25:31.629532042Z  LastFailedTime: (*v1.Time)(0xc001a3ff08)(2024-10-24 13:25:31.629360012 +0000 UTC m=+445.480979837),
2024-10-24T13:25:31.629532042Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:25:31.629532042Z  LastFailedCount: (int) 1,
2024-10-24T13:25:31.629532042Z  LastFallbackCount: (int) 0,
2024-10-24T13:25:31.629532042Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:25:31.629532042Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:23:53.148987       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:03.148942       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:13.149702       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:23.148978       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:33.149148       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:33.150178       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:24:33.150207       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:25:31.629532042Z  }
2024-10-24T13:25:31.629532042Z }
2024-10-24T13:25:31.629532042Z  because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:31.629532042Z W1024 13:23:53.148987       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:31.629532042Z W1024 13:24:03.148942       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:31.629532042Z W1024 13:24:13.149702       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:31.629532042Z W1024 13:24:23.148978       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:31.629532042Z W1024 13:24:33.149148       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:31.629532042Z W1024 13:24:33.150178       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:31.629532042Z F1024 13:24:33.150207       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:25:31.629555292Z I1024 13:25:31.629494       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:31.629555292Z W1024 13:23:53.148987       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:31.629555292Z W1024 13:24:03.148942       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:31.629555292Z W1024 13:24:13.149702       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:31.629555292Z W1024 13:24:23.148978       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:31.629555292Z W1024 13:24:33.149148       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:31.629555292Z W1024 13:24:33.150178       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:31.629555292Z F1024 13:24:33.150207       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:25:31.631429052Z W1024 13:25:31.631382       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:25:31.631429052Z W1024 13:25:31.631402       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:25:31.631429052Z W1024 13:25:31.631407       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:25:31.828199971Z I1024 13:25:31.828124       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:32.699737328Z I1024 13:25:32.699663       1 reflector.go:368] Caches populated for *v1.SecurityContextConstraints from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:32.839714848Z I1024 13:25:32.839627       1 reflector.go:368] Caches populated for *v1.CustomResourceDefinition from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:32.840168498Z I1024 13:25:32.840116       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:25:32.840449388Z I1024 13:25:32.840404       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:25:32.840709848Z I1024 13:25:32.840664       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:25:32.840988828Z I1024 13:25:32.840943       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:25:32.841236708Z I1024 13:25:32.841182       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:25:33.507085756Z I1024 13:25:33.507027       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:34.825709041Z I1024 13:25:34.825640       1 installer_controller.go:506] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-0" for revision 9 for the 1st time because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.825709041Z W1024 13:23:53.148987       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.825709041Z W1024 13:24:03.148942       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.825709041Z W1024 13:24:13.149702       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.825709041Z W1024 13:24:23.148978       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.825709041Z W1024 13:24:33.149148       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.825709041Z W1024 13:24:33.150178       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.825709041Z F1024 13:24:33.150207       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:25:34.825870971Z I1024 13:25:34.825745       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:25:34.825870971Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:25:34.825870971Z  CurrentRevision: (int32) 0,
2024-10-24T13:25:34.825870971Z  TargetRevision: (int32) 9,
2024-10-24T13:25:34.825870971Z  LastFailedRevision: (int32) 9,
2024-10-24T13:25:34.825870971Z  LastFailedTime: (*v1.Time)(0xc0026738c0)(2024-10-24 13:25:34.825620931 +0000 UTC m=+448.677240756),
2024-10-24T13:25:34.825870971Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:25:34.825870971Z  LastFailedCount: (int) 1,
2024-10-24T13:25:34.825870971Z  LastFallbackCount: (int) 0,
2024-10-24T13:25:34.825870971Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:25:34.825870971Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:23:53.148987       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:03.148942       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:13.149702       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:23.148978       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:33.149148       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:33.150178       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:24:33.150207       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:25:34.825870971Z  }
2024-10-24T13:25:34.825870971Z }
2024-10-24T13:25:34.825870971Z  because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.825870971Z W1024 13:23:53.148987       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.825870971Z W1024 13:24:03.148942       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.825870971Z W1024 13:24:13.149702       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.825870971Z W1024 13:24:23.148978       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.825870971Z W1024 13:24:33.149148       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.825870971Z W1024 13:24:33.150178       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.825870971Z F1024 13:24:33.150207       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:25:34.825870971Z I1024 13:25:34.825807       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.825870971Z W1024 13:23:53.148987       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.825870971Z W1024 13:24:03.148942       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.825870971Z W1024 13:24:13.149702       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.825870971Z W1024 13:24:23.148978       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.825870971Z W1024 13:24:33.149148       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.825870971Z W1024 13:24:33.150178       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.825870971Z F1024 13:24:33.150207       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:25:34.827673031Z W1024 13:25:34.827635       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:25:34.827673031Z W1024 13:25:34.827652       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:25:34.827706471Z W1024 13:25:34.827688       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:25:36.218270006Z I1024 13:25:36.218209       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:36.767113454Z I1024 13:25:36.767054       1 reflector.go:368] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:37.224728413Z I1024 13:25:37.224627       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:38.334426569Z I1024 13:25:38.334344       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:39.148515326Z I1024 13:25:39.148447       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:39.162239656Z E1024 13:25:39.162161       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:25:39.162239656Z E1024 13:25:39.162187       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:25:39.164158936Z E1024 13:25:39.164116       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:25:39.226738596Z E1024 13:25:39.226670       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:25:39.226738596Z E1024 13:25:39.226703       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:25:39.228936626Z E1024 13:25:39.228867       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:25:39.423174985Z I1024 13:25:39.423105       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:39.626118324Z I1024 13:25:39.626055       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:41.883507366Z I1024 13:25:41.883454       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:42.284370165Z I1024 13:25:42.284297       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:42.589561264Z I1024 13:25:42.589490       1 reflector.go:368] Caches populated for *v1.KubeAPIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:42.883873063Z I1024 13:25:42.883811       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:43.329888321Z I1024 13:25:43.329813       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:43.684944800Z I1024 13:25:43.684855       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:44.584959197Z I1024 13:25:44.584898       1 reflector.go:368] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:44.888014806Z E1024 13:25:44.887940       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:25:44.888014806Z E1024 13:25:44.887987       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:25:44.890127926Z E1024 13:25:44.890055       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:25:45.265738764Z I1024 13:25:45.265686       1 reflector.go:368] Caches populated for *v1alpha1.StorageVersionMigration from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:46.081084472Z I1024 13:25:46.080792       1 request.go:700] Waited for 1.056401466s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:25:47.596262096Z I1024 13:25:47.596203       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubeapiservers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:47.597967116Z I1024 13:25:47.597935       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 9:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:53.148987       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:03.148942       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:13.149702       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:23.148978       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:33.149148       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:33.150178       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:33.150207       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:33Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 9","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:47.600629106Z I1024 13:25:47.600524       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:25:47.614214676Z I1024 13:25:47.613343       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]" to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 9:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:53.148987       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:03.148942       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:13.149702       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:23.148978       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:33.149148       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:33.150178       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:33.150207       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: "
2024-10-24T13:25:47.645651746Z I1024 13:25:47.645568       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:25:47.646451806Z I1024 13:25:47.646411       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 9:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:53.148987       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:03.148942       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:13.149702       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:23.148978       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:33.149148       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:33.150178       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:33.150207       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:33Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 9","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:47.658952946Z E1024 13:25:47.658868       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-apiserver reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-apiserver\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:47.666577476Z I1024 13:25:47.666504       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 9:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:53.148987       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:03.148942       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:13.149702       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:23.148978       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:33.149148       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:33.150178       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:33.150207       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:33Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 9","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:47.675816706Z E1024 13:25:47.675721       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-apiserver reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-apiserver\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:47.686905956Z E1024 13:25:47.686850       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:25:47.686905956Z E1024 13:25:47.686875       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:25:47.688634536Z I1024 13:25:47.688589       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 9:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:53.148987       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:03.148942       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:13.149702       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:23.148978       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:33.149148       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:33.150178       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:33.150207       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:33Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 9","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:47.688838116Z E1024 13:25:47.688800       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:25:47.698866306Z E1024 13:25:47.697901       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-apiserver reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-apiserver\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:47.723943966Z I1024 13:25:47.723628       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 9:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:53.148987       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:03.148942       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:13.149702       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:23.148978       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:33.149148       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:33.150178       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:33.150207       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:33Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 9","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:47.737105166Z E1024 13:25:47.735970       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-apiserver reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-apiserver\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:47.780463966Z I1024 13:25:47.780413       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 9:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:53.148987       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:03.148942       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:13.149702       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:23.148978       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:33.149148       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:33.150178       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:33.150207       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:33Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 9","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:47.794485466Z E1024 13:25:47.794424       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-apiserver reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-apiserver\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:47.877288065Z I1024 13:25:47.877204       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 9:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:53.148987       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:03.148942       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:13.149702       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:23.148978       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:33.149148       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:33.150178       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:33.150207       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:33Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 9","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:47.882904995Z I1024 13:25:47.882807       1 reflector.go:368] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:47.883376246Z I1024 13:25:47.883306       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:25:47.884475315Z E1024 13:25:47.884377       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-apiserver reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-apiserver\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:48.047217985Z I1024 13:25:48.047143       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 9:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:53.148987       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:03.148942       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:13.149702       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:23.148978       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:33.149148       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:33.150178       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:33.150207       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:33Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 9","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:48.054975105Z E1024 13:25:48.054921       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-apiserver reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-apiserver\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:48.378029913Z I1024 13:25:48.377356       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 9:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:53.148987       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:03.148942       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:13.149702       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:23.148978       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:33.149148       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:33.150178       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:33.150207       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:33Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 9","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:48.388794113Z E1024 13:25:48.388275       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-apiserver reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-apiserver\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:48.680981462Z I1024 13:25:48.680919       1 request.go:700] Waited for 1.083696146s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T13:25:48.750839942Z I1024 13:25:48.750739       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:49.681194149Z I1024 13:25:49.681129       1 request.go:700] Waited for 1.990752973s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:25:50.682006696Z I1024 13:25:50.681954       1 request.go:700] Waited for 1.873759054s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets?resourceVersion=26956
2024-10-24T13:25:50.688968756Z I1024 13:25:50.688905       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:51.687137272Z E1024 13:25:51.687090       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:25:51.687137272Z E1024 13:25:51.687117       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:25:51.689310972Z E1024 13:25:51.689281       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:25:51.881648692Z I1024 13:25:51.881592       1 request.go:700] Waited for 1.931412833s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:25:52.451606509Z I1024 13:25:52.451540       1 reflector.go:368] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:52.451668939Z I1024 13:25:52.451643       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX
2024-10-24T13:25:52.452135719Z I1024 13:25:52.452051       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:25:52.864384238Z I1024 13:25:52.864316       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:52.917064498Z I1024 13:25:52.916991       1 reflector.go:368] Caches populated for *v1.Proxy from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:53.055905747Z I1024 13:25:53.055837       1 reflector.go:368] Caches populated for *v1.ValidatingWebhookConfiguration from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:53.080722407Z I1024 13:25:53.080669       1 request.go:700] Waited for 1.049421016s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T13:25:53.731019415Z I1024 13:25:53.730929       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:25:53.734840905Z I1024 13:25:53.734773       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:25:53.803574245Z I1024 13:25:53.803481       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:25:54.080901614Z I1024 13:25:54.080825       1 request.go:700] Waited for 1.308788836s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts?resourceVersion=26978
2024-10-24T13:25:54.083852874Z I1024 13:25:54.083797       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:54.684152812Z I1024 13:25:54.684074       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:54.884584611Z I1024 13:25:54.884523       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:55.081264810Z I1024 13:25:55.081214       1 request.go:700] Waited for 1.791347284s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-10-24T13:25:55.706404518Z I1024 13:25:55.706354       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-9-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-apiserver because it was missing
2024-10-24T13:25:56.081653427Z I1024 13:25:56.081589       1 request.go:700] Waited for 1.997027503s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T13:25:56.195290386Z I1024 13:25:56.195200       1 reflector.go:368] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:56.488507105Z I1024 13:25:56.488421       1 termination_observer.go:130] Observed termination of API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0" at 2024-10-24 13:24:31 +0000 UTC
2024-10-24T13:25:57.280806802Z I1024 13:25:57.280695       1 request.go:700] Waited for 1.994044482s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-9-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:25:57.487922292Z I1024 13:25:57.487841       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 9, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:25:57.990734490Z I1024 13:25:57.990667       1 reflector.go:368] Caches populated for *v1.OAuth from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:58.169915309Z I1024 13:25:58.169841       1 reflector.go:368] Caches populated for *v1.Image from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:58.281593209Z I1024 13:25:58.281461       1 request.go:700] Waited for 1.792899124s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:25:58.688837747Z E1024 13:25:58.688130       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:25:58.688837747Z E1024 13:25:58.688164       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:25:58.691507407Z E1024 13:25:58.690511       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:25:59.481010165Z I1024 13:25:59.480947       1 request.go:700] Waited for 1.392930495s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T13:25:59.485844645Z I1024 13:25:59.485813       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:26:00.018826293Z I1024 13:26:00.018776       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:26:00.019102672Z I1024 13:26:00.018987       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2024-10-24T13:26:00.481229391Z I1024 13:26:00.481165       1 request.go:700] Waited for 1.391613915s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:00.887368050Z I1024 13:26:00.887300       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:26:01.287978568Z E1024 13:26:01.287916       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:01.287978568Z E1024 13:26:01.287945       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:01.289808688Z E1024 13:26:01.289735       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:26:01.681158297Z I1024 13:26:01.681022       1 request.go:700] Waited for 1.192451546s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:02.083414135Z I1024 13:26:02.083355       1 reflector.go:368] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:26:03.289625321Z I1024 13:26:03.289560       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 9, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:26:04.903281235Z I1024 13:26:04.903219       1 reflector.go:368] Caches populated for monitoring.coreos.com/v1, Resource=prometheusrules from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:26:05.952548252Z I1024 13:26:05.952482       1 reflector.go:368] Caches populated for *v1.Authentication from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:26:06.409129851Z I1024 13:26:06.409058       1 reflector.go:368] Caches populated for *v1.MutatingWebhookConfiguration from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:26:06.515536460Z E1024 13:26:06.515467       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:06.515536460Z E1024 13:26:06.515492       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:06.517601100Z E1024 13:26:06.517554       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:26:08.060828534Z E1024 13:26:08.060725       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:08.060828534Z E1024 13:26:08.060803       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:08.062984934Z E1024 13:26:08.062895       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:26:08.146558594Z I1024 13:26:08.146496       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:26:08.334579414Z I1024 13:26:08.334512       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:26:10.980314715Z I1024 13:26:10.980251       1 reflector.go:368] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:26:27.051909129Z E1024 13:26:27.050404       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:27.051909129Z E1024 13:26:27.050443       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:27.069722809Z E1024 13:26:27.069627       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:26:28.542128094Z E1024 13:26:28.541091       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:28.542128094Z E1024 13:26:28.541132       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:28.559059734Z E1024 13:26:28.558991       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:26:29.055155762Z E1024 13:26:29.055087       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:29.055155762Z E1024 13:26:29.055115       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:29.057567942Z E1024 13:26:29.057511       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:26:34.466094534Z I1024 13:26:34.465986       1 termination_observer.go:236] Observed event "TerminationPreShutdownHooksFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0" (last termination at 2024-10-24 13:24:31 +0000 UTC) at 2024-10-24 13:26:34 +0000 UTC
2024-10-24T13:26:34.506218953Z I1024 13:26:34.506144       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 10 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:26:34.700633303Z I1024 13:26:34.700557       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-10 -n openshift-kube-apiserver because it was missing
2024-10-24T13:26:35.499874710Z I1024 13:26:35.499815       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 9, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:26:35.688388539Z I1024 13:26:35.688305       1 request.go:700] Waited for 1.069265036s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:26:36.100936918Z I1024 13:26:36.100864       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-10 -n openshift-kube-apiserver because it was missing
2024-10-24T13:26:36.688460786Z I1024 13:26:36.688364       1 request.go:700] Waited for 1.603808654s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:37.689234042Z I1024 13:26:37.689148       1 request.go:700] Waited for 2.179529462s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:38.297842541Z I1024 13:26:38.297563       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-10 -n openshift-kube-apiserver because it was missing
2024-10-24T13:26:38.889107268Z I1024 13:26:38.889039       1 request.go:700] Waited for 2.193299652s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:38.903684109Z E1024 13:26:38.903625       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:38.903826668Z E1024 13:26:38.903809       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:38.906383789Z E1024 13:26:38.906349       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:26:40.088701655Z I1024 13:26:40.088607       1 request.go:700] Waited for 2.193730152s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T13:26:40.498815223Z I1024 13:26:40.498721       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/oauth-metadata-10 -n openshift-kube-apiserver because it was missing
2024-10-24T13:26:41.289100940Z I1024 13:26:41.289053       1 request.go:700] Waited for 1.793016293s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-10-24T13:26:42.289207787Z I1024 13:26:42.289137       1 request.go:700] Waited for 1.790642104s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T13:26:42.298704887Z I1024 13:26:42.298645       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-10 -n openshift-kube-apiserver because it was missing
2024-10-24T13:26:42.696241255Z E1024 13:26:42.696167       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:42.696241255Z E1024 13:26:42.696201       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:42.698500745Z E1024 13:26:42.698444       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:26:43.488732922Z I1024 13:26:43.488672       1 request.go:700] Waited for 1.791859813s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-9-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:44.099382120Z I1024 13:26:44.099301       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-10 -n openshift-kube-apiserver because it was missing
2024-10-24T13:26:44.489155519Z I1024 13:26:44.489068       1 request.go:700] Waited for 1.788790934s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:45.489217405Z I1024 13:26:45.489141       1 request.go:700] Waited for 1.792130273s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T13:26:45.900189474Z I1024 13:26:45.900118       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-10 -n openshift-kube-apiserver because it was missing
2024-10-24T13:26:46.296145102Z E1024 13:26:46.296080       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:46.296145102Z E1024 13:26:46.296113       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:46.297954582Z E1024 13:26:46.297909       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:26:46.688771701Z I1024 13:26:46.688673       1 request.go:700] Waited for 1.993370433s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:47.496454518Z I1024 13:26:47.496376       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 9, but has not made progress because waiting for static pod of revision 9, found 7
2024-10-24T13:26:47.688778918Z I1024 13:26:47.688692       1 request.go:700] Waited for 2.126877643s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:26:48.299261666Z I1024 13:26:48.299180       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-10 -n openshift-kube-apiserver because it was missing
2024-10-24T13:26:48.689070285Z I1024 13:26:48.689005       1 request.go:700] Waited for 2.389264122s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:49.689217761Z I1024 13:26:49.689138       1 request.go:700] Waited for 2.190215244s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:50.299588199Z I1024 13:26:50.299517       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-10 -n openshift-kube-apiserver because it was missing
2024-10-24T13:26:50.689351738Z I1024 13:26:50.689274       1 request.go:700] Waited for 1.992726304s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:50.696129668Z E1024 13:26:50.696074       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:50.696129668Z E1024 13:26:50.696104       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:50.697849088Z E1024 13:26:50.697805       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:26:51.889170153Z I1024 13:26:51.889103       1 request.go:700] Waited for 1.791781133s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:26:52.101742303Z I1024 13:26:52.101635       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-10 -n openshift-kube-apiserver because it was missing
2024-10-24T13:26:53.088654199Z I1024 13:26:53.088601       1 request.go:700] Waited for 1.784296975s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:26:53.902255517Z I1024 13:26:53.902109       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-10 -n openshift-kube-apiserver because it was missing
2024-10-24T13:26:54.288935606Z I1024 13:26:54.288862       1 request.go:700] Waited for 1.793345643s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:54.295658556Z E1024 13:26:54.295575       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:54.295658556Z E1024 13:26:54.295605       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:54.297529506Z E1024 13:26:54.297486       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:26:55.489267481Z I1024 13:26:55.489196       1 request.go:700] Waited for 1.587383504s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-10
2024-10-24T13:26:56.688687197Z I1024 13:26:56.688604       1 request.go:700] Waited for 1.192483266s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets
2024-10-24T13:26:56.700301827Z I1024 13:26:56.700238       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-10 -n openshift-kube-apiserver because it was missing
2024-10-24T13:26:57.296040455Z I1024 13:26:57.295990       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 9, but has not made progress because waiting for static pod of revision 9, found 7
2024-10-24T13:26:57.702858104Z I1024 13:26:57.702795       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-10 -n openshift-kube-apiserver because it was missing
2024-10-24T13:26:57.889338273Z I1024 13:26:57.889214       1 request.go:700] Waited for 1.185732736s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:26:59.088428368Z I1024 13:26:59.088353       1 request.go:700] Waited for 1.385755174s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets
2024-10-24T13:26:59.099720788Z I1024 13:26:59.099656       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-10 -n openshift-kube-apiserver because it was missing
2024-10-24T13:26:59.496360426Z E1024 13:26:59.496290       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:59.496360426Z E1024 13:26:59.496319       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:59.498243587Z E1024 13:26:59.498187       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:27:00.088783635Z I1024 13:27:00.088709       1 request.go:700] Waited for 1.392189995s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:27:00.500156813Z I1024 13:27:00.500084       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 10 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:27:00.500873443Z W1024 13:27:00.500819       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:27:00.500971203Z W1024 13:27:00.500953       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:27:00.536427283Z W1024 13:27:00.536365       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:27:00.536536723Z W1024 13:27:00.536520       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:27:00.537659693Z I1024 13:27:00.537631       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:27:01.289005611Z I1024 13:27:01.288923       1 request.go:700] Waited for 1.194142787s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:02.289233087Z I1024 13:27:02.289160       1 request.go:700] Waited for 1.751144984s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T13:27:02.698525346Z E1024 13:27:02.698452       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:27:02.698525346Z E1024 13:27:02.698485       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:02.701292216Z E1024 13:27:02.701219       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:27:03.488461753Z I1024 13:27:03.488382       1 request.go:700] Waited for 1.790217574s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:27:04.489164910Z I1024 13:27:04.489107       1 request.go:700] Waited for 1.193534956s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T13:27:05.497038067Z I1024 13:27:05.496980       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 9, but has not made progress because waiting for static pod of revision 9, found 7
2024-10-24T13:27:05.688522106Z I1024 13:27:05.688438       1 request.go:700] Waited for 1.126278597s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:27:06.518143583Z I1024 13:27:06.518047       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-10-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-apiserver because it was missing
2024-10-24T13:27:07.689252510Z I1024 13:27:07.689183       1 request.go:700] Waited for 1.171200846s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:27:08.889343856Z I1024 13:27:08.889253       1 request.go:700] Waited for 1.392866096s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:27:09.096169135Z E1024 13:27:09.096100       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:27:09.096169135Z E1024 13:27:09.096147       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:09.098423715Z E1024 13:27:09.098369       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:27:09.304805565Z I1024 13:27:09.304696       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-10-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-apiserver because it was missing
2024-10-24T13:27:09.697564793Z I1024 13:27:09.697473       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:27:09.697564793Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:27:09.697564793Z  CurrentRevision: (int32) 0,
2024-10-24T13:27:09.697564793Z  TargetRevision: (int32) 10,
2024-10-24T13:27:09.697564793Z  LastFailedRevision: (int32) 9,
2024-10-24T13:27:09.697564793Z  LastFailedTime: (*v1.Time)(0xc006bd25a0)(2024-10-24 13:25:34 +0000 UTC),
2024-10-24T13:27:09.697564793Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:27:09.697564793Z  LastFailedCount: (int) 1,
2024-10-24T13:27:09.697564793Z  LastFallbackCount: (int) 0,
2024-10-24T13:27:09.697564793Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:27:09.697564793Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:23:53.148987       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:03.148942       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:13.149702       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:23.148978       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:33.149148       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:33.150178       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:24:33.150207       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:27:09.697564793Z  }
2024-10-24T13:27:09.697564793Z }
2024-10-24T13:27:09.697564793Z  because new revision pending
2024-10-24T13:27:09.704912353Z W1024 13:27:09.704875       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:27:09.704996763Z W1024 13:27:09.704965       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:27:09.705046023Z W1024 13:27:09.705031       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:27:09.705082623Z W1024 13:27:09.705069       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:27:09.705117373Z W1024 13:27:09.705104       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:27:09.752730933Z I1024 13:27:09.752674       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:27:09.773140633Z I1024 13:27:09.769505       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:33Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 10","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:27:09.790342753Z I1024 13:27:09.789229       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 9:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:53.148987       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:03.148942       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:13.149702       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:23.148978       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:33.149148       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:33.150178       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:33.150207       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: " to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]",Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 9" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 10",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 9" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 10"
2024-10-24T13:27:09.796926693Z I1024 13:27:09.796848       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:27:10.089207632Z I1024 13:27:10.089129       1 request.go:700] Waited for 1.389188085s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:27:11.289366407Z I1024 13:27:11.289282       1 request.go:700] Waited for 1.539322974s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:27:12.292208004Z I1024 13:27:12.292122       1 request.go:700] Waited for 2.192617363s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:27:12.696009032Z E1024 13:27:12.695942       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:27:12.696009032Z E1024 13:27:12.695975       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:12.697842603Z E1024 13:27:12.697793       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:27:12.905450332Z I1024 13:27:12.905381       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-10-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-apiserver because it was missing
2024-10-24T13:27:13.488632230Z I1024 13:27:13.488564       1 request.go:700] Waited for 2.180491113s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:27:14.488961775Z I1024 13:27:14.488894       1 request.go:700] Waited for 2.185571491s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:27:15.489438179Z I1024 13:27:15.489367       1 request.go:700] Waited for 2.193766569s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:16.689218381Z I1024 13:27:16.689134       1 request.go:700] Waited for 1.793197399s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:27:16.699354771Z E1024 13:27:16.699255       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:27:16.699354771Z E1024 13:27:16.699345       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:16.702499101Z E1024 13:27:16.702418       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:27:16.703981771Z E1024 13:27:16.703935       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:27:16.703981771Z E1024 13:27:16.703965       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:17.296490267Z I1024 13:27:17.296396       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:27:17.296490267Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:27:17.296490267Z  CurrentRevision: (int32) 0,
2024-10-24T13:27:17.296490267Z  TargetRevision: (int32) 10,
2024-10-24T13:27:17.296490267Z  LastFailedRevision: (int32) 9,
2024-10-24T13:27:17.296490267Z  LastFailedTime: (*v1.Time)(0xc00249cb88)(2024-10-24 13:25:34 +0000 UTC),
2024-10-24T13:27:17.296490267Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:27:17.296490267Z  LastFailedCount: (int) 1,
2024-10-24T13:27:17.296490267Z  LastFallbackCount: (int) 0,
2024-10-24T13:27:17.296490267Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:27:17.296490267Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:23:53.148987       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:03.148942       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:13.149702       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:23.148978       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:33.149148       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:33.150178       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:24:33.150207       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:27:17.296490267Z  }
2024-10-24T13:27:17.296490267Z }
2024-10-24T13:27:17.296490267Z  because new revision pending
2024-10-24T13:27:17.888541094Z I1024 13:27:17.888478       1 request.go:700] Waited for 1.575073241s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:27:18.889256347Z I1024 13:27:18.889165       1 request.go:700] Waited for 1.58976886s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:27:19.897434701Z E1024 13:27:19.897354       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:27:20.088737409Z I1024 13:27:20.088672       1 request.go:700] Waited for 1.390797432s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-10-24T13:27:22.305102776Z I1024 13:27:22.305023       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-apiserver because it was missing
2024-10-24T13:27:23.296704610Z I1024 13:27:23.296627       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 10, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:27:23.488512009Z I1024 13:27:23.488417       1 request.go:700] Waited for 1.183528013s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:27:24.687931492Z I1024 13:27:24.687859       1 request.go:700] Waited for 1.192364273s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:27:24.694919742Z E1024 13:27:24.694864       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:27:24.694919742Z E1024 13:27:24.694895       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:24.697162092Z E1024 13:27:24.697056       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:27:25.688822126Z I1024 13:27:25.688734       1 request.go:700] Waited for 1.192485632s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:27:26.495012291Z E1024 13:27:26.494934       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:27:26.495012291Z E1024 13:27:26.494971       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:26.497078890Z E1024 13:27:26.497008       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:27:27.295524346Z I1024 13:27:27.295445       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 10, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:27:28.296165710Z I1024 13:27:28.296101       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 10, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:27:28.318093730Z E1024 13:27:28.318047       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:27:28.318093730Z E1024 13:27:28.318076       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:28.698081577Z E1024 13:27:28.698007       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:27:30.007893300Z I1024 13:27:30.007806       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveStorageUpdated' Updated storage urls to https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379,https://localhost:2379
2024-10-24T13:27:30.007948589Z I1024 13:27:30.007905       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-10-24T13:27:30.007948589Z   	"admission": map[string]any{"pluginConfig": map[string]any{"PodSecurity": map[string]any{"configuration": map[string]any{"defaults": map[string]any{"audit": string("restricted"), "audit-version": string("latest"), "enforce": string("restricted"), "enforce-version": string("latest"), ...}}}, "network.openshift.io/ExternalIPRanger": map[string]any{"configuration": map[string]any{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]any{"configuration": map[string]any{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []any{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2024-10-24T13:27:30.007948589Z   	"apiServerArguments": map[string]any{
2024-10-24T13:27:30.007948589Z   		"api-audiences":                            []any{string("https://kubernetes.default.svc")},
2024-10-24T13:27:30.007948589Z   		"authentication-token-webhook-config-file": []any{string("/etc/kubernetes/static-pod-resources/secrets/webhook-authenticat"...)},
2024-10-24T13:27:30.007948589Z   		"authentication-token-webhook-version":     []any{string("v1")},
2024-10-24T13:27:30.007948589Z   		"etcd-servers": []any{
2024-10-24T13:27:30.007948589Z   			string("https://10.0.0.3:2379"),
2024-10-24T13:27:30.007948589Z   			string("https://10.0.0.4:2379"),
2024-10-24T13:27:30.007948589Z - 			string("https://10.0.0.5:2379"),
2024-10-24T13:27:30.007948589Z   			string("https://10.0.0.6:2379"),
2024-10-24T13:27:30.007948589Z   			string("https://localhost:2379"),
2024-10-24T13:27:30.007948589Z   		},
2024-10-24T13:27:30.007948589Z   		"feature-gates":  []any{string("AWSEFSDriverVolumeMetrics=true"), string("AdminNetworkPolicy=true"), string("AlibabaPlatform=true"), string("AzureWorkloadIdentity=true"), ...},
2024-10-24T13:27:30.007948589Z   		"runtime-config": []any{string("admissionregistration.k8s.io/v1beta1=true")},
2024-10-24T13:27:30.007948589Z   		... // 3 identical entries
2024-10-24T13:27:30.007948589Z   	},
2024-10-24T13:27:30.007948589Z   	"authConfig":         map[string]any{"oauthMetadataFile": string("/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/o"...)},
2024-10-24T13:27:30.007948589Z   	"corsAllowedOrigins": []any{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2024-10-24T13:27:30.007948589Z   	... // 3 identical entries
2024-10-24T13:27:30.007948589Z   }
2024-10-24T13:27:30.066878669Z I1024 13:27:30.066815       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:27:30.099798699Z I1024 13:27:30.099682       1 core.go:352] ConfigMap "openshift-kube-apiserver/config" changes: {"apiVersion":"v1","data":{"config.yaml":"{\"admission\":{\"pluginConfig\":{\"PodSecurity\":{\"configuration\":{\"apiVersion\":\"pod-security.admission.config.k8s.io/v1\",\"defaults\":{\"audit\":\"restricted\",\"audit-version\":\"latest\",\"enforce\":\"restricted\",\"enforce-version\":\"latest\",\"warn\":\"restricted\",\"warn-version\":\"latest\"},\"exemptions\":{\"usernames\":[\"system:serviceaccount:openshift-infra:build-controller\"]},\"kind\":\"PodSecurityConfiguration\"}},\"network.openshift.io/ExternalIPRanger\":{\"configuration\":{\"allowIngressIP\":false,\"apiVersion\":\"network.openshift.io/v1\",\"externalIPNetworkCIDRs\":null,\"kind\":\"ExternalIPRangerAdmissionConfig\"},\"location\":\"\"},\"network.openshift.io/RestrictedEndpointsAdmission\":{\"configuration\":{\"apiVersion\":\"network.openshift.io/v1\",\"kind\":\"RestrictedEndpointsAdmissionConfig\",\"restrictedCIDRs\":[\"10.128.0.0/14\",\"172.30.0.0/16\"]}}}},\"apiServerArguments\":{\"allow-privileged\":[\"true\"],\"anonymous-auth\":[\"true\"],\"api-audiences\":[\"https://kubernetes.default.svc\"],\"audit-log-format\":[\"json\"],\"audit-log-maxbackup\":[\"10\"],\"audit-log-maxsize\":[\"200\"],\"audit-log-path\":[\"/var/log/kube-apiserver/audit.log\"],\"audit-policy-file\":[\"/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-audit-policies/policy.yaml\"],\"authentication-token-webhook-config-file\":[\"/etc/kubernetes/static-pod-resources/secrets/webhook-authenticator/kubeConfig\"],\"authentication-token-webhook-version\":[\"v1\"],\"authorization-mode\":[\"Scope\",\"SystemMasters\",\"RBAC\",\"Node\"],\"client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/client-ca/ca-bundle.crt\"],\"enable-admission-plugins\":[\"CertificateApproval\",\"CertificateSigning\",\"CertificateSubjectRestriction\",\"DefaultIngressClass\",\"DefaultStorageClass\",\"DefaultTolerationSeconds\",\"LimitRanger\",\"MutatingAdmissionWebhook\",\"NamespaceLifecycle\",\"NodeRestriction\",\"OwnerReferencesPermissionEnforcement\",\"PersistentVolumeClaimResize\",\"PodNodeSelector\",\"PodTolerationRestriction\",\"Priority\",\"ResourceQuota\",\"RuntimeClass\",\"ServiceAccount\",\"StorageObjectInUseProtection\",\"TaintNodesByCondition\",\"ValidatingAdmissionWebhook\",\"ValidatingAdmissionPolicy\",\"authorization.openshift.io/RestrictSubjectBindings\",\"authorization.openshift.io/ValidateRoleBindingRestriction\",\"config.openshift.io/DenyDeleteClusterConfiguration\",\"config.openshift.io/ValidateAPIServer\",\"config.openshift.io/ValidateAuthentication\",\"config.openshift.io/ValidateConsole\",\"config.openshift.io/ValidateFeatureGate\",\"config.openshift.io/ValidateImage\",\"config.openshift.io/ValidateOAuth\",\"config.openshift.io/ValidateProject\",\"config.openshift.io/ValidateScheduler\",\"image.openshift.io/ImagePolicy\",\"network.openshift.io/ExternalIPRanger\",\"network.openshift.io/RestrictedEndpointsAdmission\",\"quota.openshift.io/ClusterResourceQuota\",\"quota.openshift.io/ValidateClusterResourceQuota\",\"route.openshift.io/IngressAdmission\",\"scheduling.openshift.io/OriginPodNodeEnvironment\",\"security.openshift.io/DefaultSecurityContextConstraints\",\"security.openshift.io/SCCExecRestrictions\",\"security.openshift.io/SecurityContextConstraint\",\"security.openshift.io/ValidateSecurityContextConstraints\",\"storage.openshift.io/CSIInlineVolumeSecurity\"],\"enable-aggregator-routing\":[\"true\"],\"enable-logs-handler\":[\"false\"],\"endpoint-reconciler-type\":[\"lease\"],\"etcd-cafile\":[\"/etc/kubernetes/static-pod-resources/configmaps/etcd-serving-ca/ca-bundle.crt\"],\"etcd-certfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.crt\"],\"etcd-healthcheck-timeout\":[\"9s\"],\"etcd-keyfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.key\"],\"etcd-prefix\":[\"kubernetes.io\"],\"etcd-readycheck-timeout\":[\"9s\"],\"etcd-servers\":[\"https://10.0.0.3:2379\",\"https://10.0.0.4:2379\",\"https://10.0.0.6:2379\",\"https://localhost:2379\"],\"event-ttl\":[\"3h\"],\"feature-gates\":[\"AWSEFSDriverVolumeMetrics=true\",\"AdminNetworkPolicy=true\",\"AlibabaPlatform=true\",\"AzureWorkloadIdentity=true\",\"BareMetalLoadBalancer=true\",\"BuildCSIVolumes=true\",\"ChunkSizeMiB=true\",\"CloudDualStackNodeIPs=true\",\"DisableKubeletCloudCredentialProviders=true\",\"GCPLabelsTags=true\",\"HardwareSpeed=true\",\"IngressControllerLBSubnetsAWS=true\",\"KMSv1=true\",\"ManagedBootImages=true\",\"MetricsServer=true\",\"MultiArchInstallAWS=true\",\"MultiArchInstallGCP=true\",\"NetworkDiagnosticsConfig=true\",\"NetworkLiveMigration=true\",\"NodeDisruptionPolicy=true\",\"OpenShiftPodSecurityAdmission=true\",\"PrivateHostedZoneAWS=true\",\"SetEIPForNLBIngressController=true\",\"VSphereControlPlaneMachineSet=true\",\"VSphereDriverConfiguration=true\",\"VSphereStaticIPs=true\",\"ValidatingAdmissionPolicy=true\",\"AWSClusterHostedDNS=false\",\"AdditionalRoutingCapabilities=false\",\"AutomatedEtcdBackup=false\",\"BootcNodeManagement=false\",\"CSIDriverSharedResource=false\",\"ClusterAPIInstall=false\",\"ClusterAPIInstallIBMCloud=false\",\"ClusterMonitoringConfig=false\",\"DNSNameResolver=false\",\"DynamicResourceAllocation=false\",\"EtcdBackendQuota=false\",\"EventedPLEG=false\",\"Example=false\",\"ExternalOIDC=false\",\"GCPClusterHostedDNS=false\",\"GatewayAPI=false\",\"ImageStreamImportMode=false\",\"IngressControllerDynamicConfigurationManager=false\",\"InsightsConfig=false\",\"InsightsConfigAPI=false\",\"InsightsOnDemandDataGather=false\",\"InsightsRuntimeExtractor=false\",\"MachineAPIMigration=false\",\"MachineAPIOperatorDisableMachineHealthCheckController=false\",\"MachineAPIProviderOpenStack=false\",\"MachineConfigNodes=false\",\"ManagedBootImagesAWS=false\",\"MaxUnavailableStatefulSet=false\",\"MetricsCollectionProfiles=false\",\"MixedCPUsAllocation=false\",\"MultiArchInstallAzure=false\",\"NetworkSegmentation=false\",\"NewOLM=false\",\"NodeSwap=false\",\"OVNObservability=false\",\"OnClusterBuild=false\",\"PersistentIPsForVirtualization=false\",\"PinnedImages=false\",\"PlatformOperators=false\",\"ProcMountType=false\",\"RouteAdvertisements=false\",\"RouteExternalCertificate=false\",\"ServiceAccountTokenNodeBinding=false\",\"SignatureStores=false\",\"SigstoreImageVerification=false\",\"TranslateStreamCloseWebsocketRequests=false\",\"UpgradeStatus=false\",\"UserNamespacesPodSecurityStandards=false\",\"UserNamespacesSupport=false\",\"VSphereMultiNetworks=false\",\"VSphereMultiVCenters=false\",\"VolumeGroupSnapshot=false\"],\"goaway-chance\":[\"0\"],\"http2-max-streams-per-connection\":[\"2000\"],\"kubelet-certificate-authority\":[\"/etc/kubernetes/static-pod-resources/configmaps/kubelet-serving-ca/ca-bundle.crt\"],\"kubelet-client-certificate\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.crt\"],\"kubelet-client-key\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.key\"],\"kubelet-preferred-address-types\":[\"InternalIP\"],\"kubelet-read-only-port\":[\"0\"],\"kubernetes-service-node-port\":[\"0\"],\"max-mutating-requests-inflight\":[\"1000\"],\"max-requests-inflight\":[\"3000\"],\"min-request-timeout\":[\"3600\"],\"proxy-client-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.crt\"],\"proxy-client-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.key\"],\"requestheader-allowed-names\":[\"kube-apiserver-proxy\",\"system:kube-apiserver-proxy\",\"system:openshift-aggregator\"],\"requestheader-client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/aggregator-client-ca/ca-bundle.crt\"],\"requestheader-extra-headers-prefix\":[\"X-Remote-Extra-\"],\"requestheader-group-headers\":[\"X-Remote-Group\"],\"requestheader-username-headers\":[\"X-Remote-User\"],\"runtime-config\":[\"admissionregistration.k8s.io/v1beta1=true\"],\"send-retry-after-while-not-ready-once\":[\"false\"],\"service-account-issuer\":[\"https://kubernetes.default.svc\"],\"service-account-jwks-uri\":[\"https://api.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX:6443/openid/v1/jwks\"],\"service-account-lookup\":[\"true\"],\"service-account-signing-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/bound-service-account-signing-key/service-account.key\"],\"service-node-port-range\":[\"30000-32767\"],\"shutdown-delay-duration\":[\"70s\"],\"shutdown-send-retry-after\":[\"true\"],\"storage-backend\":[\"etcd3\"],\"storage-media-type\":[\"application/vnd.kubernetes.protobuf\"],\"strict-transport-security-directives\":[\"max-age=31536000,includeSubDomains,preload\"],\"tls-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\"],\"tls-private-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"]},\"apiVersion\":\"kubecontrolplane.config.openshift.io/v1\",\"authConfig\":{\"oauthMetadataFile\":\"/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/oauthMetadata\"},\"consolePublicURL\":\"\",\"corsAllowedOrigins\":[\"//127\\\\.0\\\\.0\\\\.1(:|$)\",\"//localhost(:|$)\"],\"imagePolicyConfig\":{\"internalRegistryHostname\":\"image-registry.openshift-image-registry.svc:5000\"},\"kind\":\"KubeAPIServerConfig\",\"projectConfig\":{\"defaultNodeSelector\":\"\"},\"serviceAccountPublicKeyFiles\":[\"/etc/kubernetes/static-pod-resources/configmaps/sa-token-signing-certs\",\"/etc/kubernetes/static-pod-resources/configmaps/bound-sa-token-signing-certs\"],\"servicesSubnet\":\"172.30.0.0/16\",\"servingInfo\":{\"bindAddress\":\"0.0.0.0:6443\",\"bindNetwork\":\"tcp4\",\"cipherSuites\":[\"TLS_AES_128_GCM_SHA256\",\"TLS_AES_256_GCM_SHA384\",\"TLS_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"],\"minTLSVersion\":\"VersionTLS12\",\"namedCertificates\":[{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.key\"}]}}"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:27:30.101482359Z I1024 13:27:30.101099       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/config -n openshift-kube-apiserver:
2024-10-24T13:27:30.101482359Z cause by changes in data.config.yaml
2024-10-24T13:27:30.105236539Z I1024 13:27:30.105148       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:27:30.133740808Z E1024 13:27:30.133691       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:27:30.133858689Z E1024 13:27:30.133839       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:31.088715382Z I1024 13:27:31.088646       1 request.go:700] Waited for 1.016117623s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-10-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:27:32.288094005Z I1024 13:27:32.288029       1 request.go:700] Waited for 1.792815199s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:27:33.288868649Z I1024 13:27:33.288771       1 request.go:700] Waited for 1.592247711s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T13:27:33.300327129Z I1024 13:27:33.300249       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-11 -n openshift-kube-apiserver because it was missing
2024-10-24T13:27:33.698206377Z E1024 13:27:33.698095       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:27:34.295554512Z I1024 13:27:34.295489       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 10, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:27:34.488416801Z I1024 13:27:34.488351       1 request.go:700] Waited for 1.726395799s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:27:35.101703768Z I1024 13:27:35.101606       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-11 -n openshift-kube-apiserver because it was missing
2024-10-24T13:27:35.688704994Z I1024 13:27:35.688631       1 request.go:700] Waited for 1.784221979s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:27:36.703596108Z I1024 13:27:36.703522       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-11 -n openshift-kube-apiserver because it was missing
2024-10-24T13:27:36.887875546Z I1024 13:27:36.887771       1 request.go:700] Waited for 1.590846851s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:27:37.094479705Z E1024 13:27:37.094373       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:27:37.094479705Z E1024 13:27:37.094401       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:37.096285685Z E1024 13:27:37.096245       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:27:37.888272400Z I1024 13:27:37.888198       1 request.go:700] Waited for 1.59280521s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-10-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:38.299058788Z I1024 13:27:38.297779       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/oauth-metadata-11 -n openshift-kube-apiserver because it was missing
2024-10-24T13:27:38.888344715Z I1024 13:27:38.888263       1 request.go:700] Waited for 1.394298791s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:39.697202789Z I1024 13:27:39.697104       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-11 -n openshift-kube-apiserver because it was missing
2024-10-24T13:27:40.088438567Z I1024 13:27:40.088357       1 request.go:700] Waited for 1.383965971s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:27:41.088737661Z I1024 13:27:41.088670       1 request.go:700] Waited for 1.391560671s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T13:27:41.100978421Z I1024 13:27:41.100894       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-11 -n openshift-kube-apiserver because it was missing
2024-10-24T13:27:41.695461287Z I1024 13:27:41.695378       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 10, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:27:42.288770493Z I1024 13:27:42.288630       1 request.go:700] Waited for 1.59200028s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-10-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:42.700856940Z I1024 13:27:42.700734       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-11 -n openshift-kube-apiserver because it was missing
2024-10-24T13:27:43.288723407Z I1024 13:27:43.288641       1 request.go:700] Waited for 1.59054118s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:27:43.495374176Z E1024 13:27:43.495299       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:27:43.495374176Z E1024 13:27:43.495326       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:43.496935986Z E1024 13:27:43.496880       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:27:44.297964941Z I1024 13:27:44.297880       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-11 -n openshift-kube-apiserver because it was missing
2024-10-24T13:27:44.487906040Z I1024 13:27:44.487829       1 request.go:700] Waited for 1.59144067s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:27:44.492490400Z E1024 13:27:44.492422       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:44.691653758Z W1024 13:27:44.691603       1 base_controller.go:234] Updating status of "NodeKubeconfigController" failed: unable to ApplyStatus for operator using fieldManager "NodeKubeconfigController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=NodeKubeconfigController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:44.691714738Z E1024 13:27:44.691670       1 base_controller.go:271] "Unhandled Error" err="NodeKubeconfigController reconciliation failed: \"secret/node-kubeconfigs\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:45.289382145Z E1024 13:27:45.289299       1 base_controller.go:271] "Unhandled Error" err="PruneController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-10-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:45.488265814Z I1024 13:27:45.488194       1 request.go:700] Waited for 1.392102992s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-10-24T13:27:45.689507403Z I1024 13:27:45.689404       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMapCreateFailed' Failed to create ConfigMap/sa-token-signing-certs-11 -n openshift-kube-apiserver: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:45.691079322Z E1024 13:27:45.690995       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.18016687e23cc229  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:25c703bd-fced-4623-ab7c-91be89cc0822,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/sa-token-signing-certs-11 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:27:45.689231913 +0000 UTC m=+579.540851737,LastTimestamp:2024-10-24 13:27:45.689231913 +0000 UTC m=+579.540851737,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:27:45.691886362Z I1024 13:27:45.691805       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:45.691886362Z E1024 13:27:45.691823       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:45.696846693Z I1024 13:27:45.696731       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:27:45.891999481Z E1024 13:27:45.891938       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:46.093195890Z E1024 13:27:46.093132       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:46.291548529Z W1024 13:27:46.291475       1 base_controller.go:234] Updating status of "NodeKubeconfigController" failed: unable to ApplyStatus for operator using fieldManager "NodeKubeconfigController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=NodeKubeconfigController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:46.291548529Z E1024 13:27:46.291533       1 base_controller.go:271] "Unhandled Error" err="NodeKubeconfigController reconciliation failed: \"secret/node-kubeconfigs\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:46.452528698Z I1024 13:27:46.452440       1 termination_observer.go:236] Observed event "TerminationGracefulTerminationFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0" (last termination at 2024-10-24 13:24:31 +0000 UTC) at 2024-10-24 13:27:46 +0000 UTC
2024-10-24T13:27:46.488691248Z I1024 13:27:46.488595       1 request.go:700] Waited for 1.59991675s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:46.690019186Z E1024 13:27:46.689557       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:46.926949875Z E1024 13:27:46.926856       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:27:46.927951805Z E1024 13:27:46.927914       1 leaderelection.go:436] error retrieving resource lock openshift-kube-apiserver-operator/kube-apiserver-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:47.288798592Z E1024 13:27:47.288728       1 base_controller.go:271] "Unhandled Error" err="PruneController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-10-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:47.488679111Z I1024 13:27:47.488611       1 request.go:700] Waited for 1.999110307s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-10-24T13:27:47.691447660Z E1024 13:27:47.691372       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:47.691500410Z I1024 13:27:47.691432       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:47.697057930Z I1024 13:27:47.696970       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:27:47.891872009Z E1024 13:27:47.891798       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:48.093054458Z E1024 13:27:48.093002       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:48.291191006Z W1024 13:27:48.291128       1 base_controller.go:234] Updating status of "NodeKubeconfigController" failed: unable to ApplyStatus for operator using fieldManager "NodeKubeconfigController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=NodeKubeconfigController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:48.291248206Z E1024 13:27:48.291184       1 base_controller.go:271] "Unhandled Error" err="NodeKubeconfigController reconciliation failed: \"secret/node-kubeconfigs\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:48.489811895Z I1024 13:27:48.489686       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 10 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:48.490603005Z E1024 13:27:48.490547       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.180166888925a995  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:25c703bd-fced-4623-ab7c-91be89cc0822,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 10 count 1 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:27:48.489513365 +0000 UTC m=+582.341133190,LastTimestamp:2024-10-24 13:27:48.489513365 +0000 UTC m=+582.341133190,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:27:48.491689695Z W1024 13:27:48.491622       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:27:48.491689695Z W1024 13:27:48.491659       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:27:48.491689695Z W1024 13:27:48.491668       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:27:48.492695995Z E1024 13:27:48.492654       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-Installer\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-Installer&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:48.688270174Z I1024 13:27:48.688203       1 request.go:700] Waited for 1.991778508s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:27:48.689456034Z E1024 13:27:48.689346       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:49.111002891Z E1024 13:27:49.110913       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:49.289229420Z E1024 13:27:49.289163       1 base_controller.go:271] "Unhandled Error" err="PruneController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-10-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:49.490256049Z E1024 13:27:49.490199       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:49.688584248Z I1024 13:27:49.688516       1 request.go:700] Waited for 1.991520827s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T13:27:49.692652137Z E1024 13:27:49.692564       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:49.692720367Z I1024 13:27:49.692632       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:49.698463817Z I1024 13:27:49.698389       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:27:49.891666456Z E1024 13:27:49.891601       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:50.092435065Z E1024 13:27:50.092360       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:50.292022253Z W1024 13:27:50.291939       1 base_controller.go:234] Updating status of "NodeKubeconfigController" failed: unable to ApplyStatus for operator using fieldManager "NodeKubeconfigController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=NodeKubeconfigController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:50.292022253Z E1024 13:27:50.292004       1 base_controller.go:271] "Unhandled Error" err="NodeKubeconfigController reconciliation failed: \"secret/node-kubeconfigs\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:50.463975283Z E1024 13:27:50.463904       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.180166888925a995  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:25c703bd-fced-4623-ab7c-91be89cc0822,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 10 count 1 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:27:48.489513365 +0000 UTC m=+582.341133190,LastTimestamp:2024-10-24 13:27:48.489513365 +0000 UTC m=+582.341133190,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:27:50.689165281Z E1024 13:27:50.689107       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:50.887861770Z I1024 13:27:50.887803       1 request.go:700] Waited for 1.999122738s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:50.891128660Z E1024 13:27:50.891074       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:51.289462277Z E1024 13:27:51.289393       1 base_controller.go:271] "Unhandled Error" err="PruneController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-10-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:51.691361335Z E1024 13:27:51.691303       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:51.691361335Z I1024 13:27:51.691343       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:51.695848155Z I1024 13:27:51.695793       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:27:51.888720084Z I1024 13:27:51.888651       1 request.go:700] Waited for 1.995233358s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:27:51.891776264Z E1024 13:27:51.891697       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:52.092784993Z E1024 13:27:52.092707       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:52.291674361Z W1024 13:27:52.291605       1 base_controller.go:234] Updating status of "NodeKubeconfigController" failed: unable to ApplyStatus for operator using fieldManager "NodeKubeconfigController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=NodeKubeconfigController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:52.291674361Z E1024 13:27:52.291650       1 base_controller.go:271] "Unhandled Error" err="NodeKubeconfigController reconciliation failed: \"secret/node-kubeconfigs\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:52.688633709Z E1024 13:27:52.688569       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:53.088247676Z I1024 13:27:53.088146       1 request.go:700] Waited for 1.998434957s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T13:27:53.289261425Z E1024 13:27:53.289195       1 base_controller.go:271] "Unhandled Error" err="PruneController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-10-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:53.691450613Z E1024 13:27:53.691386       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:53.691450613Z I1024 13:27:53.691429       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:53.696282382Z I1024 13:27:53.696197       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:27:53.696918653Z E1024 13:27:53.696871       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.18016687e23cc229  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:25c703bd-fced-4623-ab7c-91be89cc0822,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/sa-token-signing-certs-11 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:27:45.689231913 +0000 UTC m=+579.540851737,LastTimestamp:2024-10-24 13:27:45.689231913 +0000 UTC m=+579.540851737,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:27:53.891390811Z E1024 13:27:53.891319       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:54.092343800Z E1024 13:27:54.092270       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:54.288673889Z I1024 13:27:54.288599       1 request.go:700] Waited for 1.995184217s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:27:54.291765819Z W1024 13:27:54.291691       1 base_controller.go:234] Updating status of "NodeKubeconfigController" failed: unable to ApplyStatus for operator using fieldManager "NodeKubeconfigController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=NodeKubeconfigController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:54.291813589Z E1024 13:27:54.291742       1 base_controller.go:271] "Unhandled Error" err="NodeKubeconfigController reconciliation failed: \"secret/node-kubeconfigs\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:54.688895246Z E1024 13:27:54.688775       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:55.103470734Z E1024 13:27:55.103382       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:55.289841233Z E1024 13:27:55.289414       1 base_controller.go:271] "Unhandled Error" err="PruneController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-10-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:55.488199311Z I1024 13:27:55.488147       1 request.go:700] Waited for 1.998483577s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-10-24T13:27:55.693200370Z E1024 13:27:55.693133       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:55.693257530Z I1024 13:27:55.693188       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:55.698428810Z I1024 13:27:55.698356       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:27:55.891775838Z E1024 13:27:55.891690       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:56.092863747Z E1024 13:27:56.092745       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:56.292532916Z W1024 13:27:56.292457       1 base_controller.go:234] Updating status of "NodeKubeconfigController" failed: unable to ApplyStatus for operator using fieldManager "NodeKubeconfigController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=NodeKubeconfigController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:56.292615966Z E1024 13:27:56.292527       1 base_controller.go:271] "Unhandled Error" err="NodeKubeconfigController reconciliation failed: \"secret/node-kubeconfigs\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:56.488332115Z I1024 13:27:56.488245       1 request.go:700] Waited for 1.999061017s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:27:56.489433975Z I1024 13:27:56.489343       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 10 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:56.491352135Z W1024 13:27:56.491301       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:27:56.491352135Z W1024 13:27:56.491331       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:27:56.491352135Z W1024 13:27:56.491335       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:27:56.492253935Z E1024 13:27:56.492202       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-Installer\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-Installer&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:56.689029914Z E1024 13:27:56.688950       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:56.891426512Z E1024 13:27:56.891359       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:57.289356350Z E1024 13:27:57.289302       1 base_controller.go:271] "Unhandled Error" err="PruneController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-10-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:57.488326669Z I1024 13:27:57.488273       1 request.go:700] Waited for 1.999111508s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-10-24T13:27:57.691742968Z E1024 13:27:57.691678       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:57.691812148Z I1024 13:27:57.691727       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:57.696523938Z I1024 13:27:57.696476       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:27:57.898547076Z E1024 13:27:57.898491       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:58.092994365Z E1024 13:27:58.092929       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:58.292076784Z W1024 13:27:58.292013       1 base_controller.go:234] Updating status of "NodeKubeconfigController" failed: unable to ApplyStatus for operator using fieldManager "NodeKubeconfigController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=NodeKubeconfigController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:58.292076784Z E1024 13:27:58.292062       1 base_controller.go:271] "Unhandled Error" err="NodeKubeconfigController reconciliation failed: \"secret/node-kubeconfigs\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:58.688896451Z I1024 13:27:58.688811       1 request.go:700] Waited for 1.838165228s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:27:58.690091171Z E1024 13:27:58.690015       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:59.289707288Z E1024 13:27:59.289634       1 base_controller.go:271] "Unhandled Error" err="PruneController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-10-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:59.691368125Z E1024 13:27:59.691299       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:59.691368125Z I1024 13:27:59.691347       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:59.696245115Z I1024 13:27:59.696193       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:27:59.888333844Z I1024 13:27:59.888266       1 request.go:700] Waited for 1.987984548s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:27:59.892728964Z E1024 13:27:59.892658       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:00.091805023Z W1024 13:28:00.091707       1 base_controller.go:234] Updating status of "NodeKubeconfigController" failed: unable to ApplyStatus for operator using fieldManager "NodeKubeconfigController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=NodeKubeconfigController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:00.091805023Z E1024 13:28:00.091775       1 base_controller.go:271] "Unhandled Error" err="NodeKubeconfigController reconciliation failed: \"secret/node-kubeconfigs\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:00.291409382Z E1024 13:28:00.291352       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:00.465960231Z E1024 13:28:00.465901       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.180166888925a995  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:25c703bd-fced-4623-ab7c-91be89cc0822,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 10 count 1 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:27:48.489513365 +0000 UTC m=+582.341133190,LastTimestamp:2024-10-24 13:27:48.489513365 +0000 UTC m=+582.341133190,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:28:00.888390398Z I1024 13:28:00.888313       1 request.go:700] Waited for 1.875910489s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:28:00.889268748Z E1024 13:28:00.889236       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:01.105085707Z E1024 13:28:01.105024       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:01.289621325Z E1024 13:28:01.289562       1 base_controller.go:271] "Unhandled Error" err="PruneController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-10-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:01.490877234Z E1024 13:28:01.490824       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:01.691914443Z E1024 13:28:01.691858       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:01.691966733Z I1024 13:28:01.691901       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:01.697288293Z I1024 13:28:01.697225       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:28:01.888661631Z I1024 13:28:01.888589       1 request.go:700] Waited for 1.994018247s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:28:01.892010351Z E1024 13:28:01.891976       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:02.091414440Z W1024 13:28:02.091346       1 base_controller.go:234] Updating status of "NodeKubeconfigController" failed: unable to ApplyStatus for operator using fieldManager "NodeKubeconfigController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=NodeKubeconfigController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:02.091414440Z E1024 13:28:02.091393       1 base_controller.go:271] "Unhandled Error" err="NodeKubeconfigController reconciliation failed: \"secret/node-kubeconfigs\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:02.492169778Z E1024 13:28:02.492109       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:02.691795726Z E1024 13:28:02.691724       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:03.088219714Z I1024 13:28:03.088156       1 request.go:700] Waited for 1.796697769s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-10-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:28:03.089306244Z E1024 13:28:03.089251       1 base_controller.go:271] "Unhandled Error" err="PruneController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-10-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:03.488690591Z E1024 13:28:03.488629       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:03.691018870Z E1024 13:28:03.690963       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:03.691018870Z I1024 13:28:03.691002       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:03.696336700Z I1024 13:28:03.696284       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:28:03.698080040Z E1024 13:28:03.698049       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.18016687e23cc229  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:25c703bd-fced-4623-ab7c-91be89cc0822,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/sa-token-signing-certs-11 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:27:45.689231913 +0000 UTC m=+579.540851737,LastTimestamp:2024-10-24 13:27:45.689231913 +0000 UTC m=+579.540851737,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:28:03.891297139Z E1024 13:28:03.891223       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:04.088694288Z I1024 13:28:04.088636       1 request.go:700] Waited for 1.995319347s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:28:04.092191088Z W1024 13:28:04.092138       1 base_controller.go:234] Updating status of "NodeKubeconfigController" failed: unable to ApplyStatus for operator using fieldManager "NodeKubeconfigController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=NodeKubeconfigController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:04.092222658Z E1024 13:28:04.092193       1 base_controller.go:271] "Unhandled Error" err="NodeKubeconfigController reconciliation failed: \"secret/node-kubeconfigs\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:04.289287137Z I1024 13:28:04.289200       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 10 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:04.291147546Z W1024 13:28:04.291102       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:28:04.291238267Z W1024 13:28:04.291222       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:28:04.291272936Z W1024 13:28:04.291261       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:28:04.292884867Z E1024 13:28:04.292836       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-Installer\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-Installer&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:04.889903183Z E1024 13:28:04.889846       1 base_controller.go:271] "Unhandled Error" err="PruneController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-10-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:05.288434550Z I1024 13:28:05.288362       1 request.go:700] Waited for 1.59206682s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T13:28:05.291564040Z E1024 13:28:05.291527       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:05.291594230Z I1024 13:28:05.291556       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:05.490975389Z E1024 13:28:05.490906       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:05.692979988Z E1024 13:28:05.692912       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:06.257155854Z I1024 13:28:06.257088       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:28:06.288828044Z I1024 13:28:06.288773       1 request.go:700] Waited for 1.63465347s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:28:06.292569334Z W1024 13:28:06.292486       1 base_controller.go:234] Updating status of "NodeKubeconfigController" failed: unable to ApplyStatus for operator using fieldManager "NodeKubeconfigController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=NodeKubeconfigController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:06.292569334Z E1024 13:28:06.292527       1 base_controller.go:271] "Unhandled Error" err="NodeKubeconfigController reconciliation failed: \"secret/node-kubeconfigs\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:06.505969793Z E1024 13:28:06.505898       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:06.688690162Z E1024 13:28:06.688616       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:07.092077849Z E1024 13:28:07.092015       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:07.290052387Z E1024 13:28:07.289994       1 base_controller.go:271] "Unhandled Error" err="PruneController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-10-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:07.488615086Z I1024 13:28:07.488543       1 request.go:700] Waited for 1.599280899s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:28:07.691360565Z E1024 13:28:07.691306       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:07.891252984Z E1024 13:28:07.891179       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:07.891252984Z I1024 13:28:07.891229       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:09.092913127Z E1024 13:28:09.092848       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:09.489104004Z I1024 13:28:09.489020       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 10 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:09.491147934Z W1024 13:28:09.491111       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:28:09.491147934Z W1024 13:28:09.491132       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:28:09.491147934Z W1024 13:28:09.491139       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:28:09.492039754Z E1024 13:28:09.491980       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-Installer\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-Installer&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:09.904560412Z E1024 13:28:09.904462       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:10.089098391Z E1024 13:28:10.089040       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:10.291473870Z E1024 13:28:10.291407       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:10.468222369Z E1024 13:28:10.468124       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.180166888925a995  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:25c703bd-fced-4623-ab7c-91be89cc0822,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 10 count 1 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:27:48.489513365 +0000 UTC m=+582.341133190,LastTimestamp:2024-10-24 13:27:48.489513365 +0000 UTC m=+582.341133190,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:28:10.692634257Z E1024 13:28:10.692555       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:12.505035537Z E1024 13:28:12.504955       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:12.889467335Z I1024 13:28:12.889381       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 10 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:12.891250025Z W1024 13:28:12.891166       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:28:12.891250025Z W1024 13:28:12.891187       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:28:12.891250025Z W1024 13:28:12.891191       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:28:12.892069625Z E1024 13:28:12.892001       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-Installer\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-Installer&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:12.929708185Z E1024 13:28:12.929623       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:28:12.930615785Z E1024 13:28:12.930517       1 leaderelection.go:436] error retrieving resource lock openshift-kube-apiserver-operator/kube-apiserver-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:13.092840033Z E1024 13:28:13.092723       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:13.699316980Z E1024 13:28:13.699255       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.18016687e23cc229  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:25c703bd-fced-4623-ab7c-91be89cc0822,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/sa-token-signing-certs-11 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:27:45.689231913 +0000 UTC m=+579.540851737,LastTimestamp:2024-10-24 13:27:45.689231913 +0000 UTC m=+579.540851737,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:28:14.491285025Z E1024 13:28:14.491224       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:15.103930992Z E1024 13:28:15.103854       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:15.288225520Z I1024 13:28:15.288155       1 request.go:700] Waited for 1.072680983s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T13:28:15.292953970Z E1024 13:28:15.292905       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:15.498549279Z E1024 13:28:15.498484       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:15.891985576Z E1024 13:28:15.891922       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:16.288788054Z E1024 13:28:16.288697       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:16.688876951Z I1024 13:28:16.688806       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 10 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:16.690489821Z W1024 13:28:16.690456       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:28:16.690489821Z W1024 13:28:16.690475       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:28:16.690489821Z W1024 13:28:16.690480       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:28:16.691262131Z E1024 13:28:16.691218       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-Installer\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-Installer&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:16.887790810Z I1024 13:28:16.887696       1 request.go:700] Waited for 1.154198503s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:28:16.891132190Z E1024 13:28:16.891086       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:17.691860485Z W1024 13:28:17.691797       1 base_controller.go:234] Updating status of "NodeKubeconfigController" failed: unable to ApplyStatus for operator using fieldManager "NodeKubeconfigController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=NodeKubeconfigController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:17.691916365Z E1024 13:28:17.691867       1 base_controller.go:271] "Unhandled Error" err="NodeKubeconfigController reconciliation failed: \"secret/node-kubeconfigs\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:17.887967424Z I1024 13:28:17.887905       1 request.go:700] Waited for 1.195087893s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:28:18.103442763Z E1024 13:28:18.103365       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:18.136704533Z I1024 13:28:18.136646       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:28:18.689103049Z E1024 13:28:18.689045       1 base_controller.go:271] "Unhandled Error" err="PruneController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-10-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:19.288873295Z I1024 13:28:19.288655       1 request.go:700] Waited for 1.151985473s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T13:28:19.292236625Z E1024 13:28:19.292182       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:19.292303845Z I1024 13:28:19.292230       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:19.491570274Z E1024 13:28:19.491503       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:20.469461458Z E1024 13:28:20.469395       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.180166888925a995  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:25c703bd-fced-4623-ab7c-91be89cc0822,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 10 count 1 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:27:48.489513365 +0000 UTC m=+582.341133190,LastTimestamp:2024-10-24 13:27:48.489513365 +0000 UTC m=+582.341133190,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:28:20.489516858Z I1024 13:28:20.489438       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 10 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:20.491408698Z W1024 13:28:20.491325       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:28:20.491408698Z W1024 13:28:20.491356       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:28:20.491408698Z W1024 13:28:20.491361       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:28:20.492430218Z E1024 13:28:20.492393       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-Installer\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-Installer&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:20.706983337Z E1024 13:28:20.706904       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:21.091716614Z E1024 13:28:21.091659       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:22.491974206Z E1024 13:28:22.491908       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:23.104005582Z E1024 13:28:23.103937       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:23.490179880Z I1024 13:28:23.490073       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 10 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:23.492042900Z W1024 13:28:23.491981       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:28:23.492042900Z W1024 13:28:23.492012       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:28:23.492042900Z W1024 13:28:23.492020       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:28:23.493249550Z E1024 13:28:23.493180       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-Installer\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-Installer&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:23.700326459Z E1024 13:28:23.700262       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.18016687e23cc229  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:25c703bd-fced-4623-ab7c-91be89cc0822,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/sa-token-signing-certs-11 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:27:45.689231913 +0000 UTC m=+579.540851737,LastTimestamp:2024-10-24 13:27:45.689231913 +0000 UTC m=+579.540851737,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:28:24.291575125Z E1024 13:28:24.291522       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:25.303240428Z E1024 13:28:25.303179       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:25.691620965Z E1024 13:28:25.691548       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:26.091822893Z E1024 13:28:26.091736       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:26.292820132Z E1024 13:28:26.292729       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:26.889442698Z I1024 13:28:26.889370       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 10 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:26.891273858Z W1024 13:28:26.891227       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:28:26.891273858Z W1024 13:28:26.891254       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:28:26.891273858Z W1024 13:28:26.891259       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:28:26.892344317Z E1024 13:28:26.892311       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-Installer\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-Installer&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:27.289506905Z E1024 13:28:27.289426       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:27.904566831Z E1024 13:28:27.904475       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:29.289381813Z I1024 13:28:29.289305       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 10 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:29.290988953Z W1024 13:28:29.290946       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:28:29.290988953Z W1024 13:28:29.290969       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:28:29.290988953Z W1024 13:28:29.290976       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:28:29.291744152Z E1024 13:28:29.291707       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-Installer\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-Installer&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:29.490398841Z E1024 13:28:29.490334       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:30.292449567Z E1024 13:28:30.292379       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:30.470952065Z E1024 13:28:30.470890       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.180166888925a995  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:25c703bd-fced-4623-ab7c-91be89cc0822,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 10 count 1 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:27:48.489513365 +0000 UTC m=+582.341133190,LastTimestamp:2024-10-24 13:27:48.489513365 +0000 UTC m=+582.341133190,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:28:31.289511410Z I1024 13:28:31.289431       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 10 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:31.291269090Z W1024 13:28:31.291219       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:28:31.291269090Z W1024 13:28:31.291249       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:28:31.291269090Z W1024 13:28:31.291254       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:28:31.292330390Z E1024 13:28:31.292261       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-Installer\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-Installer&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:31.890728717Z E1024 13:28:31.890675       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:33.289542918Z I1024 13:28:33.289460       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 10 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:33.291251778Z W1024 13:28:33.291208       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:28:33.291251778Z W1024 13:28:33.291229       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:28:33.291251778Z W1024 13:28:33.291234       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:28:33.292177998Z E1024 13:28:33.292118       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-Installer\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-Installer&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:33.701977185Z E1024 13:28:33.701907       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.18016687e23cc229  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:25c703bd-fced-4623-ab7c-91be89cc0822,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/sa-token-signing-certs-11 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:27:45.689231913 +0000 UTC m=+579.540851737,LastTimestamp:2024-10-24 13:27:45.689231913 +0000 UTC m=+579.540851737,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:28:33.891791954Z E1024 13:28:33.891710       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:34.091169183Z E1024 13:28:34.091087       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:35.290151106Z E1024 13:28:35.290090       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:36.492547228Z E1024 13:28:36.492483       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:37.091483824Z E1024 13:28:37.091423       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:38.168199708Z E1024 13:28:38.168128       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:38.176337158Z W1024 13:28:38.176263       1 base_controller.go:234] Updating status of "NodeKubeconfigController" failed: unable to ApplyStatus for operator using fieldManager "NodeKubeconfigController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=NodeKubeconfigController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:38.176337158Z E1024 13:28:38.176297       1 base_controller.go:271] "Unhandled Error" err="NodeKubeconfigController reconciliation failed: \"secret/node-kubeconfigs\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:38.929117783Z E1024 13:28:38.929035       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:28:38.929764983Z E1024 13:28:38.929717       1 leaderelection.go:436] error retrieving resource lock openshift-kube-apiserver-operator/kube-apiserver-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:39.172409152Z E1024 13:28:39.172336       1 base_controller.go:271] "Unhandled Error" err="PruneController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-10-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:39.778882077Z I1024 13:28:39.778786       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:28:39.782563228Z E1024 13:28:39.782501       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:39.782563228Z I1024 13:28:39.782520       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:40.472879714Z E1024 13:28:40.472825       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.180166888925a995  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:25c703bd-fced-4623-ab7c-91be89cc0822,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 10 count 1 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:27:48.489513365 +0000 UTC m=+582.341133190,LastTimestamp:2024-10-24 13:27:48.489513365 +0000 UTC m=+582.341133190,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:28:42.224196563Z E1024 13:28:42.224144       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:43.537502055Z I1024 13:28:43.537433       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 10 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:43.539959175Z W1024 13:28:43.539913       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:28:43.539959175Z W1024 13:28:43.539942       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:28:43.539959175Z W1024 13:28:43.539950       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:28:43.540727125Z E1024 13:28:43.540680       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-Installer\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-Installer&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:43.630671494Z I1024 13:28:43.630585       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:28:43.633537624Z E1024 13:28:43.633495       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:43.633537624Z I1024 13:28:43.633516       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:43.656836084Z E1024 13:28:43.656793       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:43.703015594Z E1024 13:28:43.702962       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.18016687e23cc229  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:25c703bd-fced-4623-ab7c-91be89cc0822,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/sa-token-signing-certs-11 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:27:45.689231913 +0000 UTC m=+579.540851737,LastTimestamp:2024-10-24 13:27:45.689231913 +0000 UTC m=+579.540851737,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:28:44.633818138Z E1024 13:28:44.633724       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:44.836953168Z E1024 13:28:44.836908       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:45.025600196Z E1024 13:28:45.025532       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:45.028735136Z E1024 13:28:45.028682       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:45.849173281Z E1024 13:28:45.849104       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:46.739567856Z E1024 13:28:46.739504       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:46.778555946Z E1024 13:28:46.778500       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:47.772664230Z E1024 13:28:47.772606       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:50.475066844Z E1024 13:28:50.474993       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.180166888925a995  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:25c703bd-fced-4623-ab7c-91be89cc0822,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 10 count 1 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:27:48.489513365 +0000 UTC m=+582.341133190,LastTimestamp:2024-10-24 13:27:48.489513365 +0000 UTC m=+582.341133190,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:28:52.478047561Z E1024 13:28:52.478001       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:53.659007544Z E1024 13:28:53.658939       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:53.704514823Z E1024 13:28:53.704463       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.18016687e23cc229  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:25c703bd-fced-4623-ab7c-91be89cc0822,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/sa-token-signing-certs-11 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:27:45.689231913 +0000 UTC m=+579.540851737,LastTimestamp:2024-10-24 13:27:45.689231913 +0000 UTC m=+579.540851737,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:28:58.678313504Z E1024 13:28:58.678246       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml\" (string): Get \"https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml\" (string): Get \"https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/api-usage.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/audit-errors.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-requests.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-basic.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/podsecurity-violations.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/alerts/kube-apiserver-slos-extended.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeAPIServerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=KubeAPIServerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:29:00.477234773Z E1024 13:29:00.477169       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.180166888925a995  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:25c703bd-fced-4623-ab7c-91be89cc0822,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 10 count 1 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:27:48.489513365 +0000 UTC m=+582.341133190,LastTimestamp:2024-10-24 13:27:48.489513365 +0000 UTC m=+582.341133190,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:29:04.065175561Z I1024 13:29:04.065075       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:29:04.065175561Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:29:04.065175561Z  CurrentRevision: (int32) 0,
2024-10-24T13:29:04.065175561Z  TargetRevision: (int32) 10,
2024-10-24T13:29:04.065175561Z  LastFailedRevision: (int32) 10,
2024-10-24T13:29:04.065175561Z  LastFailedTime: (*v1.Time)(0xc00653e7b0)(2024-10-24 13:29:04.064948261 +0000 UTC m=+657.916568096),
2024-10-24T13:29:04.065175561Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:29:04.065175561Z  LastFailedCount: (int) 1,
2024-10-24T13:29:04.065175561Z  LastFallbackCount: (int) 0,
2024-10-24T13:29:04.065175561Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:29:04.065175561Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:29:04.065175561Z  }
2024-10-24T13:29:04.065175561Z }
2024-10-24T13:29:04.065175561Z  because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:04.065175561Z W1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:04.065175561Z W1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:04.065175561Z W1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:04.065175561Z W1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:04.065175561Z W1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:04.065175561Z W1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:04.065175561Z F1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:29:04.065260561Z I1024 13:29:04.065086       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:04.065260561Z W1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:04.065260561Z W1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:04.065260561Z W1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:04.065260561Z W1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:04.065260561Z W1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:04.065260561Z W1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:04.065260561Z F1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:29:04.067868101Z W1024 13:29:04.067805       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:29:04.067868101Z W1024 13:29:04.067843       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:29:04.067868101Z W1024 13:29:04.067852       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:29:20.749227104Z I1024 13:29:20.749141       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:29:20.771730484Z I1024 13:29:20.771650       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-11 -n openshift-kube-apiserver because it was missing
2024-10-24T13:29:20.783427994Z I1024 13:29:20.783338       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-11 -n openshift-kube-apiserver because it was missing
2024-10-24T13:29:20.796493714Z I1024 13:29:20.796409       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-11 -n openshift-kube-apiserver because it was missing
2024-10-24T13:29:20.821647664Z I1024 13:29:20.821582       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-11 -n openshift-kube-apiserver because it was missing
2024-10-24T13:29:20.837983344Z I1024 13:29:20.837922       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-11 -n openshift-kube-apiserver because it was missing
2024-10-24T13:29:20.851844654Z I1024 13:29:20.851762       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-11 -n openshift-kube-apiserver because it was missing
2024-10-24T13:29:20.867266814Z I1024 13:29:20.867200       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:29:20.868879534Z W1024 13:29:20.868835       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:29:20.868879534Z W1024 13:29:20.868852       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:29:34.091635090Z I1024 13:29:34.091579       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:39.111704738Z I1024 13:29:39.111634       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:40.194683771Z I1024 13:29:40.194618       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:41.990178590Z I1024 13:29:41.990108       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:42.719679315Z I1024 13:29:42.719618       1 reflector.go:368] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:43.630902890Z I1024 13:29:43.630809       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:29:43.666106319Z I1024 13:29:43.666020       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMapCreateFailed' Failed to create ConfigMap/sa-token-signing-certs-11 -n openshift-kube-apiserver: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:29:43.689155169Z E1024 13:29:43.689085       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": KubeAPIServer.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:29:43.689155169Z I1024 13:29:43.689121       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:29:43.700066529Z I1024 13:29:43.699997       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:29:43.733416179Z I1024 13:29:43.733329       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMapCreateFailed' Failed to create ConfigMap/sa-token-signing-certs-11 -n openshift-kube-apiserver: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:29:43.740427079Z I1024 13:29:43.740389       1 reflector.go:368] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:43.740647459Z I1024 13:29:43.740613       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX
2024-10-24T13:29:43.741083659Z I1024 13:29:43.741033       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:29:43.761957369Z E1024 13:29:43.761928       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": KubeAPIServer.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:29:43.761989639Z I1024 13:29:43.761961       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:29:43.778434339Z I1024 13:29:43.778351       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:29:43.803191188Z I1024 13:29:43.803051       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMapCreateFailed' Failed to create ConfigMap/sa-token-signing-certs-11 -n openshift-kube-apiserver: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:29:43.829812818Z E1024 13:29:43.829743       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": KubeAPIServer.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:29:43.829857668Z I1024 13:29:43.829803       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:29:43.863471738Z I1024 13:29:43.863379       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:29:44.134784976Z I1024 13:29:44.134682       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMapCreateFailed' Failed to create ConfigMap/sa-token-signing-certs-11 -n openshift-kube-apiserver: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:29:44.163437326Z E1024 13:29:44.163386       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": KubeAPIServer.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:29:44.163480816Z I1024 13:29:44.163447       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:29:44.210232846Z I1024 13:29:44.210142       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:29:44.525599104Z I1024 13:29:44.525533       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:44.736079053Z I1024 13:29:44.735990       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMapCreateFailed' Failed to create ConfigMap/sa-token-signing-certs-11 -n openshift-kube-apiserver: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:29:44.768346562Z E1024 13:29:44.768286       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": KubeAPIServer.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:29:44.768411652Z I1024 13:29:44.768361       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:29:44.854443861Z I1024 13:29:44.854360       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:29:45.514611967Z I1024 13:29:45.514550       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:45.527149357Z I1024 13:29:45.527068       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:45.528282987Z E1024 13:29:45.528206       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:29:46.120771983Z I1024 13:29:46.120688       1 request.go:700] Waited for 1.095658553s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:29:46.433620621Z I1024 13:29:46.433543       1 reflector.go:368] Caches populated for *v1.Image from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:46.926486908Z I1024 13:29:46.926419       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:47.129390107Z I1024 13:29:47.129308       1 termination_observer.go:130] Observed termination of API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0" at 2024-10-24 13:29:00 +0000 UTC
2024-10-24T13:29:47.156368997Z I1024 13:29:47.156313       1 reflector.go:368] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:47.321470406Z I1024 13:29:47.321393       1 request.go:700] Waited for 1.792848698s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:29:47.736820103Z I1024 13:29:47.736712       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMapCreateFailed' Failed to create ConfigMap/sa-token-signing-certs-11 -n openshift-kube-apiserver: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:29:47.761064603Z E1024 13:29:47.761006       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": KubeAPIServer.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:29:47.761183933Z I1024 13:29:47.761077       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:29:47.927408741Z I1024 13:29:47.927315       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:29:48.520609508Z I1024 13:29:48.520543       1 request.go:700] Waited for 1.691860169s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T13:29:48.928394065Z E1024 13:29:48.928333       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:29:48.930253715Z E1024 13:29:48.930212       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:29:49.325285283Z I1024 13:29:49.325126       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:49.521207142Z I1024 13:29:49.521149       1 request.go:700] Waited for 1.717542329s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts?resourceVersion=28835
2024-10-24T13:29:49.523770272Z I1024 13:29:49.523714       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:50.097985208Z I1024 13:29:50.097919       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:50.098157738Z I1024 13:29:50.098106       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2024-10-24T13:29:50.521502765Z I1024 13:29:50.521441       1 request.go:700] Waited for 1.58941493s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:29:51.135925051Z I1024 13:29:51.135833       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMapCreateFailed' Failed to create ConfigMap/sa-token-signing-certs-11 -n openshift-kube-apiserver: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:29:51.176328171Z E1024 13:29:51.176264       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": KubeAPIServer.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:29:51.176389061Z I1024 13:29:51.176323       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:29:51.501839809Z I1024 13:29:51.501728       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:29:51.721361857Z I1024 13:29:51.721290       1 request.go:700] Waited for 1.306383841s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:29:51.928235276Z E1024 13:29:51.928166       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:29:51.928235276Z E1024 13:29:51.928207       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:29:51.929972626Z E1024 13:29:51.929924       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:29:52.920902970Z I1024 13:29:52.920828       1 request.go:700] Waited for 1.387287131s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:29:53.737702035Z I1024 13:29:53.737635       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMapCreateFailed' Failed to create ConfigMap/sa-token-signing-certs-11 -n openshift-kube-apiserver: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:29:53.762344275Z E1024 13:29:53.762304       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": KubeAPIServer.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:29:53.762382335Z I1024 13:29:53.762347       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:29:54.408081240Z I1024 13:29:54.408016       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:29:55.728155142Z I1024 13:29:55.728052       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:55.728155142Z W1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:55.728155142Z W1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:55.728155142Z W1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:55.728155142Z W1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:55.728155142Z W1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:55.728155142Z W1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:55.728155142Z F1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:29:55.728155142Z I1024 13:29:55.728054       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:29:55.728155142Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:29:55.728155142Z  CurrentRevision: (int32) 0,
2024-10-24T13:29:55.728155142Z  TargetRevision: (int32) 10,
2024-10-24T13:29:55.728155142Z  LastFailedRevision: (int32) 10,
2024-10-24T13:29:55.728155142Z  LastFailedTime: (*v1.Time)(0xc00654f2d8)(2024-10-24 13:29:55.727918432 +0000 UTC m=+709.579538277),
2024-10-24T13:29:55.728155142Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:29:55.728155142Z  LastFailedCount: (int) 1,
2024-10-24T13:29:55.728155142Z  LastFallbackCount: (int) 0,
2024-10-24T13:29:55.728155142Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:29:55.728155142Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:29:55.728155142Z  }
2024-10-24T13:29:55.728155142Z }
2024-10-24T13:29:55.728155142Z  because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:55.728155142Z W1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:55.728155142Z W1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:55.728155142Z W1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:55.728155142Z W1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:55.728155142Z W1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:55.728155142Z W1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:55.728155142Z F1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:29:55.730737322Z W1024 13:29:55.730683       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:29:55.730737322Z W1024 13:29:55.730708       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:29:55.730737322Z W1024 13:29:55.730715       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:29:55.935539400Z I1024 13:29:55.935454       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMapCreateFailed' Failed to create ConfigMap/sa-token-signing-certs-11 -n openshift-kube-apiserver: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:29:55.960288820Z E1024 13:29:55.960191       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": KubeAPIServer.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:29:55.960416640Z I1024 13:29:55.960349       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:29:56.473581267Z I1024 13:29:56.473503       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:56.888684784Z I1024 13:29:56.888623       1 reflector.go:368] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:56.928516114Z I1024 13:29:56.928462       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:56.935324654Z I1024 13:29:56.934871       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:29:57.524515680Z I1024 13:29:57.524440       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:57.611169720Z I1024 13:29:57.611116       1 reflector.go:368] Caches populated for monitoring.coreos.com/v1, Resource=prometheusrules from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:58.121151306Z I1024 13:29:58.121085       1 request.go:700] Waited for 1.186356872s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T13:29:59.142031470Z I1024 13:29:59.141948       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMapCreateFailed' Failed to create ConfigMap/sa-token-signing-certs-11 -n openshift-kube-apiserver: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:29:59.174616720Z E1024 13:29:59.174548       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": KubeAPIServer.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:29:59.174672910Z I1024 13:29:59.174634       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:29:59.179692929Z I1024 13:29:59.179646       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:29:59.520842468Z I1024 13:29:59.520771       1 request.go:700] Waited for 1.102036962s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services?resourceVersion=29314
2024-10-24T13:29:59.524263538Z I1024 13:29:59.524215       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:59.735947886Z I1024 13:29:59.735880       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:29:59.735947886Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:29:59.735947886Z  CurrentRevision: (int32) 0,
2024-10-24T13:29:59.735947886Z  TargetRevision: (int32) 10,
2024-10-24T13:29:59.735947886Z  LastFailedRevision: (int32) 10,
2024-10-24T13:29:59.735947886Z  LastFailedTime: (*v1.Time)(0xc00246f5c0)(2024-10-24 13:29:59.735784666 +0000 UTC m=+713.587404481),
2024-10-24T13:29:59.735947886Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:29:59.735947886Z  LastFailedCount: (int) 1,
2024-10-24T13:29:59.735947886Z  LastFallbackCount: (int) 0,
2024-10-24T13:29:59.735947886Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:29:59.735947886Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:29:59.735947886Z  }
2024-10-24T13:29:59.735947886Z }
2024-10-24T13:29:59.735947886Z  because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.735947886Z W1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.735947886Z W1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.735947886Z W1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.735947886Z W1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.735947886Z W1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.735947886Z W1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.735947886Z F1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:29:59.736020976Z I1024 13:29:59.735942       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.736020976Z W1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.736020976Z W1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.736020976Z W1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.736020976Z W1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.736020976Z W1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.736020976Z W1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.736020976Z F1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:29:59.737946656Z W1024 13:29:59.737890       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:29:59.737946656Z W1024 13:29:59.737909       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:29:59.737946656Z W1024 13:29:59.737914       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:29:59.933519995Z I1024 13:29:59.933442       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:00.521240331Z I1024 13:30:00.521153       1 request.go:700] Waited for 1.187493562s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-10-24T13:30:01.135438087Z I1024 13:30:01.135375       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMapCreateFailed' Failed to create ConfigMap/sa-token-signing-certs-11 -n openshift-kube-apiserver: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:30:01.165318617Z E1024 13:30:01.165272       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": KubeAPIServer.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:30:01.165318617Z I1024 13:30:01.165304       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:30:01.167978087Z I1024 13:30:01.167938       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:01.376981666Z I1024 13:30:01.376924       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:01.740902554Z I1024 13:30:01.740804       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required configmap/config has changed"
2024-10-24T13:30:03.335235313Z I1024 13:30:03.335137       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMapCreateFailed' Failed to create ConfigMap/sa-token-signing-certs-11 -n openshift-kube-apiserver: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:30:03.366523933Z E1024 13:30:03.366452       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": KubeAPIServer.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:30:03.366586893Z I1024 13:30:03.366548       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 11: configmaps "sa-token-signing-certs-11" already exists
2024-10-24T13:30:03.728813031Z I1024 13:30:03.728710       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:30:03.728813031Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:30:03.728813031Z  CurrentRevision: (int32) 0,
2024-10-24T13:30:03.728813031Z  TargetRevision: (int32) 10,
2024-10-24T13:30:03.728813031Z  LastFailedRevision: (int32) 10,
2024-10-24T13:30:03.728813031Z  LastFailedTime: (*v1.Time)(0xc0052ffa58)(2024-10-24 13:30:03.728601811 +0000 UTC m=+717.580221636),
2024-10-24T13:30:03.728813031Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:30:03.728813031Z  LastFailedCount: (int) 1,
2024-10-24T13:30:03.728813031Z  LastFallbackCount: (int) 0,
2024-10-24T13:30:03.728813031Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:30:03.728813031Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:30:03.728813031Z  }
2024-10-24T13:30:03.728813031Z }
2024-10-24T13:30:03.728813031Z  because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:03.728813031Z W1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:03.728813031Z W1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:03.728813031Z W1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:03.728813031Z W1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:03.728813031Z W1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:03.728813031Z W1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:03.728813031Z F1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:30:03.728908561Z I1024 13:30:03.728838       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:03.728908561Z W1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:03.728908561Z W1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:03.728908561Z W1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:03.728908561Z W1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:03.728908561Z W1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:03.728908561Z W1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:03.728908561Z F1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:30:03.731046771Z W1024 13:30:03.731003       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:30:03.731046771Z W1024 13:30:03.731023       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:30:03.731077671Z W1024 13:30:03.731049       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:30:03.756143740Z I1024 13:30:03.756101       1 reflector.go:368] Caches populated for *v1.KubeAPIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:07.490712727Z I1024 13:30:07.490655       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:09.021011677Z I1024 13:30:09.020942       1 reflector.go:368] Caches populated for *v1.MutatingWebhookConfiguration from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:09.281441725Z I1024 13:30:09.281370       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:09.281946785Z I1024 13:30:09.281901       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:30:09.722832793Z I1024 13:30:09.722713       1 reflector.go:368] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:11.758937649Z I1024 13:30:11.758867       1 reflector.go:368] Caches populated for *v1.CustomResourceDefinition from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:11.759449619Z I1024 13:30:11.759407       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:30:11.759806759Z I1024 13:30:11.759784       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:30:11.760212089Z I1024 13:30:11.760149       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:30:11.760454089Z I1024 13:30:11.760428       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:30:12.152978077Z I1024 13:30:12.152902       1 reflector.go:368] Caches populated for *v1.Proxy from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:12.527286445Z I1024 13:30:12.527218       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubeapiservers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:12.528402575Z I1024 13:30:12.528292       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 10:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:33Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 10","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:30:12.528440345Z I1024 13:30:12.528416       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:30:12.531272395Z W1024 13:30:12.531231       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:30:12.531272395Z W1024 13:30:12.531256       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:30:12.536209164Z W1024 13:30:12.534573       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:30:12.536209164Z I1024 13:30:12.534830       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:12.545825915Z I1024 13:30:12.545708       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]" to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 10:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: "
2024-10-24T13:30:12.559547684Z E1024 13:30:12.559496       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": KubeAPIServer.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:30:12.574544094Z I1024 13:30:12.574467       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:30:12.579246274Z W1024 13:30:12.578647       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:30:12.579246274Z W1024 13:30:12.578680       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:30:12.589072294Z I1024 13:30:12.588991       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-11-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-apiserver because it was missing
2024-10-24T13:30:12.614385264Z I1024 13:30:12.614321       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nInstallerControllerDegraded: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11\nNodeInstallerDegraded: 1 nodes are failing on revision 10:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::InstallerController_Error::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:33Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 11","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:30:12.617623184Z I1024 13:30:12.617582       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:30:12.620239134Z E1024 13:30:12.620117       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:12.622333634Z I1024 13:30:12.622255       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:12.624233914Z E1024 13:30:12.624180       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:12.627680904Z I1024 13:30:12.627649       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:12.630190104Z E1024 13:30:12.630113       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:12.638142774Z I1024 13:30:12.638097       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 10:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: " to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nInstallerControllerDegraded: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11\nNodeInstallerDegraded: 1 nodes are failing on revision 10:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ",Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 10" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 11",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 10" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 11"
2024-10-24T13:30:12.639821794Z I1024 13:30:12.639790       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:12.640301304Z E1024 13:30:12.640254       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:12.643517594Z E1024 13:30:12.643444       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": KubeAPIServer.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:30:12.648023894Z W1024 13:30:12.647966       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:30:12.648023894Z W1024 13:30:12.647995       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:30:12.656181024Z I1024 13:30:12.656078       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:12.657985954Z E1024 13:30:12.657936       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:12.673887284Z E1024 13:30:12.673807       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": KubeAPIServer.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:30:12.739881163Z I1024 13:30:12.739804       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:12.741712543Z E1024 13:30:12.741678       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:12.904596632Z I1024 13:30:12.904505       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:12.906521622Z E1024 13:30:12.906474       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:13.229895330Z I1024 13:30:13.229825       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:13.232316280Z E1024 13:30:13.232265       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:13.301900459Z I1024 13:30:13.301815       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:13.303091930Z E1024 13:30:13.303031       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:13.610066078Z W1024 13:30:13.609995       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:30:13.610066078Z W1024 13:30:13.610023       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:30:13.634894058Z E1024 13:30:13.634848       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": KubeAPIServer.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:30:13.728639377Z I1024 13:30:13.728591       1 request.go:700] Waited for 1.149820443s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:30:13.874819806Z I1024 13:30:13.874679       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:13.876508006Z E1024 13:30:13.876456       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:14.455182223Z I1024 13:30:14.455095       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:14.456418433Z E1024 13:30:14.456359       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:14.928999420Z I1024 13:30:14.928921       1 request.go:700] Waited for 1.790857029s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:30:15.737226965Z E1024 13:30:15.737158       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:30:15.737226965Z E1024 13:30:15.737201       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:15.741039225Z E1024 13:30:15.740996       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:30:15.765593064Z I1024 13:30:15.765536       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:15.767084564Z E1024 13:30:15.767040       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:16.128329842Z I1024 13:30:16.128252       1 request.go:700] Waited for 1.807821149s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:30:16.351095901Z I1024 13:30:16.350674       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-11-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-apiserver because it was missing
2024-10-24T13:30:16.352522231Z I1024 13:30:16.352457       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:16.353140730Z E1024 13:30:16.353084       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:16.368822090Z I1024 13:30:16.368742       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:16.370054201Z E1024 13:30:16.370022       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:16.390296930Z I1024 13:30:16.390235       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:16.392785580Z E1024 13:30:16.392731       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:16.439223680Z I1024 13:30:16.439129       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:16.441280840Z E1024 13:30:16.441217       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:17.128795435Z I1024 13:30:17.128707       1 request.go:700] Waited for 1.982342618s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets?resourceVersion=29031
2024-10-24T13:30:17.145711655Z I1024 13:30:17.145649       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:17.332011544Z I1024 13:30:17.331955       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:17.333617714Z E1024 13:30:17.333565       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:18.122364709Z I1024 13:30:18.122201       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:18.124932689Z E1024 13:30:18.124860       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:18.328444918Z I1024 13:30:18.328379       1 request.go:700] Waited for 1.791187989s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-10-24T13:30:18.935366944Z E1024 13:30:18.935312       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:30:18.935366944Z E1024 13:30:18.935352       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:18.936999664Z E1024 13:30:18.936964       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:30:19.328723071Z I1024 13:30:19.328661       1 request.go:700] Waited for 1.391419112s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T13:30:19.396300741Z I1024 13:30:19.396224       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:19.400796951Z E1024 13:30:19.400700       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:19.545933420Z I1024 13:30:19.545868       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-11-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-apiserver because it was missing
2024-10-24T13:30:19.546061510Z I1024 13:30:19.546026       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:19.547454010Z E1024 13:30:19.547398       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:19.560284650Z I1024 13:30:19.560203       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:19.560797620Z E1024 13:30:19.560725       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:19.578044900Z I1024 13:30:19.577960       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:19.579011250Z E1024 13:30:19.578947       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:19.942091608Z I1024 13:30:19.942027       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:19.945430537Z I1024 13:30:19.944844       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11
2024-10-24T13:30:19.948189128Z E1024 13:30:19.948120       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-Installer reconciliation failed: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11"
2024-10-24T13:30:19.950080827Z W1024 13:30:19.949574       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:30:19.950080827Z W1024 13:30:19.949609       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:30:19.973333277Z E1024 13:30:19.973227       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-RevisionController\": KubeAPIServer.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:30:20.329179815Z I1024 13:30:20.329098       1 request.go:700] Waited for 1.58933328s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:30:20.936224661Z I1024 13:30:20.936156       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:21.529053457Z I1024 13:30:21.528994       1 request.go:700] Waited for 1.794313248s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2024-10-24T13:30:22.530376271Z I1024 13:30:22.530299       1 request.go:700] Waited for 2.189843356s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:30:22.736024650Z E1024 13:30:22.735954       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:30:22.736024650Z E1024 13:30:22.735986       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:22.738504360Z E1024 13:30:22.738436       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:30:23.333200046Z I1024 13:30:23.333127       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:23.728613393Z I1024 13:30:23.728553       1 request.go:700] Waited for 2.188549007s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-10-24T13:30:23.935362052Z I1024 13:30:23.935296       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:24.928889996Z I1024 13:30:24.928820       1 request.go:700] Waited for 1.790320239s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T13:30:25.936168550Z I1024 13:30:25.936102       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:26.128711168Z I1024 13:30:26.128630       1 request.go:700] Waited for 1.590014s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:30:26.334891977Z I1024 13:30:26.334803       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:26.535660996Z E1024 13:30:26.535609       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:30:26.535660996Z E1024 13:30:26.535644       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:26.537777856Z E1024 13:30:26.537738       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:30:26.539914546Z E1024 13:30:26.539857       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:30:26.539914546Z E1024 13:30:26.539879       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:27.328266861Z I1024 13:30:27.328201       1 request.go:700] Waited for 1.59249241s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:30:28.328725354Z I1024 13:30:28.328674       1 request.go:700] Waited for 1.192979942s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-10-24T13:30:28.535406323Z I1024 13:30:28.535348       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:30:28.535406323Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:30:28.535406323Z  CurrentRevision: (int32) 0,
2024-10-24T13:30:28.535406323Z  TargetRevision: (int32) 11,
2024-10-24T13:30:28.535406323Z  LastFailedRevision: (int32) 10,
2024-10-24T13:30:28.535406323Z  LastFailedTime: (*v1.Time)(0xc0025d7920)(2024-10-24 13:30:03 +0000 UTC),
2024-10-24T13:30:28.535406323Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:30:28.535406323Z  LastFailedCount: (int) 1,
2024-10-24T13:30:28.535406323Z  LastFallbackCount: (int) 0,
2024-10-24T13:30:28.535406323Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:30:28.535406323Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:30:28.535406323Z  }
2024-10-24T13:30:28.535406323Z }
2024-10-24T13:30:28.535406323Z  because new revision pending
2024-10-24T13:30:28.537693023Z W1024 13:30:28.537660       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:30:28.537693023Z W1024 13:30:28.537679       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:30:28.537693023Z W1024 13:30:28.537685       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:30:28.537721253Z W1024 13:30:28.537690       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:30:28.537721253Z W1024 13:30:28.537695       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:30:28.572230773Z I1024 13:30:28.572163       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:33Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 11","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:30:28.572607553Z I1024 13:30:28.572557       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:30:28.589352453Z I1024 13:30:28.588666       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nInstallerControllerDegraded: missing required resources: configmaps: kube-apiserver-audit-policies-11,sa-token-signing-certs-11\nNodeInstallerDegraded: 1 nodes are failing on revision 10:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: " to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:30:28.617692542Z I1024 13:30:28.617600       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:30:28.937889240Z E1024 13:30:28.937817       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:30:29.029574690Z I1024 13:30:29.029519       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:29.328962888Z I1024 13:30:29.328871       1 request.go:700] Waited for 1.192298622s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-11-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:30:30.440789751Z I1024 13:30:30.440670       1 reflector.go:368] Caches populated for *v1alpha1.StorageVersionMigration from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:30.528779220Z I1024 13:30:30.528708       1 request.go:700] Waited for 1.790121838s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:30:31.058676537Z I1024 13:30:31.058604       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:31.728639703Z I1024 13:30:31.728573       1 request.go:700] Waited for 1.5904143s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:30:32.928877145Z I1024 13:30:32.928811       1 request.go:700] Waited for 1.58956865s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:34.129058138Z I1024 13:30:34.128998       1 request.go:700] Waited for 1.191674183s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:30:34.336027516Z E1024 13:30:34.335977       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:30:34.336027516Z E1024 13:30:34.336011       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:34.337683326Z E1024 13:30:34.337644       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:30:35.328260010Z I1024 13:30:35.328190       1 request.go:700] Waited for 1.191540212s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-10-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:30:35.336058420Z I1024 13:30:35.335988       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:30:35.336058420Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:30:35.336058420Z  CurrentRevision: (int32) 0,
2024-10-24T13:30:35.336058420Z  TargetRevision: (int32) 11,
2024-10-24T13:30:35.336058420Z  LastFailedRevision: (int32) 10,
2024-10-24T13:30:35.336058420Z  LastFailedTime: (*v1.Time)(0xc00643bb30)(2024-10-24 13:30:03 +0000 UTC),
2024-10-24T13:30:35.336058420Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:30:35.336058420Z  LastFailedCount: (int) 1,
2024-10-24T13:30:35.336058420Z  LastFallbackCount: (int) 0,
2024-10-24T13:30:35.336058420Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:30:35.336058420Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:30:35.336058420Z  }
2024-10-24T13:30:35.336058420Z }
2024-10-24T13:30:35.336058420Z  because new revision pending
2024-10-24T13:30:37.945064484Z I1024 13:30:37.944991       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-11-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-apiserver because it was missing
2024-10-24T13:30:37.947126973Z E1024 13:30:37.947055       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:30:37.947126973Z E1024 13:30:37.947084       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:38.136257172Z I1024 13:30:38.136153       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:30:39.528370673Z I1024 13:30:39.528285       1 request.go:700] Waited for 1.170113652s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-apiserver/secrets?resourceVersion=29541
2024-10-24T13:30:39.532547033Z I1024 13:30:39.532480       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:39.749529111Z E1024 13:30:39.749473       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:30:39.931322040Z I1024 13:30:39.931247       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:39.931851400Z I1024 13:30:39.931811       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:30:40.530793136Z I1024 13:30:40.530718       1 reflector.go:368] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:40.531309247Z I1024 13:30:40.531228       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:30:40.728431185Z I1024 13:30:40.728362       1 request.go:700] Waited for 1.59260036s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:30:42.135611406Z E1024 13:30:42.135563       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:30:42.135611406Z E1024 13:30:42.135598       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:42.137870466Z E1024 13:30:42.137826       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:30:42.539415274Z E1024 13:30:42.539362       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:42.744540722Z I1024 13:30:42.744484       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:43.137312080Z I1024 13:30:43.137250       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:30:43.292409709Z I1024 13:30:43.291823       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:30:44.137615234Z E1024 13:30:44.137543       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:30:44.139273994Z E1024 13:30:44.139226       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:30:44.396125352Z I1024 13:30:44.396025       1 reflector.go:368] Caches populated for *v1.SecurityContextConstraints from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:46.128605321Z I1024 13:30:46.128532       1 request.go:700] Waited for 1.102917554s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:30:46.282661470Z I1024 13:30:46.282608       1 reflector.go:368] Caches populated for *v1.OAuth from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:46.335721550Z E1024 13:30:46.335673       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:30:46.335721550Z E1024 13:30:46.335698       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:46.337288040Z E1024 13:30:46.337239       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:30:47.335073244Z I1024 13:30:47.334995       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:30:47.731468791Z I1024 13:30:47.731406       1 reflector.go:368] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:48.308000617Z I1024 13:30:48.307943       1 reflector.go:368] Caches populated for *v1.Authentication from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:49.535867060Z E1024 13:30:49.535798       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:30:49.535867060Z E1024 13:30:49.535835       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:49.538260260Z E1024 13:30:49.538213       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:30:52.588821790Z E1024 13:30:52.587262       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:52.611080440Z E1024 13:30:52.610990       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:30:52.613188650Z E1024 13:30:52.613157       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:30:53.930593591Z I1024 13:30:53.930513       1 reflector.go:368] Caches populated for *v1.ValidatingWebhookConfiguration from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:58.294803333Z I1024 13:30:58.294744       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:31:00.584783559Z E1024 13:31:00.584702       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:31:00.584830699Z E1024 13:31:00.584821       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:00.587126499Z E1024 13:31:00.587054       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:31:00.973881556Z I1024 13:31:00.973832       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:31:02.374175447Z E1024 13:31:02.374101       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:31:02.374175447Z E1024 13:31:02.374143       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:02.382618547Z E1024 13:31:02.382530       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:31:03.974098487Z E1024 13:31:03.974026       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:31:03.974098487Z E1024 13:31:03.974053       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:03.975767487Z E1024 13:31:03.975717       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:31:04.766337751Z I1024 13:31:04.766249       1 request.go:700] Waited for 1.103089923s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:31:05.389392408Z I1024 13:31:05.389298       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:31:05.773558545Z E1024 13:31:05.773484       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:31:05.773558545Z E1024 13:31:05.773512       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:05.775335395Z E1024 13:31:05.775287       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:31:07.375621175Z E1024 13:31:07.375517       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:31:07.375621175Z E1024 13:31:07.375549       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:07.377539465Z E1024 13:31:07.377494       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:31:08.773820916Z I1024 13:31:08.773721       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:31:09.582709561Z E1024 13:31:09.582639       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:31:09.582709561Z E1024 13:31:09.582672       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:09.584893530Z E1024 13:31:09.584848       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:31:15.201889585Z E1024 13:31:15.201769       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:31:15.201889585Z E1024 13:31:15.201798       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:15.203557515Z E1024 13:31:15.203491       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:31:16.722383745Z I1024 13:31:16.722275       1 termination_observer.go:236] Observed event "TerminationPreShutdownHooksFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0" (last termination at 2024-10-24 13:29:00 +0000 UTC) at 2024-10-24 13:31:16 +0000 UTC
2024-10-24T13:31:17.855123178Z E1024 13:31:17.855073       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:31:17.855123178Z E1024 13:31:17.855095       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:17.857124208Z E1024 13:31:17.857075       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:31:18.245142316Z I1024 13:31:18.245065       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:31:19.845958865Z E1024 13:31:19.845894       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:31:19.845958865Z E1024 13:31:19.845924       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:19.847926965Z E1024 13:31:19.847884       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:31:20.845096049Z E1024 13:31:20.845046       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:31:20.845210439Z E1024 13:31:20.845196       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:20.847365689Z E1024 13:31:20.847340       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:31:21.246547987Z I1024 13:31:21.246479       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because waiting for static pod of revision 11, found 9
2024-10-24T13:31:25.581081308Z E1024 13:31:25.581032       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:31:25.581170008Z E1024 13:31:25.581155       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:25.585119928Z E1024 13:31:25.585090       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:31:28.295315691Z I1024 13:31:28.295233       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:31:30.780524985Z E1024 13:31:30.780470       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:30.799517015Z E1024 13:31:30.799464       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:31:30.801047515Z E1024 13:31:30.801000       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:31:31.389424427Z I1024 13:31:31.389359       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because waiting for static pod of revision 11, found 9
2024-10-24T13:31:46.104211807Z E1024 13:31:46.104128       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:31:46.104211807Z E1024 13:31:46.104181       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:46.106535217Z E1024 13:31:46.106489       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:31:47.723490724Z I1024 13:31:47.723410       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:31:56.133954745Z E1024 13:31:56.133888       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:31:56.133954745Z E1024 13:31:56.133919       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:56.148133705Z E1024 13:31:56.148054       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:32:28.691652151Z I1024 13:32:28.691572       1 termination_observer.go:236] Observed event "TerminationGracefulTerminationFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0" (last termination at 2024-10-24 13:29:00 +0000 UTC) at 2024-10-24 13:32:28 +0000 UTC
2024-10-24T13:32:33.036574479Z E1024 13:32:33.036494       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:32:33.037138099Z E1024 13:32:33.037090       1 leaderelection.go:436] error retrieving resource lock openshift-kube-apiserver-operator/kube-apiserver-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:33.672152440Z E1024 13:32:33.672083       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:33.681571840Z E1024 13:32:33.681513       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:33.697103449Z E1024 13:32:33.697043       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:33.722097539Z E1024 13:32:33.722030       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:33.767896379Z E1024 13:32:33.767824       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:33.853610537Z E1024 13:32:33.853524       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:34.019182805Z E1024 13:32:34.019130       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:34.346135930Z E1024 13:32:34.346064       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:34.992275981Z E1024 13:32:34.992209       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:36.277140173Z E1024 13:32:36.277073       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:38.841909906Z E1024 13:32:38.841846       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:43.673378308Z E1024 13:32:43.673313       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:43.967482054Z E1024 13:32:43.967414       1 base_controller.go:271] "Unhandled Error" err="auditPolicyController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-AuditPolicy\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-AuditPolicy&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:44.635676594Z E1024 13:32:44.635621       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:44.646138664Z E1024 13:32:44.646081       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:44.660555164Z E1024 13:32:44.660513       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:44.686313934Z E1024 13:32:44.686252       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:44.732180453Z E1024 13:32:44.732113       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:44.819028862Z E1024 13:32:44.818963       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:45.034632109Z E1024 13:32:45.034553       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:45.236599296Z E1024 13:32:45.236538       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:45.432552783Z E1024 13:32:45.432494       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:46.032841824Z E1024 13:32:46.032779       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:46.237055042Z E1024 13:32:46.236997       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:47.032965470Z E1024 13:32:47.032886       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:47.235547237Z E1024 13:32:47.235474       1 base_controller.go:271] "Unhandled Error" err="kube-apiserver-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-apiserver-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status?fieldManager=kube-apiserver-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:48.586442658Z E1024 13:32:48.586353       1 base_controller.go:271] "Unhandled Error" err="KubeAPIServerStaticResources-StaticResources reconciliation failed: [\"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:50.288860734Z I1024 13:32:50.288788       1 helpers.go:260] lister was stale at resourceVersion=30819, live get showed resourceVersion=31925
2024-10-24T13:33:00.329914792Z I1024 13:33:00.329846       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because static pod is pending
2024-10-24T13:33:01.588807043Z I1024 13:33:01.588727       1 reflector.go:368] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:01.589298803Z I1024 13:33:01.589231       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:33:04.339515714Z I1024 13:33:04.339442       1 reflector.go:368] Caches populated for *v1.SecurityContextConstraints from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:04.418595973Z I1024 13:33:04.418512       1 reflector.go:368] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:05.371639539Z I1024 13:33:05.371576       1 reflector.go:368] Caches populated for *v1.ValidatingWebhookConfiguration from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:05.537220237Z I1024 13:33:05.537150       1 reflector.go:368] Caches populated for *v1.MutatingWebhookConfiguration from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:05.631388896Z I1024 13:33:05.631337       1 reflector.go:368] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:06.252072747Z I1024 13:33:06.252004       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:06.612828932Z I1024 13:33:06.612739       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:06.760362080Z I1024 13:33:06.760289       1 reflector.go:368] Caches populated for *v1.Image from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:07.511935979Z I1024 13:33:07.511862       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:07.512352219Z I1024 13:33:07.512296       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:33:07.523310509Z I1024 13:33:07.523250       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:07.659099107Z I1024 13:33:07.659048       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:07.675173187Z E1024 13:33:07.675101       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:33:07.675173187Z E1024 13:33:07.675136       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:33:07.677526177Z E1024 13:33:07.676812       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:33:07.678237967Z E1024 13:33:07.678182       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:33:07.691992987Z E1024 13:33:07.691932       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:33:07.694097816Z E1024 13:33:07.694022       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:33:08.413055647Z I1024 13:33:08.412981       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:09.460874141Z I1024 13:33:09.460787       1 reflector.go:368] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:09.478183032Z I1024 13:33:09.478112       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:10.851312982Z I1024 13:33:10.851254       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:11.233725086Z I1024 13:33:11.233650       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:12.232007602Z I1024 13:33:12.231939       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:12.428262010Z E1024 13:33:12.428199       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:33:12.428262010Z E1024 13:33:12.428237       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:33:12.430807159Z E1024 13:33:12.430742       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:33:13.819390950Z I1024 13:33:13.819298       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:15.220284770Z I1024 13:33:15.220199       1 reflector.go:368] Caches populated for monitoring.coreos.com/v1, Resource=prometheusrules from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:15.421651617Z E1024 13:33:15.421592       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:33:15.421651617Z E1024 13:33:15.421613       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:33:15.423334747Z E1024 13:33:15.423296       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:33:17.824414933Z E1024 13:33:17.824345       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:33:17.824414933Z E1024 13:33:17.824376       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:33:17.827048593Z E1024 13:33:17.827002       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:33:21.459317611Z E1024 13:33:21.459256       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:33:21.459317611Z E1024 13:33:21.459295       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:33:21.461499641Z E1024 13:33:21.461440       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:33:27.082942301Z I1024 13:33:27.082876       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:29.865686191Z I1024 13:33:29.865607       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:31.536346008Z I1024 13:33:31.536271       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:31.744134045Z I1024 13:33:31.744047       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:33:31.744134045Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:33:31.744134045Z  CurrentRevision: (int32) 11,
2024-10-24T13:33:31.744134045Z  TargetRevision: (int32) 0,
2024-10-24T13:33:31.744134045Z  LastFailedRevision: (int32) 10,
2024-10-24T13:33:31.744134045Z  LastFailedTime: (*v1.Time)(0xc0068e8ea0)(2024-10-24 13:30:03 +0000 UTC),
2024-10-24T13:33:31.744134045Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:33:31.744134045Z  LastFailedCount: (int) 1,
2024-10-24T13:33:31.744134045Z  LastFallbackCount: (int) 0,
2024-10-24T13:33:31.744134045Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:33:31.744134045Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:33:31.744134045Z  }
2024-10-24T13:33:31.744134045Z }
2024-10-24T13:33:31.744134045Z  because static pod is ready
2024-10-24T13:33:31.745947115Z W1024 13:33:31.745905       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:33:31.745947115Z W1024 13:33:31.745920       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:33:31.745947115Z W1024 13:33:31.745924       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:33:31.745947115Z W1024 13:33:31.745929       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:33:31.745947115Z W1024 13:33:31.745932       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:33:31.745947115Z W1024 13:33:31.745935       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T13:33:31.774881854Z I1024 13:33:31.774832       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 0 to 11 because static pod is ready
2024-10-24T13:33:31.860738873Z I1024 13:33:31.860667       1 reflector.go:368] Caches populated for *v1.Authentication from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:33.135277055Z I1024 13:33:33.135226       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:34.352615568Z I1024 13:33:34.352515       1 reflector.go:368] Caches populated for *v1.CustomResourceDefinition from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:34.353072298Z I1024 13:33:34.353028       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:33:34.353395698Z I1024 13:33:34.353373       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:33:34.353717328Z I1024 13:33:34.353689       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:33:34.354018058Z I1024 13:33:34.353970       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:33:35.494273142Z I1024 13:33:35.494207       1 reflector.go:368] Caches populated for *v1.KubeAPIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:36.134072633Z I1024 13:33:36.134023       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:36.153924152Z I1024 13:33:36.153879       1 reflector.go:368] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:36.339556820Z I1024 13:33:36.339488       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:33:36.339556820Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:33:36.339556820Z  CurrentRevision: (int32) 11,
2024-10-24T13:33:36.339556820Z  TargetRevision: (int32) 0,
2024-10-24T13:33:36.339556820Z  LastFailedRevision: (int32) 10,
2024-10-24T13:33:36.339556820Z  LastFailedTime: (*v1.Time)(0xc0032061b0)(2024-10-24 13:30:03 +0000 UTC),
2024-10-24T13:33:36.339556820Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:33:36.339556820Z  LastFailedCount: (int) 1,
2024-10-24T13:33:36.339556820Z  LastFallbackCount: (int) 0,
2024-10-24T13:33:36.339556820Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:33:36.339556820Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:33:36.339556820Z  }
2024-10-24T13:33:36.339556820Z }
2024-10-24T13:33:36.339556820Z  because static pod is ready
2024-10-24T13:33:36.341490090Z W1024 13:33:36.341444       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:33:36.341490090Z W1024 13:33:36.341467       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:33:36.341490090Z W1024 13:33:36.341475       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:33:36.341490090Z W1024 13:33:36.341481       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:33:36.341525460Z W1024 13:33:36.341486       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:33:36.341525460Z W1024 13:33:36.341492       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T13:33:36.380610889Z I1024 13:33:36.380550       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 0 to 11 because static pod is ready
2024-10-24T13:33:36.480235198Z I1024 13:33:36.480164       1 reflector.go:368] Caches populated for *v1.Proxy from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:36.535653647Z I1024 13:33:36.535581       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:36.641980055Z I1024 13:33:36.641937       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:37.330917836Z I1024 13:33:37.330855       1 request.go:700] Waited for 1.175943654s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T13:33:37.786459899Z I1024 13:33:37.786383       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:37.912777047Z I1024 13:33:37.912693       1 reflector.go:368] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:38.150745064Z I1024 13:33:38.150668       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:41.881790931Z E1024 13:33:41.881658       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:33:41.881790931Z E1024 13:33:41.881693       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:33:41.884313281Z E1024 13:33:41.884248       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:33:42.412508563Z I1024 13:33:42.412260       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:33:42.479627032Z I1024 13:33:42.479549       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:33:45.330465302Z I1024 13:33:45.330000       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:45.336176962Z E1024 13:33:45.336113       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:33:45.336284322Z E1024 13:33:45.336271       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:33:45.460095450Z I1024 13:33:45.459477       1 termination_observer.go:130] Observed termination of API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0" at 2024-10-24 13:32:46 +0000 UTC
2024-10-24T13:33:46.832579830Z I1024 13:33:46.832495       1 request.go:700] Waited for 1.002270745s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T13:33:47.243395985Z E1024 13:33:47.243311       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:33:47.244943574Z E1024 13:33:47.244864       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:33:47.244943574Z E1024 13:33:47.244896       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:33:47.436666582Z I1024 13:33:47.436599       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:47.833230676Z I1024 13:33:47.833169       1 request.go:700] Waited for 1.116748374s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-apiserver/secrets?resourceVersion=31477
2024-10-24T13:33:47.836365576Z I1024 13:33:47.836301       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:48.651919524Z I1024 13:33:48.651821       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:49.007026879Z I1024 13:33:49.006965       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:49.033256869Z I1024 13:33:49.033197       1 request.go:700] Waited for 1.39373896s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:33:49.137188148Z I1024 13:33:49.137125       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubeapiservers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:49.138257877Z I1024 13:33:49.138194       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:33:49.138400498Z I1024 13:33:49.138338       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/config\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/kube-apiserver-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/client-ca\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca\": dial tcp 172.30.0.1:443: connect: connection refused","reason":"GuardController_SyncError::KubeAPIServerStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:49.152797177Z I1024 13:33:49.152558       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]" to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/config\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/kube-apiserver-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/client-ca\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca\": dial tcp 172.30.0.1:443: connect: connection refused",Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 11" to "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 11",Available changed from False to True ("StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 11")
2024-10-24T13:33:49.199215487Z I1024 13:33:49.199129       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:33:49.252802006Z I1024 13:33:49.252476       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:49.518870692Z I1024 13:33:49.518739       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:49.518870692Z I1024 13:33:49.518823       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2024-10-24T13:33:49.533023212Z W1024 13:33:49.532952       1 dynamic_operator_client.go:355] .status.conditions["KubeAPIServerStaticResourcesDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:33:49.564964851Z I1024 13:33:49.564894       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:33:49.566401501Z I1024 13:33:49.566356       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nTargetConfigControllerDegraded: \"configmap/config\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/kube-apiserver-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/client-ca\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca\": dial tcp 172.30.0.1:443: connect: connection refused","reason":"GuardController_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:49.580673881Z I1024 13:33:49.580589       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/check-endpoints-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \"assets/kube-apiserver/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeAPIServerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/config\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/kube-apiserver-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/client-ca\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca\": dial tcp 172.30.0.1:443: connect: connection refused" to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nTargetConfigControllerDegraded: \"configmap/config\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/kube-apiserver-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/client-ca\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:33:49.840627278Z E1024 13:33:49.840567       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:33:50.033358295Z I1024 13:33:50.033281       1 request.go:700] Waited for 1.193178623s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-10-24T13:33:50.883726773Z I1024 13:33:50.883668       1 reflector.go:368] Caches populated for *v1alpha1.StorageVersionMigration from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:51.232932338Z I1024 13:33:51.232880       1 request.go:700] Waited for 1.670588597s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T13:33:52.249168293Z I1024 13:33:52.249071       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:52.433381311Z I1024 13:33:52.433302       1 request.go:700] Waited for 1.787673175s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:33:53.632608753Z I1024 13:33:53.632543       1 request.go:700] Waited for 1.993402091s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-10-24T13:33:53.841522181Z I1024 13:33:53.841378       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:33:53.841522181Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:33:53.841522181Z  CurrentRevision: (int32) 11,
2024-10-24T13:33:53.841522181Z  TargetRevision: (int32) 0,
2024-10-24T13:33:53.841522181Z  LastFailedRevision: (int32) 10,
2024-10-24T13:33:53.841522181Z  LastFailedTime: (*v1.Time)(0xc006ebe048)(2024-10-24 13:30:03 +0000 UTC),
2024-10-24T13:33:53.841522181Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:33:53.841522181Z  LastFailedCount: (int) 1,
2024-10-24T13:33:53.841522181Z  LastFallbackCount: (int) 0,
2024-10-24T13:33:53.841522181Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:33:53.841522181Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:33:53.841522181Z  }
2024-10-24T13:33:53.841522181Z }
2024-10-24T13:33:53.841522181Z  because static pod is ready
2024-10-24T13:33:53.844225171Z I1024 13:33:53.844134       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 0 to 11 because static pod is ready
2024-10-24T13:33:54.633450899Z I1024 13:33:54.633397       1 request.go:700] Waited for 1.530361639s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:33:54.798594597Z I1024 13:33:54.798504       1 reflector.go:368] Caches populated for *v1.OAuth from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:54.804193877Z I1024 13:33:54.804158       1 reflector.go:368] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:54.804282507Z I1024 13:33:54.804242       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX
2024-10-24T13:33:54.804788727Z I1024 13:33:54.804729       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:33:55.038002634Z E1024 13:33:55.037937       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:33:55.038002634Z E1024 13:33:55.037965       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:33:55.039712534Z E1024 13:33:55.039644       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:33:55.833199483Z I1024 13:33:55.833145       1 request.go:700] Waited for 1.39363242s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:33:57.033248035Z I1024 13:33:57.033191       1 request.go:700] Waited for 1.570101508s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-apiserver/services?resourceVersion=31480
2024-10-24T13:33:57.035992895Z I1024 13:33:57.035943       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:57.036488165Z I1024 13:33:57.036420       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:33:57.878279113Z I1024 13:33:57.878212       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:33:57.882146833Z I1024 13:33:57.882105       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:57.902186393Z I1024 13:33:57.902111       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nTargetConfigControllerDegraded: \"configmap/config\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/kube-apiserver-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/client-ca\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca\": dial tcp 172.30.0.1:443: connect: connection refused" to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:33:58.033276131Z I1024 13:33:58.033202       1 request.go:700] Waited for 1.195521403s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:33:58.447915995Z I1024 13:33:58.447853       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:59.232985894Z I1024 13:33:59.232910       1 request.go:700] Waited for 1.352663491s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:34:00.037209482Z I1024 13:34:00.037143       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:34:00.433600676Z I1024 13:34:00.433525       1 request.go:700] Waited for 1.590219666s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:34:00.838409371Z I1024 13:34:00.838342       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-1 static pod not found and needs new revision 11
2024-10-24T13:34:00.838471891Z I1024 13:34:00.838407       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:34:00.838471891Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:34:00.838471891Z  CurrentRevision: (int32) 0,
2024-10-24T13:34:00.838471891Z  TargetRevision: (int32) 11,
2024-10-24T13:34:00.838471891Z  LastFailedRevision: (int32) 0,
2024-10-24T13:34:00.838471891Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:34:00.838471891Z  LastFailedReason: (string) "",
2024-10-24T13:34:00.838471891Z  LastFailedCount: (int) 0,
2024-10-24T13:34:00.838471891Z  LastFallbackCount: (int) 0,
2024-10-24T13:34:00.838471891Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:34:00.838471891Z }
2024-10-24T13:34:00.840324921Z W1024 13:34:00.840270       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:34:00.840324921Z W1024 13:34:00.840291       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:34:00.840324921Z W1024 13:34:00.840299       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:34:00.840324921Z W1024 13:34:00.840305       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:34:00.840324921Z W1024 13:34:00.840311       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:34:00.840324921Z W1024 13:34:00.840315       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T13:34:00.873737191Z I1024 13:34:00.873667       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 0 to 11 because node ci-op-2fcpj5j6-f6035-2lklf-master-1 static pod not found
2024-10-24T13:34:00.875230460Z I1024 13:34:00.875193       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:34:00.920787700Z I1024 13:34:00.920712       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:34:01.632669860Z I1024 13:34:01.632584       1 request.go:700] Waited for 1.085341245s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-apiserver/configmaps?resourceVersion=31838
2024-10-24T13:34:01.642795089Z I1024 13:34:01.642712       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:34:02.633240226Z I1024 13:34:02.633173       1 request.go:700] Waited for 1.752928466s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:34:03.832568798Z I1024 13:34:03.832495       1 request.go:700] Waited for 1.581098167s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:34:04.832893314Z I1024 13:34:04.832837       1 request.go:700] Waited for 1.590168397s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:34:05.833268880Z I1024 13:34:05.833221       1 request.go:700] Waited for 1.191467623s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T13:34:07.240631870Z I1024 13:34:07.240579       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-1 static pod not found and needs new revision 11
2024-10-24T13:34:07.240671210Z I1024 13:34:07.240636       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:34:07.240671210Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:34:07.240671210Z  CurrentRevision: (int32) 0,
2024-10-24T13:34:07.240671210Z  TargetRevision: (int32) 11,
2024-10-24T13:34:07.240671210Z  LastFailedRevision: (int32) 0,
2024-10-24T13:34:07.240671210Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:34:07.240671210Z  LastFailedReason: (string) "",
2024-10-24T13:34:07.240671210Z  LastFailedCount: (int) 0,
2024-10-24T13:34:07.240671210Z  LastFallbackCount: (int) 0,
2024-10-24T13:34:07.240671210Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:34:07.240671210Z }
2024-10-24T13:34:07.243582500Z I1024 13:34:07.243514       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 0 to 11 because node ci-op-2fcpj5j6-f6035-2lklf-master-1 static pod not found
2024-10-24T13:34:09.277933691Z I1024 13:34:09.277858       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-11-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-apiserver because it was missing
2024-10-24T13:34:10.432774764Z I1024 13:34:10.432682       1 request.go:700] Waited for 1.154935663s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-11-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:34:10.440977184Z I1024 13:34:10.440920       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 11, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:34:10.840822019Z E1024 13:34:10.840729       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:34:10.840822019Z E1024 13:34:10.840802       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:34:10.842737099Z E1024 13:34:10.842705       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:34:11.632920457Z I1024 13:34:11.632846       1 request.go:700] Waited for 1.189581733s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:34:12.840869200Z E1024 13:34:12.840804       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:34:12.840869200Z E1024 13:34:12.840828       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:34:12.842350250Z E1024 13:34:12.842273       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:34:13.290726284Z I1024 13:34:13.289086       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:34:14.039405383Z E1024 13:34:14.039346       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:34:14.039405383Z E1024 13:34:14.039375       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:34:14.041477783Z E1024 13:34:14.041423       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:34:14.642902445Z I1024 13:34:14.642845       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:34:15.642035350Z I1024 13:34:15.641962       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:34:17.331908826Z E1024 13:34:17.331853       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:34:17.332015406Z E1024 13:34:17.331995       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:34:17.334565956Z E1024 13:34:17.334534       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:34:19.648400303Z E1024 13:34:19.648338       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:34:19.648400303Z E1024 13:34:19.648373       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:34:19.650731203Z E1024 13:34:19.650681       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:34:27.421052203Z E1024 13:34:27.420989       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:34:27.421052203Z E1024 13:34:27.421027       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:34:27.423156553Z E1024 13:34:27.423102       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:34:37.643472857Z E1024 13:34:37.643419       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:34:37.643579927Z E1024 13:34:37.643561       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:34:37.646230707Z E1024 13:34:37.646177       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:34:47.860711482Z E1024 13:34:47.860618       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:34:47.860833532Z E1024 13:34:47.860801       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:34:47.862904772Z E1024 13:34:47.862873       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:34:47.951430001Z E1024 13:34:47.951347       1 guard_controller.go:300] Missing PodIP in operand kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:34:47.951430001Z E1024 13:34:47.951409       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:34:47.982886440Z E1024 13:34:47.982836       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing PodIP in operand kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:34:47.990767820Z I1024 13:34:47.990670       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:34:47.998241920Z I1024 13:34:47.998155       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:34:48.010669320Z I1024 13:34:48.010585       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]" to "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:34:49.048321545Z I1024 13:34:49.047964       1 request.go:700] Waited for 1.049103115s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-10-24T13:34:50.247255998Z I1024 13:34:50.247191       1 request.go:700] Waited for 1.507093328s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:34:51.248100384Z I1024 13:34:51.248029       1 request.go:700] Waited for 1.589222897s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:34:52.060452132Z E1024 13:34:52.060374       1 guard_controller.go:300] Missing PodIP in operand kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:34:52.060452132Z E1024 13:34:52.060417       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:34:52.062953742Z E1024 13:34:52.062916       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing PodIP in operand kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:34:52.447739677Z I1024 13:34:52.447683       1 request.go:700] Waited for 1.578273668s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-10-24T13:34:53.058635949Z I1024 13:34:53.058566       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 11, but has not made progress because static pod is pending
2024-10-24T13:34:54.447307089Z I1024 13:34:54.447229       1 request.go:700] Waited for 1.170209534s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:34:55.447844014Z I1024 13:34:55.447771       1 request.go:700] Waited for 1.38958478s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:34:56.448793080Z I1024 13:34:56.447887       1 request.go:700] Waited for 1.190586863s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:34:57.462731436Z E1024 13:34:57.462655       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:34:57.465394286Z I1024 13:34:57.465346       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-apiserver because it was missing
2024-10-24T13:34:57.505763065Z E1024 13:34:57.504788       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:34:57.526794875Z I1024 13:34:57.526660       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:34:57.526863215Z I1024 13:34:57.526830       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:34:57.551737354Z I1024 13:34:57.551639       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]" to "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:34:58.647640589Z I1024 13:34:58.647563       1 request.go:700] Waited for 1.137245974s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T13:34:59.847441922Z I1024 13:34:59.847378       1 request.go:700] Waited for 2.191809759s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:35:00.054358099Z I1024 13:35:00.054284       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 11, but has not made progress because static pod is pending
2024-10-24T13:35:00.847688287Z I1024 13:35:00.847625       1 request.go:700] Waited for 1.787591324s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-10-24T13:35:02.048010180Z I1024 13:35:02.047943       1 request.go:700] Waited for 1.590599807s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:35:03.048102866Z I1024 13:35:03.048037       1 request.go:700] Waited for 1.592438448s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:35:03.456408610Z I1024 13:35:03.456321       1 core.go:220] Pod "openshift-kube-apiserver/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1" changes: {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{"k8s.ovn.org/pod-networks":null,"k8s.v1.cni.cncf.io/network-status":null,"target.workload.openshift.io/management":"{\"effect\": \"PreferredDuringScheduling\"}"},"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null},"spec":{"containers":[{"args":["-c","# properly handle TERM and exit as soon as it is signaled\nset -euo pipefail\ntrap 'jobs -p | xargs -r kill; exit 0' TERM\nsleep infinity \u0026 wait\n"],"command":["/bin/bash"],"image":"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:adc55330a214af3a57e2fac059ed409c2a7b1dc54d829a3ad1f719ce6c15ffa0","imagePullPolicy":"IfNotPresent","name":"guard","readinessProbe":{"failureThreshold":3,"httpGet":{"host":"10.0.0.4","path":"readyz","port":6443,"scheme":"HTTPS"},"periodSeconds":5,"successThreshold":1,"timeoutSeconds":5},"resources":{"requests":{"cpu":"10m","memory":"5Mi"}},"terminationMessagePolicy":"FallbackToLogsOnError"}],"dnsPolicy":null,"enableServiceLinks":null,"imagePullSecrets":null,"preemptionPolicy":null,"priority":null,"restartPolicy":null,"schedulerName":null,"securityContext":null,"serviceAccount":null,"serviceAccountName":null,"volumes":null},"status":{"conditions":null,"containerStatuses":null,"hostIP":null,"hostIPs":null,"phase":null,"podIP":null,"podIPs":null,"qosClass":null,"startTime":null}}
2024-10-24T13:35:04.265356969Z E1024 13:35:04.265294       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:35:04.265663499Z I1024 13:35:04.265598       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-apiserver because it changed
2024-10-24T13:35:04.267668849Z E1024 13:35:04.267628       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:35:05.448191292Z I1024 13:35:05.448122       1 request.go:700] Waited for 1.183428813s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:35:06.454901958Z E1024 13:35:06.454843       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:35:06.855785392Z I1024 13:35:06.855714       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 11, but has not made progress because static pod is pending
2024-10-24T13:35:07.656693630Z E1024 13:35:07.656628       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:35:09.455363114Z I1024 13:35:09.455282       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:35:09.455363114Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:35:09.455363114Z  CurrentRevision: (int32) 11,
2024-10-24T13:35:09.455363114Z  TargetRevision: (int32) 0,
2024-10-24T13:35:09.455363114Z  LastFailedRevision: (int32) 0,
2024-10-24T13:35:09.455363114Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:35:09.455363114Z  LastFailedReason: (string) "",
2024-10-24T13:35:09.455363114Z  LastFailedCount: (int) 0,
2024-10-24T13:35:09.455363114Z  LastFallbackCount: (int) 0,
2024-10-24T13:35:09.455363114Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:35:09.455363114Z }
2024-10-24T13:35:09.455363114Z  because static pod is ready
2024-10-24T13:35:09.457244335Z W1024 13:35:09.457199       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:35:09.457244335Z W1024 13:35:09.457233       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:35:09.457244335Z W1024 13:35:09.457240       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:35:09.457269965Z W1024 13:35:09.457244       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:35:09.457269965Z W1024 13:35:09.457247       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:35:09.457269965Z W1024 13:35:09.457250       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T13:35:09.489204474Z I1024 13:35:09.489136       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 0 to 11 because static pod is ready
2024-10-24T13:35:09.493861914Z I1024 13:35:09.493829       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 2 nodes are at revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:35:09.494623824Z I1024 13:35:09.494597       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:35:09.515823224Z I1024 13:35:09.515713       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 11" to "NodeInstallerProgressing: 1 node is at revision 0; 2 nodes are at revision 11",Available message changed from "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 11" to "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 11"
2024-10-24T13:35:09.540627333Z I1024 13:35:09.540564       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:35:10.647867408Z I1024 13:35:10.647786       1 request.go:700] Waited for 1.149306844s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-11-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:35:11.847979331Z I1024 13:35:11.847906       1 request.go:700] Waited for 1.793280045s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:35:12.848169396Z I1024 13:35:12.848095       1 request.go:700] Waited for 1.784202755s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T13:35:13.257613121Z E1024 13:35:13.257546       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:35:13.259880121Z E1024 13:35:13.259858       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:35:14.047467830Z I1024 13:35:14.047401       1 request.go:700] Waited for 1.39172185s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-10-24T13:35:15.247568062Z I1024 13:35:15.247510       1 request.go:700] Waited for 1.391889121s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-11-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:35:16.247785288Z I1024 13:35:16.247711       1 request.go:700] Waited for 1.39284811s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:35:18.055547333Z E1024 13:35:18.055485       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:35:18.057302953Z E1024 13:35:18.057275       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:35:20.254108331Z E1024 13:35:20.254043       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:35:20.256769342Z E1024 13:35:20.256663       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:35:21.854415329Z E1024 13:35:21.854292       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:35:21.857293159Z E1024 13:35:21.857221       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:35:27.333240561Z E1024 13:35:27.333183       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:35:27.335664221Z E1024 13:35:27.335613       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:35:28.617276882Z E1024 13:35:28.617210       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:35:28.619681133Z E1024 13:35:28.619621       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:35:29.480550820Z E1024 13:35:29.480472       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:35:29.482742920Z E1024 13:35:29.482694       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:35:31.596892840Z E1024 13:35:31.596842       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:35:31.626716390Z E1024 13:35:31.626631       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:35:34.679119486Z I1024 13:35:34.679062       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:35:38.648501530Z I1024 13:35:38.648441       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-2 static pod not found and needs new revision 11
2024-10-24T13:35:38.648583130Z I1024 13:35:38.648500       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:35:38.648583130Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:35:38.648583130Z  CurrentRevision: (int32) 0,
2024-10-24T13:35:38.648583130Z  TargetRevision: (int32) 11,
2024-10-24T13:35:38.648583130Z  LastFailedRevision: (int32) 0,
2024-10-24T13:35:38.648583130Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:35:38.648583130Z  LastFailedReason: (string) "",
2024-10-24T13:35:38.648583130Z  LastFailedCount: (int) 0,
2024-10-24T13:35:38.648583130Z  LastFallbackCount: (int) 0,
2024-10-24T13:35:38.648583130Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:35:38.648583130Z }
2024-10-24T13:35:38.651372010Z W1024 13:35:38.651309       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:35:38.651372010Z W1024 13:35:38.651333       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:35:38.651372010Z W1024 13:35:38.651340       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:35:38.651372010Z W1024 13:35:38.651346       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:35:38.651372010Z W1024 13:35:38.651353       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:35:38.651372010Z W1024 13:35:38.651358       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T13:35:38.687367910Z I1024 13:35:38.687296       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:35:38.690884140Z I1024 13:35:38.690805       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:35:38.693667219Z I1024 13:35:38.693614       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 0 to 11 because node ci-op-2fcpj5j6-f6035-2lklf-master-2 static pod not found
2024-10-24T13:35:38.712013729Z I1024 13:35:38.711943       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:35:38.769185739Z I1024 13:35:38.766792       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:35:38.853274677Z I1024 13:35:38.853181       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:35:38.855520787Z I1024 13:35:38.855456       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:35:39.790522254Z E1024 13:35:39.790411       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:35:39.803630554Z I1024 13:35:39.803575       1 request.go:700] Waited for 1.036340146s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T13:35:40.803722310Z I1024 13:35:40.803659       1 request.go:700] Waited for 1.590748258s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-10-24T13:35:42.004276263Z I1024 13:35:42.004207       1 request.go:700] Waited for 1.193410733s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-10-24T13:35:43.204264536Z I1024 13:35:43.204198       1 request.go:700] Waited for 1.187921634s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-10-24T13:35:43.633177349Z I1024 13:35:43.633118       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-11-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-apiserver because it was missing
2024-10-24T13:35:44.403499619Z I1024 13:35:44.403436       1 request.go:700] Waited for 1.191318374s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-10-24T13:35:44.810856313Z I1024 13:35:44.810785       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 11, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:35:45.403895395Z I1024 13:35:45.403829       1 request.go:700] Waited for 1.723145835s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:35:45.615716561Z E1024 13:35:45.615646       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:35:45.617112022Z E1024 13:35:45.617072       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:35:46.603627407Z I1024 13:35:46.603561       1 request.go:700] Waited for 1.969903052s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T13:35:47.603900603Z I1024 13:35:47.603837       1 request.go:700] Waited for 1.789128524s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:35:48.604553729Z I1024 13:35:48.604474       1 request.go:700] Waited for 1.193216853s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:35:50.618123390Z E1024 13:35:50.618064       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:35:51.011973495Z I1024 13:35:51.011907       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:35:53.412503371Z E1024 13:35:53.412441       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:35:53.414435712Z E1024 13:35:53.414390       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:35:53.613476353Z I1024 13:35:53.613385       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:35:59.342110800Z E1024 13:35:59.342044       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:35:59.344466540Z E1024 13:35:59.344414       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:36:04.863624496Z E1024 13:36:04.863563       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:36:04.865858996Z E1024 13:36:04.865745       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:36:08.534918234Z E1024 13:36:08.534834       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:36:08.571529103Z E1024 13:36:08.571485       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:36:10.626597192Z E1024 13:36:10.626520       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:36:10.628658502Z E1024 13:36:10.628603       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:36:15.504450307Z E1024 13:36:15.504355       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:36:15.542158495Z E1024 13:36:15.542100       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:36:22.596960974Z E1024 13:36:22.596895       1 guard_controller.go:300] Missing PodIP in operand kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2 on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:36:22.635938412Z E1024 13:36:22.635877       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing PodIP in operand kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2 on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:36:22.641632702Z I1024 13:36:22.641576       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing PodIP in operand kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2 on node ci-op-2fcpj5j6-f6035-2lklf-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 2 nodes are at revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:36:22.643702672Z I1024 13:36:22.643645       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:36:22.663603071Z I1024 13:36:22.663252       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2" to "GuardControllerDegraded: Missing PodIP in operand kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2 on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:36:23.787848991Z I1024 13:36:23.787775       1 request.go:700] Waited for 1.143265889s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:36:24.395898145Z I1024 13:36:24.395828       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:36:24.787954977Z I1024 13:36:24.787894       1 request.go:700] Waited for 1.753310072s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:36:25.788315293Z I1024 13:36:25.788242       1 request.go:700] Waited for 1.989781482s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:36:26.988678470Z I1024 13:36:26.988603       1 request.go:700] Waited for 1.786370001s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:36:28.188592607Z I1024 13:36:28.188536       1 request.go:700] Waited for 1.58590572s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:36:29.388668574Z I1024 13:36:29.388604       1 request.go:700] Waited for 1.192666917s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:36:30.588650091Z I1024 13:36:30.588588       1 request.go:700] Waited for 1.191503267s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:36:32.196164310Z I1024 13:36:32.196088       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 11, but has not made progress because static pod is pending
2024-10-24T13:36:32.405274861Z W1024 13:36:32.405218       1 dynamic_operator_client.go:355] .status.conditions["GuardControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:36:32.405945701Z I1024 13:36:32.405690       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-apiserver because it was missing
2024-10-24T13:36:32.451482979Z I1024 13:36:32.451427       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:36:32.455046639Z I1024 13:36:32.455022       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:05:18Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 2 nodes are at revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:36:32.470037948Z I1024 13:36:32.470004       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded changed from True to False ("NodeControllerDegraded: All master nodes are ready")
2024-10-24T13:36:33.587790078Z I1024 13:36:33.587717       1 request.go:700] Waited for 1.13969983s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:36:34.588533065Z I1024 13:36:34.588463       1 request.go:700] Waited for 2.132227895s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-11-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:36:35.788703851Z I1024 13:36:35.788577       1 request.go:700] Waited for 1.993487912s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T13:36:36.987664729Z I1024 13:36:36.987605       1 request.go:700] Waited for 1.788207181s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:36:37.988328774Z I1024 13:36:37.988259       1 request.go:700] Waited for 1.592777009s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-11-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:36:39.796019454Z I1024 13:36:39.795944       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 11, but has not made progress because static pod is pending
2024-10-24T13:36:39.999569256Z I1024 13:36:39.999481       1 core.go:220] Pod "openshift-kube-apiserver/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2" changes: {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{"k8s.ovn.org/pod-networks":null,"k8s.v1.cni.cncf.io/network-status":null,"target.workload.openshift.io/management":"{\"effect\": \"PreferredDuringScheduling\"}"},"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null},"spec":{"containers":[{"args":["-c","# properly handle TERM and exit as soon as it is signaled\nset -euo pipefail\ntrap 'jobs -p | xargs -r kill; exit 0' TERM\nsleep infinity \u0026 wait\n"],"command":["/bin/bash"],"image":"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:adc55330a214af3a57e2fac059ed409c2a7b1dc54d829a3ad1f719ce6c15ffa0","imagePullPolicy":"IfNotPresent","name":"guard","readinessProbe":{"failureThreshold":3,"httpGet":{"host":"10.0.0.6","path":"readyz","port":6443,"scheme":"HTTPS"},"periodSeconds":5,"successThreshold":1,"timeoutSeconds":5},"resources":{"requests":{"cpu":"10m","memory":"5Mi"}},"terminationMessagePolicy":"FallbackToLogsOnError"}],"dnsPolicy":null,"enableServiceLinks":null,"imagePullSecrets":null,"preemptionPolicy":null,"priority":null,"restartPolicy":null,"schedulerName":null,"securityContext":null,"serviceAccount":null,"serviceAccountName":null,"volumes":null},"status":{"conditions":null,"containerStatuses":null,"hostIP":null,"hostIPs":null,"phase":null,"podIP":null,"podIPs":null,"qosClass":null,"startTime":null}}
2024-10-24T13:36:40.604394929Z I1024 13:36:40.604236       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-apiserver because it changed
2024-10-24T13:36:41.788235257Z I1024 13:36:41.788165       1 request.go:700] Waited for 1.180124137s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:36:44.195105620Z I1024 13:36:44.195004       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:36:44.195105620Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:36:44.195105620Z  CurrentRevision: (int32) 11,
2024-10-24T13:36:44.195105620Z  TargetRevision: (int32) 0,
2024-10-24T13:36:44.195105620Z  LastFailedRevision: (int32) 0,
2024-10-24T13:36:44.195105620Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:36:44.195105620Z  LastFailedReason: (string) "",
2024-10-24T13:36:44.195105620Z  LastFailedCount: (int) 0,
2024-10-24T13:36:44.195105620Z  LastFallbackCount: (int) 0,
2024-10-24T13:36:44.195105620Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:36:44.195105620Z }
2024-10-24T13:36:44.195105620Z  because static pod is ready
2024-10-24T13:36:44.196840610Z W1024 13:36:44.196790       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:36:44.196840610Z W1024 13:36:44.196814       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:36:44.196840610Z W1024 13:36:44.196819       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:36:44.196840610Z W1024 13:36:44.196823       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:36:44.196840610Z W1024 13:36:44.196826       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T13:36:44.228902889Z I1024 13:36:44.228838       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 0 to 11 because static pod is ready
2024-10-24T13:36:44.234087539Z I1024 13:36:44.234044       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:36:44Z","message":"NodeInstallerProgressing: 3 nodes are at revision 11","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:36:44.235852899Z I1024 13:36:44.235818       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:36:44.251146388Z I1024 13:36:44.250022       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing changed from True to False ("NodeInstallerProgressing: 3 nodes are at revision 11"),Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 11" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 11"
2024-10-24T13:36:44.286547726Z I1024 13:36:44.286476       1 connectivity_check_controller.go:172] ConnectivityCheckController is waiting for transition to desired version (4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest) to be completed.
2024-10-24T13:36:45.388248038Z I1024 13:36:45.388192       1 request.go:700] Waited for 1.155133779s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T13:36:46.388569123Z I1024 13:36:46.388512       1 request.go:700] Waited for 1.791639501s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:36:47.587609741Z I1024 13:36:47.587542       1 request.go:700] Waited for 1.990579323s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-11-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:36:48.587910037Z I1024 13:36:48.587839       1 request.go:700] Waited for 1.392460608s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:36:49.788249584Z I1024 13:36:49.788179       1 request.go:700] Waited for 1.191504668s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:36:50.988406131Z I1024 13:36:50.988356       1 request.go:700] Waited for 1.192329348s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:36:58.332786207Z E1024 13:36:58.332680       1 base_controller.go:271] "Unhandled Error" err="ConnectivityCheckController reconciliation failed: customresourcedefinitions.apiextensions.k8s.io \"podnetworkconnectivitychecks.controlplane.operator.openshift.io\" already exists"
2024-10-24T13:36:58.332786207Z I1024 13:36:58.332730       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'CustomResourceDefinitionCreateFailed' Failed to create CustomResourceDefinition.apiextensions.k8s.io/podnetworkconnectivitychecks.controlplane.operator.openshift.io: customresourcedefinitions.apiextensions.k8s.io "podnetworkconnectivitychecks.controlplane.operator.openshift.io" already exists
2024-10-24T13:36:58.359948586Z I1024 13:36:58.359895       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2024-10-24T13:43:37.339293833Z I1024 13:43:37.339193       1 request.go:700] Waited for 1.151088927s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:43:38.539317509Z I1024 13:43:38.539241       1 request.go:700] Waited for 1.192044406s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:43:47.011360230Z I1024 13:43:47.011283       1 request.go:700] Waited for 1.176302016s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T13:43:49.519691871Z I1024 13:43:49.519609       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2024-10-24T13:43:53.411594896Z I1024 13:43:53.411513       1 request.go:700] Waited for 1.159341887s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-11-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:43:54.610925162Z I1024 13:43:54.610843       1 request.go:700] Waited for 1.391023784s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:43:54.805265500Z I1024 13:43:54.805198       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX
2024-10-24T13:43:55.611333430Z I1024 13:43:55.611268       1 request.go:700] Waited for 1.386921433s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-10-24T13:43:56.612570948Z I1024 13:43:56.612495       1 request.go:700] Waited for 1.382586214s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:46:19.045948417Z I1024 13:46:19.045780       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:36:44Z","message":"NodeInstallerProgressing: 3 nodes are at revision 11","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"CertRotationTimeUpgradeable: configmap[\"openshift-config\"]/unsupported-cert-rotation-config .data[\"base\"]==\"2y\"","reason":"CertRotationTime_CertRotationBaseOverridden","status":"False","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:46:19.070536587Z I1024 13:46:19.070466       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Upgradeable changed from True to False ("CertRotationTimeUpgradeable: configmap[\"openshift-config\"]/unsupported-cert-rotation-config .data[\"base\"]==\"2y\"")
2024-10-24T13:46:19.202256865Z I1024 13:46:19.202181       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:36:44Z","message":"NodeInstallerProgressing: 3 nodes are at revision 11","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:46:19.220716585Z I1024 13:46:19.220331       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Upgradeable changed from False to True ("KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.")
2024-10-24T13:46:19.382624154Z I1024 13:46:19.382548       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SignerUpdateRequired' "aggregator-client-signer" in "openshift-kube-apiserver-operator" requires a new signing cert/key pair: secret doesn't exist
2024-10-24T13:46:19.578360092Z I1024 13:46:19.578287       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready\nCertRotation_AggregatorProxyClientCert_Degraded: secrets \"aggregator-client-signer\" already exists","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:36:44Z","message":"NodeInstallerProgressing: 3 nodes are at revision 11","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:46:19.596238962Z I1024 13:46:19.596159       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready" to "NodeControllerDegraded: All master nodes are ready\nCertRotation_AggregatorProxyClientCert_Degraded: secrets \"aggregator-client-signer\" already exists"
2024-10-24T13:46:19.831727829Z I1024 13:46:19.831618       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:36:44Z","message":"NodeInstallerProgressing: 3 nodes are at revision 11","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:46:19.847545739Z I1024 13:46:19.847473       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nCertRotation_AggregatorProxyClientCert_Degraded: secrets \"aggregator-client-signer\" already exists" to "NodeControllerDegraded: All master nodes are ready"
2024-10-24T13:46:20.147945366Z I1024 13:46:20.147877       1 request.go:700] Waited for 1.101831519s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-11-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:46:21.148205756Z I1024 13:46:21.148132       1 request.go:700] Waited for 1.591608414s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:46:21.364299824Z I1024 13:46:21.364208       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretCreateFailed' Failed to create Secret/: secrets "aggregator-client-signer" already exists
2024-10-24T13:46:21.405039033Z E1024 13:46:21.404977       1 base_controller.go:271] "Unhandled Error" err="CertRotationController reconciliation failed: secrets \"aggregator-client-signer\" already exists"
2024-10-24T13:46:21.405090533Z I1024 13:46:21.405062       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RotationError' secrets "aggregator-client-signer" already exists
2024-10-24T13:46:21.408575053Z I1024 13:46:21.408544       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready\nCertRotation_AggregatorProxyClientCert_Degraded: secrets \"aggregator-client-signer\" already exists","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:36:44Z","message":"NodeInstallerProgressing: 3 nodes are at revision 11","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:46:21.429665343Z I1024 13:46:21.429605       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready" to "NodeControllerDegraded: All master nodes are ready\nCertRotation_AggregatorProxyClientCert_Degraded: secrets \"aggregator-client-signer\" already exists"
2024-10-24T13:46:21.470803203Z I1024 13:46:21.469478       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:36:44Z","message":"NodeInstallerProgressing: 3 nodes are at revision 11","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:46:21.492988623Z I1024 13:46:21.492380       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nCertRotation_AggregatorProxyClientCert_Degraded: secrets \"aggregator-client-signer\" already exists" to "NodeControllerDegraded: All master nodes are ready"
2024-10-24T13:46:21.759575470Z I1024 13:46:21.759506       1 core.go:352] ConfigMap "openshift-kube-apiserver/aggregator-client-ca" changes: {"data":{"ca-bundle.crt":"-----BEGIN CERTIFICATE-----\nMIIDJDCCAgygAwIBAgIIF/RXtfGPvuMwDQYJKoZIhvcNAQELBQAwMDESMBAGA1UE\nCxMJb3BlbnNoaWZ0MRowGAYDVQQDExFhZ2dyZWdhdG9yLXNpZ25lcjAeFw0yNDEw\nMjQxMjQ5MzJaFw0yNDEwMjUxMjQ5MzJaMDAxEjAQBgNVBAsTCW9wZW5zaGlmdDEa\nMBgGA1UEAxMRYWdncmVnYXRvci1zaWduZXIwggEiMA0GCSqGSIb3DQEBAQUAA4IB\nDwAwggEKAoIBAQDD722hp3hbDTJbd/BBHJ/BcpUdsOvcwmWyQqNo/kZx3w/9jP6s\noRg9q2amHP1/cjXBXiFKkYXCjFIGhLLxi5rJYZxsdq54thnhPyhL4cXR2xu7AQKv\nQCW6e0aC5/0dEQVe98ttrpEVHw8xO+JfNZO8NHX+1hTamgrnqeUfSVyhiisbYVX6\nmoFC7uelTV8QZ6FaJnDVRasoFtHaQtLxgabpvxO6sh6s7p+8NhlI/PamyspwGjGz\nPFB6OAxki1UHtv0M5aXXZvvr5lIv1iNkudJ57TO17RyKTl8oxSL4M8SBelrYTVsP\noBzpya4rPb0iD0yhsJMCvG6wk6pQBeAQ3VbVAgMBAAGjQjBAMA4GA1UdDwEB/wQE\nAwICpDAPBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBSB3HmXaA4JHRhSMFJt3JFG\nxNDfLDANBgkqhkiG9w0BAQsFAAOCAQEAc+GK/sDrcd8OzpS0k9TZ4eraTPzSThPU\nLqqnb3jGB8DBm36ZNiigakcsuWAQJ/4xQJkJtJq6He0701HqAzw7zP6LmhMCFvXZ\nNsvLsPd6woJfmOaeWaaPBL+tI7D0v16sLf+a9Q/ONu5tVHiRoEUEMG9iih9KNltm\nUwkUKq6Xx5p1+iE37J9shYmsbD649PGTFK2eeYBSFgAZB4PBotKrIR4frTMoJLfU\nwxCuqTrm/VxyKFryZktjHX2jsLZu3tMzFAPe4UovKJl9H7vhkJ6pYSmGlrMAiXtV\nVrWGuEmpfntCC+LWyHdkrwjCUd7QclZb8TZwinu4ItpXsDAbyo6miA==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDhTCCAm2gAwIBAgIIBEEBnt4lt+cwDQYJKoZIhvcNAQELBQAwUDFOMEwGA1UE\nAwxFb3BlbnNoaWZ0LWt1YmUtYXBpc2VydmVyLW9wZXJhdG9yX2FnZ3JlZ2F0b3It\nY2xpZW50LXNpZ25lckAxNzI5Nzc3NTc5MB4XDTI0MTAyNDEzNDYxOFoXDTI0MTAy\nNTAxNDYxOVowUDFOMEwGA1UEAwxFb3BlbnNoaWZ0LWt1YmUtYXBpc2VydmVyLW9w\nZXJhdG9yX2FnZ3JlZ2F0b3ItY2xpZW50LXNpZ25lckAxNzI5Nzc3NTc5MIIBIjAN\nBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAo6Yb/O+mIGclq/AhBxIb6hP09XVu\n4lbC8pc0svu+a+XNHI1LoNHYL7HARDXBeIi6EWjUiNb3kBgCnjqeTu0r/LRx0Jlx\n1vIDmq6RJRc/oUqsxG74kz2sSVTu048NIjOKMxPwzFVY/nhBh/vZnEKe+0SDeex1\nZMV44Vtf3iVUUd362/vB0uoInsTRbpza3Jx3nJmxeyI5i4XQtgQHC0x2Q/h5Vwmh\nkvjxwlYtTEpN0AZNum0/WLZoY3xSVz4MW1btrYYrLohkD2bypx90hsB1RKBD8Ye6\nhWOf2VXIO2fXXuFsacOgucuX4RAyKbo4L2UivmnkfL4w6xYXH5OdXanSaQIDAQAB\no2MwYTAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQU\n50OJDmU5YhbiEaS58G3De3RUmBgwHwYDVR0jBBgwFoAU50OJDmU5YhbiEaS58G3D\ne3RUmBgwDQYJKoZIhvcNAQELBQADggEBADNMf830Ay4RhwyQN9aMb/XlUirZUbcg\nc/5i5ZuI0AXhz/YuLSHDoWCxk/oWSNFmK07xN2OleHj8b/OI1LEcuUuFbqPG8gI4\nRI1TWPNai4ibu37cHtC1BrkdZJuvDTy0IdDR7wKp3/Sl1YY0Lzf6e/9lWb8TuqEL\nWc9qwFeS6RA/q2fsKPg1Ix0vASgTFFcwtpstQQo3j94G6Ermtq3Rw59xcF5AAGzh\nv85qCkrkIdJR2Akewjb13mjoFz3pvMns8L3lquFgAkxnERXN8BoGST/F2UoWdGHM\nTKm+Z1iZpZTeYyrffJqO+2ftALH8iBTwpiZnpqd3l3lFWP+dYy09Lq0=\n-----END CERTIFICATE-----\n"},"metadata":{"creationTimestamp":"2024-10-24T13:03:37Z","managedFields":[{"apiVersion":"v1","fieldsType":"FieldsV1","fieldsV1":{"f:data":{".":{},"f:ca-bundle.crt":{}},"f:metadata":{"f:annotations":{".":{},"f:certificates.openshift.io/auto-regenerate-after-offline-expiry":{},"f:openshift.io/owning-component":{}},"f:labels":{".":{},"f:auth.openshift.io/managed-certificate-type":{}}}},"manager":"cluster-kube-apiserver-operator","operation":"Update","time":"2024-10-24T13:46:19Z"}],"resourceVersion":null,"uid":"b4d32c57-86bc-4670-9e1a-17c3bcb7a4cd"}}
2024-10-24T13:46:21.760774170Z I1024 13:46:21.760303       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/aggregator-client-ca -n openshift-kube-apiserver:
2024-10-24T13:46:21.760774170Z cause by changes in data.ca-bundle.crt
2024-10-24T13:46:21.807929179Z I1024 13:46:21.806447       1 tlsconfig.go:181] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"admin-kubeconfig-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:31 +0000 UTC to 2034-10-22 12:49:31 +0000 UTC (now=2024-10-24 13:46:21.806374589 +0000 UTC))"
2024-10-24T13:46:21.807929179Z I1024 13:46:21.806498       1 tlsconfig.go:181] "Loaded client CA" index=1 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2024-10-25 12:49:34 +0000 UTC (now=2024-10-24 13:46:21.806481469 +0000 UTC))"
2024-10-24T13:46:21.807929179Z I1024 13:46:21.806520       1 tlsconfig.go:181] "Loaded client CA" index=2 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-control-plane-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2025-10-24 12:49:34 +0000 UTC (now=2024-10-24 13:46:21.806505109 +0000 UTC))"
2024-10-24T13:46:21.807929179Z I1024 13:46:21.806547       1 tlsconfig.go:181] "Loaded client CA" index=3 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-apiserver-to-kubelet-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2025-10-24 12:49:34 +0000 UTC (now=2024-10-24 13:46:21.80652678 +0000 UTC))"
2024-10-24T13:46:21.807929179Z I1024 13:46:21.806567       1 tlsconfig.go:181] "Loaded client CA" index=4 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-bootstrap-kubeconfig-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:32 +0000 UTC to 2034-10-22 12:49:32 +0000 UTC (now=2024-10-24 13:46:21.806552349 +0000 UTC))"
2024-10-24T13:46:21.807929179Z I1024 13:46:21.806585       1 tlsconfig.go:181] "Loaded client CA" index=5 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-csr-signer_@1729775012\" [] issuer=\"kubelet-signer\" (2024-10-24 13:03:31 +0000 UTC to 2024-10-25 12:49:34 +0000 UTC (now=2024-10-24 13:46:21.806573749 +0000 UTC))"
2024-10-24T13:46:21.807929179Z I1024 13:46:21.806603       1 tlsconfig.go:181] "Loaded client CA" index=6 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_node-system-admin-signer@1729775011\" [] issuer=\"<self>\" (2024-10-24 13:03:30 +0000 UTC to 2025-10-24 13:03:31 +0000 UTC (now=2024-10-24 13:46:21.806590609 +0000 UTC))"
2024-10-24T13:46:21.807929179Z I1024 13:46:21.806621       1 tlsconfig.go:181] "Loaded client CA" index=7 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"aggregator-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:32 +0000 UTC to 2024-10-25 12:49:32 +0000 UTC (now=2024-10-24 13:46:21.8066106 +0000 UTC))"
2024-10-24T13:46:21.807929179Z I1024 13:46:21.806641       1 tlsconfig.go:181] "Loaded client CA" index=8 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_aggregator-client-signer@1729777579\" [] issuer=\"<self>\" (2024-10-24 13:46:18 +0000 UTC to 2024-10-25 01:46:19 +0000 UTC (now=2024-10-24 13:46:21.806626589 +0000 UTC))"
2024-10-24T13:46:21.807929179Z I1024 13:46:21.806889       1 tlsconfig.go:203] "Loaded serving cert" certName="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key" certDetail="\"metrics.openshift-kube-apiserver-operator.svc\" [serving] validServingFor=[metrics.openshift-kube-apiserver-operator.svc,metrics.openshift-kube-apiserver-operator.svc.cluster.local] issuer=\"openshift-service-serving-signer@1729775010\" (2024-10-24 13:03:41 +0000 UTC to 2026-10-24 13:03:42 +0000 UTC (now=2024-10-24 13:46:21.806839519 +0000 UTC))"
2024-10-24T13:46:21.807929179Z I1024 13:46:21.807041       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1729775940\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1729775940\" (2024-10-24 12:19:00 +0000 UTC to 2025-10-24 12:19:00 +0000 UTC (now=2024-10-24 13:46:21.80702054 +0000 UTC))"
2024-10-24T13:46:22.148552856Z I1024 13:46:22.148487       1 request.go:700] Waited for 1.98938525s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-11-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:46:23.348438724Z I1024 13:46:23.348360       1 request.go:700] Waited for 2.99204483s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-10-24T13:46:24.348570604Z I1024 13:46:24.348504       1 request.go:700] Waited for 2.784812152s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T13:46:25.548116222Z I1024 13:46:25.548053       1 request.go:700] Waited for 2.792594291s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-11
2024-10-24T13:46:26.747675519Z I1024 13:46:26.747618       1 request.go:700] Waited for 2.789180042s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:46:27.748033329Z I1024 13:46:27.747963       1 request.go:700] Waited for 2.594451274s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:46:28.948324447Z I1024 13:46:28.948264       1 request.go:700] Waited for 2.594396684s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T13:46:30.148286764Z I1024 13:46:30.148201       1 request.go:700] Waited for 2.153428759s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:46:31.348274852Z I1024 13:46:31.348213       1 request.go:700] Waited for 2.790775721s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets
2024-10-24T13:46:31.359690392Z I1024 13:46:31.359610       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'EncryptionKeyCreated' Secret "encryption-key-openshift-kube-apiserver-1" successfully created: ["key-does-not-exist"]
2024-10-24T13:46:32.548465820Z I1024 13:46:32.548406       1 request.go:700] Waited for 2.99285128s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:46:33.747923588Z I1024 13:46:33.747856       1 request.go:700] Waited for 2.378712916s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:46:34.748076848Z I1024 13:46:34.748027       1 request.go:700] Waited for 2.383912876s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config
2024-10-24T13:46:35.748435288Z I1024 13:46:35.748355       1 request.go:700] Waited for 2.392629236s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-11
2024-10-24T13:46:36.948264126Z I1024 13:46:36.948199       1 request.go:700] Waited for 2.590827234s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:46:38.147904174Z I1024 13:46:38.147844       1 request.go:700] Waited for 2.553243594s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:46:39.348391492Z I1024 13:46:39.348321       1 request.go:700] Waited for 2.99425715s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:46:40.547731770Z I1024 13:46:40.547664       1 request.go:700] Waited for 2.97205775s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:46:40.962230295Z I1024 13:46:40.962146       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/encryption-config-openshift-kube-apiserver -n openshift-config-managed because it was missing
2024-10-24T13:46:40.962328305Z I1024 13:46:40.962304       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'EncryptionResourceAdded' Resource "secrets" was added to encryption config without write key
2024-10-24T13:46:40.962375865Z I1024 13:46:40.962354       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'EncryptionResourceAdded' Resource "configmaps" was added to encryption config without write key
2024-10-24T13:46:41.548485370Z I1024 13:46:41.548394       1 request.go:700] Waited for 2.489689306s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-11
2024-10-24T13:46:42.747609978Z I1024 13:46:42.747546       1 request.go:700] Waited for 2.386967116s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config
2024-10-24T13:46:43.748418677Z I1024 13:46:43.748348       1 request.go:700] Waited for 2.390798956s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:46:44.948386986Z I1024 13:46:44.948316       1 request.go:700] Waited for 2.393045656s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:46:45.166118694Z I1024 13:46:45.166053       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/encryption-config -n openshift-kube-apiserver because it was missing
2024-10-24T13:46:45.170857394Z I1024 13:46:45.170813       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 12 triggered by "optional secret/encryption-config has been created"
2024-10-24T13:46:45.235663183Z I1024 13:46:45.235581       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveEncryptionConfigChanged' encryption config file changed from [] to /etc/kubernetes/static-pod-resources/secrets/encryption-config/encryption-config
2024-10-24T13:46:45.241518503Z I1024 13:46:45.241455       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-10-24T13:46:45.241518503Z   	"admission": map[string]any{"pluginConfig": map[string]any{"PodSecurity": map[string]any{"configuration": map[string]any{"defaults": map[string]any{"audit": string("restricted"), "audit-version": string("latest"), "enforce": string("restricted"), "enforce-version": string("latest"), ...}}}, "network.openshift.io/ExternalIPRanger": map[string]any{"configuration": map[string]any{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]any{"configuration": map[string]any{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []any{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2024-10-24T13:46:45.241518503Z   	"apiServerArguments": map[string]any{
2024-10-24T13:46:45.241518503Z   		"api-audiences":                            []any{string("https://kubernetes.default.svc")},
2024-10-24T13:46:45.241518503Z   		"authentication-token-webhook-config-file": []any{string("/etc/kubernetes/static-pod-resources/secrets/webhook-authenticat"...)},
2024-10-24T13:46:45.241518503Z   		"authentication-token-webhook-version":     []any{string("v1")},
2024-10-24T13:46:45.241518503Z + 		"encryption-provider-config": []any{
2024-10-24T13:46:45.241518503Z + 			string("/etc/kubernetes/static-pod-resources/secrets/encryption-config/encryption-config"),
2024-10-24T13:46:45.241518503Z + 		},
2024-10-24T13:46:45.241518503Z   		"etcd-servers":  []any{string("https://10.0.0.3:2379"), string("https://10.0.0.4:2379"), string("https://10.0.0.6:2379"), string("https://localhost:2379")},
2024-10-24T13:46:45.241518503Z   		"feature-gates": []any{string("AWSEFSDriverVolumeMetrics=true"), string("AdminNetworkPolicy=true"), string("AlibabaPlatform=true"), string("AzureWorkloadIdentity=true"), ...},
2024-10-24T13:46:45.241518503Z   		... // 4 identical entries
2024-10-24T13:46:45.241518503Z   	},
2024-10-24T13:46:45.241518503Z   	"authConfig":         map[string]any{"oauthMetadataFile": string("/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/o"...)},
2024-10-24T13:46:45.241518503Z   	"corsAllowedOrigins": []any{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2024-10-24T13:46:45.241518503Z   	... // 3 identical entries
2024-10-24T13:46:45.241518503Z   }
2024-10-24T13:46:45.284139433Z I1024 13:46:45.284063       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveEncryptionConfigChanged' encryption config file changed from [] to /etc/kubernetes/static-pod-resources/secrets/encryption-config/encryption-config
2024-10-24T13:46:45.284238093Z I1024 13:46:45.284211       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-10-24T13:46:45.284238093Z   	"admission": map[string]any{"pluginConfig": map[string]any{"PodSecurity": map[string]any{"configuration": map[string]any{"defaults": map[string]any{"audit": string("restricted"), "audit-version": string("latest"), "enforce": string("restricted"), "enforce-version": string("latest"), ...}}}, "network.openshift.io/ExternalIPRanger": map[string]any{"configuration": map[string]any{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]any{"configuration": map[string]any{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []any{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2024-10-24T13:46:45.284238093Z   	"apiServerArguments": map[string]any{
2024-10-24T13:46:45.284238093Z   		"api-audiences":                            []any{string("https://kubernetes.default.svc")},
2024-10-24T13:46:45.284238093Z   		"authentication-token-webhook-config-file": []any{string("/etc/kubernetes/static-pod-resources/secrets/webhook-authenticat"...)},
2024-10-24T13:46:45.284238093Z   		"authentication-token-webhook-version":     []any{string("v1")},
2024-10-24T13:46:45.284238093Z + 		"encryption-provider-config": []any{
2024-10-24T13:46:45.284238093Z + 			string("/etc/kubernetes/static-pod-resources/secrets/encryption-config/encryption-config"),
2024-10-24T13:46:45.284238093Z + 		},
2024-10-24T13:46:45.284238093Z   		"etcd-servers":  []any{string("https://10.0.0.3:2379"), string("https://10.0.0.4:2379"), string("https://10.0.0.6:2379"), string("https://localhost:2379")},
2024-10-24T13:46:45.284238093Z   		"feature-gates": []any{string("AWSEFSDriverVolumeMetrics=true"), string("AdminNetworkPolicy=true"), string("AlibabaPlatform=true"), string("AzureWorkloadIdentity=true"), ...},
2024-10-24T13:46:45.284238093Z   		... // 4 identical entries
2024-10-24T13:46:45.284238093Z   	},
2024-10-24T13:46:45.284238093Z   	"authConfig":         map[string]any{"oauthMetadataFile": string("/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/o"...)},
2024-10-24T13:46:45.284238093Z   	"corsAllowedOrigins": []any{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2024-10-24T13:46:45.284238093Z   	... // 3 identical entries
2024-10-24T13:46:45.284238093Z   }
2024-10-24T13:46:46.148171204Z I1024 13:46:46.148087       1 request.go:700] Waited for 2.522499115s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:46:47.148443244Z I1024 13:46:47.148369       1 request.go:700] Waited for 2.794633262s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2024-10-24T13:46:48.348216272Z I1024 13:46:48.348157       1 request.go:700] Waited for 3.177366408s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T13:46:49.548487680Z I1024 13:46:49.548438       1 request.go:700] Waited for 3.191036588s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:46:50.748016408Z I1024 13:46:50.747949       1 request.go:700] Waited for 3.182868858s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T13:46:51.360386972Z I1024 13:46:51.360326       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-12 -n openshift-kube-apiserver because it was missing
2024-10-24T13:46:51.947640086Z I1024 13:46:51.947579       1 request.go:700] Waited for 2.99004724s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-config-openshift-kube-apiserver
2024-10-24T13:46:52.947797556Z I1024 13:46:52.947693       1 request.go:700] Waited for 2.99239291s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:46:53.359992932Z I1024 13:46:53.359224       1 core.go:352] ConfigMap "openshift-kube-apiserver/config" changes: {"apiVersion":"v1","data":{"config.yaml":"{\"admission\":{\"pluginConfig\":{\"PodSecurity\":{\"configuration\":{\"apiVersion\":\"pod-security.admission.config.k8s.io/v1\",\"defaults\":{\"audit\":\"restricted\",\"audit-version\":\"latest\",\"enforce\":\"restricted\",\"enforce-version\":\"latest\",\"warn\":\"restricted\",\"warn-version\":\"latest\"},\"exemptions\":{\"usernames\":[\"system:serviceaccount:openshift-infra:build-controller\"]},\"kind\":\"PodSecurityConfiguration\"}},\"network.openshift.io/ExternalIPRanger\":{\"configuration\":{\"allowIngressIP\":false,\"apiVersion\":\"network.openshift.io/v1\",\"externalIPNetworkCIDRs\":null,\"kind\":\"ExternalIPRangerAdmissionConfig\"},\"location\":\"\"},\"network.openshift.io/RestrictedEndpointsAdmission\":{\"configuration\":{\"apiVersion\":\"network.openshift.io/v1\",\"kind\":\"RestrictedEndpointsAdmissionConfig\",\"restrictedCIDRs\":[\"10.128.0.0/14\",\"172.30.0.0/16\"]}}}},\"apiServerArguments\":{\"allow-privileged\":[\"true\"],\"anonymous-auth\":[\"true\"],\"api-audiences\":[\"https://kubernetes.default.svc\"],\"audit-log-format\":[\"json\"],\"audit-log-maxbackup\":[\"10\"],\"audit-log-maxsize\":[\"200\"],\"audit-log-path\":[\"/var/log/kube-apiserver/audit.log\"],\"audit-policy-file\":[\"/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-audit-policies/policy.yaml\"],\"authentication-token-webhook-config-file\":[\"/etc/kubernetes/static-pod-resources/secrets/webhook-authenticator/kubeConfig\"],\"authentication-token-webhook-version\":[\"v1\"],\"authorization-mode\":[\"Scope\",\"SystemMasters\",\"RBAC\",\"Node\"],\"client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/client-ca/ca-bundle.crt\"],\"enable-admission-plugins\":[\"CertificateApproval\",\"CertificateSigning\",\"CertificateSubjectRestriction\",\"DefaultIngressClass\",\"DefaultStorageClass\",\"DefaultTolerationSeconds\",\"LimitRanger\",\"MutatingAdmissionWebhook\",\"NamespaceLifecycle\",\"NodeRestriction\",\"OwnerReferencesPermissionEnforcement\",\"PersistentVolumeClaimResize\",\"PodNodeSelector\",\"PodTolerationRestriction\",\"Priority\",\"ResourceQuota\",\"RuntimeClass\",\"ServiceAccount\",\"StorageObjectInUseProtection\",\"TaintNodesByCondition\",\"ValidatingAdmissionWebhook\",\"ValidatingAdmissionPolicy\",\"authorization.openshift.io/RestrictSubjectBindings\",\"authorization.openshift.io/ValidateRoleBindingRestriction\",\"config.openshift.io/DenyDeleteClusterConfiguration\",\"config.openshift.io/ValidateAPIServer\",\"config.openshift.io/ValidateAuthentication\",\"config.openshift.io/ValidateConsole\",\"config.openshift.io/ValidateFeatureGate\",\"config.openshift.io/ValidateImage\",\"config.openshift.io/ValidateOAuth\",\"config.openshift.io/ValidateProject\",\"config.openshift.io/ValidateScheduler\",\"image.openshift.io/ImagePolicy\",\"network.openshift.io/ExternalIPRanger\",\"network.openshift.io/RestrictedEndpointsAdmission\",\"quota.openshift.io/ClusterResourceQuota\",\"quota.openshift.io/ValidateClusterResourceQuota\",\"route.openshift.io/IngressAdmission\",\"scheduling.openshift.io/OriginPodNodeEnvironment\",\"security.openshift.io/DefaultSecurityContextConstraints\",\"security.openshift.io/SCCExecRestrictions\",\"security.openshift.io/SecurityContextConstraint\",\"security.openshift.io/ValidateSecurityContextConstraints\",\"storage.openshift.io/CSIInlineVolumeSecurity\"],\"enable-aggregator-routing\":[\"true\"],\"enable-logs-handler\":[\"false\"],\"encryption-provider-config\":[\"/etc/kubernetes/static-pod-resources/secrets/encryption-config/encryption-config\"],\"endpoint-reconciler-type\":[\"lease\"],\"etcd-cafile\":[\"/etc/kubernetes/static-pod-resources/configmaps/etcd-serving-ca/ca-bundle.crt\"],\"etcd-certfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.crt\"],\"etcd-healthcheck-timeout\":[\"9s\"],\"etcd-keyfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.key\"],\"etcd-prefix\":[\"kubernetes.io\"],\"etcd-readycheck-timeout\":[\"9s\"],\"etcd-servers\":[\"https://10.0.0.3:2379\",\"https://10.0.0.4:2379\",\"https://10.0.0.6:2379\",\"https://localhost:2379\"],\"event-ttl\":[\"3h\"],\"feature-gates\":[\"AWSEFSDriverVolumeMetrics=true\",\"AdminNetworkPolicy=true\",\"AlibabaPlatform=true\",\"AzureWorkloadIdentity=true\",\"BareMetalLoadBalancer=true\",\"BuildCSIVolumes=true\",\"ChunkSizeMiB=true\",\"CloudDualStackNodeIPs=true\",\"DisableKubeletCloudCredentialProviders=true\",\"GCPLabelsTags=true\",\"HardwareSpeed=true\",\"IngressControllerLBSubnetsAWS=true\",\"KMSv1=true\",\"ManagedBootImages=true\",\"MetricsServer=true\",\"MultiArchInstallAWS=true\",\"MultiArchInstallGCP=true\",\"NetworkDiagnosticsConfig=true\",\"NetworkLiveMigration=true\",\"NodeDisruptionPolicy=true\",\"OpenShiftPodSecurityAdmission=true\",\"PrivateHostedZoneAWS=true\",\"SetEIPForNLBIngressController=true\",\"VSphereControlPlaneMachineSet=true\",\"VSphereDriverConfiguration=true\",\"VSphereStaticIPs=true\",\"ValidatingAdmissionPolicy=true\",\"AWSClusterHostedDNS=false\",\"AdditionalRoutingCapabilities=false\",\"AutomatedEtcdBackup=false\",\"BootcNodeManagement=false\",\"CSIDriverSharedResource=false\",\"ClusterAPIInstall=false\",\"ClusterAPIInstallIBMCloud=false\",\"ClusterMonitoringConfig=false\",\"DNSNameResolver=false\",\"DynamicResourceAllocation=false\",\"EtcdBackendQuota=false\",\"EventedPLEG=false\",\"Example=false\",\"ExternalOIDC=false\",\"GCPClusterHostedDNS=false\",\"GatewayAPI=false\",\"ImageStreamImportMode=false\",\"IngressControllerDynamicConfigurationManager=false\",\"InsightsConfig=false\",\"InsightsConfigAPI=false\",\"InsightsOnDemandDataGather=false\",\"InsightsRuntimeExtractor=false\",\"MachineAPIMigration=false\",\"MachineAPIOperatorDisableMachineHealthCheckController=false\",\"MachineAPIProviderOpenStack=false\",\"MachineConfigNodes=false\",\"ManagedBootImagesAWS=false\",\"MaxUnavailableStatefulSet=false\",\"MetricsCollectionProfiles=false\",\"MixedCPUsAllocation=false\",\"MultiArchInstallAzure=false\",\"NetworkSegmentation=false\",\"NewOLM=false\",\"NodeSwap=false\",\"OVNObservability=false\",\"OnClusterBuild=false\",\"PersistentIPsForVirtualization=false\",\"PinnedImages=false\",\"PlatformOperators=false\",\"ProcMountType=false\",\"RouteAdvertisements=false\",\"RouteExternalCertificate=false\",\"ServiceAccountTokenNodeBinding=false\",\"SignatureStores=false\",\"SigstoreImageVerification=false\",\"TranslateStreamCloseWebsocketRequests=false\",\"UpgradeStatus=false\",\"UserNamespacesPodSecurityStandards=false\",\"UserNamespacesSupport=false\",\"VSphereMultiNetworks=false\",\"VSphereMultiVCenters=false\",\"VolumeGroupSnapshot=false\"],\"goaway-chance\":[\"0\"],\"http2-max-streams-per-connection\":[\"2000\"],\"kubelet-certificate-authority\":[\"/etc/kubernetes/static-pod-resources/configmaps/kubelet-serving-ca/ca-bundle.crt\"],\"kubelet-client-certificate\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.crt\"],\"kubelet-client-key\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.key\"],\"kubelet-preferred-address-types\":[\"InternalIP\"],\"kubelet-read-only-port\":[\"0\"],\"kubernetes-service-node-port\":[\"0\"],\"max-mutating-requests-inflight\":[\"1000\"],\"max-requests-inflight\":[\"3000\"],\"min-request-timeout\":[\"3600\"],\"proxy-client-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.crt\"],\"proxy-client-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.key\"],\"requestheader-allowed-names\":[\"kube-apiserver-proxy\",\"system:kube-apiserver-proxy\",\"system:openshift-aggregator\"],\"requestheader-client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/aggregator-client-ca/ca-bundle.crt\"],\"requestheader-extra-headers-prefix\":[\"X-Remote-Extra-\"],\"requestheader-group-headers\":[\"X-Remote-Group\"],\"requestheader-username-headers\":[\"X-Remote-User\"],\"runtime-config\":[\"admissionregistration.k8s.io/v1beta1=true\"],\"send-retry-after-while-not-ready-once\":[\"false\"],\"service-account-issuer\":[\"https://kubernetes.default.svc\"],\"service-account-jwks-uri\":[\"https://api.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX:6443/openid/v1/jwks\"],\"service-account-lookup\":[\"true\"],\"service-account-signing-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/bound-service-account-signing-key/service-account.key\"],\"service-node-port-range\":[\"30000-32767\"],\"shutdown-delay-duration\":[\"70s\"],\"shutdown-send-retry-after\":[\"true\"],\"storage-backend\":[\"etcd3\"],\"storage-media-type\":[\"application/vnd.kubernetes.protobuf\"],\"strict-transport-security-directives\":[\"max-age=31536000,includeSubDomains,preload\"],\"tls-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\"],\"tls-private-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"]},\"apiVersion\":\"kubecontrolplane.config.openshift.io/v1\",\"authConfig\":{\"oauthMetadataFile\":\"/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/oauthMetadata\"},\"consolePublicURL\":\"\",\"corsAllowedOrigins\":[\"//127\\\\.0\\\\.0\\\\.1(:|$)\",\"//localhost(:|$)\"],\"imagePolicyConfig\":{\"internalRegistryHostname\":\"image-registry.openshift-image-registry.svc:5000\"},\"kind\":\"KubeAPIServerConfig\",\"projectConfig\":{\"defaultNodeSelector\":\"\"},\"serviceAccountPublicKeyFiles\":[\"/etc/kubernetes/static-pod-resources/configmaps/sa-token-signing-certs\",\"/etc/kubernetes/static-pod-resources/configmaps/bound-sa-token-signing-certs\"],\"servicesSubnet\":\"172.30.0.0/16\",\"servingInfo\":{\"bindAddress\":\"0.0.0.0:6443\",\"bindNetwork\":\"tcp4\",\"cipherSuites\":[\"TLS_AES_128_GCM_SHA256\",\"TLS_AES_256_GCM_SHA384\",\"TLS_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"],\"minTLSVersion\":\"VersionTLS12\",\"namedCertificates\":[{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.key\"}]}}"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:46:53.360903532Z I1024 13:46:53.360833       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/config -n openshift-kube-apiserver:
2024-10-24T13:46:53.360903532Z cause by changes in data.config.yaml
2024-10-24T13:46:53.947927136Z I1024 13:46:53.947850       1 request.go:700] Waited for 2.791915152s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:46:54.161966694Z I1024 13:46:54.161914       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-12 -n openshift-kube-apiserver because it was missing
2024-10-24T13:46:54.948257956Z I1024 13:46:54.948126       1 request.go:700] Waited for 2.793166472s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:46:56.148370823Z I1024 13:46:56.148302       1 request.go:700] Waited for 2.785668222s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-10-24T13:46:56.957569586Z I1024 13:46:56.957496       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-12 -n openshift-kube-apiserver because it was missing
2024-10-24T13:46:57.348057071Z I1024 13:46:57.347997       1 request.go:700] Waited for 2.790327742s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-11-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:46:58.348074411Z I1024 13:46:58.348007       1 request.go:700] Waited for 2.790281031s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-11
2024-10-24T13:46:59.358014801Z I1024 13:46:59.357953       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/oauth-metadata-12 -n openshift-kube-apiserver because it was missing
2024-10-24T13:46:59.548106379Z I1024 13:46:59.548050       1 request.go:700] Waited for 2.392430605s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:47:00.548361389Z I1024 13:47:00.548274       1 request.go:700] Waited for 2.390044086s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:47:01.748647817Z I1024 13:47:01.748589       1 request.go:700] Waited for 2.390616426s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T13:47:01.759989706Z I1024 13:47:01.759926       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-12 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:02.947998144Z I1024 13:47:02.947948       1 request.go:700] Waited for 2.189831997s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:47:03.760087466Z I1024 13:47:03.759640       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-12 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:04.148409282Z I1024 13:47:04.148332       1 request.go:700] Waited for 1.99123682s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-11-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:47:05.348708370Z I1024 13:47:05.348629       1 request.go:700] Waited for 1.589169894s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T13:47:05.359913500Z I1024 13:47:05.359850       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-12 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:06.548414078Z I1024 13:47:06.548343       1 request.go:700] Waited for 1.593986083s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T13:47:06.959163354Z I1024 13:47:06.959102       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-12 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:07.747849557Z I1024 13:47:07.747742       1 request.go:700] Waited for 1.589465755s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:47:08.559334279Z I1024 13:47:08.558925       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-12 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:08.747975907Z I1024 13:47:08.747916       1 request.go:700] Waited for 1.592514015s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:47:09.748491127Z I1024 13:47:09.748429       1 request.go:700] Waited for 1.495467606s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T13:47:10.157826283Z I1024 13:47:10.157770       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-12 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:10.948381085Z I1024 13:47:10.948326       1 request.go:700] Waited for 1.591969124s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:47:11.760260467Z I1024 13:47:11.760202       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-12 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:12.148084033Z I1024 13:47:12.148009       1 request.go:700] Waited for 1.591589484s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-11-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:47:13.148599293Z I1024 13:47:13.148531       1 request.go:700] Waited for 1.590016815s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:47:13.359920811Z I1024 13:47:13.359832       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/encryption-config-12 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:14.348127831Z I1024 13:47:14.348058       1 request.go:700] Waited for 2.577749515s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:47:15.548477279Z I1024 13:47:15.548414       1 request.go:700] Waited for 2.391429476s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:47:15.769473417Z I1024 13:47:15.769400       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-12 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:16.747989397Z I1024 13:47:16.747912       1 request.go:700] Waited for 2.591683114s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-11
2024-10-24T13:47:17.748396847Z I1024 13:47:17.748324       1 request.go:700] Waited for 2.583228384s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:47:18.363649001Z I1024 13:47:18.363589       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-12 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:18.948045535Z I1024 13:47:18.947979       1 request.go:700] Waited for 2.393555596s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:47:19.948645155Z I1024 13:47:19.948580       1 request.go:700] Waited for 2.385259456s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:47:20.761086437Z I1024 13:47:20.761001       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-12 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:21.147879113Z I1024 13:47:21.147814       1 request.go:700] Waited for 2.392269796s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:47:22.148543623Z I1024 13:47:22.148471       1 request.go:700] Waited for 2.390909216s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-11-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:47:23.148605253Z I1024 13:47:23.148538       1 request.go:700] Waited for 2.389203206s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/revision-status-12
2024-10-24T13:47:23.159226292Z I1024 13:47:23.159144       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 12 triggered by "optional secret/encryption-config has been created"
2024-10-24T13:47:23.161509543Z W1024 13:47:23.161465       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:47:23.161509543Z W1024 13:47:23.161491       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:47:23.193085102Z W1024 13:47:23.193023       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:47:23.193085102Z W1024 13:47:23.193054       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:47:23.232073332Z I1024 13:47:23.231984       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 13 triggered by "required configmap/config has changed"
2024-10-24T13:47:24.148694122Z I1024 13:47:24.148578       1 request.go:700] Waited for 2.390921556s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-11
2024-10-24T13:47:25.348621911Z I1024 13:47:25.348546       1 request.go:700] Waited for 2.189383238s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:47:26.348699361Z I1024 13:47:26.348631       1 request.go:700] Waited for 2.98738958s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-11
2024-10-24T13:47:27.548489209Z I1024 13:47:27.548341       1 request.go:700] Waited for 2.98143423s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:47:28.748236857Z I1024 13:47:28.748163       1 request.go:700] Waited for 2.99249754s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:47:28.961564265Z I1024 13:47:28.961501       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-13 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:29.748625827Z I1024 13:47:29.748560       1 request.go:700] Waited for 2.792074922s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:47:30.948155135Z I1024 13:47:30.948071       1 request.go:700] Waited for 2.794171262s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:47:31.760375007Z I1024 13:47:31.760305       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-13 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:31.948189255Z I1024 13:47:31.948113       1 request.go:700] Waited for 2.790204412s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-config-openshift-kube-apiserver
2024-10-24T13:47:32.948655205Z I1024 13:47:32.948589       1 request.go:700] Waited for 2.792167922s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:47:34.148361363Z I1024 13:47:34.148277       1 request.go:700] Waited for 2.792986812s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-12-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:47:34.356835471Z I1024 13:47:34.356773       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-13 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:35.348582861Z I1024 13:47:35.348510       1 request.go:700] Waited for 2.593671654s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:47:36.548184959Z I1024 13:47:36.548112       1 request.go:700] Waited for 2.590886474s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:47:36.775965496Z I1024 13:47:36.775887       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-12-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:36.958831555Z I1024 13:47:36.958736       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/oauth-metadata-13 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:37.747664087Z I1024 13:47:37.747593       1 request.go:700] Waited for 1.98531542s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:47:38.948019784Z I1024 13:47:38.947931       1 request.go:700] Waited for 2.172524049s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:47:40.148592002Z I1024 13:47:40.148522       1 request.go:700] Waited for 3.190032517s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T13:47:40.159605582Z I1024 13:47:40.159536       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-13 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:41.348085951Z I1024 13:47:41.348017       1 request.go:700] Waited for 3.191906698s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T13:47:42.348255161Z I1024 13:47:42.348184       1 request.go:700] Waited for 3.187777608s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:47:42.964631535Z I1024 13:47:42.964536       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-12-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:43.348313430Z I1024 13:47:43.348239       1 request.go:700] Waited for 3.188803829s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T13:47:43.362110391Z I1024 13:47:43.362017       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-13 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:44.348365890Z I1024 13:47:44.348306       1 request.go:700] Waited for 3.190685047s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-10-24T13:47:45.548662748Z I1024 13:47:45.548543       1 request.go:700] Waited for 3.190421218s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:47:46.569548608Z I1024 13:47:46.569494       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-13 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:46.748540666Z I1024 13:47:46.748479       1 request.go:700] Waited for 3.192826058s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:47:47.948091613Z I1024 13:47:47.948010       1 request.go:700] Waited for 3.288950427s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T13:47:48.948248994Z I1024 13:47:48.948191       1 request.go:700] Waited for 3.389254565s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:47:49.560350568Z I1024 13:47:49.560271       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-12-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:49.960060504Z I1024 13:47:49.959980       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-13 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:50.148474171Z I1024 13:47:50.148396       1 request.go:700] Waited for 3.391375266s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-11
2024-10-24T13:47:51.347923769Z I1024 13:47:51.347843       1 request.go:700] Waited for 3.189695928s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:47:52.348206279Z I1024 13:47:52.348136       1 request.go:700] Waited for 3.190293378s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-11
2024-10-24T13:47:53.158620201Z I1024 13:47:53.158549       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-13 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:53.548449457Z I1024 13:47:53.548384       1 request.go:700] Waited for 3.193968238s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:47:54.747682585Z I1024 13:47:54.747611       1 request.go:700] Waited for 3.189145838s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:47:55.748529185Z I1024 13:47:55.748457       1 request.go:700] Waited for 3.192602058s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:47:56.360657759Z I1024 13:47:56.360580       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-13 -n openshift-kube-apiserver because it was missing
2024-10-24T13:47:56.948516103Z I1024 13:47:56.948459       1 request.go:700] Waited for 3.190011768s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:47:58.148344712Z I1024 13:47:58.148274       1 request.go:700] Waited for 3.192901778s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:47:59.347600980Z I1024 13:47:59.347534       1 request.go:700] Waited for 3.180431788s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:47:59.558930547Z I1024 13:47:59.558869       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-13 -n openshift-kube-apiserver because it was missing
2024-10-24T13:48:00.347713650Z I1024 13:48:00.347630       1 request.go:700] Waited for 3.184153809s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:48:01.347966000Z I1024 13:48:01.347900       1 request.go:700] Waited for 2.992145811s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:48:02.348380060Z I1024 13:48:02.348302       1 request.go:700] Waited for 2.789676612s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets
2024-10-24T13:48:02.359977640Z I1024 13:48:02.359799       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/encryption-config-13 -n openshift-kube-apiserver because it was missing
2024-10-24T13:48:03.349565260Z I1024 13:48:03.349499       1 request.go:700] Waited for 2.788556152s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-10-24T13:48:04.547740359Z I1024 13:48:04.547659       1 request.go:700] Waited for 2.591752804s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-12-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:48:04.959341354Z I1024 13:48:04.959276       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-13 -n openshift-kube-apiserver because it was missing
2024-10-24T13:48:05.547920378Z I1024 13:48:05.547861       1 request.go:700] Waited for 2.592155374s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:48:06.747768086Z I1024 13:48:06.747681       1 request.go:700] Waited for 2.589347564s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:48:07.561284618Z I1024 13:48:07.560784       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-13 -n openshift-kube-apiserver because it was missing
2024-10-24T13:48:07.748357235Z I1024 13:48:07.748288       1 request.go:700] Waited for 2.592250784s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-config-openshift-kube-apiserver
2024-10-24T13:48:08.948282173Z I1024 13:48:08.948216       1 request.go:700] Waited for 2.391297326s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:48:09.761032895Z I1024 13:48:09.760947       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-13 -n openshift-kube-apiserver because it was missing
2024-10-24T13:48:09.948633583Z I1024 13:48:09.948565       1 request.go:700] Waited for 2.191504468s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:48:11.148063152Z I1024 13:48:11.147993       1 request.go:700] Waited for 2.191437718s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:48:11.959211614Z I1024 13:48:11.959144       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 13 triggered by "required configmap/config has changed"
2024-10-24T13:48:11.961249523Z W1024 13:48:11.961180       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:48:11.961249523Z W1024 13:48:11.961211       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:48:11.992140183Z W1024 13:48:11.992070       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:48:11.992140183Z W1024 13:48:11.992096       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:48:12.148257152Z I1024 13:48:12.148166       1 request.go:700] Waited for 2.190201179s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-11
2024-10-24T13:48:12.556088608Z I1024 13:48:12.556037       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 11 is the oldest and needs new revision 12
2024-10-24T13:48:12.556146628Z I1024 13:48:12.556127       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:48:12.556146628Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:48:12.556146628Z  CurrentRevision: (int32) 11,
2024-10-24T13:48:12.556146628Z  TargetRevision: (int32) 12,
2024-10-24T13:48:12.556146628Z  LastFailedRevision: (int32) 10,
2024-10-24T13:48:12.556146628Z  LastFailedTime: (*v1.Time)(0xc00731b758)(2024-10-24 13:30:03 +0000 UTC),
2024-10-24T13:48:12.556146628Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:48:12.556146628Z  LastFailedCount: (int) 1,
2024-10-24T13:48:12.556146628Z  LastFallbackCount: (int) 0,
2024-10-24T13:48:12.556146628Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:48:12.556146628Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:48:12.556146628Z  }
2024-10-24T13:48:12.556146628Z }
2024-10-24T13:48:12.558545708Z W1024 13:48:12.558502       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:48:12.558545708Z W1024 13:48:12.558520       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:48:12.558545708Z W1024 13:48:12.558525       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:48:12.558545708Z W1024 13:48:12.558529       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:48:12.558545708Z W1024 13:48:12.558532       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:48:12.558545708Z W1024 13:48:12.558535       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T13:48:12.594331047Z I1024 13:48:12.594236       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 11 to 12 because node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 11 is the oldest
2024-10-24T13:48:12.597323487Z I1024 13:48:12.597245       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:48:12Z","message":"NodeInstallerProgressing: 3 nodes are at revision 11; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 11; 0 nodes have achieved new revision 12","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:48:12.615675217Z I1024 13:48:12.615588       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing changed from False to True ("NodeInstallerProgressing: 3 nodes are at revision 11; 0 nodes have achieved new revision 12"),Available message changed from "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 11" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 11; 0 nodes have achieved new revision 12"
2024-10-24T13:48:13.148212261Z I1024 13:48:13.148155       1 request.go:700] Waited for 2.099800049s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T13:48:14.348323529Z I1024 13:48:14.348237       1 request.go:700] Waited for 2.389240725s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-12-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:48:15.348436249Z I1024 13:48:15.348329       1 request.go:700] Waited for 2.753629372s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:48:16.548104788Z I1024 13:48:16.548034       1 request.go:700] Waited for 2.783582402s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-11
2024-10-24T13:48:17.548346427Z I1024 13:48:17.548275       1 request.go:700] Waited for 2.789015062s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:48:18.748524984Z I1024 13:48:18.748465       1 request.go:700] Waited for 2.589672584s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:48:19.947808503Z I1024 13:48:19.947730       1 request.go:700] Waited for 2.191269917s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:48:21.147995991Z I1024 13:48:21.147906       1 request.go:700] Waited for 2.190764678s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:48:22.148221841Z I1024 13:48:22.148152       1 request.go:700] Waited for 2.191369128s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-11
2024-10-24T13:48:23.347607039Z I1024 13:48:23.347539       1 request.go:700] Waited for 2.190058068s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-11
2024-10-24T13:48:23.976871872Z I1024 13:48:23.976797       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-13-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-apiserver because it was missing
2024-10-24T13:48:24.347899929Z I1024 13:48:24.347831       1 request.go:700] Waited for 2.192502458s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:48:25.348235079Z I1024 13:48:25.348163       1 request.go:700] Waited for 2.193564058s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:48:26.548373977Z I1024 13:48:26.548299       1 request.go:700] Waited for 2.571951776s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:48:27.747965326Z I1024 13:48:27.747867       1 request.go:700] Waited for 2.792449254s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-10-24T13:48:28.748469867Z I1024 13:48:28.748383       1 request.go:700] Waited for 2.390066547s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:48:29.163080873Z I1024 13:48:29.163028       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-13-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-apiserver because it was missing
2024-10-24T13:48:29.948411215Z I1024 13:48:29.948355       1 request.go:700] Waited for 2.392202837s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:48:31.148122002Z I1024 13:48:31.148047       1 request.go:700] Waited for 2.391809547s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:48:32.348153951Z I1024 13:48:32.348079       1 request.go:700] Waited for 2.391390436s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:48:33.547886030Z I1024 13:48:33.547815       1 request.go:700] Waited for 2.390863347s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:48:33.963496265Z I1024 13:48:33.963426       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-13-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-apiserver because it was missing
2024-10-24T13:48:34.548036359Z I1024 13:48:34.547956       1 request.go:700] Waited for 2.393760126s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:48:34.758740128Z I1024 13:48:34.758619       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 11 is the oldest and needs new revision 13
2024-10-24T13:48:34.758828477Z I1024 13:48:34.758741       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:48:34.758828477Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:48:34.758828477Z  CurrentRevision: (int32) 11,
2024-10-24T13:48:34.758828477Z  TargetRevision: (int32) 13,
2024-10-24T13:48:34.758828477Z  LastFailedRevision: (int32) 10,
2024-10-24T13:48:34.758828477Z  LastFailedTime: (*v1.Time)(0xc007246ab0)(2024-10-24 13:30:03 +0000 UTC),
2024-10-24T13:48:34.758828477Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:48:34.758828477Z  LastFailedCount: (int) 1,
2024-10-24T13:48:34.758828477Z  LastFallbackCount: (int) 0,
2024-10-24T13:48:34.758828477Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:48:34.758828477Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:48:34.758828477Z  }
2024-10-24T13:48:34.758828477Z }
2024-10-24T13:48:34.762486227Z W1024 13:48:34.762447       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:48:34.762486227Z W1024 13:48:34.762467       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:48:34.762486227Z W1024 13:48:34.762472       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:48:34.762486227Z W1024 13:48:34.762476       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:48:34.762486227Z W1024 13:48:34.762479       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:48:34.762486227Z W1024 13:48:34.762482       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T13:48:34.794884127Z I1024 13:48:34.794784       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 11 to 13 because node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 11 is the oldest
2024-10-24T13:48:34.799602247Z I1024 13:48:34.799546       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:48:12Z","message":"NodeInstallerProgressing: 3 nodes are at revision 11; 0 nodes have achieved new revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 11; 0 nodes have achieved new revision 13","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:48:34.817622387Z I1024 13:48:34.815320       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 11; 0 nodes have achieved new revision 12" to "NodeInstallerProgressing: 3 nodes are at revision 11; 0 nodes have achieved new revision 13",Available message changed from "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 11; 0 nodes have achieved new revision 12" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 11; 0 nodes have achieved new revision 13"
2024-10-24T13:48:35.747870869Z I1024 13:48:35.747738       1 request.go:700] Waited for 2.384151108s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:48:36.748258630Z I1024 13:48:36.748195       1 request.go:700] Waited for 2.391760849s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-config-openshift-kube-apiserver
2024-10-24T13:48:37.948365588Z I1024 13:48:37.948275       1 request.go:700] Waited for 3.143316901s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:48:38.948422058Z I1024 13:48:38.948318       1 request.go:700] Waited for 3.192063419s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-11
2024-10-24T13:48:40.147674907Z I1024 13:48:40.147610       1 request.go:700] Waited for 3.191113349s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:48:41.148538237Z I1024 13:48:41.148444       1 request.go:700] Waited for 3.178112889s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:48:42.148536678Z I1024 13:48:42.148476       1 request.go:700] Waited for 3.19385065s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:48:43.347865585Z I1024 13:48:43.347765       1 request.go:700] Waited for 2.992410531s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:48:44.348567748Z I1024 13:48:44.348489       1 request.go:700] Waited for 2.591326687s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:48:45.548052827Z I1024 13:48:45.547989       1 request.go:700] Waited for 2.190230422s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:48:46.548474049Z I1024 13:48:46.548403       1 request.go:700] Waited for 2.39194822s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:48:47.548642592Z I1024 13:48:47.548570       1 request.go:700] Waited for 2.59304853s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:48:48.354185734Z I1024 13:48:48.354119       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:48:48.354185734Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:48:48.354185734Z  CurrentRevision: (int32) 11,
2024-10-24T13:48:48.354185734Z  TargetRevision: (int32) 13,
2024-10-24T13:48:48.354185734Z  LastFailedRevision: (int32) 10,
2024-10-24T13:48:48.354185734Z  LastFailedTime: (*v1.Time)(0xc004fc4348)(2024-10-24 13:30:03 +0000 UTC),
2024-10-24T13:48:48.354185734Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:48:48.354185734Z  LastFailedCount: (int) 1,
2024-10-24T13:48:48.354185734Z  LastFallbackCount: (int) 0,
2024-10-24T13:48:48.354185734Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:48:48.354185734Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:48:48.354185734Z  }
2024-10-24T13:48:48.354185734Z }
2024-10-24T13:48:48.354185734Z  because new revision pending
2024-10-24T13:48:48.748669810Z I1024 13:48:48.748593       1 request.go:700] Waited for 2.592230188s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T13:48:49.947772647Z I1024 13:48:49.947676       1 request.go:700] Waited for 2.390361205s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:48:50.947860747Z I1024 13:48:50.947797       1 request.go:700] Waited for 2.128037768s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:48:51.947991537Z I1024 13:48:51.947927       1 request.go:700] Waited for 2.183290338s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:48:52.947995206Z I1024 13:48:52.947938       1 request.go:700] Waited for 1.89894401s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T13:48:53.948622666Z I1024 13:48:53.948547       1 request.go:700] Waited for 1.990799159s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-11
2024-10-24T13:48:54.948672275Z I1024 13:48:54.948603       1 request.go:700] Waited for 1.99440778s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T13:48:56.148326323Z I1024 13:48:56.148252       1 request.go:700] Waited for 2.193779367s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:48:57.348011221Z I1024 13:48:57.347954       1 request.go:700] Waited for 2.189447158s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-10-24T13:48:57.774504216Z I1024 13:48:57.774417       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-apiserver because it was missing
2024-10-24T13:48:58.356859721Z I1024 13:48:58.356782       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:48:58.948215055Z I1024 13:48:58.948146       1 request.go:700] Waited for 1.173290908s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:48:59.948456254Z I1024 13:48:59.948384       1 request.go:700] Waited for 2.166377868s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:49:01.147626772Z I1024 13:49:01.147550       1 request.go:700] Waited for 2.192447048s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:49:02.148377472Z I1024 13:49:02.148314       1 request.go:700] Waited for 2.122282049s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-11
2024-10-24T13:49:03.348309819Z I1024 13:49:03.348252       1 request.go:700] Waited for 2.192863297s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:49:04.548507447Z I1024 13:49:04.548431       1 request.go:700] Waited for 1.9922674s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:49:05.748201035Z I1024 13:49:05.748140       1 request.go:700] Waited for 1.99257169s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-config-openshift-kube-apiserver
2024-10-24T13:49:06.947980453Z I1024 13:49:06.947917       1 request.go:700] Waited for 1.98908133s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:49:08.148207351Z I1024 13:49:08.148154       1 request.go:700] Waited for 1.593099934s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:49:08.356093009Z I1024 13:49:08.356014       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:49:09.148476361Z I1024 13:49:09.148388       1 request.go:700] Waited for 1.592252564s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-11
2024-10-24T13:49:10.148663911Z I1024 13:49:10.148607       1 request.go:700] Waited for 1.593557244s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:49:12.356075068Z I1024 13:49:12.356001       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:49:36.779951968Z I1024 13:49:36.779863       1 termination_observer.go:236] Observed event "TerminationPreShutdownHooksFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0" (last termination at 2024-10-24 13:32:46 +0000 UTC) at 2024-10-24 13:49:36 +0000 UTC
2024-10-24T13:49:38.625383229Z I1024 13:49:38.625316       1 request.go:700] Waited for 1.187816688s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-11
2024-10-24T13:49:39.824887887Z I1024 13:49:39.824812       1 request.go:700] Waited for 1.591824174s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:49:40.825126297Z I1024 13:49:40.825033       1 request.go:700] Waited for 1.99191185s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-11
2024-10-24T13:49:42.024846215Z I1024 13:49:42.024742       1 request.go:700] Waited for 1.987274s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:49:43.024999324Z I1024 13:49:43.024886       1 request.go:700] Waited for 1.590258143s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:49:44.025264704Z I1024 13:49:44.025202       1 request.go:700] Waited for 1.583308474s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:49:44.834084516Z I1024 13:49:44.834014       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because waiting for static pod of revision 13, found 11
2024-10-24T13:49:45.225129822Z I1024 13:49:45.225068       1 request.go:700] Waited for 1.593571074s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:49:46.425046330Z I1024 13:49:46.424968       1 request.go:700] Waited for 1.780623042s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T13:49:47.625277778Z I1024 13:49:47.625198       1 request.go:700] Waited for 2.391488075s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:49:48.625324027Z I1024 13:49:48.625258       1 request.go:700] Waited for 2.394232675s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:49:49.825414495Z I1024 13:49:49.825343       1 request.go:700] Waited for 1.991478899s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-config-openshift-kube-apiserver
2024-10-24T13:49:51.025913503Z I1024 13:49:51.025862       1 request.go:700] Waited for 1.99031504s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-10-24T13:49:52.224708661Z I1024 13:49:52.224625       1 request.go:700] Waited for 1.928502891s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:49:53.224984710Z I1024 13:49:53.224850       1 request.go:700] Waited for 2.389743096s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:49:54.225505590Z I1024 13:49:54.225419       1 request.go:700] Waited for 2.392178485s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-11
2024-10-24T13:49:55.424907908Z I1024 13:49:55.424851       1 request.go:700] Waited for 1.792514322s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:49:56.425378468Z I1024 13:49:56.425301       1 request.go:700] Waited for 1.9842788s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:49:57.032347441Z I1024 13:49:57.032295       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because waiting for static pod of revision 13, found 11
2024-10-24T13:49:57.625036315Z I1024 13:49:57.624967       1 request.go:700] Waited for 1.793441683s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:49:58.825435443Z I1024 13:49:58.825331       1 request.go:700] Waited for 1.789591132s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:50:00.025492520Z I1024 13:50:00.025423       1 request.go:700] Waited for 1.192444668s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:50:02.633190084Z I1024 13:50:02.633135       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because waiting for static pod of revision 13, found 11
2024-10-24T13:50:46.245472428Z I1024 13:50:46.245386       1 request.go:700] Waited for 1.189348569s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-11
2024-10-24T13:50:47.246270707Z I1024 13:50:47.246183       1 request.go:700] Waited for 1.391675685s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:50:48.761786502Z I1024 13:50:48.761652       1 termination_observer.go:236] Observed event "TerminationGracefulTerminationFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0" (last termination at 2024-10-24 13:32:46 +0000 UTC) at 2024-10-24 13:50:48 +0000 UTC
2024-10-24T13:50:48.862632241Z I1024 13:50:48.860869       1 request.go:700] Waited for 1.00967908s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:50:51.562823924Z I1024 13:50:51.562274       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:50:51.576490883Z I1024 13:50:51.576449       1 reflector.go:368] Caches populated for *v1.Authentication from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:50:51.622722423Z I1024 13:50:51.622667       1 reflector.go:368] Caches populated for *v1.Proxy from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:50:51.678375582Z I1024 13:50:51.677456       1 reflector.go:368] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:50:51.750832981Z I1024 13:50:51.749446       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:50:51.764566931Z I1024 13:50:51.764227       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:50:51.764566931Z I1024 13:50:51.764496       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2024-10-24T13:50:51.802448051Z I1024 13:50:51.802368       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:50:51.838627251Z I1024 13:50:51.838569       1 reflector.go:368] Caches populated for *v1alpha1.StorageVersionMigration from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:50:52.176366667Z I1024 13:50:52.175699       1 reflector.go:368] Caches populated for *v1.OAuth from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:51:04.359345273Z I1024 13:51:04.359268       1 request.go:700] Waited for 1.151323138s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:51:04.967652687Z I1024 13:51:04.967577       1 termination_observer.go:130] Observed termination of API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0" at 2024-10-24 13:51:03 +0000 UTC
2024-10-24T13:51:05.558532711Z I1024 13:51:05.558468       1 request.go:700] Waited for 1.99272918s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:51:06.559051640Z I1024 13:51:06.558991       1 request.go:700] Waited for 2.191623328s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:51:07.758623028Z I1024 13:51:07.758545       1 request.go:700] Waited for 2.189863487s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:51:08.758768858Z I1024 13:51:08.758669       1 request.go:700] Waited for 1.99076707s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:51:09.959295466Z I1024 13:51:09.959229       1 request.go:700] Waited for 1.9934791s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:51:11.158594354Z I1024 13:51:11.158516       1 request.go:700] Waited for 1.989576029s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:51:11.765725847Z I1024 13:51:11.765672       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because static pod is pending
2024-10-24T13:51:12.158950183Z I1024 13:51:12.158873       1 request.go:700] Waited for 1.991862909s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:51:13.159338793Z I1024 13:51:13.159270       1 request.go:700] Waited for 1.99398563s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:51:14.358854920Z I1024 13:51:14.358799       1 request.go:700] Waited for 1.98751581s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:51:15.359321310Z I1024 13:51:15.359256       1 request.go:700] Waited for 1.590798893s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:51:17.368346290Z I1024 13:51:17.368262       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because static pod is pending
2024-10-24T13:51:46.046440177Z I1024 13:51:46.046358       1 request.go:700] Waited for 1.002066129s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:51:47.047028507Z I1024 13:51:47.046958       1 request.go:700] Waited for 1.594059174s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:51:53.649206880Z I1024 13:51:53.649135       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:51:53.649206880Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:51:53.649206880Z  CurrentRevision: (int32) 13,
2024-10-24T13:51:53.649206880Z  TargetRevision: (int32) 0,
2024-10-24T13:51:53.649206880Z  LastFailedRevision: (int32) 10,
2024-10-24T13:51:53.649206880Z  LastFailedTime: (*v1.Time)(0xc006ff3830)(2024-10-24 13:30:03 +0000 UTC),
2024-10-24T13:51:53.649206880Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:51:53.649206880Z  LastFailedCount: (int) 1,
2024-10-24T13:51:53.649206880Z  LastFallbackCount: (int) 0,
2024-10-24T13:51:53.649206880Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:51:53.649206880Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:51:53.649206880Z  }
2024-10-24T13:51:53.649206880Z }
2024-10-24T13:51:53.649206880Z  because static pod is ready
2024-10-24T13:51:53.651563400Z W1024 13:51:53.651509       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:51:53.651563400Z W1024 13:51:53.651530       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:51:53.651563400Z W1024 13:51:53.651535       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:51:53.651563400Z W1024 13:51:53.651539       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:51:53.651563400Z W1024 13:51:53.651542       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:51:53.651563400Z W1024 13:51:53.651544       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T13:51:53.682882750Z I1024 13:51:53.682806       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 11 to 13 because static pod is ready
2024-10-24T13:51:53.691161989Z I1024 13:51:53.691100       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:48:12Z","message":"NodeInstallerProgressing: 2 nodes are at revision 11; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 11; 1 node is at revision 13","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:51:53.711184189Z I1024 13:51:53.710991       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 11; 0 nodes have achieved new revision 13" to "NodeInstallerProgressing: 2 nodes are at revision 11; 1 node is at revision 13",Available message changed from "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 11; 0 nodes have achieved new revision 13" to "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 11; 1 node is at revision 13"
2024-10-24T13:51:54.803887398Z I1024 13:51:54.803807       1 request.go:700] Waited for 1.113066529s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:51:56.003645956Z I1024 13:51:56.003565       1 request.go:700] Waited for 2.303370557s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:51:57.003720916Z I1024 13:51:57.003639       1 request.go:700] Waited for 2.593685434s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:51:58.003963285Z I1024 13:51:58.003896       1 request.go:700] Waited for 2.788949081s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-10-24T13:51:59.203796193Z I1024 13:51:59.203715       1 request.go:700] Waited for 2.189664157s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:52:00.403557721Z I1024 13:52:00.403480       1 request.go:700] Waited for 1.189280488s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:52:01.603921129Z I1024 13:52:01.603841       1 request.go:700] Waited for 1.193603518s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:52:02.803873056Z I1024 13:52:02.803813       1 request.go:700] Waited for 1.190502937s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:52:05.011008934Z I1024 13:52:05.010942       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-1 with revision 11 is the oldest and needs new revision 13
2024-10-24T13:52:05.011008934Z I1024 13:52:05.011000       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:52:05.011008934Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:52:05.011008934Z  CurrentRevision: (int32) 11,
2024-10-24T13:52:05.011008934Z  TargetRevision: (int32) 13,
2024-10-24T13:52:05.011008934Z  LastFailedRevision: (int32) 0,
2024-10-24T13:52:05.011008934Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:52:05.011008934Z  LastFailedReason: (string) "",
2024-10-24T13:52:05.011008934Z  LastFailedCount: (int) 0,
2024-10-24T13:52:05.011008934Z  LastFallbackCount: (int) 0,
2024-10-24T13:52:05.011008934Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:52:05.011008934Z }
2024-10-24T13:52:05.013006723Z W1024 13:52:05.012956       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:52:05.013006723Z W1024 13:52:05.012984       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:52:05.013006723Z W1024 13:52:05.012989       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:52:05.013006723Z W1024 13:52:05.012992       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:52:05.013006723Z W1024 13:52:05.012995       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:52:05.013006723Z W1024 13:52:05.012999       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T13:52:05.040181534Z I1024 13:52:05.040093       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 11 to 13 because node ci-op-2fcpj5j6-f6035-2lklf-master-1 with revision 11 is the oldest
2024-10-24T13:52:06.203668081Z I1024 13:52:06.203603       1 request.go:700] Waited for 1.160930428s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:52:07.403779969Z I1024 13:52:07.403706       1 request.go:700] Waited for 2.357521946s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T13:52:08.404034209Z I1024 13:52:08.403964       1 request.go:700] Waited for 2.790583521s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:52:09.603610447Z I1024 13:52:09.603551       1 request.go:700] Waited for 2.792410791s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:52:10.803797365Z I1024 13:52:10.803715       1 request.go:700] Waited for 2.791512772s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:52:12.003301283Z I1024 13:52:12.003208       1 request.go:700] Waited for 1.192822898s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:52:13.003480283Z I1024 13:52:13.003394       1 request.go:700] Waited for 1.089235469s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T13:52:14.004009542Z I1024 13:52:14.003927       1 request.go:700] Waited for 1.192894568s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-13-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:52:15.203440300Z I1024 13:52:15.203346       1 request.go:700] Waited for 1.393108876s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:52:16.204021190Z I1024 13:52:16.203949       1 request.go:700] Waited for 1.389869346s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:52:17.411843098Z I1024 13:52:17.411773       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-1 with revision 11 is the oldest and needs new revision 13
2024-10-24T13:52:17.411902898Z I1024 13:52:17.411840       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:52:17.411902898Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:52:17.411902898Z  CurrentRevision: (int32) 11,
2024-10-24T13:52:17.411902898Z  TargetRevision: (int32) 13,
2024-10-24T13:52:17.411902898Z  LastFailedRevision: (int32) 0,
2024-10-24T13:52:17.411902898Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:52:17.411902898Z  LastFailedReason: (string) "",
2024-10-24T13:52:17.411902898Z  LastFailedCount: (int) 0,
2024-10-24T13:52:17.411902898Z  LastFallbackCount: (int) 0,
2024-10-24T13:52:17.411902898Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:52:17.411902898Z }
2024-10-24T13:52:17.414503568Z I1024 13:52:17.414433       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 11 to 13 because node ci-op-2fcpj5j6-f6035-2lklf-master-1 with revision 11 is the oldest
2024-10-24T13:52:19.852778703Z I1024 13:52:19.852663       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-apiserver because it was missing
2024-10-24T13:52:20.413254687Z I1024 13:52:20.413186       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:52:21.004000792Z I1024 13:52:21.003940       1 request.go:700] Waited for 1.150627538s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:52:22.203976199Z I1024 13:52:22.203900       1 request.go:700] Waited for 1.98923715s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:52:23.403164077Z I1024 13:52:23.403088       1 request.go:700] Waited for 1.98857369s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:52:24.403976467Z I1024 13:52:24.403911       1 request.go:700] Waited for 1.99105217s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:52:26.616135374Z I1024 13:52:26.616058       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:52:28.813309091Z I1024 13:52:28.813235       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:52:58.427845710Z I1024 13:52:58.427729       1 termination_observer.go:236] Observed event "TerminationPreShutdownHooksFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1" (last termination at 2024-10-24 13:34:47 +0000 UTC) at 2024-10-24 13:52:58 +0000 UTC
2024-10-24T13:53:01.571635449Z I1024 13:53:01.571567       1 request.go:700] Waited for 1.143994438s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:53:02.771094286Z I1024 13:53:02.771018       1 request.go:700] Waited for 1.978545479s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:53:03.183898892Z I1024 13:53:03.183831       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because waiting for static pod of revision 13, found 11
2024-10-24T13:53:04.371567890Z I1024 13:53:04.371507       1 request.go:700] Waited for 1.150828798s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:53:07.371083886Z I1024 13:53:07.371005       1 request.go:700] Waited for 1.115946079s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:53:08.371172582Z I1024 13:53:08.371105       1 request.go:700] Waited for 1.592975902s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:53:08.381469553Z I1024 13:53:08.381379       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because waiting for static pod of revision 13, found 11
2024-10-24T13:53:09.371213698Z I1024 13:53:09.371133       1 request.go:700] Waited for 1.586800511s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:53:13.971457598Z I1024 13:53:13.971383       1 request.go:700] Waited for 1.139344939s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:53:15.172819130Z I1024 13:53:15.170901       1 request.go:700] Waited for 2.330828701s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:53:16.170993486Z I1024 13:53:16.170928       1 request.go:700] Waited for 2.348617242s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:53:17.171224142Z I1024 13:53:17.171153       1 request.go:700] Waited for 1.390933636s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:53:19.577375585Z I1024 13:53:19.577314       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because waiting for static pod of revision 13, found 11
2024-10-24T13:53:32.739111088Z I1024 13:53:32.739037       1 request.go:700] Waited for 1.16334565s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:53:33.739791544Z I1024 13:53:33.739720       1 request.go:700] Waited for 1.792301197s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:53:34.939371286Z I1024 13:53:34.939310       1 request.go:700] Waited for 1.785133407s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:53:35.939577312Z I1024 13:53:35.939514       1 request.go:700] Waited for 1.749019446s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:53:36.546221998Z I1024 13:53:36.546153       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because waiting for static pod of revision 13, found 11
2024-10-24T13:53:37.139350323Z I1024 13:53:37.139279       1 request.go:700] Waited for 1.000505126s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:53:38.339908314Z I1024 13:53:38.339842       1 request.go:700] Waited for 1.183362691s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:53:41.747357804Z I1024 13:53:41.747290       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because waiting for static pod of revision 13, found 11
2024-10-24T13:53:46.139950639Z I1024 13:53:46.139877       1 request.go:700] Waited for 1.093966529s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:53:47.339117730Z I1024 13:53:47.339058       1 request.go:700] Waited for 2.007235712s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:53:48.339889426Z I1024 13:53:48.339787       1 request.go:700] Waited for 2.394707583s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:53:49.548299597Z I1024 13:53:49.548243       1 request.go:700] Waited for 2.401995232s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:53:50.740078278Z I1024 13:53:50.739976       1 request.go:700] Waited for 1.199965082s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:53:51.940018620Z I1024 13:53:51.939972       1 request.go:700] Waited for 1.91226383s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:53:53.340100276Z I1024 13:53:53.340023       1 request.go:700] Waited for 1.087799358s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:53:54.539090348Z I1024 13:53:54.539014       1 request.go:700] Waited for 1.593416022s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T13:53:54.805930535Z I1024 13:53:54.805838       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX
2024-10-24T13:53:55.539477824Z I1024 13:53:55.539403       1 request.go:700] Waited for 1.590531232s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-10-24T13:53:55.950144695Z I1024 13:53:55.950077       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because waiting for static pod of revision 13, found 11
2024-10-24T13:53:56.541152050Z I1024 13:53:56.540911       1 request.go:700] Waited for 1.382641756s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:53:57.739925071Z I1024 13:53:57.739874       1 request.go:700] Waited for 1.202640491s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:53:58.939284442Z I1024 13:53:58.939233       1 request.go:700] Waited for 1.987868603s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:54:02.546929597Z I1024 13:54:02.546867       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because waiting for static pod of revision 13, found 11
2024-10-24T13:54:10.399361412Z I1024 13:54:10.399295       1 termination_observer.go:236] Observed event "TerminationGracefulTerminationFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1" (last termination at 2024-10-24 13:34:47 +0000 UTC) at 2024-10-24 13:54:10 +0000 UTC
2024-10-24T13:54:15.498666556Z I1024 13:54:15.498597       1 request.go:700] Waited for 1.182185831s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:54:15.705510311Z I1024 13:54:15.705441       1 termination_observer.go:130] Observed termination of API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1" at 2024-10-24 13:54:14 +0000 UTC
2024-10-24T13:54:16.698271537Z I1024 13:54:16.698201       1 request.go:700] Waited for 1.988111242s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:54:17.700012003Z I1024 13:54:17.698981       1 request.go:700] Waited for 1.993267102s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:54:18.898188744Z I1024 13:54:18.898113       1 request.go:700] Waited for 1.984450302s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:54:20.098810296Z I1024 13:54:20.098511       1 request.go:700] Waited for 1.984368462s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:54:21.098804262Z I1024 13:54:21.098734       1 request.go:700] Waited for 1.789279297s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:54:21.504712762Z I1024 13:54:21.504642       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because static pod is pending
2024-10-24T13:54:24.098141140Z I1024 13:54:24.098079       1 request.go:700] Waited for 1.181015951s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:54:25.298025171Z I1024 13:54:25.297962       1 request.go:700] Waited for 1.55243744s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:54:26.298146258Z I1024 13:54:26.298077       1 request.go:700] Waited for 1.911782311s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:54:27.497891969Z I1024 13:54:27.497832       1 request.go:700] Waited for 1.989267942s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:54:28.498343495Z I1024 13:54:28.498266       1 request.go:700] Waited for 1.989898842s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:54:28.905328716Z I1024 13:54:28.905263       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because static pod is pending
2024-10-24T13:54:31.908195814Z I1024 13:54:31.908115       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because static pod is pending
2024-10-24T13:54:35.498315778Z I1024 13:54:35.498253       1 request.go:700] Waited for 1.102791919s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:55:04.650454579Z I1024 13:55:04.650370       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:55:04.650454579Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:55:04.650454579Z  CurrentRevision: (int32) 13,
2024-10-24T13:55:04.650454579Z  TargetRevision: (int32) 0,
2024-10-24T13:55:04.650454579Z  LastFailedRevision: (int32) 0,
2024-10-24T13:55:04.650454579Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:55:04.650454579Z  LastFailedReason: (string) "",
2024-10-24T13:55:04.650454579Z  LastFailedCount: (int) 0,
2024-10-24T13:55:04.650454579Z  LastFallbackCount: (int) 0,
2024-10-24T13:55:04.650454579Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:55:04.650454579Z }
2024-10-24T13:55:04.650454579Z  because static pod is ready
2024-10-24T13:55:04.653163529Z W1024 13:55:04.653118       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:55:04.653163529Z W1024 13:55:04.653147       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:55:04.653163529Z W1024 13:55:04.653154       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:55:04.653216269Z W1024 13:55:04.653159       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:55:04.653216269Z W1024 13:55:04.653166       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:55:04.653216269Z W1024 13:55:04.653170       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T13:55:04.682986560Z I1024 13:55:04.682732       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 11 to 13 because static pod is ready
2024-10-24T13:55:04.692101270Z I1024 13:55:04.692002       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:48:12Z","message":"NodeInstallerProgressing: 1 node is at revision 11; 2 nodes are at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 11; 2 nodes are at revision 13","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:55:04.709924931Z I1024 13:55:04.709860       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 11; 1 node is at revision 13" to "NodeInstallerProgressing: 1 node is at revision 11; 2 nodes are at revision 13",Available message changed from "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 11; 1 node is at revision 13" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 11; 2 nodes are at revision 13"
2024-10-24T13:55:05.848155770Z I1024 13:55:05.848071       1 request.go:700] Waited for 1.154887081s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:55:07.047929312Z I1024 13:55:07.047854       1 request.go:700] Waited for 2.32133951s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:55:08.247966703Z I1024 13:55:08.247890       1 request.go:700] Waited for 2.588823508s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:55:09.447709864Z I1024 13:55:09.447640       1 request.go:700] Waited for 2.585828598s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:55:10.448124221Z I1024 13:55:10.448028       1 request.go:700] Waited for 1.094676889s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T13:55:11.647246892Z I1024 13:55:11.647184       1 request.go:700] Waited for 1.193324031s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T13:55:12.847369504Z I1024 13:55:12.847283       1 request.go:700] Waited for 1.122948779s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:55:13.847991970Z I1024 13:55:13.847906       1 request.go:700] Waited for 1.194558622s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:55:15.253797536Z I1024 13:55:15.253722       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-2 with revision 11 is the oldest and needs new revision 13
2024-10-24T13:55:15.253874476Z I1024 13:55:15.253802       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:55:15.253874476Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:55:15.253874476Z  CurrentRevision: (int32) 11,
2024-10-24T13:55:15.253874476Z  TargetRevision: (int32) 13,
2024-10-24T13:55:15.253874476Z  LastFailedRevision: (int32) 0,
2024-10-24T13:55:15.253874476Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:55:15.253874476Z  LastFailedReason: (string) "",
2024-10-24T13:55:15.253874476Z  LastFailedCount: (int) 0,
2024-10-24T13:55:15.253874476Z  LastFallbackCount: (int) 0,
2024-10-24T13:55:15.253874476Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:55:15.253874476Z }
2024-10-24T13:55:15.255902607Z W1024 13:55:15.255873       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:55:15.255902607Z W1024 13:55:15.255890       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:55:15.255902607Z W1024 13:55:15.255895       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:55:15.255902607Z W1024 13:55:15.255899       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:55:15.255960507Z W1024 13:55:15.255902       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:55:15.255960507Z W1024 13:55:15.255904       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T13:55:15.289537707Z I1024 13:55:15.289459       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 11 to 13 because node ci-op-2fcpj5j6-f6035-2lklf-master-2 with revision 11 is the oldest
2024-10-24T13:55:16.447842008Z I1024 13:55:16.447715       1 request.go:700] Waited for 1.15662476s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:55:17.448146614Z I1024 13:55:17.448077       1 request.go:700] Waited for 2.153314947s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T13:55:18.647882125Z I1024 13:55:18.647803       1 request.go:700] Waited for 2.791186933s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:55:19.847886496Z I1024 13:55:19.847830       1 request.go:700] Waited for 2.786624712s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-13-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:55:21.047698447Z I1024 13:55:21.047625       1 request.go:700] Waited for 2.791391013s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:55:22.047767393Z I1024 13:55:22.047677       1 request.go:700] Waited for 1.708091385s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:55:23.048139410Z I1024 13:55:23.048029       1 request.go:700] Waited for 1.189947491s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-13-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:55:24.247702831Z I1024 13:55:24.247619       1 request.go:700] Waited for 1.188999971s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-13-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:55:25.248196457Z I1024 13:55:25.248076       1 request.go:700] Waited for 1.388728126s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:55:26.447616348Z I1024 13:55:26.447542       1 request.go:700] Waited for 1.192470771s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:55:27.655087030Z I1024 13:55:27.655008       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-2 with revision 11 is the oldest and needs new revision 13
2024-10-24T13:55:27.655087030Z I1024 13:55:27.655074       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:55:27.655087030Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:55:27.655087030Z  CurrentRevision: (int32) 11,
2024-10-24T13:55:27.655087030Z  TargetRevision: (int32) 13,
2024-10-24T13:55:27.655087030Z  LastFailedRevision: (int32) 0,
2024-10-24T13:55:27.655087030Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:55:27.655087030Z  LastFailedReason: (string) "",
2024-10-24T13:55:27.655087030Z  LastFailedCount: (int) 0,
2024-10-24T13:55:27.655087030Z  LastFallbackCount: (int) 0,
2024-10-24T13:55:27.655087030Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:55:27.655087030Z }
2024-10-24T13:55:27.657891780Z I1024 13:55:27.657718       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 11 to 13 because node ci-op-2fcpj5j6-f6035-2lklf-master-2 with revision 11 is the oldest
2024-10-24T13:55:30.270392157Z I1024 13:55:30.270255       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-apiserver because it was missing
2024-10-24T13:55:30.454240832Z I1024 13:55:30.454138       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 13, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:55:31.447766988Z I1024 13:55:31.447658       1 request.go:700] Waited for 1.17611685s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:55:32.648026670Z I1024 13:55:32.647955       1 request.go:700] Waited for 1.987121022s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:55:33.648804616Z I1024 13:55:33.648366       1 request.go:700] Waited for 1.991475992s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:55:34.848102057Z I1024 13:55:34.848031       1 request.go:700] Waited for 1.992528892s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:55:36.047487419Z I1024 13:55:36.047394       1 request.go:700] Waited for 1.589906121s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:55:37.253571690Z I1024 13:55:37.253517       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 13, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:55:39.453715118Z I1024 13:55:39.453648       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 13, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:56:08.991377518Z I1024 13:56:08.991246       1 termination_observer.go:236] Observed event "TerminationPreShutdownHooksFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2" (last termination at 2024-10-24 13:36:22 +0000 UTC) at 2024-10-24 13:56:08 +0000 UTC
2024-10-24T13:56:12.199737082Z I1024 13:56:12.199677       1 request.go:700] Waited for 1.1396462s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:56:13.401934973Z I1024 13:56:13.401877       1 request.go:700] Waited for 1.992749252s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:56:14.008956439Z I1024 13:56:14.008905       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 13, but has not made progress because waiting for static pod of revision 13, found 11
2024-10-24T13:56:16.809643982Z I1024 13:56:16.809544       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 13, but has not made progress because waiting for static pod of revision 13, found 11
2024-10-24T13:56:25.373331195Z I1024 13:56:25.373260       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 13, but has not made progress because waiting for static pod of revision 13, found 11
2024-10-24T13:57:20.967822945Z I1024 13:57:20.967631       1 termination_observer.go:236] Observed event "TerminationGracefulTerminationFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2" (last termination at 2024-10-24 13:36:22 +0000 UTC) at 2024-10-24 13:57:20 +0000 UTC
2024-10-24T13:57:28.001485999Z I1024 13:57:28.001417       1 request.go:700] Waited for 1.121688819s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:57:28.413515889Z I1024 13:57:28.413403       1 termination_observer.go:130] Observed termination of API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2" at 2024-10-24 13:57:26 +0000 UTC
2024-10-24T13:57:29.200620420Z I1024 13:57:29.200518       1 request.go:700] Waited for 1.983401802s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:57:30.201524466Z I1024 13:57:30.201451       1 request.go:700] Waited for 1.989948212s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:57:31.401365777Z I1024 13:57:31.401281       1 request.go:700] Waited for 1.987705172s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:57:32.401389904Z I1024 13:57:32.401320       1 request.go:700] Waited for 1.991107542s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:57:33.601272015Z I1024 13:57:33.601177       1 request.go:700] Waited for 1.648175993s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:57:34.801423956Z I1024 13:57:34.801326       1 request.go:700] Waited for 1.988646741s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T13:57:36.001567328Z I1024 13:57:36.001480       1 request.go:700] Waited for 2.189522627s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:57:36.410630868Z I1024 13:57:36.410563       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 13, but has not made progress because static pod is pending
2024-10-24T13:57:37.201400929Z I1024 13:57:37.201315       1 request.go:700] Waited for 1.792193667s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:57:40.010178682Z I1024 13:57:40.010116       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 13, but has not made progress because static pod is pending
2024-10-24T13:57:46.062646680Z I1024 13:57:46.062581       1 request.go:700] Waited for 1.005690076s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:57:48.062596093Z I1024 13:57:48.062532       1 request.go:700] Waited for 1.114649479s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:57:49.062711719Z I1024 13:57:49.062646       1 request.go:700] Waited for 2.107492715s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:57:50.063457645Z I1024 13:57:50.063381       1 request.go:700] Waited for 1.791739026s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-13
2024-10-24T13:57:51.263327846Z I1024 13:57:51.263250       1 request.go:700] Waited for 1.592906782s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:57:52.462944507Z I1024 13:57:52.462867       1 request.go:700] Waited for 1.590201231s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:57:53.662580508Z I1024 13:57:53.662499       1 request.go:700] Waited for 1.955070961s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:57:54.663460494Z I1024 13:57:54.663290       1 request.go:700] Waited for 2.793033962s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:57:55.862985265Z I1024 13:57:55.862929       1 request.go:700] Waited for 2.792587913s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:57:56.863482932Z I1024 13:57:56.863420       1 request.go:700] Waited for 2.391767343s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-10-24T13:57:57.278347732Z I1024 13:57:57.277526       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretUpdated' Updated Secret/encryption-config-openshift-kube-apiserver -n openshift-config-managed because it changed
2024-10-24T13:57:57.278347732Z I1024 13:57:57.277566       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'EncryptionKeyPromoted' Promoting key "1" for resource "configmaps" to write key
2024-10-24T13:57:57.278347732Z I1024 13:57:57.277577       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'EncryptionKeyPromoted' Promoting key "1" for resource "secrets" to write key
2024-10-24T13:57:58.062725443Z I1024 13:57:58.062664       1 request.go:700] Waited for 2.32299175s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T13:57:59.062978549Z I1024 13:57:59.062911       1 request.go:700] Waited for 2.191897577s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-10-24T13:57:59.698206035Z I1024 13:57:59.698114       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretUpdated' Updated Secret/encryption-config -n openshift-kube-apiserver because it changed
2024-10-24T13:57:59.715123805Z I1024 13:57:59.715051       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 14 triggered by "optional secret/encryption-config has changed"
2024-10-24T13:58:00.063200655Z I1024 13:58:00.063109       1 request.go:700] Waited for 2.392749683s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:58:01.063288071Z I1024 13:58:01.063224       1 request.go:700] Waited for 1.369955256s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:58:02.263485452Z I1024 13:58:02.263395       1 request.go:700] Waited for 1.992762962s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:58:03.463027603Z I1024 13:58:03.462967       1 request.go:700] Waited for 1.785629196s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:58:03.874796984Z I1024 13:58:03.874705       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-14 -n openshift-kube-apiserver because it was missing
2024-10-24T13:58:04.663053065Z I1024 13:58:04.662994       1 request.go:700] Waited for 2.376409812s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:58:05.863387436Z I1024 13:58:05.863226       1 request.go:700] Waited for 2.192036687s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-13-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:58:06.285520797Z I1024 13:58:06.285463       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-14 -n openshift-kube-apiserver because it was missing
2024-10-24T13:58:07.062891247Z I1024 13:58:07.062821       1 request.go:700] Waited for 2.392363142s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-13
2024-10-24T13:58:08.063028444Z I1024 13:58:08.062975       1 request.go:700] Waited for 2.29829067s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T13:58:08.673020890Z I1024 13:58:08.672956       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-14 -n openshift-kube-apiserver because it was missing
2024-10-24T13:58:09.063348150Z I1024 13:58:09.063275       1 request.go:700] Waited for 2.192940428s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:58:10.262762591Z I1024 13:58:10.262655       1 request.go:700] Waited for 2.391260153s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:58:11.074328932Z I1024 13:58:11.074257       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/oauth-metadata-14 -n openshift-kube-apiserver because it was missing
2024-10-24T13:58:11.263259667Z I1024 13:58:11.263179       1 request.go:700] Waited for 2.386598962s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:58:12.263265183Z I1024 13:58:12.263196       1 request.go:700] Waited for 2.390947312s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-10-24T13:58:13.463397533Z I1024 13:58:13.463329       1 request.go:700] Waited for 2.389038991s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T13:58:13.475385194Z I1024 13:58:13.475311       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-14 -n openshift-kube-apiserver because it was missing
2024-10-24T13:58:14.663190065Z I1024 13:58:14.663126       1 request.go:700] Waited for 1.700445643s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T13:58:15.273735841Z I1024 13:58:15.273649       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-14 -n openshift-kube-apiserver because it was missing
2024-10-24T13:58:15.863255375Z I1024 13:58:15.863155       1 request.go:700] Waited for 1.792197456s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-10-24T13:58:16.873842560Z I1024 13:58:16.873744       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-14 -n openshift-kube-apiserver because it was missing
2024-10-24T13:58:17.063157115Z I1024 13:58:17.063082       1 request.go:700] Waited for 1.586498879s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:58:18.262820336Z I1024 13:58:18.262711       1 request.go:700] Waited for 1.5897583s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:58:18.474821451Z I1024 13:58:18.474746       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-14 -n openshift-kube-apiserver because it was missing
2024-10-24T13:58:19.263455221Z I1024 13:58:19.263384       1 request.go:700] Waited for 1.5921716s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:58:20.072526382Z I1024 13:58:20.072456       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-14 -n openshift-kube-apiserver because it was missing
2024-10-24T13:58:20.462770282Z I1024 13:58:20.462697       1 request.go:700] Waited for 1.589542371s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:58:21.462988117Z I1024 13:58:21.462903       1 request.go:700] Waited for 1.588048021s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:58:21.674635963Z I1024 13:58:21.674568       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-14 -n openshift-kube-apiserver because it was missing
2024-10-24T13:58:22.463272574Z I1024 13:58:22.463196       1 request.go:700] Waited for 1.591499722s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:58:22.473967894Z I1024 13:58:22.473909       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:58:22.473967894Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:58:22.473967894Z  CurrentRevision: (int32) 13,
2024-10-24T13:58:22.473967894Z  TargetRevision: (int32) 0,
2024-10-24T13:58:22.473967894Z  LastFailedRevision: (int32) 0,
2024-10-24T13:58:22.473967894Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:58:22.473967894Z  LastFailedReason: (string) "",
2024-10-24T13:58:22.473967894Z  LastFailedCount: (int) 0,
2024-10-24T13:58:22.473967894Z  LastFallbackCount: (int) 0,
2024-10-24T13:58:22.473967894Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:58:22.473967894Z }
2024-10-24T13:58:22.473967894Z  because static pod is ready
2024-10-24T13:58:22.476098454Z W1024 13:58:22.476041       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:58:22.476098454Z W1024 13:58:22.476069       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:58:22.476098454Z W1024 13:58:22.476075       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:58:22.476098454Z W1024 13:58:22.476081       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:58:22.476098454Z W1024 13:58:22.476086       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T13:58:22.507291695Z I1024 13:58:22.507204       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 11 to 13 because static pod is ready
2024-10-24T13:58:22.513391785Z I1024 13:58:22.513324       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:58:22Z","message":"NodeInstallerProgressing: 3 nodes are at revision 13","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 13","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:58:22.534878606Z I1024 13:58:22.534342       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing changed from True to False ("NodeInstallerProgressing: 3 nodes are at revision 13"),Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 11; 2 nodes are at revision 13" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 13"
2024-10-24T13:58:23.276101694Z I1024 13:58:23.276018       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-14 -n openshift-kube-apiserver because it was missing
2024-10-24T13:58:23.463389969Z I1024 13:58:23.463290       1 request.go:700] Waited for 1.58127827s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:58:24.662929970Z I1024 13:58:24.662843       1 request.go:700] Waited for 2.150266526s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:58:25.863186029Z I1024 13:58:25.863058       1 request.go:700] Waited for 2.991323545s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-13-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:58:26.274181029Z I1024 13:58:26.274121       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/encryption-config-14 -n openshift-kube-apiserver because it was missing
2024-10-24T13:58:27.063820431Z I1024 13:58:27.063733       1 request.go:700] Waited for 2.992629475s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:58:28.262652881Z I1024 13:58:28.262555       1 request.go:700] Waited for 2.991851145s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:58:29.262665195Z I1024 13:58:29.262589       1 request.go:700] Waited for 2.988424956s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets
2024-10-24T13:58:29.277303076Z I1024 13:58:29.277214       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-14 -n openshift-kube-apiserver because it was missing
2024-10-24T13:58:30.263015139Z I1024 13:58:30.262946       1 request.go:700] Waited for 2.991056933s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:58:31.263851916Z I1024 13:58:31.263201       1 request.go:700] Waited for 2.79389922s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:58:31.888510072Z I1024 13:58:31.888448       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-14 -n openshift-kube-apiserver because it was missing
2024-10-24T13:58:32.462931086Z I1024 13:58:32.462864       1 request.go:700] Waited for 2.592640476s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-10-24T13:58:33.463039023Z I1024 13:58:33.462970       1 request.go:700] Waited for 2.588906097s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:58:34.476640297Z I1024 13:58:34.476585       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-14 -n openshift-kube-apiserver because it was missing
2024-10-24T13:58:34.663472892Z I1024 13:58:34.663369       1 request.go:700] Waited for 2.583771085s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:58:35.862538153Z I1024 13:58:35.862448       1 request.go:700] Waited for 2.575355485s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:58:36.862636011Z I1024 13:58:36.862556       1 request.go:700] Waited for 2.791833963s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T13:58:37.073927057Z I1024 13:58:37.073861       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 14 triggered by "optional secret/encryption-config has changed"
2024-10-24T13:58:37.075279607Z W1024 13:58:37.075213       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:58:37.075279607Z W1024 13:58:37.075241       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:58:37.111657357Z W1024 13:58:37.111594       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:58:37.111817448Z W1024 13:58:37.111740       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:58:37.863316637Z I1024 13:58:37.863234       1 request.go:700] Waited for 2.592604609s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:58:37.871697117Z I1024 13:58:37.871644       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:58:37.871697117Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:58:37.871697117Z  CurrentRevision: (int32) 13,
2024-10-24T13:58:37.871697117Z  TargetRevision: (int32) 0,
2024-10-24T13:58:37.871697117Z  LastFailedRevision: (int32) 0,
2024-10-24T13:58:37.871697117Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:58:37.871697117Z  LastFailedReason: (string) "",
2024-10-24T13:58:37.871697117Z  LastFailedCount: (int) 0,
2024-10-24T13:58:37.871697117Z  LastFallbackCount: (int) 0,
2024-10-24T13:58:37.871697117Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:58:37.871697117Z }
2024-10-24T13:58:37.871697117Z  because static pod is ready
2024-10-24T13:58:37.874770817Z I1024 13:58:37.874672       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 11 to 13 because static pod is ready
2024-10-24T13:58:39.062918306Z I1024 13:58:39.062835       1 request.go:700] Waited for 2.392323109s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:58:40.262713398Z I1024 13:58:40.262643       1 request.go:700] Waited for 2.791494781s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:58:41.263048266Z I1024 13:58:41.262983       1 request.go:700] Waited for 2.792239505s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:58:42.462459356Z I1024 13:58:42.462393       1 request.go:700] Waited for 2.791533834s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-13-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:58:43.463220722Z I1024 13:58:43.463149       1 request.go:700] Waited for 2.390498881s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-13
2024-10-24T13:58:44.663067883Z I1024 13:58:44.662993       1 request.go:700] Waited for 2.191270277s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-13-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:58:45.863401925Z I1024 13:58:45.863322       1 request.go:700] Waited for 2.175287456s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:58:47.063398736Z I1024 13:58:47.063321       1 request.go:700] Waited for 2.408603853s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T13:58:48.262993638Z I1024 13:58:48.262929       1 request.go:700] Waited for 2.790168164s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-13
2024-10-24T13:58:49.263299244Z I1024 13:58:49.263194       1 request.go:700] Waited for 2.582833648s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:58:49.688005605Z I1024 13:58:49.687926       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-14-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-apiserver because it was missing
2024-10-24T13:58:50.462951805Z I1024 13:58:50.462881       1 request.go:700] Waited for 2.187490637s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:58:51.663503127Z I1024 13:58:51.663417       1 request.go:700] Waited for 2.192695647s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T13:58:52.862619988Z I1024 13:58:52.862559       1 request.go:700] Waited for 2.591068858s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:58:53.863366954Z I1024 13:58:53.863291       1 request.go:700] Waited for 2.591981628s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:58:54.877820461Z I1024 13:58:54.877741       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-14-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-apiserver because it was missing
2024-10-24T13:58:55.062816866Z I1024 13:58:55.062666       1 request.go:700] Waited for 2.591468737s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:58:56.263305507Z I1024 13:58:56.263185       1 request.go:700] Waited for 2.590909018s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:58:57.463161798Z I1024 13:58:57.463097       1 request.go:700] Waited for 2.585564287s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-14-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:58:58.662802680Z I1024 13:58:58.662703       1 request.go:700] Waited for 2.586029478s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-13
2024-10-24T13:58:59.862450180Z I1024 13:58:59.862372       1 request.go:700] Waited for 2.391862182s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods
2024-10-24T13:58:59.878581701Z I1024 13:58:59.878509       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-14-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-apiserver because it was missing
2024-10-24T13:59:00.473043736Z I1024 13:59:00.472964       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 13 is the oldest and needs new revision 14
2024-10-24T13:59:00.473109596Z I1024 13:59:00.473095       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:59:00.473109596Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:59:00.473109596Z  CurrentRevision: (int32) 13,
2024-10-24T13:59:00.473109596Z  TargetRevision: (int32) 14,
2024-10-24T13:59:00.473109596Z  LastFailedRevision: (int32) 10,
2024-10-24T13:59:00.473109596Z  LastFailedTime: (*v1.Time)(0xc006ec6ae0)(2024-10-24 13:30:03 +0000 UTC),
2024-10-24T13:59:00.473109596Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:59:00.473109596Z  LastFailedCount: (int) 1,
2024-10-24T13:59:00.473109596Z  LastFallbackCount: (int) 0,
2024-10-24T13:59:00.473109596Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:59:00.473109596Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:59:00.473109596Z  }
2024-10-24T13:59:00.473109596Z }
2024-10-24T13:59:00.475220346Z W1024 13:59:00.475167       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:59:00.475220346Z W1024 13:59:00.475194       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:59:00.475220346Z W1024 13:59:00.475200       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:59:00.475220346Z W1024 13:59:00.475204       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:59:00.475220346Z W1024 13:59:00.475207       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T13:59:00.475220346Z W1024 13:59:00.475210       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T13:59:00.508975597Z I1024 13:59:00.508903       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 13 to 14 because node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 13 is the oldest
2024-10-24T13:59:00.513654777Z I1024 13:59:00.513453       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:59:00Z","message":"NodeInstallerProgressing: 3 nodes are at revision 13; 0 nodes have achieved new revision 14","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 13; 0 nodes have achieved new revision 14","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:59:00.533343918Z I1024 13:59:00.533268       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing changed from False to True ("NodeInstallerProgressing: 3 nodes are at revision 13; 0 nodes have achieved new revision 14"),Available message changed from "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 13" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 13; 0 nodes have achieved new revision 14"
2024-10-24T13:59:00.862866077Z I1024 13:59:00.862742       1 request.go:700] Waited for 2.390858303s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:59:02.063241208Z I1024 13:59:02.063160       1 request.go:700] Waited for 2.391878352s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:59:03.262471130Z I1024 13:59:03.262375       1 request.go:700] Waited for 2.750525422s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:59:04.263022596Z I1024 13:59:04.262891       1 request.go:700] Waited for 3.192282784s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:59:05.263125422Z I1024 13:59:05.263006       1 request.go:700] Waited for 3.190643804s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:59:06.463399094Z I1024 13:59:06.463323       1 request.go:700] Waited for 3.182471613s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T13:59:07.662785985Z I1024 13:59:07.662704       1 request.go:700] Waited for 3.191530544s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:59:08.662896151Z I1024 13:59:08.662805       1 request.go:700] Waited for 3.191723404s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:59:09.663502497Z I1024 13:59:09.663389       1 request.go:700] Waited for 2.791940323s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-14-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:59:10.863358178Z I1024 13:59:10.863282       1 request.go:700] Waited for 2.791836322s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:59:12.062975110Z I1024 13:59:12.062893       1 request.go:700] Waited for 2.192630756s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:59:13.063497296Z I1024 13:59:13.063435       1 request.go:700] Waited for 2.183499487s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:59:14.263335747Z I1024 13:59:14.263271       1 request.go:700] Waited for 2.191561187s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-config-openshift-kube-apiserver
2024-10-24T13:59:15.462993359Z I1024 13:59:15.462925       1 request.go:700] Waited for 2.191948328s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:59:16.663338710Z I1024 13:59:16.663220       1 request.go:700] Waited for 2.391939703s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:59:17.863050811Z I1024 13:59:17.862967       1 request.go:700] Waited for 1.991483992s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:59:19.470550803Z I1024 13:59:19.470484       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 13 is the oldest and needs new revision 14
2024-10-24T13:59:19.470597333Z I1024 13:59:19.470583       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:59:19.470597333Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:59:19.470597333Z  CurrentRevision: (int32) 13,
2024-10-24T13:59:19.470597333Z  TargetRevision: (int32) 14,
2024-10-24T13:59:19.470597333Z  LastFailedRevision: (int32) 10,
2024-10-24T13:59:19.470597333Z  LastFailedTime: (*v1.Time)(0xc00246e9c0)(2024-10-24 13:30:03 +0000 UTC),
2024-10-24T13:59:19.470597333Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:59:19.470597333Z  LastFailedCount: (int) 1,
2024-10-24T13:59:19.470597333Z  LastFallbackCount: (int) 0,
2024-10-24T13:59:19.470597333Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:59:19.470597333Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:59:19.470597333Z  }
2024-10-24T13:59:19.470597333Z }
2024-10-24T13:59:19.473121633Z I1024 13:59:19.473043       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 13 to 14 because node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 13 is the oldest
2024-10-24T13:59:22.292943117Z I1024 13:59:22.292864       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-14-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-apiserver because it was missing
2024-10-24T13:59:22.671213187Z I1024 13:59:22.671098       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 14, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:59:23.462579747Z I1024 13:59:23.462471       1 request.go:700] Waited for 1.1684535s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:59:24.464895203Z I1024 13:59:24.464841       1 request.go:700] Waited for 1.993475923s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:59:25.663344154Z I1024 13:59:25.663271       1 request.go:700] Waited for 1.991559681s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-13
2024-10-24T13:59:26.862523145Z I1024 13:59:26.862422       1 request.go:700] Waited for 2.190602576s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:59:27.863426542Z I1024 13:59:27.863349       1 request.go:700] Waited for 2.193219608s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:59:29.062933013Z I1024 13:59:29.062866       1 request.go:700] Waited for 1.591725071s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:59:30.062969889Z I1024 13:59:30.062894       1 request.go:700] Waited for 1.581672501s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:59:31.063065476Z I1024 13:59:31.063001       1 request.go:700] Waited for 1.575240722s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T13:59:32.063173642Z I1024 13:59:32.063089       1 request.go:700] Waited for 1.592546722s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-14-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:59:32.071115022Z I1024 13:59:32.071064       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 14, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:59:33.262933064Z I1024 13:59:33.262860       1 request.go:700] Waited for 1.591768982s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:59:34.862898795Z I1024 13:59:34.862824       1 request.go:700] Waited for 1.099821078s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T13:59:36.670921703Z I1024 13:59:36.670833       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 14, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:59:46.255526032Z I1024 13:59:46.255451       1 request.go:700] Waited for 1.192061591s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-13
2024-10-24T13:59:47.255562109Z I1024 13:59:47.255492       1 request.go:700] Waited for 1.393285677s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T13:59:48.255661175Z I1024 13:59:48.255589       1 request.go:700] Waited for 1.193154711s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T13:59:49.454831446Z I1024 13:59:49.454773       1 request.go:700] Waited for 1.117834019s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:00:01.093599279Z I1024 14:00:01.093519       1 termination_observer.go:236] Observed event "TerminationPreShutdownHooksFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0" (last termination at 2024-10-24 13:51:03 +0000 UTC) at 2024-10-24 14:00:01 +0000 UTC
2024-10-24T14:00:03.367383629Z I1024 14:00:03.367299       1 request.go:700] Waited for 1.185573541s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-13
2024-10-24T14:00:04.566884480Z I1024 14:00:04.566800       1 request.go:700] Waited for 1.589853761s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-13
2024-10-24T14:00:05.567161336Z I1024 14:00:05.567067       1 request.go:700] Waited for 1.993614802s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:00:06.567691772Z I1024 14:00:06.567604       1 request.go:700] Waited for 2.193600667s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:00:07.767790213Z I1024 14:00:07.767676       1 request.go:700] Waited for 1.592693591s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-14-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:00:08.967238185Z I1024 14:00:08.967162       1 request.go:700] Waited for 1.576955091s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:00:09.374664785Z I1024 14:00:09.374600       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 14, but has not made progress because waiting for static pod of revision 14, found 13
2024-10-24T14:00:10.167300186Z I1024 14:00:10.167209       1 request.go:700] Waited for 1.592235161s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:00:11.367526317Z I1024 14:00:11.367473       1 request.go:700] Waited for 1.393160386s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:00:12.367705913Z I1024 14:00:12.367618       1 request.go:700] Waited for 1.193042571s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:00:14.378150076Z I1024 14:00:14.378086       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 14, but has not made progress because waiting for static pod of revision 14, found 13
2024-10-24T14:00:16.966925864Z I1024 14:00:16.966856       1 request.go:700] Waited for 1.195602631s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:00:17.967006100Z I1024 14:00:17.966938       1 request.go:700] Waited for 1.791768137s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:00:18.967126096Z I1024 14:00:18.967024       1 request.go:700] Waited for 1.591423611s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-13
2024-10-24T14:00:20.167863727Z I1024 14:00:20.167744       1 request.go:700] Waited for 1.592112282s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:00:21.367061919Z I1024 14:00:21.366990       1 request.go:700] Waited for 1.390223637s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:00:22.576010440Z I1024 14:00:22.575940       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 14, but has not made progress because waiting for static pod of revision 14, found 13
2024-10-24T14:00:46.089132084Z I1024 14:00:46.089046       1 request.go:700] Waited for 1.025755557s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-13
2024-10-24T14:00:47.089374090Z I1024 14:00:47.089296       1 request.go:700] Waited for 1.242909713s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T14:00:48.289416441Z I1024 14:00:48.289250       1 request.go:700] Waited for 1.393656196s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:00:49.289486617Z I1024 14:00:49.289397       1 request.go:700] Waited for 1.391469056s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-config-openshift-kube-apiserver
2024-10-24T14:00:51.765475572Z I1024 14:00:51.765351       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2024-10-24T14:01:13.071425059Z I1024 14:01:13.071257       1 termination_observer.go:236] Observed event "TerminationGracefulTerminationFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0" (last termination at 2024-10-24 13:51:03 +0000 UTC) at 2024-10-24 14:01:13 +0000 UTC
2024-10-24T14:01:14.207412603Z I1024 14:01:14.204804       1 reflector.go:368] Caches populated for *v1alpha1.StorageVersionMigration from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:01:14.543478941Z I1024 14:01:14.543410       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:01:14.713263021Z I1024 14:01:14.713163       1 reflector.go:368] Caches populated for *v1.Image from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:01:14.738451880Z I1024 14:01:14.738374       1 reflector.go:368] Caches populated for *v1.Proxy from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:01:15.007239089Z I1024 14:01:15.007167       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:01:15.115024908Z I1024 14:01:15.114929       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:01:15.407520177Z I1024 14:01:15.407397       1 reflector.go:368] Caches populated for *v1.Authentication from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:01:15.472141067Z I1024 14:01:15.471984       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:01:15.472501827Z I1024 14:01:15.472436       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2024-10-24T14:01:15.529156536Z I1024 14:01:15.529019       1 reflector.go:368] Caches populated for monitoring.coreos.com/v1, Resource=prometheusrules from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:01:15.578877256Z I1024 14:01:15.578799       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubeapiservers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:01:15.909195534Z I1024 14:01:15.908954       1 reflector.go:368] Caches populated for *v1.KubeAPIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:01:15.945685234Z I1024 14:01:15.945548       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:01:16.120342213Z I1024 14:01:16.120182       1 reflector.go:368] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:01:16.463811921Z I1024 14:01:16.462992       1 reflector.go:368] Caches populated for *v1.OAuth from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:01:16.542396791Z I1024 14:01:16.542306       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:01:16.609804110Z I1024 14:01:16.607671       1 request.go:700] Waited for 1.027930424s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:01:17.607846715Z I1024 14:01:17.607723       1 request.go:700] Waited for 2.021227949s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T14:01:18.807202808Z I1024 14:01:18.807106       1 request.go:700] Waited for 2.583985196s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:01:20.007536912Z I1024 14:01:20.007402       1 request.go:700] Waited for 1.992609349s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-14-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:01:20.217903581Z I1024 14:01:20.217805       1 termination_observer.go:130] Observed termination of API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0" at 2024-10-24 14:01:18 +0000 UTC
2024-10-24T14:01:21.007838347Z I1024 14:01:21.007675       1 request.go:700] Waited for 2.585225777s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:01:22.007899611Z I1024 14:01:22.007743       1 request.go:700] Waited for 2.593910416s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-10-24T14:01:23.007895356Z I1024 14:01:23.007810       1 request.go:700] Waited for 2.591012906s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:01:24.207856660Z I1024 14:01:24.207607       1 request.go:700] Waited for 2.573167976s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:01:25.407796873Z I1024 14:01:25.407681       1 request.go:700] Waited for 2.189282769s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:01:26.607918966Z I1024 14:01:26.607861       1 request.go:700] Waited for 2.376630967s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:01:27.806989540Z I1024 14:01:27.806907       1 request.go:700] Waited for 2.386291957s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:01:28.807353935Z I1024 14:01:28.807264       1 request.go:700] Waited for 2.178923749s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:01:29.413693682Z I1024 14:01:29.413597       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 14, but has not made progress because static pod is pending
2024-10-24T14:01:29.807665850Z I1024 14:01:29.807580       1 request.go:700] Waited for 2.189535418s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:01:31.007141793Z I1024 14:01:31.007049       1 request.go:700] Waited for 1.189139844s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:01:33.217568761Z I1024 14:01:33.217495       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 14, but has not made progress because static pod is pending
2024-10-24T14:01:46.051001526Z I1024 14:01:46.050932       1 request.go:700] Waited for 1.000916937s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:02:09.206168899Z I1024 14:02:09.206086       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T14:02:09.206168899Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T14:02:09.206168899Z  CurrentRevision: (int32) 14,
2024-10-24T14:02:09.206168899Z  TargetRevision: (int32) 0,
2024-10-24T14:02:09.206168899Z  LastFailedRevision: (int32) 10,
2024-10-24T14:02:09.206168899Z  LastFailedTime: (*v1.Time)(0xc00678ef90)(2024-10-24 13:30:03 +0000 UTC),
2024-10-24T14:02:09.206168899Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T14:02:09.206168899Z  LastFailedCount: (int) 1,
2024-10-24T14:02:09.206168899Z  LastFallbackCount: (int) 0,
2024-10-24T14:02:09.206168899Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T14:02:09.206168899Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T14:02:09.206168899Z  }
2024-10-24T14:02:09.206168899Z }
2024-10-24T14:02:09.206168899Z  because static pod is ready
2024-10-24T14:02:09.208475439Z W1024 14:02:09.208401       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:02:09.208475439Z W1024 14:02:09.208436       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:02:09.208475439Z W1024 14:02:09.208442       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:02:09.208475439Z W1024 14:02:09.208445       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:02:09.208475439Z W1024 14:02:09.208449       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T14:02:09.208475439Z W1024 14:02:09.208452       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T14:02:09.236122809Z I1024 14:02:09.236024       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 13 to 14 because static pod is ready
2024-10-24T14:02:09.248471049Z I1024 14:02:09.248302       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:59:00Z","message":"NodeInstallerProgressing: 2 nodes are at revision 13; 1 node is at revision 14","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 13; 1 node is at revision 14","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T14:02:09.274422498Z I1024 14:02:09.274350       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 13; 0 nodes have achieved new revision 14" to "NodeInstallerProgressing: 2 nodes are at revision 13; 1 node is at revision 14",Available message changed from "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 13; 0 nodes have achieved new revision 14" to "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 13; 1 node is at revision 14"
2024-10-24T14:02:10.396838075Z I1024 14:02:10.396728       1 request.go:700] Waited for 1.148134786s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-10-24T14:02:11.397386882Z I1024 14:02:11.397312       1 request.go:700] Waited for 2.139379023s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:02:12.597214889Z I1024 14:02:12.597136       1 request.go:700] Waited for 2.593228663s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:02:13.796792525Z I1024 14:02:13.796698       1 request.go:700] Waited for 2.585721252s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:02:14.797420312Z I1024 14:02:14.797345       1 request.go:700] Waited for 2.790798731s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-14-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:02:15.996446609Z I1024 14:02:15.996356       1 request.go:700] Waited for 1.790931045s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:02:16.996788266Z I1024 14:02:16.996635       1 request.go:700] Waited for 1.184587757s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:02:17.997271363Z I1024 14:02:17.997186       1 request.go:700] Waited for 1.193521277s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:02:19.197072429Z I1024 14:02:19.196993       1 request.go:700] Waited for 1.192214906s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:02:21.203390923Z I1024 14:02:21.203313       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-1 with revision 13 is the oldest and needs new revision 14
2024-10-24T14:02:21.203458543Z I1024 14:02:21.203384       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T14:02:21.203458543Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T14:02:21.203458543Z  CurrentRevision: (int32) 13,
2024-10-24T14:02:21.203458543Z  TargetRevision: (int32) 14,
2024-10-24T14:02:21.203458543Z  LastFailedRevision: (int32) 0,
2024-10-24T14:02:21.203458543Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T14:02:21.203458543Z  LastFailedReason: (string) "",
2024-10-24T14:02:21.203458543Z  LastFailedCount: (int) 0,
2024-10-24T14:02:21.203458543Z  LastFallbackCount: (int) 0,
2024-10-24T14:02:21.203458543Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T14:02:21.203458543Z }
2024-10-24T14:02:21.205343873Z W1024 14:02:21.205296       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:02:21.205343873Z W1024 14:02:21.205320       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:02:21.205343873Z W1024 14:02:21.205325       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:02:21.205343873Z W1024 14:02:21.205329       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:02:21.205343873Z W1024 14:02:21.205332       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T14:02:21.205343873Z W1024 14:02:21.205335       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T14:02:21.238246243Z I1024 14:02:21.238165       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 13 to 14 because node ci-op-2fcpj5j6-f6035-2lklf-master-1 with revision 13 is the oldest
2024-10-24T14:02:22.397176300Z I1024 14:02:22.397102       1 request.go:700] Waited for 1.156984897s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:02:23.596415566Z I1024 14:02:23.596341       1 request.go:700] Waited for 2.349005973s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T14:02:24.596806753Z I1024 14:02:24.596713       1 request.go:700] Waited for 2.790370812s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:02:25.597042450Z I1024 14:02:25.596952       1 request.go:700] Waited for 2.789079331s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:02:26.797381807Z I1024 14:02:26.797316       1 request.go:700] Waited for 2.783281662s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:02:27.996978983Z I1024 14:02:27.996914       1 request.go:700] Waited for 1.521158905s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:02:29.197199690Z I1024 14:02:29.197121       1 request.go:700] Waited for 1.100410276s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T14:02:30.197229117Z I1024 14:02:30.197161       1 request.go:700] Waited for 1.193528856s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:02:31.396450883Z I1024 14:02:31.396357       1 request.go:700] Waited for 1.192524046s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:02:32.396656880Z I1024 14:02:32.396590       1 request.go:700] Waited for 1.192879227s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:02:33.604840677Z I1024 14:02:33.604775       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-1 with revision 13 is the oldest and needs new revision 14
2024-10-24T14:02:33.604840677Z I1024 14:02:33.604831       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T14:02:33.604840677Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T14:02:33.604840677Z  CurrentRevision: (int32) 13,
2024-10-24T14:02:33.604840677Z  TargetRevision: (int32) 14,
2024-10-24T14:02:33.604840677Z  LastFailedRevision: (int32) 0,
2024-10-24T14:02:33.604840677Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T14:02:33.604840677Z  LastFailedReason: (string) "",
2024-10-24T14:02:33.604840677Z  LastFailedCount: (int) 0,
2024-10-24T14:02:33.604840677Z  LastFallbackCount: (int) 0,
2024-10-24T14:02:33.604840677Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T14:02:33.604840677Z }
2024-10-24T14:02:33.607598377Z I1024 14:02:33.607537       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 13 to 14 because node ci-op-2fcpj5j6-f6035-2lklf-master-1 with revision 13 is the oldest
2024-10-24T14:02:36.028532469Z I1024 14:02:36.028468       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-14-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-apiserver because it was missing
2024-10-24T14:02:36.405505418Z I1024 14:02:36.405433       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 14, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T14:02:37.196796336Z I1024 14:02:37.196679       1 request.go:700] Waited for 1.170273096s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:02:38.397054223Z I1024 14:02:38.396952       1 request.go:700] Waited for 1.988506955s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:02:39.597236159Z I1024 14:02:39.597138       1 request.go:700] Waited for 1.985598044s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:02:40.797476636Z I1024 14:02:40.797397       1 request.go:700] Waited for 2.188286094s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:02:41.997096452Z I1024 14:02:41.997035       1 request.go:700] Waited for 1.790573165s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:02:43.806437927Z I1024 14:02:43.806358       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 14, but has not made progress because installer is not finished, but in Running phase
2024-10-24T14:02:44.797192514Z I1024 14:02:44.797123       1 request.go:700] Waited for 1.022096417s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:02:46.197311990Z I1024 14:02:46.197244       1 request.go:700] Waited for 1.147016647s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:02:47.396687907Z I1024 14:02:47.396613       1 request.go:700] Waited for 2.334999103s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:02:50.205575878Z I1024 14:02:50.205503       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 14, but has not made progress because installer is not finished, but in Running phase
2024-10-24T14:03:14.683809137Z I1024 14:03:14.683669       1 termination_observer.go:236] Observed event "TerminationPreShutdownHooksFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1" (last termination at 2024-10-24 13:54:14 +0000 UTC) at 2024-10-24 14:03:14 +0000 UTC
2024-10-24T14:03:16.055626053Z I1024 14:03:16.055524       1 request.go:700] Waited for 1.020039907s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:03:17.056006410Z I1024 14:03:17.055935       1 request.go:700] Waited for 2.018430644s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:03:18.255947646Z I1024 14:03:18.255861       1 request.go:700] Waited for 1.993647634s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:03:19.456248643Z I1024 14:03:19.456179       1 request.go:700] Waited for 2.190034814s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:03:20.655998609Z I1024 14:03:20.655867       1 request.go:700] Waited for 1.991534674s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:03:23.266380641Z I1024 14:03:23.266301       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 14, but has not made progress because waiting for static pod of revision 14, found 13
2024-10-24T14:03:25.862651334Z I1024 14:03:25.862547       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 14, but has not made progress because waiting for static pod of revision 14, found 13
2024-10-24T14:03:28.855295855Z I1024 14:03:28.855194       1 request.go:700] Waited for 1.015084087s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:03:31.065258909Z I1024 14:03:31.065141       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 14, but has not made progress because waiting for static pod of revision 14, found 13
2024-10-24T14:03:32.655740904Z I1024 14:03:32.655648       1 request.go:700] Waited for 1.111382497s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:03:33.655848431Z I1024 14:03:33.655769       1 request.go:700] Waited for 1.789076385s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:03:34.656062569Z I1024 14:03:34.655993       1 request.go:700] Waited for 1.787554675s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:03:37.666731820Z I1024 14:03:37.666654       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 14, but has not made progress because waiting for static pod of revision 14, found 13
2024-10-24T14:03:38.255883798Z I1024 14:03:38.255825       1 request.go:700] Waited for 1.082083087s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:03:42.465813206Z I1024 14:03:42.465718       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 14, but has not made progress because waiting for static pod of revision 14, found 13
2024-10-24T14:03:46.055837196Z I1024 14:03:46.055730       1 request.go:700] Waited for 1.004531376s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:03:47.256233372Z I1024 14:03:47.256144       1 request.go:700] Waited for 1.919102364s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:03:48.455379729Z I1024 14:03:48.455293       1 request.go:700] Waited for 2.182706404s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:03:49.455376466Z I1024 14:03:49.455297       1 request.go:700] Waited for 2.189157103s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:03:53.261920394Z I1024 14:03:53.260845       1 request.go:700] Waited for 1.007080538s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-14-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:03:53.666097683Z I1024 14:03:53.666035       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 14, but has not made progress because waiting for static pod of revision 14, found 13
2024-10-24T14:03:54.455768921Z I1024 14:03:54.455666       1 request.go:700] Waited for 1.387065706s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:03:54.806402440Z I1024 14:03:54.806322       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX
2024-10-24T14:03:55.656022817Z I1024 14:03:55.655958       1 request.go:700] Waited for 1.294314277s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T14:03:56.856010394Z I1024 14:03:56.855945       1 request.go:700] Waited for 1.394713366s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2024-10-24T14:03:59.866068215Z I1024 14:03:59.866007       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 14, but has not made progress because waiting for static pod of revision 14, found 13
2024-10-24T14:04:26.675465107Z I1024 14:04:26.675388       1 termination_observer.go:236] Observed event "TerminationGracefulTerminationFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1" (last termination at 2024-10-24 13:54:14 +0000 UTC) at 2024-10-24 14:04:26 +0000 UTC
2024-10-24T14:04:31.495971183Z I1024 14:04:31.495901       1 request.go:700] Waited for 1.183754027s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T14:04:31.503067003Z I1024 14:04:31.503003       1 termination_observer.go:130] Observed termination of API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1" at 2024-10-24 14:04:30 +0000 UTC
2024-10-24T14:04:32.699611659Z I1024 14:04:32.699194       1 request.go:700] Waited for 1.996205794s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:04:33.896253656Z I1024 14:04:33.895744       1 request.go:700] Waited for 1.970606754s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:04:34.895903073Z I1024 14:04:34.895829       1 request.go:700] Waited for 1.989130954s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:04:35.895949470Z I1024 14:04:35.895842       1 request.go:700] Waited for 2.111276224s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:04:36.896084687Z I1024 14:04:36.895999       1 request.go:700] Waited for 1.785073215s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:04:36.905381427Z I1024 14:04:36.905337       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 14, but has not made progress because static pod is pending
2024-10-24T14:04:38.896309431Z I1024 14:04:38.896215       1 request.go:700] Waited for 1.076079517s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T14:04:40.095514767Z I1024 14:04:40.095446       1 request.go:700] Waited for 1.992838594s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:04:41.496209933Z I1024 14:04:41.496137       1 request.go:700] Waited for 1.093014847s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:04:42.695984400Z I1024 14:04:42.695908       1 request.go:700] Waited for 1.990384764s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-14-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:04:43.895987927Z I1024 14:04:43.895913       1 request.go:700] Waited for 1.992371805s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:04:44.701521614Z I1024 14:04:44.701431       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 14, but has not made progress because static pod is pending
2024-10-24T14:04:45.096056903Z I1024 14:04:45.095994       1 request.go:700] Waited for 1.310690476s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:04:46.296041900Z I1024 14:04:46.295983       1 request.go:700] Waited for 1.394486976s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:04:47.496292396Z I1024 14:04:47.496185       1 request.go:700] Waited for 2.187892273s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:04:48.695737663Z I1024 14:04:48.695666       1 request.go:700] Waited for 1.190345918s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:04:51.496133985Z I1024 14:04:51.496045       1 request.go:700] Waited for 1.094523156s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:04:52.695703792Z I1024 14:04:52.695617       1 request.go:700] Waited for 2.193437254s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:04:52.901676561Z I1024 14:04:52.901596       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T14:04:52.901676561Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T14:04:52.901676561Z  CurrentRevision: (int32) 14,
2024-10-24T14:04:52.901676561Z  TargetRevision: (int32) 0,
2024-10-24T14:04:52.901676561Z  LastFailedRevision: (int32) 0,
2024-10-24T14:04:52.901676561Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T14:04:52.901676561Z  LastFailedReason: (string) "",
2024-10-24T14:04:52.901676561Z  LastFailedCount: (int) 0,
2024-10-24T14:04:52.901676561Z  LastFallbackCount: (int) 0,
2024-10-24T14:04:52.901676561Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T14:04:52.901676561Z }
2024-10-24T14:04:52.901676561Z  because static pod is ready
2024-10-24T14:04:52.904031481Z W1024 14:04:52.903962       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:04:52.904031481Z W1024 14:04:52.904005       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:04:52.904031481Z W1024 14:04:52.904012       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:04:52.904031481Z W1024 14:04:52.904017       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:04:52.904031481Z W1024 14:04:52.904023       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T14:04:52.904074091Z W1024 14:04:52.904027       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T14:04:52.935536781Z I1024 14:04:52.935442       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 13 to 14 because static pod is ready
2024-10-24T14:04:52.942558141Z I1024 14:04:52.942495       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:59:00Z","message":"NodeInstallerProgressing: 1 node is at revision 13; 2 nodes are at revision 14","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 13; 2 nodes are at revision 14","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T14:04:52.963555571Z I1024 14:04:52.963466       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 13; 1 node is at revision 14" to "NodeInstallerProgressing: 1 node is at revision 13; 2 nodes are at revision 14",Available message changed from "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 13; 1 node is at revision 14" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 13; 2 nodes are at revision 14"
2024-10-24T14:04:54.096331248Z I1024 14:04:54.096261       1 request.go:700] Waited for 1.158763157s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:04:55.295740534Z I1024 14:04:55.295662       1 request.go:700] Waited for 2.352944743s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:04:56.296033912Z I1024 14:04:56.295965       1 request.go:700] Waited for 2.790175382s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:04:57.495932328Z I1024 14:04:57.495862       1 request.go:700] Waited for 2.792971012s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:04:58.496240415Z I1024 14:04:58.496153       1 request.go:700] Waited for 2.779088322s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:04:59.696212822Z I1024 14:04:59.696144       1 request.go:700] Waited for 1.390397636s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-14-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:05:00.696335719Z I1024 14:05:00.696259       1 request.go:700] Waited for 1.091164977s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T14:05:01.895939575Z I1024 14:05:01.895868       1 request.go:700] Waited for 1.194371846s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:05:20.275610803Z I1024 14:05:20.275552       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-2 with revision 13 is the oldest and needs new revision 14
2024-10-24T14:05:20.275610803Z I1024 14:05:20.275603       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T14:05:20.275610803Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T14:05:20.275610803Z  CurrentRevision: (int32) 13,
2024-10-24T14:05:20.275610803Z  TargetRevision: (int32) 14,
2024-10-24T14:05:20.275610803Z  LastFailedRevision: (int32) 0,
2024-10-24T14:05:20.275610803Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T14:05:20.275610803Z  LastFailedReason: (string) "",
2024-10-24T14:05:20.275610803Z  LastFailedCount: (int) 0,
2024-10-24T14:05:20.275610803Z  LastFallbackCount: (int) 0,
2024-10-24T14:05:20.275610803Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T14:05:20.275610803Z }
2024-10-24T14:05:20.277714803Z W1024 14:05:20.277672       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:05:20.277714803Z W1024 14:05:20.277692       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:05:20.277714803Z W1024 14:05:20.277697       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:05:20.277714803Z W1024 14:05:20.277700       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:05:20.277714803Z W1024 14:05:20.277703       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T14:05:20.277714803Z W1024 14:05:20.277706       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T14:05:20.304902653Z I1024 14:05:20.304833       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 13 to 14 because node ci-op-2fcpj5j6-f6035-2lklf-master-2 with revision 13 is the oldest
2024-10-24T14:05:21.402285540Z I1024 14:05:21.402217       1 request.go:700] Waited for 1.089640277s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:05:22.602124406Z I1024 14:05:22.602041       1 request.go:700] Waited for 2.287828393s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-14-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:05:23.802543313Z I1024 14:05:23.802476       1 request.go:700] Waited for 2.589496583s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-10-24T14:05:25.001640610Z I1024 14:05:25.001567       1 request.go:700] Waited for 2.592206472s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:05:26.002409407Z I1024 14:05:26.002318       1 request.go:700] Waited for 2.213970944s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:05:27.202483603Z I1024 14:05:27.202391       1 request.go:700] Waited for 1.393123686s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-14-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:05:28.242502970Z I1024 14:05:28.242391       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-14-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-apiserver because it was missing
2024-10-24T14:05:29.212439298Z I1024 14:05:29.212366       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 14, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T14:05:29.402445347Z I1024 14:05:29.402371       1 request.go:700] Waited for 1.158824657s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:05:30.602265483Z I1024 14:05:30.602185       1 request.go:700] Waited for 2.357212794s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:05:31.802391580Z I1024 14:05:31.802314       1 request.go:700] Waited for 2.383196083s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:05:32.802405727Z I1024 14:05:32.802332       1 request.go:700] Waited for 2.388093783s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:05:33.802525525Z I1024 14:05:33.802460       1 request.go:700] Waited for 2.193701383s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:05:35.002964331Z I1024 14:05:35.002895       1 request.go:700] Waited for 1.213569097s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:05:36.611735036Z I1024 14:05:36.611667       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 14, but has not made progress because installer is not finished, but in Running phase
2024-10-24T14:05:39.408910388Z I1024 14:05:39.408817       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 14, but has not made progress because installer is not finished, but in Running phase
2024-10-24T14:05:46.108559000Z I1024 14:05:46.108486       1 request.go:700] Waited for 1.055535087s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:05:47.109067307Z I1024 14:05:47.109007       1 request.go:700] Waited for 1.794019015s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:06:06.818013281Z I1024 14:06:06.817930       1 termination_observer.go:236] Observed event "TerminationPreShutdownHooksFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2" (last termination at 2024-10-24 13:57:26 +0000 UTC) at 2024-10-24 14:06:06 +0000 UTC
2024-10-24T14:06:09.526717464Z I1024 14:06:09.526626       1 request.go:700] Waited for 1.108017217s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:06:10.726428120Z I1024 14:06:10.726351       1 request.go:700] Waited for 1.993442565s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-14-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:06:11.338378028Z I1024 14:06:11.338317       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 14, but has not made progress because waiting for static pod of revision 14, found 13
2024-10-24T14:06:13.932803131Z I1024 14:06:13.932721       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 14, but has not made progress because waiting for static pod of revision 14, found 13
2024-10-24T14:06:20.165865493Z I1024 14:06:20.165705       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 14, but has not made progress because waiting for static pod of revision 14, found 13
2024-10-24T14:07:18.783200949Z I1024 14:07:18.782223       1 termination_observer.go:236] Observed event "TerminationGracefulTerminationFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2" (last termination at 2024-10-24 13:57:26 +0000 UTC) at 2024-10-24 14:07:18 +0000 UTC
2024-10-24T14:07:19.948001105Z I1024 14:07:19.947184       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubeapiservers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:07:20.194394445Z I1024 14:07:20.194322       1 reflector.go:368] Caches populated for *v1.KubeAPIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:07:20.681531503Z I1024 14:07:20.681457       1 reflector.go:368] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:07:20.764795223Z I1024 14:07:20.764677       1 reflector.go:368] Caches populated for *v1.Proxy from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:07:21.004133122Z I1024 14:07:21.003283       1 reflector.go:368] Caches populated for *v1.Authentication from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:07:21.149498092Z I1024 14:07:21.149422       1 request.go:700] Waited for 1.185263837s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:07:21.164990072Z I1024 14:07:21.164922       1 reflector.go:368] Caches populated for *v1.Image from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:07:21.165155732Z I1024 14:07:21.165136       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:07:21.179434422Z I1024 14:07:21.179388       1 reflector.go:368] Caches populated for monitoring.coreos.com/v1, Resource=prometheusrules from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:07:21.184651762Z I1024 14:07:21.184596       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:07:21.192255062Z I1024 14:07:21.192178       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:07:21.321401101Z I1024 14:07:21.321339       1 reflector.go:368] Caches populated for *v1alpha1.StorageVersionMigration from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:07:21.392903831Z I1024 14:07:21.392278       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:07:21.430734001Z I1024 14:07:21.430606       1 reflector.go:368] Caches populated for *v1.OAuth from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:07:21.580814091Z I1024 14:07:21.580738       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:07:22.149842209Z I1024 14:07:22.149779       1 request.go:700] Waited for 1.716526175s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:07:23.350021495Z I1024 14:07:23.349954       1 request.go:700] Waited for 2.183397583s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:07:24.550112522Z I1024 14:07:24.550034       1 request.go:700] Waited for 2.186449453s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:07:25.949971397Z I1024 14:07:25.949903       1 request.go:700] Waited for 1.088700896s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T14:07:25.960041287Z I1024 14:07:25.959986       1 termination_observer.go:130] Observed termination of API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2" at 2024-10-24 14:07:24 +0000 UTC
2024-10-24T14:07:27.149894824Z I1024 14:07:27.149791       1 request.go:700] Waited for 2.284758843s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:07:28.155465951Z I1024 14:07:28.155385       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 14, but has not made progress because static pod is pending
2024-10-24T14:07:28.349449481Z I1024 14:07:28.349384       1 request.go:700] Waited for 2.389263844s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T14:07:29.350023998Z I1024 14:07:29.349945       1 request.go:700] Waited for 2.393060294s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:07:30.350076935Z I1024 14:07:30.350004       1 request.go:700] Waited for 2.191995264s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:07:31.550193912Z I1024 14:07:31.550122       1 request.go:700] Waited for 2.192554754s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:07:32.749842999Z I1024 14:07:32.749709       1 request.go:700] Waited for 2.190859754s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T14:07:33.949224185Z I1024 14:07:33.949141       1 request.go:700] Waited for 2.190062784s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:07:34.950116233Z I1024 14:07:34.949997       1 request.go:700] Waited for 2.188708614s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T14:07:36.150133299Z I1024 14:07:36.150057       1 request.go:700] Waited for 2.354995993s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:07:37.349478856Z I1024 14:07:37.349412       1 request.go:700] Waited for 2.193173164s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:07:38.357498153Z I1024 14:07:38.357422       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 14, but has not made progress because static pod is pending
2024-10-24T14:07:40.955608896Z I1024 14:07:40.955541       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 14, but has not made progress because static pod is pending
2024-10-24T14:07:45.956593091Z I1024 14:07:45.956539       1 request.go:700] Waited for 1.000883387s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:07:46.956999928Z I1024 14:07:46.956938       1 request.go:700] Waited for 1.793545465s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-14
2024-10-24T14:07:47.957094375Z I1024 14:07:47.957028       1 request.go:700] Waited for 1.994083784s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:07:49.156178042Z I1024 14:07:49.156108       1 request.go:700] Waited for 1.992967045s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:07:50.156372879Z I1024 14:07:50.156304       1 request.go:700] Waited for 1.793582755s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:07:51.356139776Z I1024 14:07:51.356069       1 request.go:700] Waited for 1.593577616s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:07:51.839499495Z I1024 14:07:51.839419       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:59:00Z","message":"EncryptionMigrationControllerProgressing: migrating resources to a new write key: [core/configmaps core/secrets]\nNodeInstallerProgressing: 1 node is at revision 13; 2 nodes are at revision 14","reason":"EncryptionMigrationController_Migrating::NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 13; 2 nodes are at revision 14","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T14:07:51.855836665Z I1024 14:07:51.855738       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 13; 2 nodes are at revision 14" to "EncryptionMigrationControllerProgressing: migrating resources to a new write key: [core/configmaps core/secrets]\nNodeInstallerProgressing: 1 node is at revision 13; 2 nodes are at revision 14"
2024-10-24T14:07:52.356455053Z I1024 14:07:52.356352       1 request.go:700] Waited for 1.591882165s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:07:53.356633931Z I1024 14:07:53.356567       1 request.go:700] Waited for 1.517309785s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:07:54.357063238Z I1024 14:07:54.356984       1 request.go:700] Waited for 2.512376253s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:07:55.358485085Z I1024 14:07:55.357813       1 request.go:700] Waited for 2.795377692s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:07:56.556861891Z I1024 14:07:56.556698       1 request.go:700] Waited for 2.391731973s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:07:57.772403658Z I1024 14:07:57.764860       1 request.go:700] Waited for 2.388062433s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:07:58.957423195Z I1024 14:07:58.957338       1 request.go:700] Waited for 2.300044654s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:08:00.157016821Z I1024 14:08:00.156934       1 request.go:700] Waited for 2.190901574s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:08:01.356898488Z I1024 14:08:01.356704       1 request.go:700] Waited for 2.592076773s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-14-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:08:02.356909325Z I1024 14:08:02.356844       1 request.go:700] Waited for 2.592779083s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:08:03.357097643Z I1024 14:08:03.357031       1 request.go:700] Waited for 2.593782063s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:08:04.556663469Z I1024 14:08:04.556574       1 request.go:700] Waited for 2.593721853s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:08:05.557563807Z I1024 14:08:05.557499       1 request.go:700] Waited for 2.366768244s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:08:06.756177015Z I1024 14:08:06.756052       1 request.go:700] Waited for 2.381383015s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:08:07.758093843Z I1024 14:08:07.756283       1 request.go:700] Waited for 1.791123147s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:08:08.956460100Z I1024 14:08:08.956400       1 request.go:700] Waited for 1.590689936s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:08:09.956546539Z I1024 14:08:09.956473       1 request.go:700] Waited for 1.580378118s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-10-24T14:08:11.156126475Z I1024 14:08:11.156064       1 request.go:700] Waited for 1.189972227s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-10-24T14:08:12.156923914Z I1024 14:08:12.156859       1 request.go:700] Waited for 1.992034085s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:08:13.157057672Z I1024 14:08:13.156984       1 request.go:700] Waited for 1.384760137s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-14
2024-10-24T14:08:13.775309371Z I1024 14:08:13.775223       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretUpdated' Updated Secret/encryption-key-openshift-kube-apiserver-1 -n openshift-config-managed because it changed
2024-10-24T14:08:13.823364751Z I1024 14:08:13.823288       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:59:00Z","message":"EncryptionMigrationControllerProgressing: migrating resources to a new write key: [core/secrets]\nNodeInstallerProgressing: 1 node is at revision 13; 2 nodes are at revision 14","reason":"EncryptionMigrationController_Migrating::NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 13; 2 nodes are at revision 14","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T14:08:13.847845611Z I1024 14:08:13.847727       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "EncryptionMigrationControllerProgressing: migrating resources to a new write key: [core/configmaps core/secrets]\nNodeInstallerProgressing: 1 node is at revision 13; 2 nodes are at revision 14" to "EncryptionMigrationControllerProgressing: migrating resources to a new write key: [core/secrets]\nNodeInstallerProgressing: 1 node is at revision 13; 2 nodes are at revision 14"
2024-10-24T14:08:14.357991200Z I1024 14:08:14.357934       1 request.go:700] Waited for 1.394185487s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:08:15.556868597Z I1024 14:08:15.556804       1 request.go:700] Waited for 1.778646566s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:08:16.756714035Z I1024 14:08:16.756594       1 request.go:700] Waited for 2.793585414s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-10-24T14:08:17.756933946Z I1024 14:08:17.756836       1 request.go:700] Waited for 2.781913249s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:08:18.956405995Z I1024 14:08:18.956310       1 request.go:700] Waited for 2.791929248s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:08:19.956428564Z I1024 14:08:19.956358       1 request.go:700] Waited for 2.589948488s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:08:21.156683974Z I1024 14:08:21.156619       1 request.go:700] Waited for 2.193845789s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:08:22.156997245Z I1024 14:08:22.156926       1 request.go:700] Waited for 2.189330911s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-14
2024-10-24T14:08:23.357062375Z I1024 14:08:23.356963       1 request.go:700] Waited for 1.783475421s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-10-24T14:08:24.556698722Z I1024 14:08:24.556634       1 request.go:700] Waited for 1.794015108s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:08:25.757192102Z I1024 14:08:25.757128       1 request.go:700] Waited for 1.959559708s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:08:26.765548019Z I1024 14:08:26.765467       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T14:08:26.765548019Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T14:08:26.765548019Z  CurrentRevision: (int32) 14,
2024-10-24T14:08:26.765548019Z  TargetRevision: (int32) 0,
2024-10-24T14:08:26.765548019Z  LastFailedRevision: (int32) 0,
2024-10-24T14:08:26.765548019Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T14:08:26.765548019Z  LastFailedReason: (string) "",
2024-10-24T14:08:26.765548019Z  LastFailedCount: (int) 0,
2024-10-24T14:08:26.765548019Z  LastFallbackCount: (int) 0,
2024-10-24T14:08:26.765548019Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T14:08:26.765548019Z }
2024-10-24T14:08:26.765548019Z  because static pod is ready
2024-10-24T14:08:26.767806109Z W1024 14:08:26.767740       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:08:26.767806109Z W1024 14:08:26.767786       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:08:26.767806109Z W1024 14:08:26.767794       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:08:26.767806109Z W1024 14:08:26.767800       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:08:26.767879859Z W1024 14:08:26.767804       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T14:08:26.805644569Z I1024 14:08:26.805483       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 13 to 14 because static pod is ready
2024-10-24T14:08:26.808717239Z I1024 14:08:26.808408       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:59:00Z","message":"EncryptionMigrationControllerProgressing: migrating resources to a new write key: [core/secrets]","reason":"EncryptionMigrationController_Migrating","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 14","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T14:08:26.834028329Z I1024 14:08:26.833909       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "EncryptionMigrationControllerProgressing: migrating resources to a new write key: [core/secrets]\nNodeInstallerProgressing: 1 node is at revision 13; 2 nodes are at revision 14" to "EncryptionMigrationControllerProgressing: migrating resources to a new write key: [core/secrets]",Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 13; 2 nodes are at revision 14" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 14"
2024-10-24T14:08:26.956339208Z I1024 14:08:26.956238       1 request.go:700] Waited for 1.985601506s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-key-openshift-kube-apiserver-1
2024-10-24T14:08:27.956973617Z I1024 14:08:27.956873       1 request.go:700] Waited for 1.152201528s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:08:29.156875654Z I1024 14:08:29.156800       1 request.go:700] Waited for 2.346932995s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:08:29.772470863Z I1024 14:08:29.772374       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretUpdated' Updated Secret/encryption-key-openshift-kube-apiserver-1 -n openshift-config-managed because it changed
2024-10-24T14:08:29.810304783Z I1024 14:08:29.810219       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T14:08:29Z","message":"NodeInstallerProgressing: 3 nodes are at revision 14","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 14","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T14:08:29.834688983Z I1024 14:08:29.834621       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing changed from True to False ("NodeInstallerProgressing: 3 nodes are at revision 14")
2024-10-24T14:08:30.156982282Z I1024 14:08:30.156894       1 request.go:700] Waited for 2.792448165s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:08:31.356422429Z I1024 14:08:31.356342       1 request.go:700] Waited for 2.786079102s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:08:32.556925305Z I1024 14:08:32.556843       1 request.go:700] Waited for 2.746086061s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:08:33.757044081Z I1024 14:08:33.756959       1 request.go:700] Waited for 2.793526192s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:08:34.956369148Z I1024 14:08:34.956259       1 request.go:700] Waited for 2.790462612s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-14-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:08:35.956876085Z I1024 14:08:35.956799       1 request.go:700] Waited for 2.791935642s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:08:37.156527921Z I1024 14:08:37.156453       1 request.go:700] Waited for 2.389950153s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-config-openshift-kube-apiserver
2024-10-24T14:08:38.356602538Z I1024 14:08:38.356516       1 request.go:700] Waited for 2.553448602s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:08:39.356916435Z I1024 14:08:39.356818       1 request.go:700] Waited for 2.787961842s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:08:40.556109801Z I1024 14:08:40.556038       1 request.go:700] Waited for 2.793071861s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:08:41.556570708Z I1024 14:08:41.556488       1 request.go:700] Waited for 2.390540703s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-14
2024-10-24T14:08:42.756940385Z I1024 14:08:42.756863       1 request.go:700] Waited for 2.193388244s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:08:43.956807502Z I1024 14:08:43.956702       1 request.go:700] Waited for 2.192935713s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:08:45.156910298Z I1024 14:08:45.156841       1 request.go:700] Waited for 2.192479333s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-10-24T14:08:46.356928634Z I1024 14:08:46.356852       1 request.go:700] Waited for 2.193415723s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:08:47.357168201Z I1024 14:08:47.357077       1 request.go:700] Waited for 2.394471294s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:08:48.557105008Z I1024 14:08:48.557010       1 request.go:700] Waited for 2.792556062s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:08:49.756102805Z I1024 14:08:49.756034       1 request.go:700] Waited for 2.391451564s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:08:50.756892942Z I1024 14:08:50.756824       1 request.go:700] Waited for 1.990622905s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:08:51.756933439Z I1024 14:08:51.756873       1 request.go:700] Waited for 1.791317045s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:08:52.956577045Z I1024 14:08:52.956502       1 request.go:700] Waited for 1.789516244s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:08:53.956626313Z I1024 14:08:53.956548       1 request.go:700] Waited for 1.593547585s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:08:55.156138839Z I1024 14:08:55.156053       1 request.go:700] Waited for 1.590018105s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-10-24T14:09:08.718910009Z I1024 14:09:08.718819       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceAccountIssuer' Desired ServiceAccountIssuer "https://first.foo.bar" is now active issuer. Previous issuer "https://kubernetes.default.svc" is trusted until 2024-10-25 14:09:08.718285479 +0000 UTC m=+89462.569905324
2024-10-24T14:09:08.723464079Z I1024 14:09:08.723393       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveServiceAccountIssuer' ServiceAccount issuer changed from https://kubernetes.default.svc to https://first.foo.bar
2024-10-24T14:09:08.743205739Z I1024 14:09:08.743104       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-10-24T14:09:08.743205739Z   	"admission": map[string]any{"pluginConfig": map[string]any{"PodSecurity": map[string]any{"configuration": map[string]any{"defaults": map[string]any{"audit": string("restricted"), "audit-version": string("latest"), "enforce": string("restricted"), "enforce-version": string("latest"), ...}}}, "network.openshift.io/ExternalIPRanger": map[string]any{"configuration": map[string]any{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]any{"configuration": map[string]any{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []any{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2024-10-24T14:09:08.743205739Z   	"apiServerArguments": map[string]any{
2024-10-24T14:09:08.743205739Z   		"api-audiences": []any{
2024-10-24T14:09:08.743205739Z + 			string("https://first.foo.bar"),
2024-10-24T14:09:08.743205739Z   			string("https://kubernetes.default.svc"),
2024-10-24T14:09:08.743205739Z   		},
2024-10-24T14:09:08.743205739Z   		"authentication-token-webhook-config-file": []any{string("/etc/kubernetes/static-pod-resources/secrets/webhook-authenticat"...)},
2024-10-24T14:09:08.743205739Z   		"authentication-token-webhook-version":     []any{string("v1")},
2024-10-24T14:09:08.743205739Z   		... // 3 identical entries
2024-10-24T14:09:08.743205739Z   		"runtime-config":                        []any{string("admissionregistration.k8s.io/v1beta1=true")},
2024-10-24T14:09:08.743205739Z   		"send-retry-after-while-not-ready-once": []any{string("false")},
2024-10-24T14:09:08.743205739Z   		"service-account-issuer": []any{
2024-10-24T14:09:08.743205739Z + 			string("https://first.foo.bar"),
2024-10-24T14:09:08.743205739Z   			string("https://kubernetes.default.svc"),
2024-10-24T14:09:08.743205739Z   		},
2024-10-24T14:09:08.743205739Z - 		"service-account-jwks-uri": []any{
2024-10-24T14:09:08.743205739Z - 			string("https://api.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX:6443/openid/v1/jwks"),
2024-10-24T14:09:08.743205739Z - 		},
2024-10-24T14:09:08.743205739Z   	},
2024-10-24T14:09:08.743205739Z   	"authConfig":         map[string]any{"oauthMetadataFile": string("/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/o"...)},
2024-10-24T14:09:08.743205739Z   	"corsAllowedOrigins": []any{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2024-10-24T14:09:08.743205739Z   	... // 3 identical entries
2024-10-24T14:09:08.743205739Z   }
2024-10-24T14:09:09.923069736Z I1024 14:09:09.922988       1 request.go:700] Waited for 1.179579037s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-14
2024-10-24T14:09:11.123283212Z I1024 14:09:11.123193       1 request.go:700] Waited for 2.338145103s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T14:09:12.323143999Z I1024 14:09:12.323050       1 request.go:700] Waited for 2.525548002s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:09:13.522866185Z I1024 14:09:13.522777       1 request.go:700] Waited for 1.992633274s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:09:14.523228112Z I1024 14:09:14.523152       1 request.go:700] Waited for 1.992898544s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-config-openshift-kube-apiserver
2024-10-24T14:09:15.723338749Z I1024 14:09:15.723248       1 request.go:700] Waited for 1.993590145s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-10-24T14:09:16.922999385Z I1024 14:09:16.922917       1 request.go:700] Waited for 2.191352494s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:09:17.923238602Z I1024 14:09:17.923152       1 request.go:700] Waited for 2.192679363s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-10-24T14:09:19.122942358Z I1024 14:09:19.122855       1 request.go:700] Waited for 1.991528454s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-14
2024-10-24T14:09:20.123660335Z I1024 14:09:20.123576       1 request.go:700] Waited for 1.994682313s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:09:22.937706427Z I1024 14:09:22.937601       1 core.go:352] ConfigMap "openshift-kube-apiserver/config" changes: {"apiVersion":"v1","data":{"config.yaml":"{\"admission\":{\"pluginConfig\":{\"PodSecurity\":{\"configuration\":{\"apiVersion\":\"pod-security.admission.config.k8s.io/v1\",\"defaults\":{\"audit\":\"restricted\",\"audit-version\":\"latest\",\"enforce\":\"restricted\",\"enforce-version\":\"latest\",\"warn\":\"restricted\",\"warn-version\":\"latest\"},\"exemptions\":{\"usernames\":[\"system:serviceaccount:openshift-infra:build-controller\"]},\"kind\":\"PodSecurityConfiguration\"}},\"network.openshift.io/ExternalIPRanger\":{\"configuration\":{\"allowIngressIP\":false,\"apiVersion\":\"network.openshift.io/v1\",\"externalIPNetworkCIDRs\":null,\"kind\":\"ExternalIPRangerAdmissionConfig\"},\"location\":\"\"},\"network.openshift.io/RestrictedEndpointsAdmission\":{\"configuration\":{\"apiVersion\":\"network.openshift.io/v1\",\"kind\":\"RestrictedEndpointsAdmissionConfig\",\"restrictedCIDRs\":[\"10.128.0.0/14\",\"172.30.0.0/16\"]}}}},\"apiServerArguments\":{\"allow-privileged\":[\"true\"],\"anonymous-auth\":[\"true\"],\"api-audiences\":[\"https://first.foo.bar\",\"https://kubernetes.default.svc\"],\"audit-log-format\":[\"json\"],\"audit-log-maxbackup\":[\"10\"],\"audit-log-maxsize\":[\"200\"],\"audit-log-path\":[\"/var/log/kube-apiserver/audit.log\"],\"audit-policy-file\":[\"/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-audit-policies/policy.yaml\"],\"authentication-token-webhook-config-file\":[\"/etc/kubernetes/static-pod-resources/secrets/webhook-authenticator/kubeConfig\"],\"authentication-token-webhook-version\":[\"v1\"],\"authorization-mode\":[\"Scope\",\"SystemMasters\",\"RBAC\",\"Node\"],\"client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/client-ca/ca-bundle.crt\"],\"enable-admission-plugins\":[\"CertificateApproval\",\"CertificateSigning\",\"CertificateSubjectRestriction\",\"DefaultIngressClass\",\"DefaultStorageClass\",\"DefaultTolerationSeconds\",\"LimitRanger\",\"MutatingAdmissionWebhook\",\"NamespaceLifecycle\",\"NodeRestriction\",\"OwnerReferencesPermissionEnforcement\",\"PersistentVolumeClaimResize\",\"PodNodeSelector\",\"PodTolerationRestriction\",\"Priority\",\"ResourceQuota\",\"RuntimeClass\",\"ServiceAccount\",\"StorageObjectInUseProtection\",\"TaintNodesByCondition\",\"ValidatingAdmissionWebhook\",\"ValidatingAdmissionPolicy\",\"authorization.openshift.io/RestrictSubjectBindings\",\"authorization.openshift.io/ValidateRoleBindingRestriction\",\"config.openshift.io/DenyDeleteClusterConfiguration\",\"config.openshift.io/ValidateAPIServer\",\"config.openshift.io/ValidateAuthentication\",\"config.openshift.io/ValidateConsole\",\"config.openshift.io/ValidateFeatureGate\",\"config.openshift.io/ValidateImage\",\"config.openshift.io/ValidateOAuth\",\"config.openshift.io/ValidateProject\",\"config.openshift.io/ValidateScheduler\",\"image.openshift.io/ImagePolicy\",\"network.openshift.io/ExternalIPRanger\",\"network.openshift.io/RestrictedEndpointsAdmission\",\"quota.openshift.io/ClusterResourceQuota\",\"quota.openshift.io/ValidateClusterResourceQuota\",\"route.openshift.io/IngressAdmission\",\"scheduling.openshift.io/OriginPodNodeEnvironment\",\"security.openshift.io/DefaultSecurityContextConstraints\",\"security.openshift.io/SCCExecRestrictions\",\"security.openshift.io/SecurityContextConstraint\",\"security.openshift.io/ValidateSecurityContextConstraints\",\"storage.openshift.io/CSIInlineVolumeSecurity\"],\"enable-aggregator-routing\":[\"true\"],\"enable-logs-handler\":[\"false\"],\"encryption-provider-config\":[\"/etc/kubernetes/static-pod-resources/secrets/encryption-config/encryption-config\"],\"endpoint-reconciler-type\":[\"lease\"],\"etcd-cafile\":[\"/etc/kubernetes/static-pod-resources/configmaps/etcd-serving-ca/ca-bundle.crt\"],\"etcd-certfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.crt\"],\"etcd-healthcheck-timeout\":[\"9s\"],\"etcd-keyfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.key\"],\"etcd-prefix\":[\"kubernetes.io\"],\"etcd-readycheck-timeout\":[\"9s\"],\"etcd-servers\":[\"https://10.0.0.3:2379\",\"https://10.0.0.4:2379\",\"https://10.0.0.6:2379\",\"https://localhost:2379\"],\"event-ttl\":[\"3h\"],\"feature-gates\":[\"AWSEFSDriverVolumeMetrics=true\",\"AdminNetworkPolicy=true\",\"AlibabaPlatform=true\",\"AzureWorkloadIdentity=true\",\"BareMetalLoadBalancer=true\",\"BuildCSIVolumes=true\",\"ChunkSizeMiB=true\",\"CloudDualStackNodeIPs=true\",\"DisableKubeletCloudCredentialProviders=true\",\"GCPLabelsTags=true\",\"HardwareSpeed=true\",\"IngressControllerLBSubnetsAWS=true\",\"KMSv1=true\",\"ManagedBootImages=true\",\"MetricsServer=true\",\"MultiArchInstallAWS=true\",\"MultiArchInstallGCP=true\",\"NetworkDiagnosticsConfig=true\",\"NetworkLiveMigration=true\",\"NodeDisruptionPolicy=true\",\"OpenShiftPodSecurityAdmission=true\",\"PrivateHostedZoneAWS=true\",\"SetEIPForNLBIngressController=true\",\"VSphereControlPlaneMachineSet=true\",\"VSphereDriverConfiguration=true\",\"VSphereStaticIPs=true\",\"ValidatingAdmissionPolicy=true\",\"AWSClusterHostedDNS=false\",\"AdditionalRoutingCapabilities=false\",\"AutomatedEtcdBackup=false\",\"BootcNodeManagement=false\",\"CSIDriverSharedResource=false\",\"ClusterAPIInstall=false\",\"ClusterAPIInstallIBMCloud=false\",\"ClusterMonitoringConfig=false\",\"DNSNameResolver=false\",\"DynamicResourceAllocation=false\",\"EtcdBackendQuota=false\",\"EventedPLEG=false\",\"Example=false\",\"ExternalOIDC=false\",\"GCPClusterHostedDNS=false\",\"GatewayAPI=false\",\"ImageStreamImportMode=false\",\"IngressControllerDynamicConfigurationManager=false\",\"InsightsConfig=false\",\"InsightsConfigAPI=false\",\"InsightsOnDemandDataGather=false\",\"InsightsRuntimeExtractor=false\",\"MachineAPIMigration=false\",\"MachineAPIOperatorDisableMachineHealthCheckController=false\",\"MachineAPIProviderOpenStack=false\",\"MachineConfigNodes=false\",\"ManagedBootImagesAWS=false\",\"MaxUnavailableStatefulSet=false\",\"MetricsCollectionProfiles=false\",\"MixedCPUsAllocation=false\",\"MultiArchInstallAzure=false\",\"NetworkSegmentation=false\",\"NewOLM=false\",\"NodeSwap=false\",\"OVNObservability=false\",\"OnClusterBuild=false\",\"PersistentIPsForVirtualization=false\",\"PinnedImages=false\",\"PlatformOperators=false\",\"ProcMountType=false\",\"RouteAdvertisements=false\",\"RouteExternalCertificate=false\",\"ServiceAccountTokenNodeBinding=false\",\"SignatureStores=false\",\"SigstoreImageVerification=false\",\"TranslateStreamCloseWebsocketRequests=false\",\"UpgradeStatus=false\",\"UserNamespacesPodSecurityStandards=false\",\"UserNamespacesSupport=false\",\"VSphereMultiNetworks=false\",\"VSphereMultiVCenters=false\",\"VolumeGroupSnapshot=false\"],\"goaway-chance\":[\"0\"],\"http2-max-streams-per-connection\":[\"2000\"],\"kubelet-certificate-authority\":[\"/etc/kubernetes/static-pod-resources/configmaps/kubelet-serving-ca/ca-bundle.crt\"],\"kubelet-client-certificate\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.crt\"],\"kubelet-client-key\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.key\"],\"kubelet-preferred-address-types\":[\"InternalIP\"],\"kubelet-read-only-port\":[\"0\"],\"kubernetes-service-node-port\":[\"0\"],\"max-mutating-requests-inflight\":[\"1000\"],\"max-requests-inflight\":[\"3000\"],\"min-request-timeout\":[\"3600\"],\"proxy-client-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.crt\"],\"proxy-client-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.key\"],\"requestheader-allowed-names\":[\"kube-apiserver-proxy\",\"system:kube-apiserver-proxy\",\"system:openshift-aggregator\"],\"requestheader-client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/aggregator-client-ca/ca-bundle.crt\"],\"requestheader-extra-headers-prefix\":[\"X-Remote-Extra-\"],\"requestheader-group-headers\":[\"X-Remote-Group\"],\"requestheader-username-headers\":[\"X-Remote-User\"],\"runtime-config\":[\"admissionregistration.k8s.io/v1beta1=true\"],\"send-retry-after-while-not-ready-once\":[\"false\"],\"service-account-issuer\":[\"https://first.foo.bar\",\"https://kubernetes.default.svc\"],\"service-account-lookup\":[\"true\"],\"service-account-signing-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/bound-service-account-signing-key/service-account.key\"],\"service-node-port-range\":[\"30000-32767\"],\"shutdown-delay-duration\":[\"70s\"],\"shutdown-send-retry-after\":[\"true\"],\"storage-backend\":[\"etcd3\"],\"storage-media-type\":[\"application/vnd.kubernetes.protobuf\"],\"strict-transport-security-directives\":[\"max-age=31536000,includeSubDomains,preload\"],\"tls-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\"],\"tls-private-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"]},\"apiVersion\":\"kubecontrolplane.config.openshift.io/v1\",\"authConfig\":{\"oauthMetadataFile\":\"/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/oauthMetadata\"},\"consolePublicURL\":\"\",\"corsAllowedOrigins\":[\"//127\\\\.0\\\\.0\\\\.1(:|$)\",\"//localhost(:|$)\"],\"imagePolicyConfig\":{\"internalRegistryHostname\":\"image-registry.openshift-image-registry.svc:5000\"},\"kind\":\"KubeAPIServerConfig\",\"projectConfig\":{\"defaultNodeSelector\":\"\"},\"serviceAccountPublicKeyFiles\":[\"/etc/kubernetes/static-pod-resources/configmaps/sa-token-signing-certs\",\"/etc/kubernetes/static-pod-resources/configmaps/bound-sa-token-signing-certs\"],\"servicesSubnet\":\"172.30.0.0/16\",\"servingInfo\":{\"bindAddress\":\"0.0.0.0:6443\",\"bindNetwork\":\"tcp4\",\"cipherSuites\":[\"TLS_AES_128_GCM_SHA256\",\"TLS_AES_256_GCM_SHA384\",\"TLS_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"],\"minTLSVersion\":\"VersionTLS12\",\"namedCertificates\":[{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.key\"}]}}"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T14:09:22.938679077Z I1024 14:09:22.938607       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/config -n openshift-kube-apiserver:
2024-10-24T14:09:22.938679077Z cause by changes in data.config.yaml
2024-10-24T14:09:22.943404077Z I1024 14:09:22.943351       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 15 triggered by "required configmap/config has changed"
2024-10-24T14:09:23.900460384Z I1024 14:09:23.900352       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceAccountIssuer' Desired ServiceAccountIssuer "https://second.foo.bar" is now active issuer. Previous issuer "https://first.foo.bar" is trusted until 2024-10-25 14:09:23.900225894 +0000 UTC m=+89477.751845779
2024-10-24T14:09:23.909547514Z I1024 14:09:23.909455       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveServiceAccountIssuer' ServiceAccount issuer changed from https://first.foo.bar to https://second.foo.bar
2024-10-24T14:09:23.915678284Z I1024 14:09:23.915604       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-10-24T14:09:23.915678284Z   	"admission": map[string]any{"pluginConfig": map[string]any{"PodSecurity": map[string]any{"configuration": map[string]any{"defaults": map[string]any{"audit": string("restricted"), "audit-version": string("latest"), "enforce": string("restricted"), "enforce-version": string("latest"), ...}}}, "network.openshift.io/ExternalIPRanger": map[string]any{"configuration": map[string]any{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]any{"configuration": map[string]any{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []any{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2024-10-24T14:09:23.915678284Z   	"apiServerArguments": map[string]any{
2024-10-24T14:09:23.915678284Z   		"api-audiences": []any{
2024-10-24T14:09:23.915678284Z + 			string("https://second.foo.bar"),
2024-10-24T14:09:23.915678284Z   			string("https://first.foo.bar"),
2024-10-24T14:09:23.915678284Z   			string("https://kubernetes.default.svc"),
2024-10-24T14:09:23.915678284Z   		},
2024-10-24T14:09:23.915678284Z   		"authentication-token-webhook-config-file": []any{string("/etc/kubernetes/static-pod-resources/secrets/webhook-authenticat"...)},
2024-10-24T14:09:23.915678284Z   		"authentication-token-webhook-version":     []any{string("v1")},
2024-10-24T14:09:23.915678284Z   		... // 3 identical entries
2024-10-24T14:09:23.915678284Z   		"runtime-config":                        []any{string("admissionregistration.k8s.io/v1beta1=true")},
2024-10-24T14:09:23.915678284Z   		"send-retry-after-while-not-ready-once": []any{string("false")},
2024-10-24T14:09:23.915678284Z   		"service-account-issuer": []any{
2024-10-24T14:09:23.915678284Z + 			string("https://second.foo.bar"),
2024-10-24T14:09:23.915678284Z   			string("https://first.foo.bar"),
2024-10-24T14:09:23.915678284Z   			string("https://kubernetes.default.svc"),
2024-10-24T14:09:23.915678284Z   		},
2024-10-24T14:09:23.915678284Z   	},
2024-10-24T14:09:23.915678284Z   	"authConfig":         map[string]any{"oauthMetadataFile": string("/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/o"...)},
2024-10-24T14:09:23.915678284Z   	"corsAllowedOrigins": []any{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2024-10-24T14:09:23.915678284Z   	... // 3 identical entries
2024-10-24T14:09:23.915678284Z   }
2024-10-24T14:09:23.932332044Z E1024 14:09:23.932266       1 base_controller.go:271] "Unhandled Error" err="ServiceAccountIssuerController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T14:09:24.123334084Z I1024 14:09:24.123262       1 request.go:700] Waited for 1.184915187s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:09:25.322887910Z I1024 14:09:25.322826       1 request.go:700] Waited for 1.793483495s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:09:26.323627327Z I1024 14:09:26.323547       1 request.go:700] Waited for 2.415094433s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T14:09:27.522612214Z I1024 14:09:27.522544       1 request.go:700] Waited for 2.785371502s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T14:09:27.542644294Z I1024 14:09:27.542573       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-15 -n openshift-kube-apiserver because it was missing
2024-10-24T14:09:28.523579771Z I1024 14:09:28.523504       1 request.go:700] Waited for 2.925605212s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:09:29.723648987Z I1024 14:09:29.723540       1 request.go:700] Waited for 2.978004441s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:09:30.535371375Z I1024 14:09:30.535281       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-15 -n openshift-kube-apiserver because it was missing
2024-10-24T14:09:30.923262414Z I1024 14:09:30.923191       1 request.go:700] Waited for 2.992423952s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:09:32.122692160Z I1024 14:09:32.122626       1 request.go:700] Waited for 2.993972661s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:09:33.122919367Z I1024 14:09:33.122836       1 request.go:700] Waited for 2.792107062s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-10-24T14:09:33.335110746Z I1024 14:09:33.335046       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-15 -n openshift-kube-apiserver because it was missing
2024-10-24T14:09:34.123090764Z I1024 14:09:34.122991       1 request.go:700] Waited for 2.791447282s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:09:35.123241591Z I1024 14:09:35.123154       1 request.go:700] Waited for 2.787685722s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:09:36.123602148Z I1024 14:09:36.123492       1 request.go:700] Waited for 2.788439192s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T14:09:36.133078938Z I1024 14:09:36.132993       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/oauth-metadata-15 -n openshift-kube-apiserver because it was missing
2024-10-24T14:09:37.322659545Z I1024 14:09:37.322593       1 request.go:700] Waited for 2.791605072s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:09:38.323368752Z I1024 14:09:38.323316       1 request.go:700] Waited for 2.790443822s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:09:38.931940250Z I1024 14:09:38.931882       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-15 -n openshift-kube-apiserver because it was missing
2024-10-24T14:09:39.522945079Z I1024 14:09:39.522877       1 request.go:700] Waited for 2.794127012s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:09:40.523382876Z I1024 14:09:40.523326       1 request.go:700] Waited for 2.791711462s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:09:41.723647672Z I1024 14:09:41.723585       1 request.go:700] Waited for 2.791996312s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T14:09:41.733500512Z I1024 14:09:41.733411       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-15 -n openshift-kube-apiserver because it was missing
2024-10-24T14:09:42.923633148Z I1024 14:09:42.923567       1 request.go:700] Waited for 1.792467594s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:09:43.335169087Z I1024 14:09:43.335094       1 core.go:352] ConfigMap "openshift-kube-apiserver/config" changes: {"apiVersion":"v1","data":{"config.yaml":"{\"admission\":{\"pluginConfig\":{\"PodSecurity\":{\"configuration\":{\"apiVersion\":\"pod-security.admission.config.k8s.io/v1\",\"defaults\":{\"audit\":\"restricted\",\"audit-version\":\"latest\",\"enforce\":\"restricted\",\"enforce-version\":\"latest\",\"warn\":\"restricted\",\"warn-version\":\"latest\"},\"exemptions\":{\"usernames\":[\"system:serviceaccount:openshift-infra:build-controller\"]},\"kind\":\"PodSecurityConfiguration\"}},\"network.openshift.io/ExternalIPRanger\":{\"configuration\":{\"allowIngressIP\":false,\"apiVersion\":\"network.openshift.io/v1\",\"externalIPNetworkCIDRs\":null,\"kind\":\"ExternalIPRangerAdmissionConfig\"},\"location\":\"\"},\"network.openshift.io/RestrictedEndpointsAdmission\":{\"configuration\":{\"apiVersion\":\"network.openshift.io/v1\",\"kind\":\"RestrictedEndpointsAdmissionConfig\",\"restrictedCIDRs\":[\"10.128.0.0/14\",\"172.30.0.0/16\"]}}}},\"apiServerArguments\":{\"allow-privileged\":[\"true\"],\"anonymous-auth\":[\"true\"],\"api-audiences\":[\"https://second.foo.bar\",\"https://first.foo.bar\",\"https://kubernetes.default.svc\"],\"audit-log-format\":[\"json\"],\"audit-log-maxbackup\":[\"10\"],\"audit-log-maxsize\":[\"200\"],\"audit-log-path\":[\"/var/log/kube-apiserver/audit.log\"],\"audit-policy-file\":[\"/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-audit-policies/policy.yaml\"],\"authentication-token-webhook-config-file\":[\"/etc/kubernetes/static-pod-resources/secrets/webhook-authenticator/kubeConfig\"],\"authentication-token-webhook-version\":[\"v1\"],\"authorization-mode\":[\"Scope\",\"SystemMasters\",\"RBAC\",\"Node\"],\"client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/client-ca/ca-bundle.crt\"],\"enable-admission-plugins\":[\"CertificateApproval\",\"CertificateSigning\",\"CertificateSubjectRestriction\",\"DefaultIngressClass\",\"DefaultStorageClass\",\"DefaultTolerationSeconds\",\"LimitRanger\",\"MutatingAdmissionWebhook\",\"NamespaceLifecycle\",\"NodeRestriction\",\"OwnerReferencesPermissionEnforcement\",\"PersistentVolumeClaimResize\",\"PodNodeSelector\",\"PodTolerationRestriction\",\"Priority\",\"ResourceQuota\",\"RuntimeClass\",\"ServiceAccount\",\"StorageObjectInUseProtection\",\"TaintNodesByCondition\",\"ValidatingAdmissionWebhook\",\"ValidatingAdmissionPolicy\",\"authorization.openshift.io/RestrictSubjectBindings\",\"authorization.openshift.io/ValidateRoleBindingRestriction\",\"config.openshift.io/DenyDeleteClusterConfiguration\",\"config.openshift.io/ValidateAPIServer\",\"config.openshift.io/ValidateAuthentication\",\"config.openshift.io/ValidateConsole\",\"config.openshift.io/ValidateFeatureGate\",\"config.openshift.io/ValidateImage\",\"config.openshift.io/ValidateOAuth\",\"config.openshift.io/ValidateProject\",\"config.openshift.io/ValidateScheduler\",\"image.openshift.io/ImagePolicy\",\"network.openshift.io/ExternalIPRanger\",\"network.openshift.io/RestrictedEndpointsAdmission\",\"quota.openshift.io/ClusterResourceQuota\",\"quota.openshift.io/ValidateClusterResourceQuota\",\"route.openshift.io/IngressAdmission\",\"scheduling.openshift.io/OriginPodNodeEnvironment\",\"security.openshift.io/DefaultSecurityContextConstraints\",\"security.openshift.io/SCCExecRestrictions\",\"security.openshift.io/SecurityContextConstraint\",\"security.openshift.io/ValidateSecurityContextConstraints\",\"storage.openshift.io/CSIInlineVolumeSecurity\"],\"enable-aggregator-routing\":[\"true\"],\"enable-logs-handler\":[\"false\"],\"encryption-provider-config\":[\"/etc/kubernetes/static-pod-resources/secrets/encryption-config/encryption-config\"],\"endpoint-reconciler-type\":[\"lease\"],\"etcd-cafile\":[\"/etc/kubernetes/static-pod-resources/configmaps/etcd-serving-ca/ca-bundle.crt\"],\"etcd-certfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.crt\"],\"etcd-healthcheck-timeout\":[\"9s\"],\"etcd-keyfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.key\"],\"etcd-prefix\":[\"kubernetes.io\"],\"etcd-readycheck-timeout\":[\"9s\"],\"etcd-servers\":[\"https://10.0.0.3:2379\",\"https://10.0.0.4:2379\",\"https://10.0.0.6:2379\",\"https://localhost:2379\"],\"event-ttl\":[\"3h\"],\"feature-gates\":[\"AWSEFSDriverVolumeMetrics=true\",\"AdminNetworkPolicy=true\",\"AlibabaPlatform=true\",\"AzureWorkloadIdentity=true\",\"BareMetalLoadBalancer=true\",\"BuildCSIVolumes=true\",\"ChunkSizeMiB=true\",\"CloudDualStackNodeIPs=true\",\"DisableKubeletCloudCredentialProviders=true\",\"GCPLabelsTags=true\",\"HardwareSpeed=true\",\"IngressControllerLBSubnetsAWS=true\",\"KMSv1=true\",\"ManagedBootImages=true\",\"MetricsServer=true\",\"MultiArchInstallAWS=true\",\"MultiArchInstallGCP=true\",\"NetworkDiagnosticsConfig=true\",\"NetworkLiveMigration=true\",\"NodeDisruptionPolicy=true\",\"OpenShiftPodSecurityAdmission=true\",\"PrivateHostedZoneAWS=true\",\"SetEIPForNLBIngressController=true\",\"VSphereControlPlaneMachineSet=true\",\"VSphereDriverConfiguration=true\",\"VSphereStaticIPs=true\",\"ValidatingAdmissionPolicy=true\",\"AWSClusterHostedDNS=false\",\"AdditionalRoutingCapabilities=false\",\"AutomatedEtcdBackup=false\",\"BootcNodeManagement=false\",\"CSIDriverSharedResource=false\",\"ClusterAPIInstall=false\",\"ClusterAPIInstallIBMCloud=false\",\"ClusterMonitoringConfig=false\",\"DNSNameResolver=false\",\"DynamicResourceAllocation=false\",\"EtcdBackendQuota=false\",\"EventedPLEG=false\",\"Example=false\",\"ExternalOIDC=false\",\"GCPClusterHostedDNS=false\",\"GatewayAPI=false\",\"ImageStreamImportMode=false\",\"IngressControllerDynamicConfigurationManager=false\",\"InsightsConfig=false\",\"InsightsConfigAPI=false\",\"InsightsOnDemandDataGather=false\",\"InsightsRuntimeExtractor=false\",\"MachineAPIMigration=false\",\"MachineAPIOperatorDisableMachineHealthCheckController=false\",\"MachineAPIProviderOpenStack=false\",\"MachineConfigNodes=false\",\"ManagedBootImagesAWS=false\",\"MaxUnavailableStatefulSet=false\",\"MetricsCollectionProfiles=false\",\"MixedCPUsAllocation=false\",\"MultiArchInstallAzure=false\",\"NetworkSegmentation=false\",\"NewOLM=false\",\"NodeSwap=false\",\"OVNObservability=false\",\"OnClusterBuild=false\",\"PersistentIPsForVirtualization=false\",\"PinnedImages=false\",\"PlatformOperators=false\",\"ProcMountType=false\",\"RouteAdvertisements=false\",\"RouteExternalCertificate=false\",\"ServiceAccountTokenNodeBinding=false\",\"SignatureStores=false\",\"SigstoreImageVerification=false\",\"TranslateStreamCloseWebsocketRequests=false\",\"UpgradeStatus=false\",\"UserNamespacesPodSecurityStandards=false\",\"UserNamespacesSupport=false\",\"VSphereMultiNetworks=false\",\"VSphereMultiVCenters=false\",\"VolumeGroupSnapshot=false\"],\"goaway-chance\":[\"0\"],\"http2-max-streams-per-connection\":[\"2000\"],\"kubelet-certificate-authority\":[\"/etc/kubernetes/static-pod-resources/configmaps/kubelet-serving-ca/ca-bundle.crt\"],\"kubelet-client-certificate\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.crt\"],\"kubelet-client-key\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.key\"],\"kubelet-preferred-address-types\":[\"InternalIP\"],\"kubelet-read-only-port\":[\"0\"],\"kubernetes-service-node-port\":[\"0\"],\"max-mutating-requests-inflight\":[\"1000\"],\"max-requests-inflight\":[\"3000\"],\"min-request-timeout\":[\"3600\"],\"proxy-client-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.crt\"],\"proxy-client-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.key\"],\"requestheader-allowed-names\":[\"kube-apiserver-proxy\",\"system:kube-apiserver-proxy\",\"system:openshift-aggregator\"],\"requestheader-client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/aggregator-client-ca/ca-bundle.crt\"],\"requestheader-extra-headers-prefix\":[\"X-Remote-Extra-\"],\"requestheader-group-headers\":[\"X-Remote-Group\"],\"requestheader-username-headers\":[\"X-Remote-User\"],\"runtime-config\":[\"admissionregistration.k8s.io/v1beta1=true\"],\"send-retry-after-while-not-ready-once\":[\"false\"],\"service-account-issuer\":[\"https://second.foo.bar\",\"https://first.foo.bar\",\"https://kubernetes.default.svc\"],\"service-account-lookup\":[\"true\"],\"service-account-signing-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/bound-service-account-signing-key/service-account.key\"],\"service-node-port-range\":[\"30000-32767\"],\"shutdown-delay-duration\":[\"70s\"],\"shutdown-send-retry-after\":[\"true\"],\"storage-backend\":[\"etcd3\"],\"storage-media-type\":[\"application/vnd.kubernetes.protobuf\"],\"strict-transport-security-directives\":[\"max-age=31536000,includeSubDomains,preload\"],\"tls-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\"],\"tls-private-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"]},\"apiVersion\":\"kubecontrolplane.config.openshift.io/v1\",\"authConfig\":{\"oauthMetadataFile\":\"/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/oauthMetadata\"},\"consolePublicURL\":\"\",\"corsAllowedOrigins\":[\"//127\\\\.0\\\\.0\\\\.1(:|$)\",\"//localhost(:|$)\"],\"imagePolicyConfig\":{\"internalRegistryHostname\":\"image-registry.openshift-image-registry.svc:5000\"},\"kind\":\"KubeAPIServerConfig\",\"projectConfig\":{\"defaultNodeSelector\":\"\"},\"serviceAccountPublicKeyFiles\":[\"/etc/kubernetes/static-pod-resources/configmaps/sa-token-signing-certs\",\"/etc/kubernetes/static-pod-resources/configmaps/bound-sa-token-signing-certs\"],\"servicesSubnet\":\"172.30.0.0/16\",\"servingInfo\":{\"bindAddress\":\"0.0.0.0:6443\",\"bindNetwork\":\"tcp4\",\"cipherSuites\":[\"TLS_AES_128_GCM_SHA256\",\"TLS_AES_256_GCM_SHA384\",\"TLS_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"],\"minTLSVersion\":\"VersionTLS12\",\"namedCertificates\":[{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.key\"}]}}"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T14:09:43.335716087Z I1024 14:09:43.335668       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/config -n openshift-kube-apiserver:
2024-10-24T14:09:43.335716087Z cause by changes in data.config.yaml
2024-10-24T14:09:43.532736577Z I1024 14:09:43.532677       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-15 -n openshift-kube-apiserver because it was missing
2024-10-24T14:09:44.090060005Z I1024 14:09:44.089939       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceAccountIssuer' Issuer set to default value "https://kubernetes.default.svc"
2024-10-24T14:09:44.112632495Z I1024 14:09:44.106601       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveServiceAccountIssuer' ServiceAccount issuer changed from https://second.foo.bar to https://kubernetes.default.svc
2024-10-24T14:09:44.112632495Z I1024 14:09:44.106641       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-10-24T14:09:44.112632495Z   	"admission": map[string]any{"pluginConfig": map[string]any{"PodSecurity": map[string]any{"configuration": map[string]any{"defaults": map[string]any{"audit": string("restricted"), "audit-version": string("latest"), "enforce": string("restricted"), "enforce-version": string("latest"), ...}}}, "network.openshift.io/ExternalIPRanger": map[string]any{"configuration": map[string]any{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]any{"configuration": map[string]any{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []any{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2024-10-24T14:09:44.112632495Z   	"apiServerArguments": map[string]any{
2024-10-24T14:09:44.112632495Z   		"api-audiences": []any{
2024-10-24T14:09:44.112632495Z - 			string("https://second.foo.bar"),
2024-10-24T14:09:44.112632495Z - 			string("https://first.foo.bar"),
2024-10-24T14:09:44.112632495Z   			string("https://kubernetes.default.svc"),
2024-10-24T14:09:44.112632495Z   		},
2024-10-24T14:09:44.112632495Z   		"authentication-token-webhook-config-file": []any{string("/etc/kubernetes/static-pod-resources/secrets/webhook-authenticat"...)},
2024-10-24T14:09:44.112632495Z   		"authentication-token-webhook-version":     []any{string("v1")},
2024-10-24T14:09:44.112632495Z   		... // 3 identical entries
2024-10-24T14:09:44.112632495Z   		"runtime-config":                        []any{string("admissionregistration.k8s.io/v1beta1=true")},
2024-10-24T14:09:44.112632495Z   		"send-retry-after-while-not-ready-once": []any{string("false")},
2024-10-24T14:09:44.112632495Z   		"service-account-issuer": []any{
2024-10-24T14:09:44.112632495Z - 			string("https://second.foo.bar"),
2024-10-24T14:09:44.112632495Z - 			string("https://first.foo.bar"),
2024-10-24T14:09:44.112632495Z   			string("https://kubernetes.default.svc"),
2024-10-24T14:09:44.112632495Z   		},
2024-10-24T14:09:44.112632495Z + 		"service-account-jwks-uri": []any{
2024-10-24T14:09:44.112632495Z + 			string("https://api.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX:6443/openid/v1/jwks"),
2024-10-24T14:09:44.112632495Z + 		},
2024-10-24T14:09:44.112632495Z   	},
2024-10-24T14:09:44.112632495Z   	"authConfig":         map[string]any{"oauthMetadataFile": string("/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/o"...)},
2024-10-24T14:09:44.112632495Z   	"corsAllowedOrigins": []any{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2024-10-24T14:09:44.112632495Z   	... // 3 identical entries
2024-10-24T14:09:44.112632495Z   }
2024-10-24T14:09:44.123915725Z I1024 14:09:44.123796       1 request.go:700] Waited for 1.734053155s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:09:44.141528655Z E1024 14:09:44.141466       1 base_controller.go:271] "Unhandled Error" err="ServiceAccountIssuerController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T14:09:45.322797362Z I1024 14:09:45.322710       1 request.go:700] Waited for 1.790200185s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T14:09:45.335141922Z I1024 14:09:45.335058       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-15 -n openshift-kube-apiserver because it was missing
2024-10-24T14:09:46.323516439Z I1024 14:09:46.323425       1 request.go:700] Waited for 2.217912684s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:09:47.523589825Z I1024 14:09:47.523508       1 request.go:700] Waited for 2.986309321s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:09:48.523652252Z I1024 14:09:48.523553       1 request.go:700] Waited for 3.1887691s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T14:09:48.534516282Z I1024 14:09:48.533697       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-15 -n openshift-kube-apiserver because it was missing
2024-10-24T14:09:49.723220389Z I1024 14:09:49.723127       1 request.go:700] Waited for 3.19019666s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-14
2024-10-24T14:09:50.922899565Z I1024 14:09:50.922833       1 request.go:700] Waited for 3.192540851s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:09:51.533908503Z I1024 14:09:51.533852       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-15 -n openshift-kube-apiserver because it was missing
2024-10-24T14:09:51.923046272Z I1024 14:09:51.922977       1 request.go:700] Waited for 2.991489801s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:09:52.923201959Z I1024 14:09:52.923131       1 request.go:700] Waited for 2.792252302s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:09:53.923281696Z I1024 14:09:53.923185       1 request.go:700] Waited for 2.793170381s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-14-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:09:54.340584825Z I1024 14:09:54.340503       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-15 -n openshift-kube-apiserver because it was missing
2024-10-24T14:09:55.123165022Z I1024 14:09:55.123100       1 request.go:700] Waited for 2.786676991s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:09:56.123244019Z I1024 14:09:56.123169       1 request.go:700] Waited for 2.715560031s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T14:09:57.123555636Z I1024 14:09:57.123501       1 request.go:700] Waited for 2.783226721s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets
2024-10-24T14:09:57.139537096Z I1024 14:09:57.139471       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/encryption-config-15 -n openshift-kube-apiserver because it was missing
2024-10-24T14:09:58.323116273Z I1024 14:09:58.323036       1 request.go:700] Waited for 2.793047252s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:09:59.523457889Z I1024 14:09:59.523319       1 request.go:700] Waited for 2.792929872s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-14-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:09:59.936366068Z I1024 14:09:59.936294       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-15 -n openshift-kube-apiserver because it was missing
2024-10-24T14:10:00.523678846Z I1024 14:10:00.523593       1 request.go:700] Waited for 2.794920702s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:10:01.723019473Z I1024 14:10:01.722930       1 request.go:700] Waited for 2.725144712s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:10:02.543331600Z I1024 14:10:02.543277       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-15 -n openshift-kube-apiserver because it was missing
2024-10-24T14:10:02.723619540Z I1024 14:10:02.723558       1 request.go:700] Waited for 2.591857282s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:10:03.923198276Z I1024 14:10:03.923125       1 request.go:700] Waited for 2.392487033s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:10:04.538898924Z I1024 14:10:04.534687       1 core.go:352] ConfigMap "openshift-kube-apiserver/config" changes: {"apiVersion":"v1","data":{"config.yaml":"{\"admission\":{\"pluginConfig\":{\"PodSecurity\":{\"configuration\":{\"apiVersion\":\"pod-security.admission.config.k8s.io/v1\",\"defaults\":{\"audit\":\"restricted\",\"audit-version\":\"latest\",\"enforce\":\"restricted\",\"enforce-version\":\"latest\",\"warn\":\"restricted\",\"warn-version\":\"latest\"},\"exemptions\":{\"usernames\":[\"system:serviceaccount:openshift-infra:build-controller\"]},\"kind\":\"PodSecurityConfiguration\"}},\"network.openshift.io/ExternalIPRanger\":{\"configuration\":{\"allowIngressIP\":false,\"apiVersion\":\"network.openshift.io/v1\",\"externalIPNetworkCIDRs\":null,\"kind\":\"ExternalIPRangerAdmissionConfig\"},\"location\":\"\"},\"network.openshift.io/RestrictedEndpointsAdmission\":{\"configuration\":{\"apiVersion\":\"network.openshift.io/v1\",\"kind\":\"RestrictedEndpointsAdmissionConfig\",\"restrictedCIDRs\":[\"10.128.0.0/14\",\"172.30.0.0/16\"]}}}},\"apiServerArguments\":{\"allow-privileged\":[\"true\"],\"anonymous-auth\":[\"true\"],\"api-audiences\":[\"https://kubernetes.default.svc\"],\"audit-log-format\":[\"json\"],\"audit-log-maxbackup\":[\"10\"],\"audit-log-maxsize\":[\"200\"],\"audit-log-path\":[\"/var/log/kube-apiserver/audit.log\"],\"audit-policy-file\":[\"/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-audit-policies/policy.yaml\"],\"authentication-token-webhook-config-file\":[\"/etc/kubernetes/static-pod-resources/secrets/webhook-authenticator/kubeConfig\"],\"authentication-token-webhook-version\":[\"v1\"],\"authorization-mode\":[\"Scope\",\"SystemMasters\",\"RBAC\",\"Node\"],\"client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/client-ca/ca-bundle.crt\"],\"enable-admission-plugins\":[\"CertificateApproval\",\"CertificateSigning\",\"CertificateSubjectRestriction\",\"DefaultIngressClass\",\"DefaultStorageClass\",\"DefaultTolerationSeconds\",\"LimitRanger\",\"MutatingAdmissionWebhook\",\"NamespaceLifecycle\",\"NodeRestriction\",\"OwnerReferencesPermissionEnforcement\",\"PersistentVolumeClaimResize\",\"PodNodeSelector\",\"PodTolerationRestriction\",\"Priority\",\"ResourceQuota\",\"RuntimeClass\",\"ServiceAccount\",\"StorageObjectInUseProtection\",\"TaintNodesByCondition\",\"ValidatingAdmissionWebhook\",\"ValidatingAdmissionPolicy\",\"authorization.openshift.io/RestrictSubjectBindings\",\"authorization.openshift.io/ValidateRoleBindingRestriction\",\"config.openshift.io/DenyDeleteClusterConfiguration\",\"config.openshift.io/ValidateAPIServer\",\"config.openshift.io/ValidateAuthentication\",\"config.openshift.io/ValidateConsole\",\"config.openshift.io/ValidateFeatureGate\",\"config.openshift.io/ValidateImage\",\"config.openshift.io/ValidateOAuth\",\"config.openshift.io/ValidateProject\",\"config.openshift.io/ValidateScheduler\",\"image.openshift.io/ImagePolicy\",\"network.openshift.io/ExternalIPRanger\",\"network.openshift.io/RestrictedEndpointsAdmission\",\"quota.openshift.io/ClusterResourceQuota\",\"quota.openshift.io/ValidateClusterResourceQuota\",\"route.openshift.io/IngressAdmission\",\"scheduling.openshift.io/OriginPodNodeEnvironment\",\"security.openshift.io/DefaultSecurityContextConstraints\",\"security.openshift.io/SCCExecRestrictions\",\"security.openshift.io/SecurityContextConstraint\",\"security.openshift.io/ValidateSecurityContextConstraints\",\"storage.openshift.io/CSIInlineVolumeSecurity\"],\"enable-aggregator-routing\":[\"true\"],\"enable-logs-handler\":[\"false\"],\"encryption-provider-config\":[\"/etc/kubernetes/static-pod-resources/secrets/encryption-config/encryption-config\"],\"endpoint-reconciler-type\":[\"lease\"],\"etcd-cafile\":[\"/etc/kubernetes/static-pod-resources/configmaps/etcd-serving-ca/ca-bundle.crt\"],\"etcd-certfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.crt\"],\"etcd-healthcheck-timeout\":[\"9s\"],\"etcd-keyfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.key\"],\"etcd-prefix\":[\"kubernetes.io\"],\"etcd-readycheck-timeout\":[\"9s\"],\"etcd-servers\":[\"https://10.0.0.3:2379\",\"https://10.0.0.4:2379\",\"https://10.0.0.6:2379\",\"https://localhost:2379\"],\"event-ttl\":[\"3h\"],\"feature-gates\":[\"AWSEFSDriverVolumeMetrics=true\",\"AdminNetworkPolicy=true\",\"AlibabaPlatform=true\",\"AzureWorkloadIdentity=true\",\"BareMetalLoadBalancer=true\",\"BuildCSIVolumes=true\",\"ChunkSizeMiB=true\",\"CloudDualStackNodeIPs=true\",\"DisableKubeletCloudCredentialProviders=true\",\"GCPLabelsTags=true\",\"HardwareSpeed=true\",\"IngressControllerLBSubnetsAWS=true\",\"KMSv1=true\",\"ManagedBootImages=true\",\"MetricsServer=true\",\"MultiArchInstallAWS=true\",\"MultiArchInstallGCP=true\",\"NetworkDiagnosticsConfig=true\",\"NetworkLiveMigration=true\",\"NodeDisruptionPolicy=true\",\"OpenShiftPodSecurityAdmission=true\",\"PrivateHostedZoneAWS=true\",\"SetEIPForNLBIngressController=true\",\"VSphereControlPlaneMachineSet=true\",\"VSphereDriverConfiguration=true\",\"VSphereStaticIPs=true\",\"ValidatingAdmissionPolicy=true\",\"AWSClusterHostedDNS=false\",\"AdditionalRoutingCapabilities=false\",\"AutomatedEtcdBackup=false\",\"BootcNodeManagement=false\",\"CSIDriverSharedResource=false\",\"ClusterAPIInstall=false\",\"ClusterAPIInstallIBMCloud=false\",\"ClusterMonitoringConfig=false\",\"DNSNameResolver=false\",\"DynamicResourceAllocation=false\",\"EtcdBackendQuota=false\",\"EventedPLEG=false\",\"Example=false\",\"ExternalOIDC=false\",\"GCPClusterHostedDNS=false\",\"GatewayAPI=false\",\"ImageStreamImportMode=false\",\"IngressControllerDynamicConfigurationManager=false\",\"InsightsConfig=false\",\"InsightsConfigAPI=false\",\"InsightsOnDemandDataGather=false\",\"InsightsRuntimeExtractor=false\",\"MachineAPIMigration=false\",\"MachineAPIOperatorDisableMachineHealthCheckController=false\",\"MachineAPIProviderOpenStack=false\",\"MachineConfigNodes=false\",\"ManagedBootImagesAWS=false\",\"MaxUnavailableStatefulSet=false\",\"MetricsCollectionProfiles=false\",\"MixedCPUsAllocation=false\",\"MultiArchInstallAzure=false\",\"NetworkSegmentation=false\",\"NewOLM=false\",\"NodeSwap=false\",\"OVNObservability=false\",\"OnClusterBuild=false\",\"PersistentIPsForVirtualization=false\",\"PinnedImages=false\",\"PlatformOperators=false\",\"ProcMountType=false\",\"RouteAdvertisements=false\",\"RouteExternalCertificate=false\",\"ServiceAccountTokenNodeBinding=false\",\"SignatureStores=false\",\"SigstoreImageVerification=false\",\"TranslateStreamCloseWebsocketRequests=false\",\"UpgradeStatus=false\",\"UserNamespacesPodSecurityStandards=false\",\"UserNamespacesSupport=false\",\"VSphereMultiNetworks=false\",\"VSphereMultiVCenters=false\",\"VolumeGroupSnapshot=false\"],\"goaway-chance\":[\"0\"],\"http2-max-streams-per-connection\":[\"2000\"],\"kubelet-certificate-authority\":[\"/etc/kubernetes/static-pod-resources/configmaps/kubelet-serving-ca/ca-bundle.crt\"],\"kubelet-client-certificate\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.crt\"],\"kubelet-client-key\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.key\"],\"kubelet-preferred-address-types\":[\"InternalIP\"],\"kubelet-read-only-port\":[\"0\"],\"kubernetes-service-node-port\":[\"0\"],\"max-mutating-requests-inflight\":[\"1000\"],\"max-requests-inflight\":[\"3000\"],\"min-request-timeout\":[\"3600\"],\"proxy-client-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.crt\"],\"proxy-client-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.key\"],\"requestheader-allowed-names\":[\"kube-apiserver-proxy\",\"system:kube-apiserver-proxy\",\"system:openshift-aggregator\"],\"requestheader-client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/aggregator-client-ca/ca-bundle.crt\"],\"requestheader-extra-headers-prefix\":[\"X-Remote-Extra-\"],\"requestheader-group-headers\":[\"X-Remote-Group\"],\"requestheader-username-headers\":[\"X-Remote-User\"],\"runtime-config\":[\"admissionregistration.k8s.io/v1beta1=true\"],\"send-retry-after-while-not-ready-once\":[\"false\"],\"service-account-issuer\":[\"https://kubernetes.default.svc\"],\"service-account-jwks-uri\":[\"https://api.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX:6443/openid/v1/jwks\"],\"service-account-lookup\":[\"true\"],\"service-account-signing-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/bound-service-account-signing-key/service-account.key\"],\"service-node-port-range\":[\"30000-32767\"],\"shutdown-delay-duration\":[\"70s\"],\"shutdown-send-retry-after\":[\"true\"],\"storage-backend\":[\"etcd3\"],\"storage-media-type\":[\"application/vnd.kubernetes.protobuf\"],\"strict-transport-security-directives\":[\"max-age=31536000,includeSubDomains,preload\"],\"tls-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\"],\"tls-private-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"]},\"apiVersion\":\"kubecontrolplane.config.openshift.io/v1\",\"authConfig\":{\"oauthMetadataFile\":\"/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/oauthMetadata\"},\"consolePublicURL\":\"\",\"corsAllowedOrigins\":[\"//127\\\\.0\\\\.0\\\\.1(:|$)\",\"//localhost(:|$)\"],\"imagePolicyConfig\":{\"internalRegistryHostname\":\"image-registry.openshift-image-registry.svc:5000\"},\"kind\":\"KubeAPIServerConfig\",\"projectConfig\":{\"defaultNodeSelector\":\"\"},\"serviceAccountPublicKeyFiles\":[\"/etc/kubernetes/static-pod-resources/configmaps/sa-token-signing-certs\",\"/etc/kubernetes/static-pod-resources/configmaps/bound-sa-token-signing-certs\"],\"servicesSubnet\":\"172.30.0.0/16\",\"servingInfo\":{\"bindAddress\":\"0.0.0.0:6443\",\"bindNetwork\":\"tcp4\",\"cipherSuites\":[\"TLS_AES_128_GCM_SHA256\",\"TLS_AES_256_GCM_SHA384\",\"TLS_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"],\"minTLSVersion\":\"VersionTLS12\",\"namedCertificates\":[{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.key\"}]}}"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T14:10:04.538980364Z I1024 14:10:04.537134       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/config -n openshift-kube-apiserver:
2024-10-24T14:10:04.538980364Z cause by changes in data.config.yaml
2024-10-24T14:10:04.735304674Z I1024 14:10:04.735222       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-15 -n openshift-kube-apiserver because it was missing
2024-10-24T14:10:05.122811083Z I1024 14:10:05.122670       1 request.go:700] Waited for 2.193307914s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:10:06.122982170Z I1024 14:10:06.122892       1 request.go:700] Waited for 2.319842303s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:10:07.123119037Z I1024 14:10:07.123037       1 request.go:700] Waited for 2.584605372s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-10-24T14:10:07.332671136Z I1024 14:10:07.332586       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 15 triggered by "required configmap/config has changed"
2024-10-24T14:10:07.333276266Z W1024 14:10:07.333235       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:10:07.333276266Z W1024 14:10:07.333266       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:10:07.365812016Z W1024 14:10:07.365739       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:10:07.365939926Z W1024 14:10:07.365893       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:10:07.400104266Z I1024 14:10:07.400028       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 16 triggered by "required configmap/config has changed"
2024-10-24T14:10:08.123495104Z I1024 14:10:08.123380       1 request.go:700] Waited for 2.592387122s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:10:09.323275241Z I1024 14:10:09.323207       1 request.go:700] Waited for 2.583438593s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:10:10.523089447Z I1024 14:10:10.523018       1 request.go:700] Waited for 2.985970681s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:10:11.722617563Z I1024 14:10:11.722550       1 request.go:700] Waited for 2.991027641s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:10:12.723031551Z I1024 14:10:12.722958       1 request.go:700] Waited for 2.992286441s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-10-24T14:10:13.133728259Z I1024 14:10:13.133615       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-16 -n openshift-kube-apiserver because it was missing
2024-10-24T14:10:13.723265597Z I1024 14:10:13.723198       1 request.go:700] Waited for 2.793179762s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:10:14.723379054Z I1024 14:10:14.723310       1 request.go:700] Waited for 2.793543772s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:10:15.723646131Z I1024 14:10:15.723556       1 request.go:700] Waited for 2.793380852s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:10:15.932160711Z I1024 14:10:15.932105       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-16 -n openshift-kube-apiserver because it was missing
2024-10-24T14:10:16.922894258Z I1024 14:10:16.922817       1 request.go:700] Waited for 2.793315012s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-config-openshift-kube-apiserver
2024-10-24T14:10:17.923013185Z I1024 14:10:17.922939       1 request.go:700] Waited for 2.786819062s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:10:18.156303834Z I1024 14:10:18.156205       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-15-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-apiserver because it was missing
2024-10-24T14:10:18.532611732Z I1024 14:10:18.532546       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-16 -n openshift-kube-apiserver because it was missing
2024-10-24T14:10:18.923683101Z I1024 14:10:18.923572       1 request.go:700] Waited for 2.594859831s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:10:20.122898336Z I1024 14:10:20.122828       1 request.go:700] Waited for 2.186067711s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:10:21.123357682Z I1024 14:10:21.123280       1 request.go:700] Waited for 2.966983288s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:10:21.732491620Z I1024 14:10:21.732433       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/oauth-metadata-16 -n openshift-kube-apiserver because it was missing
2024-10-24T14:10:22.323616058Z I1024 14:10:22.323550       1 request.go:700] Waited for 3.191514588s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-14
2024-10-24T14:10:23.523045583Z I1024 14:10:23.522981       1 request.go:700] Waited for 3.191870477s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T14:10:23.938358431Z I1024 14:10:23.938263       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-15-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-apiserver because it was missing
2024-10-24T14:10:24.523533519Z I1024 14:10:24.523430       1 request.go:700] Waited for 3.193783028s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-14
2024-10-24T14:10:24.933841027Z I1024 14:10:24.932864       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-16 -n openshift-kube-apiserver because it was missing
2024-10-24T14:10:25.523656235Z I1024 14:10:25.523564       1 request.go:700] Waited for 3.193907388s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:10:26.723219770Z I1024 14:10:26.723135       1 request.go:700] Waited for 3.191759107s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T14:10:27.723295316Z I1024 14:10:27.723207       1 request.go:700] Waited for 3.193975377s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:10:28.137708815Z I1024 14:10:28.137649       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-16 -n openshift-kube-apiserver because it was missing
2024-10-24T14:10:28.923009662Z I1024 14:10:28.922942       1 request.go:700] Waited for 3.193682998s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-config-openshift-kube-apiserver
2024-10-24T14:10:30.122920927Z I1024 14:10:30.122850       1 request.go:700] Waited for 3.190513698s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:10:30.335836496Z I1024 14:10:30.335709       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-15-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-apiserver because it was missing
2024-10-24T14:10:31.323071172Z I1024 14:10:31.322992       1 request.go:700] Waited for 3.185558458s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T14:10:31.334548452Z I1024 14:10:31.334491       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-16 -n openshift-kube-apiserver because it was missing
2024-10-24T14:10:32.323123319Z I1024 14:10:32.323063       1 request.go:700] Waited for 3.192043138s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:10:33.523210834Z I1024 14:10:33.523122       1 request.go:700] Waited for 3.186788078s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-15-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:10:34.523421450Z I1024 14:10:34.523306       1 request.go:700] Waited for 3.189039447s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T14:10:34.536719000Z I1024 14:10:34.534076       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-16 -n openshift-kube-apiserver because it was missing
2024-10-24T14:10:34.729921349Z I1024 14:10:34.729865       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 14 is the oldest and needs new revision 15
2024-10-24T14:10:34.730075269Z I1024 14:10:34.730046       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T14:10:34.730075269Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T14:10:34.730075269Z  CurrentRevision: (int32) 14,
2024-10-24T14:10:34.730075269Z  TargetRevision: (int32) 15,
2024-10-24T14:10:34.730075269Z  LastFailedRevision: (int32) 10,
2024-10-24T14:10:34.730075269Z  LastFailedTime: (*v1.Time)(0xc002db37d0)(2024-10-24 13:30:03 +0000 UTC),
2024-10-24T14:10:34.730075269Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T14:10:34.730075269Z  LastFailedCount: (int) 1,
2024-10-24T14:10:34.730075269Z  LastFallbackCount: (int) 0,
2024-10-24T14:10:34.730075269Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T14:10:34.730075269Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T14:10:34.730075269Z  }
2024-10-24T14:10:34.730075269Z }
2024-10-24T14:10:34.731966949Z W1024 14:10:34.731918       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:10:34.731966949Z W1024 14:10:34.731938       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:10:34.731966949Z W1024 14:10:34.731945       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:10:34.731966949Z W1024 14:10:34.731951       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:10:34.731966949Z W1024 14:10:34.731956       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T14:10:34.731966949Z W1024 14:10:34.731960       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T14:10:34.764921309Z I1024 14:10:34.764837       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 14 to 15 because node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 14 is the oldest
2024-10-24T14:10:34.768989579Z I1024 14:10:34.768951       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T14:10:34Z","message":"NodeInstallerProgressing: 3 nodes are at revision 14; 0 nodes have achieved new revision 15","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 14; 0 nodes have achieved new revision 15","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T14:10:34.788295709Z I1024 14:10:34.788220       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing changed from False to True ("NodeInstallerProgressing: 3 nodes are at revision 14; 0 nodes have achieved new revision 15"),Available message changed from "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 14" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 14; 0 nodes have achieved new revision 15"
2024-10-24T14:10:35.722802745Z I1024 14:10:35.722692       1 request.go:700] Waited for 3.189872107s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-14
2024-10-24T14:10:36.723337931Z I1024 14:10:36.723260       1 request.go:700] Waited for 3.194064977s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-15-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:10:37.737405537Z I1024 14:10:37.737354       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-16 -n openshift-kube-apiserver because it was missing
2024-10-24T14:10:37.923236257Z I1024 14:10:37.923169       1 request.go:700] Waited for 3.158164038s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:10:38.923611713Z I1024 14:10:38.923556       1 request.go:700] Waited for 3.391885677s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:10:40.123717158Z I1024 14:10:40.123633       1 request.go:700] Waited for 3.393568648s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-15-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:10:41.132279484Z I1024 14:10:41.132116       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-16 -n openshift-kube-apiserver because it was missing
2024-10-24T14:10:41.322646404Z I1024 14:10:41.322534       1 request.go:700] Waited for 3.390887956s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:10:42.322632310Z I1024 14:10:42.322546       1 request.go:700] Waited for 3.390815357s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:10:43.323592456Z I1024 14:10:43.323494       1 request.go:700] Waited for 2.993029878s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:10:44.136973352Z I1024 14:10:44.136905       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-16 -n openshift-kube-apiserver because it was missing
2024-10-24T14:10:44.323625732Z I1024 14:10:44.323563       1 request.go:700] Waited for 2.994720109s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:10:45.523597277Z I1024 14:10:45.523523       1 request.go:700] Waited for 2.729094969s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:10:46.723321692Z I1024 14:10:46.723211       1 request.go:700] Waited for 2.790024919s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-10-24T14:10:46.936444691Z I1024 14:10:46.936352       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/encryption-config-16 -n openshift-kube-apiserver because it was missing
2024-10-24T14:10:47.923219458Z I1024 14:10:47.923106       1 request.go:700] Waited for 2.992812728s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-14
2024-10-24T14:10:48.923209304Z I1024 14:10:48.923126       1 request.go:700] Waited for 3.186567258s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:10:49.923518500Z I1024 14:10:49.923423       1 request.go:700] Waited for 3.190971948s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-10-24T14:10:50.135711919Z I1024 14:10:50.135625       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-16 -n openshift-kube-apiserver because it was missing
2024-10-24T14:10:51.123451605Z I1024 14:10:51.123366       1 request.go:700] Waited for 2.59506049s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:10:52.323229790Z I1024 14:10:52.323152       1 request.go:700] Waited for 2.581475389s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-14
2024-10-24T14:10:52.738892829Z I1024 14:10:52.736963       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-16 -n openshift-kube-apiserver because it was missing
2024-10-24T14:10:53.323528266Z I1024 14:10:53.323450       1 request.go:700] Waited for 2.592193191s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:10:54.323562472Z I1024 14:10:54.323468       1 request.go:700] Waited for 2.593008969s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-15-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:10:55.333482349Z I1024 14:10:55.333395       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-16 -n openshift-kube-apiserver because it was missing
2024-10-24T14:10:55.522702778Z I1024 14:10:55.522595       1 request.go:700] Waited for 2.5930518s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:10:56.522771844Z I1024 14:10:56.522664       1 request.go:700] Waited for 2.71726658s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:10:57.523079330Z I1024 14:10:57.523008       1 request.go:700] Waited for 2.58468561s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:10:57.934123999Z I1024 14:10:57.934046       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 16 triggered by "required configmap/config has changed"
2024-10-24T14:10:57.934916468Z W1024 14:10:57.934856       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:10:57.934916468Z W1024 14:10:57.934887       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:10:57.966403988Z W1024 14:10:57.966327       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:10:57.966403988Z W1024 14:10:57.966364       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:10:58.723524445Z I1024 14:10:58.723430       1 request.go:700] Waited for 2.593451911s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-14
2024-10-24T14:10:59.723536602Z I1024 14:10:59.723461       1 request.go:700] Waited for 2.192701412s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-14
2024-10-24T14:11:00.723644318Z I1024 14:11:00.723564       1 request.go:700] Waited for 2.7530953s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:11:00.930878237Z I1024 14:11:00.930800       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 14 is the oldest and needs new revision 15
2024-10-24T14:11:00.930958367Z I1024 14:11:00.930905       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T14:11:00.930958367Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T14:11:00.930958367Z  CurrentRevision: (int32) 14,
2024-10-24T14:11:00.930958367Z  TargetRevision: (int32) 15,
2024-10-24T14:11:00.930958367Z  LastFailedRevision: (int32) 10,
2024-10-24T14:11:00.930958367Z  LastFailedTime: (*v1.Time)(0xc000f26d38)(2024-10-24 13:30:03 +0000 UTC),
2024-10-24T14:11:00.930958367Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T14:11:00.930958367Z  LastFailedCount: (int) 1,
2024-10-24T14:11:00.930958367Z  LastFallbackCount: (int) 0,
2024-10-24T14:11:00.930958367Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T14:11:00.930958367Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T14:11:00.930958367Z  }
2024-10-24T14:11:00.930958367Z }
2024-10-24T14:11:00.933980867Z I1024 14:11:00.933859       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 14 to 15 because node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 14 is the oldest
2024-10-24T14:11:01.923713264Z I1024 14:11:01.923613       1 request.go:700] Waited for 2.72543662s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:11:03.123566089Z I1024 14:11:03.123431       1 request.go:700] Waited for 2.792404959s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-15-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:11:04.323226944Z I1024 14:11:04.323134       1 request.go:700] Waited for 2.59385471s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:11:05.323566050Z I1024 14:11:05.323490       1 request.go:700] Waited for 2.192940852s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-15-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:11:06.523330666Z I1024 14:11:06.523226       1 request.go:700] Waited for 2.393547471s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:11:07.723272771Z I1024 14:11:07.723194       1 request.go:700] Waited for 2.392036771s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-16-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:11:08.923138536Z I1024 14:11:08.923015       1 request.go:700] Waited for 1.932668662s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:11:09.750983763Z I1024 14:11:09.750899       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-16-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-apiserver because it was missing
2024-10-24T14:11:10.123572892Z I1024 14:11:10.123500       1 request.go:700] Waited for 1.994049392s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:11:11.323232537Z I1024 14:11:11.323155       1 request.go:700] Waited for 1.572282304s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-16-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:11:12.328304583Z I1024 14:11:12.328244       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T14:11:12.328304583Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T14:11:12.328304583Z  CurrentRevision: (int32) 14,
2024-10-24T14:11:12.328304583Z  TargetRevision: (int32) 16,
2024-10-24T14:11:12.328304583Z  LastFailedRevision: (int32) 10,
2024-10-24T14:11:12.328304583Z  LastFailedTime: (*v1.Time)(0xc007742a80)(2024-10-24 13:30:03 +0000 UTC),
2024-10-24T14:11:12.328304583Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T14:11:12.328304583Z  LastFailedCount: (int) 1,
2024-10-24T14:11:12.328304583Z  LastFallbackCount: (int) 0,
2024-10-24T14:11:12.328304583Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T14:11:12.328304583Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T14:11:12.328304583Z  }
2024-10-24T14:11:12.328304583Z }
2024-10-24T14:11:12.328304583Z  because new revision pending
2024-10-24T14:11:12.330812463Z W1024 14:11:12.330774       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:11:12.330812463Z W1024 14:11:12.330796       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:11:12.330812463Z W1024 14:11:12.330803       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:11:12.330812463Z W1024 14:11:12.330808       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:11:12.330850273Z W1024 14:11:12.330813       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T14:11:12.330850273Z W1024 14:11:12.330817       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T14:11:12.371863393Z I1024 14:11:12.371792       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T14:10:34Z","message":"NodeInstallerProgressing: 3 nodes are at revision 14; 0 nodes have achieved new revision 16","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 14; 0 nodes have achieved new revision 16","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T14:11:12.393669783Z I1024 14:11:12.393585       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 14; 0 nodes have achieved new revision 15" to "NodeInstallerProgressing: 3 nodes are at revision 14; 0 nodes have achieved new revision 16",Available message changed from "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 14; 0 nodes have achieved new revision 15" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 14; 0 nodes have achieved new revision 16"
2024-10-24T14:11:12.523079423Z I1024 14:11:12.523006       1 request.go:700] Waited for 2.39180106s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:11:13.722975598Z I1024 14:11:13.722913       1 request.go:700] Waited for 2.393422361s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods
2024-10-24T14:11:13.739102218Z I1024 14:11:13.739044       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-16-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-apiserver because it was missing
2024-10-24T14:11:14.923014573Z I1024 14:11:14.922943       1 request.go:700] Waited for 2.55242842s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T14:11:15.473591241Z I1024 14:11:15.473477       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2024-10-24T14:11:15.923221389Z I1024 14:11:15.923140       1 request.go:700] Waited for 3.192923848s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:11:17.123563984Z I1024 14:11:17.123480       1 request.go:700] Waited for 3.189587237s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:11:18.123654990Z I1024 14:11:18.123570       1 request.go:700] Waited for 3.185536037s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T14:11:19.322762466Z I1024 14:11:19.322681       1 request.go:700] Waited for 3.193450758s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-14
2024-10-24T14:11:20.137721082Z I1024 14:11:20.137643       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-16-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-apiserver because it was missing
2024-10-24T14:11:20.522979351Z I1024 14:11:20.522916       1 request.go:700] Waited for 3.191878407s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:11:21.523027837Z I1024 14:11:21.522941       1 request.go:700] Waited for 2.59199894s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:11:22.523673103Z I1024 14:11:22.523601       1 request.go:700] Waited for 2.592945s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T14:11:23.723103828Z I1024 14:11:23.723007       1 request.go:700] Waited for 2.58902882s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-15-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:11:24.723638995Z I1024 14:11:24.723566       1 request.go:700] Waited for 2.592373919s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:11:25.923354930Z I1024 14:11:25.923290       1 request.go:700] Waited for 2.59372485s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:11:26.328386368Z I1024 14:11:26.328325       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T14:11:26.328386368Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T14:11:26.328386368Z  CurrentRevision: (int32) 14,
2024-10-24T14:11:26.328386368Z  TargetRevision: (int32) 16,
2024-10-24T14:11:26.328386368Z  LastFailedRevision: (int32) 10,
2024-10-24T14:11:26.328386368Z  LastFailedTime: (*v1.Time)(0xc00244f008)(2024-10-24 13:30:03 +0000 UTC),
2024-10-24T14:11:26.328386368Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T14:11:26.328386368Z  LastFailedCount: (int) 1,
2024-10-24T14:11:26.328386368Z  LastFallbackCount: (int) 0,
2024-10-24T14:11:26.328386368Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T14:11:26.328386368Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T14:11:26.328386368Z  }
2024-10-24T14:11:26.328386368Z }
2024-10-24T14:11:26.328386368Z  because new revision pending
2024-10-24T14:11:27.123576935Z I1024 14:11:27.123433       1 request.go:700] Waited for 2.793412269s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:11:28.123540561Z I1024 14:11:28.123474       1 request.go:700] Waited for 2.792854239s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-16-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:11:29.323091797Z I1024 14:11:29.323027       1 request.go:700] Waited for 2.520121351s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:11:30.522889982Z I1024 14:11:30.522812       1 request.go:700] Waited for 1.991224182s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-14
2024-10-24T14:11:31.522970608Z I1024 14:11:31.522882       1 request.go:700] Waited for 1.790833033s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:11:32.723428763Z I1024 14:11:32.723290       1 request.go:700] Waited for 1.793497933s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:11:33.723448749Z I1024 14:11:33.723382       1 request.go:700] Waited for 1.794051692s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:11:34.942800405Z I1024 14:11:34.942721       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-16-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-apiserver because it was missing
2024-10-24T14:11:35.328985154Z I1024 14:11:35.328904       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 16, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T14:11:36.122992440Z I1024 14:11:36.122929       1 request.go:700] Waited for 1.181412766s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:11:37.123372906Z I1024 14:11:37.123302       1 request.go:700] Waited for 1.994600972s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:11:38.323129212Z I1024 14:11:38.323047       1 request.go:700] Waited for 1.992204972s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-14
2024-10-24T14:11:39.522983027Z I1024 14:11:39.522905       1 request.go:700] Waited for 1.988394282s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:11:40.523667173Z I1024 14:11:40.523588       1 request.go:700] Waited for 1.991982252s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:11:41.722670458Z I1024 14:11:41.722591       1 request.go:700] Waited for 1.593662824s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:11:42.723256875Z I1024 14:11:42.723172       1 request.go:700] Waited for 1.593015424s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:11:43.723312271Z I1024 14:11:43.723242       1 request.go:700] Waited for 1.593496133s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:11:44.528967248Z I1024 14:11:44.528894       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 16, but has not made progress because installer is not finished, but in Running phase
2024-10-24T14:11:44.923415476Z I1024 14:11:44.923325       1 request.go:700] Waited for 1.591887984s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-14
2024-10-24T14:11:46.122977631Z I1024 14:11:46.122846       1 request.go:700] Waited for 1.993633222s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:11:47.323600547Z I1024 14:11:47.323547       1 request.go:700] Waited for 2.3944992s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:11:48.523656572Z I1024 14:11:48.523585       1 request.go:700] Waited for 2.385677311s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:11:49.723414077Z I1024 14:11:49.723331       1 request.go:700] Waited for 1.993021912s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:11:50.922721632Z I1024 14:11:50.922655       1 request.go:700] Waited for 1.991278442s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:11:51.922958338Z I1024 14:11:51.922854       1 request.go:700] Waited for 1.993476363s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:11:52.923685875Z I1024 14:11:52.923606       1 request.go:700] Waited for 1.993782043s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-16-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:11:54.123612000Z I1024 14:11:54.123539       1 request.go:700] Waited for 1.194179775s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-16-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:11:54.129734090Z I1024 14:11:54.129631       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 16, but has not made progress because installer is not finished, but in Running phase
2024-10-24T14:11:55.323622925Z I1024 14:11:55.323528       1 request.go:700] Waited for 1.394340244s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:12:13.489145494Z I1024 14:12:13.489056       1 termination_observer.go:236] Observed event "TerminationPreShutdownHooksFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0" (last termination at 2024-10-24 14:01:18 +0000 UTC) at 2024-10-24 14:12:13 +0000 UTC
2024-10-24T14:12:14.883146979Z I1024 14:12:14.882985       1 request.go:700] Waited for 1.186913495s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-14
2024-10-24T14:12:15.883257286Z I1024 14:12:15.883173       1 request.go:700] Waited for 1.793041983s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:12:17.082537821Z I1024 14:12:17.082375       1 request.go:700] Waited for 2.120701152s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:12:18.083162737Z I1024 14:12:18.083078       1 request.go:700] Waited for 1.995070172s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:12:19.283187863Z I1024 14:12:19.283129       1 request.go:700] Waited for 1.592827144s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:12:20.482477567Z I1024 14:12:20.482392       1 request.go:700] Waited for 1.590443233s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:12:21.088627295Z I1024 14:12:21.088567       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 16, but has not made progress because waiting for static pod of revision 16, found 14
2024-10-24T14:12:21.483099874Z I1024 14:12:21.482920       1 request.go:700] Waited for 1.593718574s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:12:22.683054299Z I1024 14:12:22.682967       1 request.go:700] Waited for 1.393903045s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:12:25.887930297Z I1024 14:12:25.887862       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 16, but has not made progress because waiting for static pod of revision 16, found 14
2024-10-24T14:12:26.882996193Z I1024 14:12:26.882929       1 request.go:700] Waited for 1.113854166s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:12:28.083083768Z I1024 14:12:28.083011       1 request.go:700] Waited for 1.990517842s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:12:29.283047084Z I1024 14:12:29.282962       1 request.go:700] Waited for 1.593643404s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-14
2024-10-24T14:12:30.482515179Z I1024 14:12:30.482453       1 request.go:700] Waited for 1.593214294s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:12:31.482882635Z I1024 14:12:31.482817       1 request.go:700] Waited for 1.192098895s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:12:32.888668540Z I1024 14:12:32.888576       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 16, but has not made progress because waiting for static pod of revision 16, found 14
2024-10-24T14:12:46.212529038Z I1024 14:12:46.212467       1 request.go:700] Waited for 1.145139966s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:12:47.212694144Z I1024 14:12:47.212613       1 request.go:700] Waited for 1.358343645s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T14:12:48.412526559Z I1024 14:12:48.412450       1 request.go:700] Waited for 1.392580735s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:12:49.413187065Z I1024 14:12:49.413095       1 request.go:700] Waited for 1.195040765s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:13:07.495879895Z I1024 14:13:07.495789       1 request.go:700] Waited for 1.051479596s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:13:08.695459181Z I1024 14:13:08.695380       1 request.go:700] Waited for 1.385637825s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:13:09.895565816Z I1024 14:13:09.895495       1 request.go:700] Waited for 1.393120205s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:13:10.895784282Z I1024 14:13:10.895698       1 request.go:700] Waited for 1.391719235s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-14
2024-10-24T14:13:12.095151347Z I1024 14:13:12.095056       1 request.go:700] Waited for 1.393843454s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:13:13.095339523Z I1024 14:13:13.095278       1 request.go:700] Waited for 1.313003565s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T14:13:14.095648480Z I1024 14:13:14.095559       1 request.go:700] Waited for 1.392896555s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:13:15.295519005Z I1024 14:13:15.295413       1 request.go:700] Waited for 1.391399214s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-10-24T14:13:25.467299406Z I1024 14:13:25.467220       1 termination_observer.go:236] Observed event "TerminationGracefulTerminationFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0" (last termination at 2024-10-24 14:01:18 +0000 UTC) at 2024-10-24 14:13:25 +0000 UTC
2024-10-24T14:13:32.741642498Z I1024 14:13:32.741567       1 request.go:700] Waited for 1.165948785s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-14
2024-10-24T14:13:33.940837443Z I1024 14:13:33.940777       1 request.go:700] Waited for 1.792003193s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:13:34.940943499Z I1024 14:13:34.940868       1 request.go:700] Waited for 1.792194613s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-10-24T14:13:35.941900586Z I1024 14:13:35.941820       1 request.go:700] Waited for 2.125791272s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:13:37.141302851Z I1024 14:13:37.141233       1 request.go:700] Waited for 1.988366012s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:13:37.350373450Z I1024 14:13:37.350278       1 termination_observer.go:130] Observed termination of API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0" at 2024-10-24 14:13:35 +0000 UTC
2024-10-24T14:13:38.141853667Z I1024 14:13:38.141702       1 request.go:700] Waited for 2.59228056s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:13:39.340904352Z I1024 14:13:39.340800       1 request.go:700] Waited for 2.791803s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:13:40.341516908Z I1024 14:13:40.341446       1 request.go:700] Waited for 2.79043372s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:13:41.341878445Z I1024 14:13:41.341821       1 request.go:700] Waited for 2.783806639s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:13:41.547376234Z I1024 14:13:41.547299       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 16, but has not made progress because static pod is pending
2024-10-24T14:13:42.540999000Z I1024 14:13:42.540912       1 request.go:700] Waited for 2.785566349s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:13:43.541472996Z I1024 14:13:43.541397       1 request.go:700] Waited for 2.769674579s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T14:13:44.740973412Z I1024 14:13:44.740907       1 request.go:700] Waited for 2.38990814s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:13:45.740981588Z I1024 14:13:45.740918       1 request.go:700] Waited for 1.924307933s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:13:46.741805714Z I1024 14:13:46.741720       1 request.go:700] Waited for 1.684821814s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:13:47.741993600Z I1024 14:13:47.741916       1 request.go:700] Waited for 2.52923158s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:13:48.941740245Z I1024 14:13:48.941670       1 request.go:700] Waited for 2.384493101s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:13:50.141030831Z I1024 14:13:50.140944       1 request.go:700] Waited for 2.304705841s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T14:13:51.141581167Z I1024 14:13:51.141436       1 request.go:700] Waited for 2.394139431s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-10-24T14:13:52.946184000Z I1024 14:13:52.946109       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 16, but has not made progress because static pod is pending
2024-10-24T14:13:53.341017918Z I1024 14:13:53.340964       1 request.go:700] Waited for 1.087886625s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:13:54.341806455Z I1024 14:13:54.341681       1 request.go:700] Waited for 1.593519064s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:13:54.806308563Z I1024 14:13:54.806242       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX
2024-10-24T14:13:55.541911140Z I1024 14:13:55.541824       1 request.go:700] Waited for 1.592209754s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:13:56.741357705Z I1024 14:13:56.741280       1 request.go:700] Waited for 1.495958074s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:13:57.941228521Z I1024 14:13:57.941149       1 request.go:700] Waited for 2.69065796s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:13:58.941641057Z I1024 14:13:58.941555       1 request.go:700] Waited for 2.992323058s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:14:01.749701856Z I1024 14:14:01.749614       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T14:14:01.749701856Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T14:14:01.749701856Z  CurrentRevision: (int32) 16,
2024-10-24T14:14:01.749701856Z  TargetRevision: (int32) 0,
2024-10-24T14:14:01.749701856Z  LastFailedRevision: (int32) 10,
2024-10-24T14:14:01.749701856Z  LastFailedTime: (*v1.Time)(0xc006897a28)(2024-10-24 13:30:03 +0000 UTC),
2024-10-24T14:14:01.749701856Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T14:14:01.749701856Z  LastFailedCount: (int) 1,
2024-10-24T14:14:01.749701856Z  LastFallbackCount: (int) 0,
2024-10-24T14:14:01.749701856Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T14:14:01.749701856Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T14:14:01.749701856Z  }
2024-10-24T14:14:01.749701856Z }
2024-10-24T14:14:01.749701856Z  because static pod is ready
2024-10-24T14:14:01.751523286Z W1024 14:14:01.751474       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:14:01.751523286Z W1024 14:14:01.751494       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:14:01.751523286Z W1024 14:14:01.751499       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:14:01.751523286Z W1024 14:14:01.751503       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:14:01.751523286Z W1024 14:14:01.751506       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T14:14:01.751523286Z W1024 14:14:01.751509       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T14:14:01.786057836Z I1024 14:14:01.785947       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 14 to 16 because static pod is ready
2024-10-24T14:14:01.795691835Z I1024 14:14:01.795614       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T14:10:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 14; 1 node is at revision 16","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 14; 1 node is at revision 16","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T14:14:01.819263485Z I1024 14:14:01.815034       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 14; 0 nodes have achieved new revision 16" to "NodeInstallerProgressing: 2 nodes are at revision 14; 1 node is at revision 16",Available message changed from "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 14; 0 nodes have achieved new revision 16" to "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 14; 1 node is at revision 16"
2024-10-24T14:14:02.941310571Z I1024 14:14:02.941241       1 request.go:700] Waited for 1.148881815s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:14:03.941470927Z I1024 14:14:03.941403       1 request.go:700] Waited for 2.145253191s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:14:05.140962563Z I1024 14:14:05.140882       1 request.go:700] Waited for 2.79240426s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:14:06.141858289Z I1024 14:14:06.141744       1 request.go:700] Waited for 2.791698009s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:14:07.341203804Z I1024 14:14:07.341106       1 request.go:700] Waited for 2.785589789s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:14:08.341701391Z I1024 14:14:08.341589       1 request.go:700] Waited for 2.393440731s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-16-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:14:11.741432797Z I1024 14:14:11.741338       1 request.go:700] Waited for 1.152185346s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:14:26.272164061Z I1024 14:14:26.272097       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-1 with revision 14 is the oldest and needs new revision 16
2024-10-24T14:14:26.272313401Z I1024 14:14:26.272272       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T14:14:26.272313401Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T14:14:26.272313401Z  CurrentRevision: (int32) 14,
2024-10-24T14:14:26.272313401Z  TargetRevision: (int32) 16,
2024-10-24T14:14:26.272313401Z  LastFailedRevision: (int32) 0,
2024-10-24T14:14:26.272313401Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T14:14:26.272313401Z  LastFailedReason: (string) "",
2024-10-24T14:14:26.272313401Z  LastFailedCount: (int) 0,
2024-10-24T14:14:26.272313401Z  LastFallbackCount: (int) 0,
2024-10-24T14:14:26.272313401Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T14:14:26.272313401Z }
2024-10-24T14:14:26.274948541Z W1024 14:14:26.274913       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:14:26.274948541Z W1024 14:14:26.274935       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:14:26.274948541Z W1024 14:14:26.274942       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:14:26.274984781Z W1024 14:14:26.274947       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:14:26.274984781Z W1024 14:14:26.274954       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T14:14:26.274984781Z W1024 14:14:26.274959       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T14:14:26.310903121Z I1024 14:14:26.310826       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 14 to 16 because node ci-op-2fcpj5j6-f6035-2lklf-master-1 with revision 14 is the oldest
2024-10-24T14:14:27.465053226Z I1024 14:14:27.464982       1 request.go:700] Waited for 1.144038406s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:14:28.664923632Z I1024 14:14:28.664731       1 request.go:700] Waited for 2.326848721s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:14:29.665519238Z I1024 14:14:29.665420       1 request.go:700] Waited for 2.59331408s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:14:30.864426053Z I1024 14:14:30.864356       1 request.go:700] Waited for 2.58939881s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:14:31.864865350Z I1024 14:14:31.864689       1 request.go:700] Waited for 2.137327982s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:14:32.865164675Z I1024 14:14:32.865105       1 request.go:700] Waited for 1.192309956s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-16-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:14:33.865235792Z I1024 14:14:33.865169       1 request.go:700] Waited for 1.193329806s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-10-24T14:14:34.138016931Z I1024 14:14:34.137923       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-16-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-apiserver because it was missing
2024-10-24T14:14:35.065103667Z I1024 14:14:35.065032       1 request.go:700] Waited for 1.245791465s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:14:35.472728775Z I1024 14:14:35.472678       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 16, but has not made progress because installer is not finished, but in Running phase
2024-10-24T14:14:36.065218603Z I1024 14:14:36.065129       1 request.go:700] Waited for 1.930420272s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:14:37.264913868Z I1024 14:14:37.264823       1 request.go:700] Waited for 2.793427649s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-16-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:14:38.265433885Z I1024 14:14:38.265367       1 request.go:700] Waited for 2.58831355s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:14:39.464838820Z I1024 14:14:39.464767       1 request.go:700] Waited for 2.59055928s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:14:42.473253369Z I1024 14:14:42.473178       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 16, but has not made progress because installer is not finished, but in Running phase
2024-10-24T14:14:46.064930495Z I1024 14:14:46.064879       1 request.go:700] Waited for 1.007073316s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:14:47.064989941Z I1024 14:14:47.064922       1 request.go:700] Waited for 1.790349233s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-10-24T14:15:12.797234212Z I1024 14:15:12.797128       1 termination_observer.go:236] Observed event "TerminationPreShutdownHooksFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1" (last termination at 2024-10-24 14:04:30 +0000 UTC) at 2024-10-24 14:15:12 +0000 UTC
2024-10-24T14:15:16.087386909Z I1024 14:15:16.087320       1 request.go:700] Waited for 1.119459015s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:15:17.287084734Z I1024 14:15:17.287014       1 request.go:700] Waited for 1.994547873s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:15:18.093452782Z I1024 14:15:18.093360       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 16, but has not made progress because waiting for static pod of revision 16, found 14
2024-10-24T14:15:20.694049691Z I1024 14:15:20.693979       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 16, but has not made progress because waiting for static pod of revision 16, found 14
2024-10-24T14:15:23.887545199Z I1024 14:15:23.887453       1 request.go:700] Waited for 1.068286576s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T14:15:25.087609124Z I1024 14:15:25.087545       1 request.go:700] Waited for 1.993625253s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:15:27.293825366Z I1024 14:15:27.293712       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 16, but has not made progress because waiting for static pod of revision 16, found 14
2024-10-24T14:15:46.117356724Z I1024 14:15:46.117259       1 request.go:700] Waited for 1.059039346s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:15:47.317292509Z I1024 14:15:47.317202       1 request.go:700] Waited for 1.193216805s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:16:24.773939716Z I1024 14:16:24.773861       1 termination_observer.go:236] Observed event "TerminationGracefulTerminationFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1" (last termination at 2024-10-24 14:04:30 +0000 UTC) at 2024-10-24 14:16:24 +0000 UTC
2024-10-24T14:16:32.496020237Z I1024 14:16:32.495965       1 request.go:700] Waited for 1.183654796s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:16:32.702540086Z I1024 14:16:32.702448       1 termination_observer.go:130] Observed termination of API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1" at 2024-10-24 14:16:31 +0000 UTC
2024-10-24T14:16:33.500264843Z I1024 14:16:33.500211       1 request.go:700] Waited for 1.993203623s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:16:34.697488179Z I1024 14:16:34.697430       1 request.go:700] Waited for 1.994839363s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T14:16:35.895434104Z I1024 14:16:35.895333       1 request.go:700] Waited for 2.068190252s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:16:36.895934590Z I1024 14:16:36.895864       1 request.go:700] Waited for 2.183448311s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T14:16:37.896396376Z I1024 14:16:37.896284       1 request.go:700] Waited for 2.184103721s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-16-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:16:39.095503132Z I1024 14:16:39.095332       1 request.go:700] Waited for 1.274228205s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:16:39.905348588Z I1024 14:16:39.905200       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 16, but has not made progress because static pod is pending
2024-10-24T14:16:40.097142557Z I1024 14:16:40.096928       1 request.go:700] Waited for 1.982608303s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:16:42.495414869Z I1024 14:16:42.495287       1 request.go:700] Waited for 1.063337686s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:16:43.495663545Z I1024 14:16:43.495595       1 request.go:700] Waited for 1.990473322s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:16:44.695478620Z I1024 14:16:44.695391       1 request.go:700] Waited for 1.992991092s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:16:45.695988257Z I1024 14:16:45.695869       1 request.go:700] Waited for 2.066384622s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:16:46.895607132Z I1024 14:16:46.895526       1 request.go:700] Waited for 1.837082783s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:16:47.895694508Z I1024 14:16:47.895623       1 request.go:700] Waited for 2.58288378s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:16:49.102546203Z I1024 14:16:49.102476       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 16, but has not made progress because static pod is pending
2024-10-24T14:16:52.495712550Z I1024 14:16:52.495580       1 request.go:700] Waited for 1.091892296s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:16:53.496278896Z I1024 14:16:53.496188       1 request.go:700] Waited for 2.083023642s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:16:55.702845688Z I1024 14:16:55.702771       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T14:16:55.702845688Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T14:16:55.702845688Z  CurrentRevision: (int32) 16,
2024-10-24T14:16:55.702845688Z  TargetRevision: (int32) 0,
2024-10-24T14:16:55.702845688Z  LastFailedRevision: (int32) 0,
2024-10-24T14:16:55.702845688Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T14:16:55.702845688Z  LastFailedReason: (string) "",
2024-10-24T14:16:55.702845688Z  LastFailedCount: (int) 0,
2024-10-24T14:16:55.702845688Z  LastFallbackCount: (int) 0,
2024-10-24T14:16:55.702845688Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T14:16:55.702845688Z }
2024-10-24T14:16:55.702845688Z  because static pod is ready
2024-10-24T14:16:55.704780049Z W1024 14:16:55.704717       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:16:55.704780049Z W1024 14:16:55.704740       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:16:55.704812349Z W1024 14:16:55.704800       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:16:55.704812349Z W1024 14:16:55.704808       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:16:55.704824998Z W1024 14:16:55.704814       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T14:16:55.704824998Z W1024 14:16:55.704819       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T14:16:55.736501968Z I1024 14:16:55.736397       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 14 to 16 because static pod is ready
2024-10-24T14:16:55.740854328Z I1024 14:16:55.740796       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T14:10:34Z","message":"NodeInstallerProgressing: 1 node is at revision 14; 2 nodes are at revision 16","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 14; 2 nodes are at revision 16","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T14:16:55.769487088Z I1024 14:16:55.765664       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 14; 1 node is at revision 16" to "NodeInstallerProgressing: 1 node is at revision 14; 2 nodes are at revision 16",Available message changed from "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 14; 1 node is at revision 16" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 14; 2 nodes are at revision 16"
2024-10-24T14:16:56.895512364Z I1024 14:16:56.895405       1 request.go:700] Waited for 1.154344786s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:16:57.895926780Z I1024 14:16:57.895848       1 request.go:700] Waited for 2.153082872s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:16:59.096195245Z I1024 14:16:59.096115       1 request.go:700] Waited for 2.79316765s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:17:00.096209642Z I1024 14:17:00.096126       1 request.go:700] Waited for 2.79325888s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:17:01.295670477Z I1024 14:17:01.295603       1 request.go:700] Waited for 2.778745839s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:17:02.295876304Z I1024 14:17:02.295808       1 request.go:700] Waited for 1.793696414s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:17:03.296183470Z I1024 14:17:03.296098       1 request.go:700] Waited for 1.090588336s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T14:17:04.296260326Z I1024 14:17:04.296188       1 request.go:700] Waited for 1.191294905s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-16-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:17:05.496038772Z I1024 14:17:05.495969       1 request.go:700] Waited for 1.392856525s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:17:22.173912818Z I1024 14:17:22.173820       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-2 with revision 14 is the oldest and needs new revision 16
2024-10-24T14:17:22.173912818Z I1024 14:17:22.173884       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T14:17:22.173912818Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T14:17:22.173912818Z  CurrentRevision: (int32) 14,
2024-10-24T14:17:22.173912818Z  TargetRevision: (int32) 16,
2024-10-24T14:17:22.173912818Z  LastFailedRevision: (int32) 0,
2024-10-24T14:17:22.173912818Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T14:17:22.173912818Z  LastFailedReason: (string) "",
2024-10-24T14:17:22.173912818Z  LastFailedCount: (int) 0,
2024-10-24T14:17:22.173912818Z  LastFallbackCount: (int) 0,
2024-10-24T14:17:22.173912818Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T14:17:22.173912818Z }
2024-10-24T14:17:22.176097358Z W1024 14:17:22.176005       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:17:22.176097358Z W1024 14:17:22.176029       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:17:22.176097358Z W1024 14:17:22.176034       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:17:22.176097358Z W1024 14:17:22.176037       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:17:22.176097358Z W1024 14:17:22.176040       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T14:17:22.176097358Z W1024 14:17:22.176043       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T14:17:22.211172638Z I1024 14:17:22.211053       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 14 to 16 because node ci-op-2fcpj5j6-f6035-2lklf-master-2 with revision 14 is the oldest
2024-10-24T14:17:23.367038964Z I1024 14:17:23.366951       1 request.go:700] Waited for 1.150389906s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:17:24.367581080Z I1024 14:17:24.367505       1 request.go:700] Waited for 2.147879882s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-10-24T14:17:25.567351916Z I1024 14:17:25.567256       1 request.go:700] Waited for 2.592317251s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:17:26.767125852Z I1024 14:17:26.767065       1 request.go:700] Waited for 2.590786871s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:17:27.767481548Z I1024 14:17:27.767399       1 request.go:700] Waited for 2.324148762s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:17:30.003103759Z I1024 14:17:30.002998       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-16-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-apiserver because it was missing
2024-10-24T14:17:31.167022855Z I1024 14:17:31.166930       1 request.go:700] Waited for 1.164808806s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:17:32.367037250Z I1024 14:17:32.366970       1 request.go:700] Waited for 2.3639491s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-16-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:17:32.380546031Z I1024 14:17:32.380454       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 16, but has not made progress because installer is not finished, but in Running phase
2024-10-24T14:17:33.367111937Z I1024 14:17:33.367027       1 request.go:700] Waited for 2.391944392s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:17:34.367481852Z I1024 14:17:34.367413       1 request.go:700] Waited for 2.3925201s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:17:35.567161118Z I1024 14:17:35.567083       1 request.go:700] Waited for 2.188574701s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:17:36.567169415Z I1024 14:17:36.567091       1 request.go:700] Waited for 1.190636116s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:17:38.576210307Z I1024 14:17:38.576143       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 16, but has not made progress because installer is not finished, but in Running phase
2024-10-24T14:17:39.566922014Z I1024 14:17:39.566839       1 request.go:700] Waited for 1.186678676s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:18:08.603819537Z I1024 14:18:08.603721       1 termination_observer.go:236] Observed event "TerminationPreShutdownHooksFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2" (last termination at 2024-10-24 14:07:24 +0000 UTC) at 2024-10-24 14:18:08 +0000 UTC
2024-10-24T14:18:11.698050293Z I1024 14:18:11.697958       1 request.go:700] Waited for 1.114429334s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:18:12.698267360Z I1024 14:18:12.698181       1 request.go:700] Waited for 1.993670501s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:18:13.504301987Z I1024 14:18:13.504234       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 16, but has not made progress because waiting for static pod of revision 16, found 14
2024-10-24T14:18:16.303816415Z I1024 14:18:16.303695       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 16, but has not made progress because waiting for static pod of revision 16, found 14
2024-10-24T14:18:25.378048319Z I1024 14:18:25.377979       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 16, but has not made progress because waiting for static pod of revision 16, found 14
2024-10-24T14:19:20.570272482Z I1024 14:19:20.570108       1 termination_observer.go:236] Observed event "TerminationGracefulTerminationFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2" (last termination at 2024-10-24 14:07:24 +0000 UTC) at 2024-10-24 14:19:20 +0000 UTC
2024-10-24T14:19:21.891489167Z I1024 14:19:21.891405       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.140983606Z I1024 14:19:22.140922       1 reflector.go:368] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.183392286Z I1024 14:19:22.183307       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.297258325Z I1024 14:19:22.297182       1 reflector.go:368] Caches populated for *v1.OAuth from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.391517205Z I1024 14:19:22.390742       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.461003995Z I1024 14:19:22.460953       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.515711794Z I1024 14:19:22.515611       1 reflector.go:368] Caches populated for *v1.Proxy from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.671652104Z I1024 14:19:22.671091       1 reflector.go:368] Caches populated for *v1.Image from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.768874444Z I1024 14:19:22.768799       1 reflector.go:368] Caches populated for *v1.Authentication from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.885250613Z I1024 14:19:22.885189       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.934833723Z I1024 14:19:22.934694       1 reflector.go:368] Caches populated for monitoring.coreos.com/v1, Resource=prometheusrules from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.939554753Z I1024 14:19:22.939503       1 reflector.go:368] Caches populated for *v1alpha1.StorageVersionMigration from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:31.076003641Z I1024 14:19:31.075927       1 termination_observer.go:130] Observed termination of API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2" at 2024-10-24 14:19:30 +0000 UTC
2024-10-24T14:19:32.067769037Z I1024 14:19:32.067631       1 request.go:700] Waited for 1.181004935s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:19:33.267677353Z I1024 14:19:33.267611       1 request.go:700] Waited for 1.991059372s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:19:34.467228398Z I1024 14:19:34.467140       1 request.go:700] Waited for 1.985235012s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:19:35.467256304Z I1024 14:19:35.467149       1 request.go:700] Waited for 1.990688152s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:19:36.467444720Z I1024 14:19:36.467362       1 request.go:700] Waited for 2.182651862s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:19:37.467535526Z I1024 14:19:37.467455       1 request.go:700] Waited for 2.190946821s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:19:38.667716242Z I1024 14:19:38.667611       1 request.go:700] Waited for 1.990336733s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:19:39.867249097Z I1024 14:19:39.867136       1 request.go:700] Waited for 1.990952482s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:19:40.076358967Z I1024 14:19:40.076285       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 16, but has not made progress because static pod is pending
2024-10-24T14:19:41.067358162Z I1024 14:19:41.067283       1 request.go:700] Waited for 1.991840623s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:19:42.067679538Z I1024 14:19:42.067610       1 request.go:700] Waited for 1.988954431s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:19:43.267632164Z I1024 14:19:43.267546       1 request.go:700] Waited for 1.394915834s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:19:46.067915153Z I1024 14:19:46.067841       1 request.go:700] Waited for 1.007370335s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:19:47.267521498Z I1024 14:19:47.267424       1 request.go:700] Waited for 1.993537113s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:19:47.273801568Z I1024 14:19:47.273702       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 16, but has not made progress because static pod is pending
2024-10-24T14:19:52.067995618Z I1024 14:19:52.067892       1 request.go:700] Waited for 1.093607545s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:19:53.267900064Z I1024 14:19:53.267832       1 request.go:700] Waited for 1.791834233s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:19:54.467252309Z I1024 14:19:54.467172       1 request.go:700] Waited for 1.593872504s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:19:55.467625165Z I1024 14:19:55.467562       1 request.go:700] Waited for 1.628837504s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:20:20.042767969Z I1024 14:20:20.042661       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T14:20:20.042767969Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T14:20:20.042767969Z  CurrentRevision: (int32) 16,
2024-10-24T14:20:20.042767969Z  TargetRevision: (int32) 0,
2024-10-24T14:20:20.042767969Z  LastFailedRevision: (int32) 0,
2024-10-24T14:20:20.042767969Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T14:20:20.042767969Z  LastFailedReason: (string) "",
2024-10-24T14:20:20.042767969Z  LastFailedCount: (int) 0,
2024-10-24T14:20:20.042767969Z  LastFallbackCount: (int) 0,
2024-10-24T14:20:20.042767969Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T14:20:20.042767969Z }
2024-10-24T14:20:20.042767969Z  because static pod is ready
2024-10-24T14:20:20.044978709Z W1024 14:20:20.044898       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:20:20.044978709Z W1024 14:20:20.044928       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:20:20.044978709Z W1024 14:20:20.044936       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:20:20.044978709Z W1024 14:20:20.044943       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:20:20.044978709Z W1024 14:20:20.044948       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T14:20:20.074419499Z I1024 14:20:20.074341       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 14 to 16 because static pod is ready
2024-10-24T14:20:20.079168969Z I1024 14:20:20.079008       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T14:20:20Z","message":"NodeInstallerProgressing: 3 nodes are at revision 16","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 16","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T14:20:20.102211168Z I1024 14:20:20.102109       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing changed from True to False ("NodeInstallerProgressing: 3 nodes are at revision 16"),Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 14; 2 nodes are at revision 16" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 16"
2024-10-24T14:20:21.196322304Z I1024 14:20:21.196225       1 request.go:700] Waited for 1.115921935s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:20:22.196686630Z I1024 14:20:22.196595       1 request.go:700] Waited for 2.110042491s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:20:23.396820546Z I1024 14:20:23.396720       1 request.go:700] Waited for 2.59249764s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:20:24.596146821Z I1024 14:20:24.595999       1 request.go:700] Waited for 2.59294247s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:20:25.597063177Z I1024 14:20:25.596979       1 request.go:700] Waited for 2.191590631s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:20:26.796558963Z I1024 14:20:26.796474       1 request.go:700] Waited for 2.128204102s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:20:27.796806049Z I1024 14:20:27.796670       1 request.go:700] Waited for 2.191461962s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:20:28.996891434Z I1024 14:20:28.996795       1 request.go:700] Waited for 1.991889012s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:20:30.196553589Z I1024 14:20:30.196474       1 request.go:700] Waited for 1.991754842s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:20:31.396412765Z I1024 14:20:31.396301       1 request.go:700] Waited for 2.931236649s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:20:32.396795901Z I1024 14:20:32.396714       1 request.go:700] Waited for 2.993495968s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-10-24T14:20:33.397075567Z I1024 14:20:33.396987       1 request.go:700] Waited for 2.993124018s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-16-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:20:34.596630772Z I1024 14:20:34.596554       1 request.go:700] Waited for 2.991671399s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:20:35.796248468Z I1024 14:20:35.796183       1 request.go:700] Waited for 2.990422049s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:20:36.796608304Z I1024 14:20:36.796534       1 request.go:700] Waited for 2.393451141s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:20:37.797396850Z I1024 14:20:37.797314       1 request.go:700] Waited for 2.393972831s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2024-10-24T14:20:38.996859135Z I1024 14:20:38.996490       1 request.go:700] Waited for 2.193985441s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:20:39.996559101Z I1024 14:20:39.996489       1 request.go:700] Waited for 2.187782711s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-10-24T14:20:40.996620857Z I1024 14:20:40.996529       1 request.go:700] Waited for 2.192264001s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-16-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:20:42.197081573Z I1024 14:20:42.196991       1 request.go:700] Waited for 1.592592593s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:20:43.396569128Z I1024 14:20:43.396503       1 request.go:700] Waited for 1.193009616s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:20:44.996504082Z I1024 14:20:44.996435       1 request.go:700] Waited for 1.155787576s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:20:46.196666797Z I1024 14:20:46.196573       1 request.go:700] Waited for 1.136142625s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:20:47.396592442Z I1024 14:20:47.396509       1 request.go:700] Waited for 2.193522261s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:20:48.596654237Z I1024 14:20:48.596562       1 request.go:700] Waited for 2.192402001s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:20:49.597709383Z I1024 14:20:49.597645       1 request.go:700] Waited for 1.995114212s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2024-10-24T14:20:50.796848689Z I1024 14:20:50.796737       1 request.go:700] Waited for 1.991696743s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:20:51.996192024Z I1024 14:20:51.996084       1 request.go:700] Waited for 1.926051583s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:20:52.997083080Z I1024 14:20:52.996985       1 request.go:700] Waited for 1.390422895s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-10-24T14:21:15.474656543Z I1024 14:21:15.474554       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2024-10-24T14:21:46.076164204Z I1024 14:21:46.076047       1 request.go:700] Waited for 1.014747446s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:21:47.076719280Z I1024 14:21:47.076584       1 request.go:700] Waited for 1.792871893s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:21:48.276743156Z I1024 14:21:48.276649       1 request.go:700] Waited for 1.790967083s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:21:49.476364601Z I1024 14:21:49.476237       1 request.go:700] Waited for 1.591850234s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:21:50.476955727Z I1024 14:21:50.476869       1 request.go:700] Waited for 1.592411004s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-10-24T14:22:46.271411889Z I1024 14:22:46.271274       1 request.go:700] Waited for 1.197984756s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:22:47.470847364Z I1024 14:22:47.470649       1 request.go:700] Waited for 1.392603545s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:22:48.470955270Z I1024 14:22:48.470812       1 request.go:700] Waited for 1.392139815s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:23:07.457568107Z I1024 14:23:07.457484       1 request.go:700] Waited for 1.008264797s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:23:08.657217032Z I1024 14:23:08.657112       1 request.go:700] Waited for 1.103267186s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T14:23:09.857342897Z I1024 14:23:09.857268       1 request.go:700] Waited for 1.192826705s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:23:11.857473809Z I1024 14:23:11.857373       1 request.go:700] Waited for 1.001665166s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T14:23:13.057009315Z I1024 14:23:13.056921       1 request.go:700] Waited for 1.391137585s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:23:28.008030777Z I1024 14:23:28.007955       1 request.go:700] Waited for 1.006418126s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:23:29.192394042Z I1024 14:23:29.192290       1 request.go:700] Waited for 1.201841015s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:23:30.192861448Z I1024 14:23:30.192665       1 request.go:700] Waited for 1.986435712s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:23:31.392294884Z I1024 14:23:31.392224       1 request.go:700] Waited for 1.982519753s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:23:32.593160919Z I1024 14:23:32.592999       1 request.go:700] Waited for 1.993863732s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:23:33.795587944Z I1024 14:23:33.795504       1 request.go:700] Waited for 1.994359223s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-10-24T14:23:34.993343790Z I1024 14:23:34.993187       1 request.go:700] Waited for 1.900642403s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T14:23:36.192865685Z I1024 14:23:36.192670       1 request.go:700] Waited for 2.192174691s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:23:37.193120581Z I1024 14:23:37.193003       1 request.go:700] Waited for 2.192739761s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:23:38.392025167Z I1024 14:23:38.391936       1 request.go:700] Waited for 2.192348221s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:23:39.392513353Z I1024 14:23:39.392417       1 request.go:700] Waited for 2.128313141s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:23:40.393070929Z I1024 14:23:40.392997       1 request.go:700] Waited for 2.184654722s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T14:23:41.393132065Z I1024 14:23:41.393040       1 request.go:700] Waited for 2.191258342s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:23:42.592379900Z I1024 14:23:42.592307       1 request.go:700] Waited for 1.791418233s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-config-openshift-kube-apiserver
2024-10-24T14:23:43.592923366Z I1024 14:23:43.592839       1 request.go:700] Waited for 1.790241843s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:23:46.192405286Z I1024 14:23:46.192288       1 request.go:700] Waited for 1.129720136s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:23:47.392932522Z I1024 14:23:47.392858       1 request.go:700] Waited for 2.193704192s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:23:48.592649207Z I1024 14:23:48.592531       1 request.go:700] Waited for 2.38752595s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:23:49.592834203Z I1024 14:23:49.592717       1 request.go:700] Waited for 2.38130889s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:23:50.593038060Z I1024 14:23:50.592970       1 request.go:700] Waited for 2.391122711s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:23:51.792435165Z I1024 14:23:51.792364       1 request.go:700] Waited for 2.192033771s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:23:52.792518431Z I1024 14:23:52.792433       1 request.go:700] Waited for 1.988836662s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:23:53.792819917Z I1024 14:23:53.792723       1 request.go:700] Waited for 1.981798242s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:23:54.807804093Z I1024 14:23:54.806900       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX
2024-10-24T14:23:54.992899522Z I1024 14:23:54.992834       1 request.go:700] Waited for 2.594334069s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2024-10-24T14:23:55.993033008Z I1024 14:23:55.992963       1 request.go:700] Waited for 2.593513449s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:23:57.192975084Z I1024 14:23:57.192910       1 request.go:700] Waited for 2.58492738s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:23:58.392618899Z I1024 14:23:58.392545       1 request.go:700] Waited for 2.59184565s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:23:59.592125244Z I1024 14:23:59.592063       1 request.go:700] Waited for 2.38286483s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:24:00.592905621Z I1024 14:24:00.592836       1 request.go:700] Waited for 1.991958442s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:24:01.792608216Z I1024 14:24:01.792511       1 request.go:700] Waited for 1.393723795s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:24:02.793029472Z I1024 14:24:02.792949       1 request.go:700] Waited for 1.394430434s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-16-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:24:46.271837535Z I1024 14:24:46.271721       1 request.go:700] Waited for 1.193160525s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:24:47.471153910Z I1024 14:24:47.471077       1 request.go:700] Waited for 1.593342504s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:24:48.471240366Z I1024 14:24:48.471173       1 request.go:700] Waited for 1.593008714s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:24:49.471629933Z I1024 14:24:49.471536       1 request.go:700] Waited for 1.392428324s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:25:46.273110457Z I1024 14:25:46.273005       1 request.go:700] Waited for 1.193742386s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:25:47.472181343Z I1024 14:25:47.472044       1 request.go:700] Waited for 1.593130195s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:25:48.473008398Z I1024 14:25:48.472939       1 request.go:700] Waited for 1.593634895s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:25:49.672534514Z I1024 14:25:49.672445       1 request.go:700] Waited for 1.192233206s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-config-openshift-kube-apiserver
2024-10-24T14:26:07.185296920Z I1024 14:26:07.183867       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-10-24T14:26:07.185296920Z   	... // 4 identical entries
2024-10-24T14:26:07.185296920Z   	"imagePolicyConfig": map[string]any{"internalRegistryHostname": string("image-registry.openshift-image-registry.svc:5000")},
2024-10-24T14:26:07.185296920Z   	"servicesSubnet":    string("172.30.0.0/16"),
2024-10-24T14:26:07.185296920Z   	"servingInfo": map[string]any{
2024-10-24T14:26:07.185296920Z   		... // 2 identical entries
2024-10-24T14:26:07.185296920Z   		"cipherSuites":  []any{string("TLS_AES_128_GCM_SHA256"), string("TLS_AES_256_GCM_SHA384"), string("TLS_CHACHA20_POLY1305_SHA256"), string("TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"), ...},
2024-10-24T14:26:07.185296920Z   		"minTLSVersion": string("VersionTLS12"),
2024-10-24T14:26:07.185296920Z   		"namedCertificates": []any{
2024-10-24T14:26:07.185296920Z   			... // 3 identical elements
2024-10-24T14:26:07.185296920Z   			map[string]any{"certFile": string("/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-s"...), "keyFile": string("/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-s"...)},
2024-10-24T14:26:07.185296920Z   			map[string]any{"certFile": string("/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-"...), "keyFile": string("/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-"...)},
2024-10-24T14:26:07.185296920Z + 			map[string]any{
2024-10-24T14:26:07.185296920Z + 				"certFile": string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-000/tls.crt"),
2024-10-24T14:26:07.185296920Z + 				"keyFile":  string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-000/tls.key"),
2024-10-24T14:26:07.185296920Z + 			},
2024-10-24T14:26:07.185296920Z + 			map[string]any{
2024-10-24T14:26:07.185296920Z + 				"certFile": string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-001/tls.crt"),
2024-10-24T14:26:07.185296920Z + 				"keyFile":  string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-001/tls.key"),
2024-10-24T14:26:07.185296920Z + 			},
2024-10-24T14:26:07.185296920Z + 			map[string]any{
2024-10-24T14:26:07.185296920Z + 				"certFile": string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-002/tls.crt"),
2024-10-24T14:26:07.185296920Z + 				"keyFile":  string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-002/tls.key"),
2024-10-24T14:26:07.185296920Z + 			},
2024-10-24T14:26:07.185296920Z   		},
2024-10-24T14:26:07.185296920Z   	},
2024-10-24T14:26:07.185296920Z   }
2024-10-24T14:26:07.210422870Z I1024 14:26:07.210334       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/user-serving-cert-000 -n openshift-kube-apiserver because it was missing
2024-10-24T14:26:08.291476275Z I1024 14:26:08.291384       1 request.go:700] Waited for 1.081015166s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets
2024-10-24T14:26:08.302521075Z I1024 14:26:08.302448       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/user-serving-cert-002 -n openshift-kube-apiserver because it was missing
2024-10-24T14:26:09.491957271Z I1024 14:26:09.491881       1 request.go:700] Waited for 2.262995872s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T14:26:10.692051376Z I1024 14:26:10.691984       1 request.go:700] Waited for 2.792616799s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:26:11.113059364Z I1024 14:26:11.112989       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/user-serving-cert-001 -n openshift-kube-apiserver because it was missing
2024-10-24T14:26:11.138200044Z I1024 14:26:11.138112       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-10-24T14:26:11.138200044Z   	... // 4 identical entries
2024-10-24T14:26:11.138200044Z   	"imagePolicyConfig": map[string]any{"internalRegistryHostname": string("image-registry.openshift-image-registry.svc:5000")},
2024-10-24T14:26:11.138200044Z   	"servicesSubnet":    string("172.30.0.0/16"),
2024-10-24T14:26:11.138200044Z   	"servingInfo": map[string]any{
2024-10-24T14:26:11.138200044Z   		... // 2 identical entries
2024-10-24T14:26:11.138200044Z   		"cipherSuites":  []any{string("TLS_AES_128_GCM_SHA256"), string("TLS_AES_256_GCM_SHA384"), string("TLS_CHACHA20_POLY1305_SHA256"), string("TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"), ...},
2024-10-24T14:26:11.138200044Z   		"minTLSVersion": string("VersionTLS12"),
2024-10-24T14:26:11.138200044Z   		"namedCertificates": []any{
2024-10-24T14:26:11.138200044Z   			... // 3 identical elements
2024-10-24T14:26:11.138200044Z   			map[string]any{"certFile": string("/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-s"...), "keyFile": string("/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-s"...)},
2024-10-24T14:26:11.138200044Z   			map[string]any{"certFile": string("/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-"...), "keyFile": string("/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-"...)},
2024-10-24T14:26:11.138200044Z + 			map[string]any{
2024-10-24T14:26:11.138200044Z + 				"certFile": string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-000/tls.crt"),
2024-10-24T14:26:11.138200044Z + 				"keyFile":  string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-000/tls.key"),
2024-10-24T14:26:11.138200044Z + 			},
2024-10-24T14:26:11.138200044Z + 			map[string]any{
2024-10-24T14:26:11.138200044Z + 				"certFile": string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-001/tls.crt"),
2024-10-24T14:26:11.138200044Z + 				"keyFile":  string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-001/tls.key"),
2024-10-24T14:26:11.138200044Z + 			},
2024-10-24T14:26:11.138200044Z + 			map[string]any{
2024-10-24T14:26:11.138200044Z + 				"certFile": string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-002/tls.crt"),
2024-10-24T14:26:11.138200044Z + 				"keyFile":  string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-002/tls.key"),
2024-10-24T14:26:11.138200044Z + 			},
2024-10-24T14:26:11.138200044Z   		},
2024-10-24T14:26:11.138200044Z   	},
2024-10-24T14:26:11.138200044Z   }
2024-10-24T14:26:11.891804202Z I1024 14:26:11.891688       1 request.go:700] Waited for 2.789011089s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-10-24T14:26:13.091808647Z I1024 14:26:13.091712       1 request.go:700] Waited for 2.39340968s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:26:14.091809813Z I1024 14:26:14.091730       1 request.go:700] Waited for 2.193521761s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-10-24T14:26:15.092194279Z I1024 14:26:15.092104       1 request.go:700] Waited for 2.194349122s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:26:16.291534645Z I1024 14:26:16.291463       1 request.go:700] Waited for 2.192502312s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-10-24T14:26:17.292250721Z I1024 14:26:17.292162       1 request.go:700] Waited for 1.791834474s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:26:18.492007986Z I1024 14:26:18.491917       1 request.go:700] Waited for 1.726774093s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:26:19.691820542Z I1024 14:26:19.691720       1 request.go:700] Waited for 1.786005734s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:26:20.891840557Z I1024 14:26:20.891742       1 request.go:700] Waited for 1.791382693s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:26:22.907314310Z I1024 14:26:22.907238       1 core.go:352] ConfigMap "openshift-kube-apiserver/config" changes: {"apiVersion":"v1","data":{"config.yaml":"{\"admission\":{\"pluginConfig\":{\"PodSecurity\":{\"configuration\":{\"apiVersion\":\"pod-security.admission.config.k8s.io/v1\",\"defaults\":{\"audit\":\"restricted\",\"audit-version\":\"latest\",\"enforce\":\"restricted\",\"enforce-version\":\"latest\",\"warn\":\"restricted\",\"warn-version\":\"latest\"},\"exemptions\":{\"usernames\":[\"system:serviceaccount:openshift-infra:build-controller\"]},\"kind\":\"PodSecurityConfiguration\"}},\"network.openshift.io/ExternalIPRanger\":{\"configuration\":{\"allowIngressIP\":false,\"apiVersion\":\"network.openshift.io/v1\",\"externalIPNetworkCIDRs\":null,\"kind\":\"ExternalIPRangerAdmissionConfig\"},\"location\":\"\"},\"network.openshift.io/RestrictedEndpointsAdmission\":{\"configuration\":{\"apiVersion\":\"network.openshift.io/v1\",\"kind\":\"RestrictedEndpointsAdmissionConfig\",\"restrictedCIDRs\":[\"10.128.0.0/14\",\"172.30.0.0/16\"]}}}},\"apiServerArguments\":{\"allow-privileged\":[\"true\"],\"anonymous-auth\":[\"true\"],\"api-audiences\":[\"https://kubernetes.default.svc\"],\"audit-log-format\":[\"json\"],\"audit-log-maxbackup\":[\"10\"],\"audit-log-maxsize\":[\"200\"],\"audit-log-path\":[\"/var/log/kube-apiserver/audit.log\"],\"audit-policy-file\":[\"/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-audit-policies/policy.yaml\"],\"authentication-token-webhook-config-file\":[\"/etc/kubernetes/static-pod-resources/secrets/webhook-authenticator/kubeConfig\"],\"authentication-token-webhook-version\":[\"v1\"],\"authorization-mode\":[\"Scope\",\"SystemMasters\",\"RBAC\",\"Node\"],\"client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/client-ca/ca-bundle.crt\"],\"enable-admission-plugins\":[\"CertificateApproval\",\"CertificateSigning\",\"CertificateSubjectRestriction\",\"DefaultIngressClass\",\"DefaultStorageClass\",\"DefaultTolerationSeconds\",\"LimitRanger\",\"MutatingAdmissionWebhook\",\"NamespaceLifecycle\",\"NodeRestriction\",\"OwnerReferencesPermissionEnforcement\",\"PersistentVolumeClaimResize\",\"PodNodeSelector\",\"PodTolerationRestriction\",\"Priority\",\"ResourceQuota\",\"RuntimeClass\",\"ServiceAccount\",\"StorageObjectInUseProtection\",\"TaintNodesByCondition\",\"ValidatingAdmissionWebhook\",\"ValidatingAdmissionPolicy\",\"authorization.openshift.io/RestrictSubjectBindings\",\"authorization.openshift.io/ValidateRoleBindingRestriction\",\"config.openshift.io/DenyDeleteClusterConfiguration\",\"config.openshift.io/ValidateAPIServer\",\"config.openshift.io/ValidateAuthentication\",\"config.openshift.io/ValidateConsole\",\"config.openshift.io/ValidateFeatureGate\",\"config.openshift.io/ValidateImage\",\"config.openshift.io/ValidateOAuth\",\"config.openshift.io/ValidateProject\",\"config.openshift.io/ValidateScheduler\",\"image.openshift.io/ImagePolicy\",\"network.openshift.io/ExternalIPRanger\",\"network.openshift.io/RestrictedEndpointsAdmission\",\"quota.openshift.io/ClusterResourceQuota\",\"quota.openshift.io/ValidateClusterResourceQuota\",\"route.openshift.io/IngressAdmission\",\"scheduling.openshift.io/OriginPodNodeEnvironment\",\"security.openshift.io/DefaultSecurityContextConstraints\",\"security.openshift.io/SCCExecRestrictions\",\"security.openshift.io/SecurityContextConstraint\",\"security.openshift.io/ValidateSecurityContextConstraints\",\"storage.openshift.io/CSIInlineVolumeSecurity\"],\"enable-aggregator-routing\":[\"true\"],\"enable-logs-handler\":[\"false\"],\"encryption-provider-config\":[\"/etc/kubernetes/static-pod-resources/secrets/encryption-config/encryption-config\"],\"endpoint-reconciler-type\":[\"lease\"],\"etcd-cafile\":[\"/etc/kubernetes/static-pod-resources/configmaps/etcd-serving-ca/ca-bundle.crt\"],\"etcd-certfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.crt\"],\"etcd-healthcheck-timeout\":[\"9s\"],\"etcd-keyfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.key\"],\"etcd-prefix\":[\"kubernetes.io\"],\"etcd-readycheck-timeout\":[\"9s\"],\"etcd-servers\":[\"https://10.0.0.3:2379\",\"https://10.0.0.4:2379\",\"https://10.0.0.6:2379\",\"https://localhost:2379\"],\"event-ttl\":[\"3h\"],\"feature-gates\":[\"AWSEFSDriverVolumeMetrics=true\",\"AdminNetworkPolicy=true\",\"AlibabaPlatform=true\",\"AzureWorkloadIdentity=true\",\"BareMetalLoadBalancer=true\",\"BuildCSIVolumes=true\",\"ChunkSizeMiB=true\",\"CloudDualStackNodeIPs=true\",\"DisableKubeletCloudCredentialProviders=true\",\"GCPLabelsTags=true\",\"HardwareSpeed=true\",\"IngressControllerLBSubnetsAWS=true\",\"KMSv1=true\",\"ManagedBootImages=true\",\"MetricsServer=true\",\"MultiArchInstallAWS=true\",\"MultiArchInstallGCP=true\",\"NetworkDiagnosticsConfig=true\",\"NetworkLiveMigration=true\",\"NodeDisruptionPolicy=true\",\"OpenShiftPodSecurityAdmission=true\",\"PrivateHostedZoneAWS=true\",\"SetEIPForNLBIngressController=true\",\"VSphereControlPlaneMachineSet=true\",\"VSphereDriverConfiguration=true\",\"VSphereStaticIPs=true\",\"ValidatingAdmissionPolicy=true\",\"AWSClusterHostedDNS=false\",\"AdditionalRoutingCapabilities=false\",\"AutomatedEtcdBackup=false\",\"BootcNodeManagement=false\",\"CSIDriverSharedResource=false\",\"ClusterAPIInstall=false\",\"ClusterAPIInstallIBMCloud=false\",\"ClusterMonitoringConfig=false\",\"DNSNameResolver=false\",\"DynamicResourceAllocation=false\",\"EtcdBackendQuota=false\",\"EventedPLEG=false\",\"Example=false\",\"ExternalOIDC=false\",\"GCPClusterHostedDNS=false\",\"GatewayAPI=false\",\"ImageStreamImportMode=false\",\"IngressControllerDynamicConfigurationManager=false\",\"InsightsConfig=false\",\"InsightsConfigAPI=false\",\"InsightsOnDemandDataGather=false\",\"InsightsRuntimeExtractor=false\",\"MachineAPIMigration=false\",\"MachineAPIOperatorDisableMachineHealthCheckController=false\",\"MachineAPIProviderOpenStack=false\",\"MachineConfigNodes=false\",\"ManagedBootImagesAWS=false\",\"MaxUnavailableStatefulSet=false\",\"MetricsCollectionProfiles=false\",\"MixedCPUsAllocation=false\",\"MultiArchInstallAzure=false\",\"NetworkSegmentation=false\",\"NewOLM=false\",\"NodeSwap=false\",\"OVNObservability=false\",\"OnClusterBuild=false\",\"PersistentIPsForVirtualization=false\",\"PinnedImages=false\",\"PlatformOperators=false\",\"ProcMountType=false\",\"RouteAdvertisements=false\",\"RouteExternalCertificate=false\",\"ServiceAccountTokenNodeBinding=false\",\"SignatureStores=false\",\"SigstoreImageVerification=false\",\"TranslateStreamCloseWebsocketRequests=false\",\"UpgradeStatus=false\",\"UserNamespacesPodSecurityStandards=false\",\"UserNamespacesSupport=false\",\"VSphereMultiNetworks=false\",\"VSphereMultiVCenters=false\",\"VolumeGroupSnapshot=false\"],\"goaway-chance\":[\"0\"],\"http2-max-streams-per-connection\":[\"2000\"],\"kubelet-certificate-authority\":[\"/etc/kubernetes/static-pod-resources/configmaps/kubelet-serving-ca/ca-bundle.crt\"],\"kubelet-client-certificate\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.crt\"],\"kubelet-client-key\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.key\"],\"kubelet-preferred-address-types\":[\"InternalIP\"],\"kubelet-read-only-port\":[\"0\"],\"kubernetes-service-node-port\":[\"0\"],\"max-mutating-requests-inflight\":[\"1000\"],\"max-requests-inflight\":[\"3000\"],\"min-request-timeout\":[\"3600\"],\"proxy-client-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.crt\"],\"proxy-client-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.key\"],\"requestheader-allowed-names\":[\"kube-apiserver-proxy\",\"system:kube-apiserver-proxy\",\"system:openshift-aggregator\"],\"requestheader-client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/aggregator-client-ca/ca-bundle.crt\"],\"requestheader-extra-headers-prefix\":[\"X-Remote-Extra-\"],\"requestheader-group-headers\":[\"X-Remote-Group\"],\"requestheader-username-headers\":[\"X-Remote-User\"],\"runtime-config\":[\"admissionregistration.k8s.io/v1beta1=true\"],\"send-retry-after-while-not-ready-once\":[\"false\"],\"service-account-issuer\":[\"https://kubernetes.default.svc\"],\"service-account-jwks-uri\":[\"https://api.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX:6443/openid/v1/jwks\"],\"service-account-lookup\":[\"true\"],\"service-account-signing-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/bound-service-account-signing-key/service-account.key\"],\"service-node-port-range\":[\"30000-32767\"],\"shutdown-delay-duration\":[\"70s\"],\"shutdown-send-retry-after\":[\"true\"],\"storage-backend\":[\"etcd3\"],\"storage-media-type\":[\"application/vnd.kubernetes.protobuf\"],\"strict-transport-security-directives\":[\"max-age=31536000,includeSubDomains,preload\"],\"tls-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\"],\"tls-private-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"]},\"apiVersion\":\"kubecontrolplane.config.openshift.io/v1\",\"authConfig\":{\"oauthMetadataFile\":\"/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/oauthMetadata\"},\"consolePublicURL\":\"\",\"corsAllowedOrigins\":[\"//127\\\\.0\\\\.0\\\\.1(:|$)\",\"//localhost(:|$)\"],\"imagePolicyConfig\":{\"internalRegistryHostname\":\"image-registry.openshift-image-registry.svc:5000\"},\"kind\":\"KubeAPIServerConfig\",\"projectConfig\":{\"defaultNodeSelector\":\"\"},\"serviceAccountPublicKeyFiles\":[\"/etc/kubernetes/static-pod-resources/configmaps/sa-token-signing-certs\",\"/etc/kubernetes/static-pod-resources/configmaps/bound-sa-token-signing-certs\"],\"servicesSubnet\":\"172.30.0.0/16\",\"servingInfo\":{\"bindAddress\":\"0.0.0.0:6443\",\"bindNetwork\":\"tcp4\",\"cipherSuites\":[\"TLS_AES_128_GCM_SHA256\",\"TLS_AES_256_GCM_SHA384\",\"TLS_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"],\"minTLSVersion\":\"VersionTLS12\",\"namedCertificates\":[{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-000/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-000/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-001/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-001/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-002/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-002/tls.key\"}]}}"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T14:26:22.908380080Z I1024 14:26:22.908291       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/config -n openshift-kube-apiserver:
2024-10-24T14:26:22.908380080Z cause by changes in data.config.yaml
2024-10-24T14:26:22.915416340Z I1024 14:26:22.915320       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 17 triggered by "required configmap/config has changed"
2024-10-24T14:26:24.091344756Z I1024 14:26:24.091209       1 request.go:700] Waited for 1.182597336s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-16-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:26:25.092255162Z I1024 14:26:25.092127       1 request.go:700] Waited for 1.390679185s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:26:25.901477359Z I1024 14:26:25.901380       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-17 -n openshift-kube-apiserver because it was missing
2024-10-24T14:26:26.292056297Z I1024 14:26:26.291949       1 request.go:700] Waited for 1.591741054s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:26:27.492197823Z I1024 14:26:27.492120       1 request.go:700] Waited for 1.590550714s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T14:26:27.505176713Z I1024 14:26:27.505095       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-17 -n openshift-kube-apiserver because it was missing
2024-10-24T14:26:28.692179918Z I1024 14:26:28.692062       1 request.go:700] Waited for 1.592961334s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-16-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:26:29.101194597Z I1024 14:26:29.101119       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-17 -n openshift-kube-apiserver because it was missing
2024-10-24T14:26:29.692245954Z I1024 14:26:29.692166       1 request.go:700] Waited for 1.593746934s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:26:30.703161321Z I1024 14:26:30.703091       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/oauth-metadata-17 -n openshift-kube-apiserver because it was missing
2024-10-24T14:26:30.891319490Z I1024 14:26:30.891240       1 request.go:700] Waited for 1.585243494s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:26:32.091927326Z I1024 14:26:32.091832       1 request.go:700] Waited for 1.592512624s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2024-10-24T14:26:32.305292135Z I1024 14:26:32.305082       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-17 -n openshift-kube-apiserver because it was missing
2024-10-24T14:26:33.094738142Z I1024 14:26:33.094655       1 request.go:700] Waited for 1.506615625s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T14:26:33.903367079Z I1024 14:26:33.902746       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-17 -n openshift-kube-apiserver because it was missing
2024-10-24T14:26:34.292212368Z I1024 14:26:34.292115       1 request.go:700] Waited for 1.593975914s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:26:35.492029873Z I1024 14:26:35.491911       1 request.go:700] Waited for 1.589156784s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T14:26:35.503453783Z I1024 14:26:35.503347       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-17 -n openshift-kube-apiserver because it was missing
2024-10-24T14:26:36.492309129Z I1024 14:26:36.492247       1 request.go:700] Waited for 1.591866744s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:26:37.104899387Z I1024 14:26:37.104745       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-17 -n openshift-kube-apiserver because it was missing
2024-10-24T14:26:37.692265154Z I1024 14:26:37.692181       1 request.go:700] Waited for 1.593163324s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:26:38.707197091Z I1024 14:26:38.707123       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-17 -n openshift-kube-apiserver because it was missing
2024-10-24T14:26:38.892051690Z I1024 14:26:38.891988       1 request.go:700] Waited for 1.586611494s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:26:40.092177955Z I1024 14:26:40.092103       1 request.go:700] Waited for 1.594094374s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-10-24T14:26:40.301377915Z I1024 14:26:40.301317       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-17 -n openshift-kube-apiserver because it was missing
2024-10-24T14:26:41.292012971Z I1024 14:26:41.291931       1 request.go:700] Waited for 1.590605414s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:26:41.908437599Z I1024 14:26:41.908373       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-17 -n openshift-kube-apiserver because it was missing
2024-10-24T14:26:42.491688367Z I1024 14:26:42.491607       1 request.go:700] Waited for 1.593884324s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:26:43.491795953Z I1024 14:26:43.491711       1 request.go:700] Waited for 1.585249044s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:26:43.706087053Z I1024 14:26:43.705997       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/encryption-config-17 -n openshift-kube-apiserver because it was missing
2024-10-24T14:26:44.691602599Z I1024 14:26:44.691525       1 request.go:700] Waited for 2.58554678s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:26:45.691927225Z I1024 14:26:45.691852       1 request.go:700] Waited for 2.386378491s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-10-24T14:26:46.106819063Z I1024 14:26:46.105103       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-17 -n openshift-kube-apiserver because it was missing
2024-10-24T14:26:46.692227921Z I1024 14:26:46.692130       1 request.go:700] Waited for 2.59358406s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:26:47.892205577Z I1024 14:26:47.892130       1 request.go:700] Waited for 2.82809424s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:26:49.092114962Z I1024 14:26:49.092031       1 request.go:700] Waited for 3.193277148s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:26:49.307050911Z I1024 14:26:49.306976       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-17 -n openshift-kube-apiserver because it was missing
2024-10-24T14:26:50.291965897Z I1024 14:26:50.291900       1 request.go:700] Waited for 2.787414749s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:26:51.292003143Z I1024 14:26:51.291930       1 request.go:700] Waited for 2.39380742s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-10-24T14:26:51.706839762Z I1024 14:26:51.706648       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-17 -n openshift-kube-apiserver because it was missing
2024-10-24T14:26:52.491323849Z I1024 14:26:52.491239       1 request.go:700] Waited for 2.381290551s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:26:53.492011016Z I1024 14:26:53.491938       1 request.go:700] Waited for 2.393277542s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:26:54.103579734Z I1024 14:26:54.103513       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 17 triggered by "required configmap/config has changed"
2024-10-24T14:26:54.105239864Z W1024 14:26:54.105192       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:26:54.105239864Z W1024 14:26:54.105224       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:26:54.692149441Z I1024 14:26:54.692066       1 request.go:700] Waited for 2.393329931s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:26:55.892104637Z I1024 14:26:55.892036       1 request.go:700] Waited for 2.194656372s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-10-24T14:26:56.892303373Z I1024 14:26:56.892202       1 request.go:700] Waited for 2.61094262s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:26:58.091536458Z I1024 14:26:58.091465       1 request.go:700] Waited for 2.79122022s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:26:59.091867415Z I1024 14:26:59.091788       1 request.go:700] Waited for 2.7868082s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:27:00.092083581Z I1024 14:27:00.092012       1 request.go:700] Waited for 2.59180951s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:27:01.291745087Z I1024 14:27:01.291674       1 request.go:700] Waited for 2.190192192s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:27:02.491976072Z I1024 14:27:02.491912       1 request.go:700] Waited for 2.193644862s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:27:03.492109188Z I1024 14:27:03.491988       1 request.go:700] Waited for 2.193278991s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:27:04.492139924Z I1024 14:27:04.492050       1 request.go:700] Waited for 1.992990863s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:27:05.525295421Z I1024 14:27:05.525195       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-17-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-apiserver because it was missing
2024-10-24T14:27:05.692226290Z I1024 14:27:05.692144       1 request.go:700] Waited for 1.827371233s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:27:06.891234276Z I1024 14:27:06.891148       1 request.go:700] Waited for 1.790294403s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:27:07.891660862Z I1024 14:27:07.891590       1 request.go:700] Waited for 2.367285951s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T14:27:09.091552117Z I1024 14:27:09.091469       1 request.go:700] Waited for 2.58839478s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:27:10.091666094Z I1024 14:27:10.091581       1 request.go:700] Waited for 2.59286934s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:27:10.713551021Z I1024 14:27:10.713488       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-17-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-apiserver because it was missing
2024-10-24T14:27:11.291257409Z I1024 14:27:11.291192       1 request.go:700] Waited for 2.591830151s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-config-openshift-kube-apiserver
2024-10-24T14:27:12.293872745Z I1024 14:27:12.293632       1 request.go:700] Waited for 2.390722401s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:27:13.491975231Z I1024 14:27:13.491877       1 request.go:700] Waited for 2.392564121s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:27:14.692246977Z I1024 14:27:14.692145       1 request.go:700] Waited for 2.387563902s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:27:15.508091923Z I1024 14:27:15.507989       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-17-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-apiserver because it was missing
2024-10-24T14:27:15.891937382Z I1024 14:27:15.891869       1 request.go:700] Waited for 2.391545981s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:27:16.897921199Z I1024 14:27:16.897837       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 16 is the oldest and needs new revision 17
2024-10-24T14:27:16.897977748Z I1024 14:27:16.897952       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T14:27:16.897977748Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T14:27:16.897977748Z  CurrentRevision: (int32) 16,
2024-10-24T14:27:16.897977748Z  TargetRevision: (int32) 17,
2024-10-24T14:27:16.897977748Z  LastFailedRevision: (int32) 10,
2024-10-24T14:27:16.897977748Z  LastFailedTime: (*v1.Time)(0xc00332f278)(2024-10-24 13:30:03 +0000 UTC),
2024-10-24T14:27:16.897977748Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T14:27:16.897977748Z  LastFailedCount: (int) 1,
2024-10-24T14:27:16.897977748Z  LastFallbackCount: (int) 0,
2024-10-24T14:27:16.897977748Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T14:27:16.897977748Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T14:27:16.897977748Z  }
2024-10-24T14:27:16.897977748Z }
2024-10-24T14:27:16.900605128Z W1024 14:27:16.900403       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:27:16.900605128Z W1024 14:27:16.900433       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:27:16.900605128Z W1024 14:27:16.900438       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:27:16.900605128Z W1024 14:27:16.900442       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:27:16.900605128Z W1024 14:27:16.900446       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T14:27:16.900605128Z W1024 14:27:16.900449       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T14:27:16.932422009Z I1024 14:27:16.932259       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 16 to 17 because node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 16 is the oldest
2024-10-24T14:27:16.935644258Z I1024 14:27:16.935554       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T14:27:16Z","message":"NodeInstallerProgressing: 3 nodes are at revision 16; 0 nodes have achieved new revision 17","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 16; 0 nodes have achieved new revision 17","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T14:27:16.950256648Z I1024 14:27:16.950195       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing changed from False to True ("NodeInstallerProgressing: 3 nodes are at revision 16; 0 nodes have achieved new revision 17"),Available message changed from "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 16" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 16; 0 nodes have achieved new revision 17"
2024-10-24T14:27:17.091509638Z I1024 14:27:17.091443       1 request.go:700] Waited for 2.591274161s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2024-10-24T14:27:18.291868683Z I1024 14:27:18.291791       1 request.go:700] Waited for 2.393365811s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:27:19.491306309Z I1024 14:27:19.491214       1 request.go:700] Waited for 2.554781841s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:27:20.492239276Z I1024 14:27:20.492150       1 request.go:700] Waited for 3.158418289s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:27:21.692229382Z I1024 14:27:21.692141       1 request.go:700] Waited for 3.192648518s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-config-openshift-kube-apiserver
2024-10-24T14:27:22.891869857Z I1024 14:27:22.891773       1 request.go:700] Waited for 3.190362399s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:27:24.092351002Z I1024 14:27:24.092250       1 request.go:700] Waited for 3.192633488s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:27:25.291533328Z I1024 14:27:25.291451       1 request.go:700] Waited for 3.194141868s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:27:26.291858324Z I1024 14:27:26.291778       1 request.go:700] Waited for 2.425571681s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:27:27.292151860Z I1024 14:27:27.292060       1 request.go:700] Waited for 2.391707551s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:27:28.491690207Z I1024 14:27:28.491612       1 request.go:700] Waited for 2.393252612s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-10-24T14:27:29.492063734Z I1024 14:27:29.491973       1 request.go:700] Waited for 2.193464103s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:27:30.691915000Z I1024 14:27:30.691832       1 request.go:700] Waited for 2.193568303s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-10-24T14:27:31.891626896Z I1024 14:27:31.891552       1 request.go:700] Waited for 1.593131516s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-17-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:27:33.698712730Z I1024 14:27:33.698632       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 16 is the oldest and needs new revision 17
2024-10-24T14:27:33.698817790Z I1024 14:27:33.698802       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T14:27:33.698817790Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T14:27:33.698817790Z  CurrentRevision: (int32) 16,
2024-10-24T14:27:33.698817790Z  TargetRevision: (int32) 17,
2024-10-24T14:27:33.698817790Z  LastFailedRevision: (int32) 10,
2024-10-24T14:27:33.698817790Z  LastFailedTime: (*v1.Time)(0xc008002b58)(2024-10-24 13:30:03 +0000 UTC),
2024-10-24T14:27:33.698817790Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T14:27:33.698817790Z  LastFailedCount: (int) 1,
2024-10-24T14:27:33.698817790Z  LastFallbackCount: (int) 0,
2024-10-24T14:27:33.698817790Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T14:27:33.698817790Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T14:27:33.698817790Z  }
2024-10-24T14:27:33.698817790Z }
2024-10-24T14:27:33.701276030Z I1024 14:27:33.701174       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 16 to 17 because node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 16 is the oldest
2024-10-24T14:27:35.311364465Z I1024 14:27:35.311265       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-17-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-apiserver because it was missing
2024-10-24T14:27:35.698605205Z I1024 14:27:35.698534       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 17, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T14:27:36.491915532Z I1024 14:27:36.491843       1 request.go:700] Waited for 1.180001186s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:27:37.491931567Z I1024 14:27:37.491854       1 request.go:700] Waited for 1.993400302s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:27:38.691284633Z I1024 14:27:38.691200       1 request.go:700] Waited for 1.993756511s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:27:39.691737370Z I1024 14:27:39.691663       1 request.go:700] Waited for 1.992650734s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:27:40.692459467Z I1024 14:27:40.692339       1 request.go:700] Waited for 1.993364425s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:27:41.891730185Z I1024 14:27:41.891654       1 request.go:700] Waited for 1.591524877s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:27:42.891924102Z I1024 14:27:42.891852       1 request.go:700] Waited for 1.585200036s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:27:44.091884755Z I1024 14:27:44.091800       1 request.go:700] Waited for 1.592071622s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:27:44.900338892Z I1024 14:27:44.900256       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 17, but has not made progress because installer is not finished, but in Running phase
2024-10-24T14:27:45.092226032Z I1024 14:27:45.092133       1 request.go:700] Waited for 1.593712003s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:27:46.292099486Z I1024 14:27:46.292021       1 request.go:700] Waited for 1.792001162s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:27:47.292232362Z I1024 14:27:47.292141       1 request.go:700] Waited for 2.22718672s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:27:48.491295279Z I1024 14:27:48.491214       1 request.go:700] Waited for 2.391795383s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:27:49.491370385Z I1024 14:27:49.491255       1 request.go:700] Waited for 1.983351355s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:27:50.491972861Z I1024 14:27:50.491887       1 request.go:700] Waited for 1.994633032s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:27:51.492017846Z I1024 14:27:51.491929       1 request.go:700] Waited for 1.99480601s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:27:52.492258981Z I1024 14:27:52.492154       1 request.go:700] Waited for 1.9923502s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:27:53.691739535Z I1024 14:27:53.691656       1 request.go:700] Waited for 1.391892623s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:27:54.498597131Z I1024 14:27:54.498520       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 17, but has not made progress because installer is not finished, but in Running phase
2024-10-24T14:27:54.692050289Z I1024 14:27:54.691977       1 request.go:700] Waited for 1.194576713s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:27:55.891826962Z I1024 14:27:55.891689       1 request.go:700] Waited for 1.191139273s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-config-openshift-kube-apiserver
2024-10-24T14:28:14.027502512Z I1024 14:28:14.027406       1 termination_observer.go:236] Observed event "TerminationPreShutdownHooksFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0" (last termination at 2024-10-24 14:13:35 +0000 UTC) at 2024-10-24 14:28:14 +0000 UTC
2024-10-24T14:28:15.534173673Z I1024 14:28:15.534089       1 request.go:700] Waited for 1.187638353s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:28:16.534896447Z I1024 14:28:16.534739       1 request.go:700] Waited for 1.594804091s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:28:17.734626159Z I1024 14:28:17.734566       1 request.go:700] Waited for 1.991580829s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:28:18.934213602Z I1024 14:28:18.934149       1 request.go:700] Waited for 1.992395288s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:28:19.934424236Z I1024 14:28:19.934342       1 request.go:700] Waited for 1.593177s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:28:21.134911329Z I1024 14:28:21.134835       1 request.go:700] Waited for 1.59323442s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:28:21.943309314Z I1024 14:28:21.943225       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 17, but has not made progress because waiting for static pod of revision 17, found 16
2024-10-24T14:28:22.334454232Z I1024 14:28:22.334391       1 request.go:700] Waited for 1.588917691s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:28:23.334906476Z I1024 14:28:23.334841       1 request.go:700] Waited for 1.388855131s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:28:24.334916540Z I1024 14:28:24.334853       1 request.go:700] Waited for 1.122723824s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:28:26.933895674Z I1024 14:28:26.933811       1 request.go:700] Waited for 1.155627703s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:28:27.934257589Z I1024 14:28:27.934191       1 request.go:700] Waited for 1.993800288s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:28:28.141127808Z I1024 14:28:28.141053       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 17, but has not made progress because waiting for static pod of revision 17, found 16
2024-10-24T14:28:28.934682572Z I1024 14:28:28.934597       1 request.go:700] Waited for 1.59399506s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:28:29.934913287Z I1024 14:28:29.934834       1 request.go:700] Waited for 1.59380462s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:28:31.134040779Z I1024 14:28:31.133966       1 request.go:700] Waited for 1.59336662s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:28:33.542422065Z I1024 14:28:33.542344       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 17, but has not made progress because waiting for static pod of revision 17, found 16
2024-10-24T14:28:46.275143207Z I1024 14:28:46.275066       1 request.go:700] Waited for 1.192728442s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-16
2024-10-24T14:28:47.275492592Z I1024 14:28:47.275398       1 request.go:700] Waited for 1.393392712s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:28:48.475599455Z I1024 14:28:48.475502       1 request.go:700] Waited for 1.394509521s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:29:25.994002440Z I1024 14:29:25.993908       1 termination_observer.go:236] Observed event "TerminationGracefulTerminationFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0" (last termination at 2024-10-24 14:13:35 +0000 UTC) at 2024-10-24 14:29:25 +0000 UTC
2024-10-24T14:29:38.357932756Z I1024 14:29:38.357852       1 request.go:700] Waited for 1.187163603s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:29:38.965209432Z I1024 14:29:38.965131       1 termination_observer.go:130] Observed termination of API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0" at 2024-10-24 14:29:37 +0000 UTC
2024-10-24T14:29:39.357927290Z I1024 14:29:39.357862       1 request.go:700] Waited for 1.994304318s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:29:40.358008294Z I1024 14:29:40.357920       1 request.go:700] Waited for 1.993564388s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:29:41.557195477Z I1024 14:29:41.557122       1 request.go:700] Waited for 1.993640769s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:29:42.757026970Z I1024 14:29:42.756921       1 request.go:700] Waited for 1.992360637s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-config-openshift-kube-apiserver
2024-10-24T14:29:43.757579454Z I1024 14:29:43.757511       1 request.go:700] Waited for 1.993258309s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-17-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:29:44.758053697Z I1024 14:29:44.757980       1 request.go:700] Waited for 1.991652798s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:29:45.766176041Z I1024 14:29:45.766106       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 17, but has not made progress because static pod is pending
2024-10-24T14:29:45.958004570Z I1024 14:29:45.957927       1 request.go:700] Waited for 2.080615097s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:29:46.958010394Z I1024 14:29:46.957943       1 request.go:700] Waited for 2.282280327s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T14:29:48.157494247Z I1024 14:29:48.157400       1 request.go:700] Waited for 2.388769655s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:29:49.158148441Z I1024 14:29:49.158063       1 request.go:700] Waited for 2.592344945s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:29:50.357645474Z I1024 14:29:50.357576       1 request.go:700] Waited for 2.393482886s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:29:51.357815888Z I1024 14:29:51.357598       1 request.go:700] Waited for 1.59316799s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-10-24T14:29:54.163449471Z I1024 14:29:54.163368       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 17, but has not made progress because static pod is pending
2024-10-24T14:29:56.963157384Z I1024 14:29:56.963076       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 17, but has not made progress because static pod is pending
2024-10-24T14:29:58.357013596Z I1024 14:29:58.356932       1 request.go:700] Waited for 1.109959933s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:29:59.357311240Z I1024 14:29:59.357231       1 request.go:700] Waited for 1.791347239s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:30:29.437989499Z I1024 14:30:29.437919       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T14:30:29.437989499Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T14:30:29.437989499Z  CurrentRevision: (int32) 17,
2024-10-24T14:30:29.437989499Z  TargetRevision: (int32) 0,
2024-10-24T14:30:29.437989499Z  LastFailedRevision: (int32) 10,
2024-10-24T14:30:29.437989499Z  LastFailedTime: (*v1.Time)(0xc0058c95a8)(2024-10-24 13:30:03 +0000 UTC),
2024-10-24T14:30:29.437989499Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T14:30:29.437989499Z  LastFailedCount: (int) 1,
2024-10-24T14:30:29.437989499Z  LastFallbackCount: (int) 0,
2024-10-24T14:30:29.437989499Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T14:30:29.437989499Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T14:30:29.437989499Z  }
2024-10-24T14:30:29.437989499Z }
2024-10-24T14:30:29.437989499Z  because static pod is ready
2024-10-24T14:30:29.439779569Z W1024 14:30:29.439712       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:30:29.439779569Z W1024 14:30:29.439739       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:30:29.439779569Z W1024 14:30:29.439744       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:30:29.439779569Z W1024 14:30:29.439766       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:30:29.439779569Z W1024 14:30:29.439773       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T14:30:29.440074010Z W1024 14:30:29.439778       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T14:30:29.466052319Z I1024 14:30:29.465978       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 16 to 17 because static pod is ready
2024-10-24T14:30:29.475214219Z I1024 14:30:29.475146       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T14:27:16Z","message":"NodeInstallerProgressing: 2 nodes are at revision 16; 1 node is at revision 17","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 16; 1 node is at revision 17","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T14:30:29.491435389Z I1024 14:30:29.491325       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 16; 0 nodes have achieved new revision 17" to "NodeInstallerProgressing: 2 nodes are at revision 16; 1 node is at revision 17",Available message changed from "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 16; 0 nodes have achieved new revision 17" to "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 16; 1 node is at revision 17"
2024-10-24T14:30:30.600525363Z I1024 14:30:30.600444       1 request.go:700] Waited for 1.125649564s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:30:31.601315477Z I1024 14:30:31.601167       1 request.go:700] Waited for 2.115270188s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:30:32.800476860Z I1024 14:30:32.800385       1 request.go:700] Waited for 2.593647385s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:30:33.801398763Z I1024 14:30:33.801317       1 request.go:700] Waited for 2.590528884s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:30:34.801482687Z I1024 14:30:34.801426       1 request.go:700] Waited for 1.392722812s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:30:36.001420020Z I1024 14:30:36.001351       1 request.go:700] Waited for 1.194213262s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:30:39.207039731Z I1024 14:30:39.206983       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-1 with revision 16 is the oldest and needs new revision 17
2024-10-24T14:30:39.207088641Z I1024 14:30:39.207036       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T14:30:39.207088641Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T14:30:39.207088641Z  CurrentRevision: (int32) 16,
2024-10-24T14:30:39.207088641Z  TargetRevision: (int32) 17,
2024-10-24T14:30:39.207088641Z  LastFailedRevision: (int32) 0,
2024-10-24T14:30:39.207088641Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T14:30:39.207088641Z  LastFailedReason: (string) "",
2024-10-24T14:30:39.207088641Z  LastFailedCount: (int) 0,
2024-10-24T14:30:39.207088641Z  LastFallbackCount: (int) 0,
2024-10-24T14:30:39.207088641Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T14:30:39.207088641Z }
2024-10-24T14:30:39.209014301Z W1024 14:30:39.208962       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:30:39.209014301Z W1024 14:30:39.208983       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:30:39.209014301Z W1024 14:30:39.208994       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:30:39.209014301Z W1024 14:30:39.208998       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:30:39.209014301Z W1024 14:30:39.209001       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T14:30:39.209014301Z W1024 14:30:39.209004       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T14:30:39.241596101Z I1024 14:30:39.241525       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 16 to 17 because node ci-op-2fcpj5j6-f6035-2lklf-master-1 with revision 16 is the oldest
2024-10-24T14:30:40.401285114Z I1024 14:30:40.401183       1 request.go:700] Waited for 1.157320863s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:30:41.600720507Z I1024 14:30:41.600652       1 request.go:700] Waited for 2.354673826s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-17-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:30:42.601135701Z I1024 14:30:42.601066       1 request.go:700] Waited for 2.789349684s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:30:43.800591874Z I1024 14:30:43.800531       1 request.go:700] Waited for 2.792685314s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:30:44.801378548Z I1024 14:30:44.801287       1 request.go:700] Waited for 2.794391074s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-10-24T14:30:46.001456621Z I1024 14:30:46.001397       1 request.go:700] Waited for 1.592989101s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-17-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:30:47.201115504Z I1024 14:30:47.201032       1 request.go:700] Waited for 2.133334108s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:30:48.201303068Z I1024 14:30:48.201197       1 request.go:700] Waited for 2.791748764s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:30:49.400566191Z I1024 14:30:49.400508       1 request.go:700] Waited for 1.190846322s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:30:50.400856754Z I1024 14:30:50.400795       1 request.go:700] Waited for 1.193377263s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:30:51.401162269Z I1024 14:30:51.401084       1 request.go:700] Waited for 1.193248163s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:30:53.207019428Z I1024 14:30:53.206917       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-1 with revision 16 is the oldest and needs new revision 17
2024-10-24T14:30:53.207019428Z I1024 14:30:53.207001       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T14:30:53.207019428Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T14:30:53.207019428Z  CurrentRevision: (int32) 16,
2024-10-24T14:30:53.207019428Z  TargetRevision: (int32) 17,
2024-10-24T14:30:53.207019428Z  LastFailedRevision: (int32) 0,
2024-10-24T14:30:53.207019428Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T14:30:53.207019428Z  LastFailedReason: (string) "",
2024-10-24T14:30:53.207019428Z  LastFailedCount: (int) 0,
2024-10-24T14:30:53.207019428Z  LastFallbackCount: (int) 0,
2024-10-24T14:30:53.207019428Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T14:30:53.207019428Z }
2024-10-24T14:30:53.212397828Z I1024 14:30:53.212262       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 16 to 17 because node ci-op-2fcpj5j6-f6035-2lklf-master-1 with revision 16 is the oldest
2024-10-24T14:30:56.246837660Z I1024 14:30:56.246744       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-17-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-apiserver because it was missing
2024-10-24T14:30:56.407282209Z I1024 14:30:56.407209       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 17, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T14:30:57.400848533Z I1024 14:30:57.400776       1 request.go:700] Waited for 1.155967143s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:30:58.600998426Z I1024 14:30:58.600941       1 request.go:700] Waited for 1.986249318s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:30:59.601224860Z I1024 14:30:59.601140       1 request.go:700] Waited for 1.992845598s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:31:00.800901943Z I1024 14:31:00.800823       1 request.go:700] Waited for 1.993889578s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:31:02.001629706Z I1024 14:31:02.001517       1 request.go:700] Waited for 1.992184478s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:31:03.608542916Z I1024 14:31:03.608431       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 17, but has not made progress because installer is not finished, but in Running phase
2024-10-24T14:31:06.009488362Z I1024 14:31:06.009396       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 17, but has not made progress because installer is not finished, but in Running phase
2024-10-24T14:31:15.475534495Z I1024 14:31:15.475432       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2024-10-24T14:31:34.934905189Z I1024 14:31:34.934560       1 termination_observer.go:236] Observed event "TerminationPreShutdownHooksFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1" (last termination at 2024-10-24 14:16:31 +0000 UTC) at 2024-10-24 14:31:34 +0000 UTC
2024-10-24T14:31:38.032331610Z I1024 14:31:38.032220       1 request.go:700] Waited for 1.145573893s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:31:39.032330104Z I1024 14:31:39.032264       1 request.go:700] Waited for 1.992380438s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:31:40.639595085Z I1024 14:31:40.639489       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 17, but has not made progress because waiting for static pod of revision 17, found 16
2024-10-24T14:31:43.039259541Z I1024 14:31:43.039152       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 17, but has not made progress because waiting for static pod of revision 17, found 16
2024-10-24T14:31:46.231950122Z I1024 14:31:46.231821       1 request.go:700] Waited for 1.163714834s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:31:47.432388214Z I1024 14:31:47.432263       1 request.go:700] Waited for 1.791988079s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-10-24T14:31:48.831777346Z I1024 14:31:48.831688       1 request.go:700] Waited for 1.015813694s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T14:31:50.032547819Z I1024 14:31:50.032458       1 request.go:700] Waited for 2.204312847s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:31:53.839073616Z I1024 14:31:53.838905       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 17, but has not made progress because waiting for static pod of revision 17, found 16
2024-10-24T14:32:46.900616429Z I1024 14:32:46.900533       1 termination_observer.go:236] Observed event "TerminationGracefulTerminationFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1" (last termination at 2024-10-24 14:16:31 +0000 UTC) at 2024-10-24 14:32:46 +0000 UTC
2024-10-24T14:32:48.108952792Z I1024 14:32:48.108864       1 reflector.go:368] Caches populated for *v1.KubeAPIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:48.450677690Z I1024 14:32:48.450551       1 reflector.go:368] Caches populated for *v1.Authentication from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:48.553441420Z I1024 14:32:48.553333       1 reflector.go:368] Caches populated for monitoring.coreos.com/v1, Resource=prometheusrules from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:48.578240109Z I1024 14:32:48.578072       1 reflector.go:368] Caches populated for *v1.Image from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:48.682297339Z I1024 14:32:48.682206       1 reflector.go:368] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:48.701040059Z I1024 14:32:48.700966       1 reflector.go:368] Caches populated for *v1alpha1.StorageVersionMigration from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:48.722927089Z I1024 14:32:48.722862       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubeapiservers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:48.733256619Z I1024 14:32:48.733153       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:48.754302869Z I1024 14:32:48.754196       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:48.754444238Z I1024 14:32:48.754377       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2024-10-24T14:32:49.003552387Z I1024 14:32:49.003459       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:49.527600604Z I1024 14:32:49.527510       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:49.811018472Z I1024 14:32:49.810927       1 reflector.go:368] Caches populated for *v1.OAuth from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:49.857566632Z I1024 14:32:49.857471       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:49.877736862Z I1024 14:32:49.877607       1 request.go:700] Waited for 1.153093934s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:32:50.015741691Z I1024 14:32:50.015515       1 reflector.go:368] Caches populated for *v1.Proxy from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:50.287570449Z I1024 14:32:50.287451       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:50.877743706Z I1024 14:32:50.877667       1 request.go:700] Waited for 2.141633327s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T14:32:51.878473970Z I1024 14:32:51.878351       1 request.go:700] Waited for 2.390180986s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:32:52.878460644Z I1024 14:32:52.878373       1 request.go:700] Waited for 2.192636097s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-17-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:32:54.078320887Z I1024 14:32:54.078231       1 request.go:700] Waited for 1.391379392s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:32:55.277829770Z I1024 14:32:55.277711       1 request.go:700] Waited for 1.385122002s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:32:56.289098444Z I1024 14:32:56.289010       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 17, but has not made progress because waiting for static pod of revision 17, found 16
2024-10-24T14:32:58.286832012Z I1024 14:32:58.286727       1 termination_observer.go:130] Observed termination of API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1" at 2024-10-24 14:32:57 +0000 UTC
2024-10-24T14:32:58.477896991Z I1024 14:32:58.477806       1 request.go:700] Waited for 1.187332042s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:32:59.479783974Z I1024 14:32:59.477889       1 request.go:700] Waited for 2.174107366s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:33:00.479933918Z I1024 14:33:00.479867       1 request.go:700] Waited for 2.192811277s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T14:33:01.679563481Z I1024 14:33:01.679477       1 request.go:700] Waited for 2.180719857s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:33:02.877860744Z I1024 14:33:02.877786       1 request.go:700] Waited for 2.185249067s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:33:03.878380608Z I1024 14:33:03.878269       1 request.go:700] Waited for 2.160005717s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:33:05.078085501Z I1024 14:33:05.077959       1 request.go:700] Waited for 1.188017363s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:33:06.477918773Z I1024 14:33:06.477727       1 request.go:700] Waited for 1.161553613s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:33:07.678002305Z I1024 14:33:07.677852       1 request.go:700] Waited for 2.192099306s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:33:08.086701663Z I1024 14:33:08.086543       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 17, but has not made progress because static pod is pending
2024-10-24T14:33:08.678489680Z I1024 14:33:08.678376       1 request.go:700] Waited for 1.791469139s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:33:09.678877374Z I1024 14:33:09.678794       1 request.go:700] Waited for 2.183042587s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:33:10.878410967Z I1024 14:33:10.878244       1 request.go:700] Waited for 2.187652428s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:33:12.078312419Z I1024 14:33:12.078220       1 request.go:700] Waited for 1.990805008s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:33:13.278400102Z I1024 14:33:13.278286       1 request.go:700] Waited for 1.190058263s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:33:14.278479806Z I1024 14:33:14.278394       1 request.go:700] Waited for 1.114686543s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:33:15.478523009Z I1024 14:33:15.478447       1 request.go:700] Waited for 1.090056323s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T14:33:16.686592982Z I1024 14:33:16.686463       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 17, but has not made progress because static pod is pending
2024-10-24T14:33:18.478211221Z I1024 14:33:18.478120       1 request.go:700] Waited for 1.076864343s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:33:19.677884784Z I1024 14:33:19.677805       1 request.go:700] Waited for 2.189378197s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:33:32.742306986Z I1024 14:33:32.742224       1 request.go:700] Waited for 1.181015013s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-10-24T14:33:33.742938270Z I1024 14:33:33.742858       1 request.go:700] Waited for 1.79088318s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:33:34.942454714Z I1024 14:33:34.942378       1 request.go:700] Waited for 1.789162659s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:33:35.943143438Z I1024 14:33:35.943050       1 request.go:700] Waited for 1.392600202s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-10-24T14:33:46.143176307Z I1024 14:33:46.143072       1 request.go:700] Waited for 1.072900104s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:33:47.342897280Z I1024 14:33:47.342817       1 request.go:700] Waited for 2.005958938s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:33:48.542985023Z I1024 14:33:48.542895       1 request.go:700] Waited for 2.390453606s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:33:49.742854156Z I1024 14:33:49.742719       1 request.go:700] Waited for 2.390105396s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:33:53.342980314Z I1024 14:33:53.342903       1 request.go:700] Waited for 1.088884323s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:33:54.152276090Z I1024 14:33:54.152210       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T14:33:54.152276090Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T14:33:54.152276090Z  CurrentRevision: (int32) 17,
2024-10-24T14:33:54.152276090Z  TargetRevision: (int32) 0,
2024-10-24T14:33:54.152276090Z  LastFailedRevision: (int32) 0,
2024-10-24T14:33:54.152276090Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T14:33:54.152276090Z  LastFailedReason: (string) "",
2024-10-24T14:33:54.152276090Z  LastFailedCount: (int) 0,
2024-10-24T14:33:54.152276090Z  LastFallbackCount: (int) 0,
2024-10-24T14:33:54.152276090Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T14:33:54.152276090Z }
2024-10-24T14:33:54.152276090Z  because static pod is ready
2024-10-24T14:33:54.154316879Z W1024 14:33:54.154265       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:33:54.154316879Z W1024 14:33:54.154287       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:33:54.154316879Z W1024 14:33:54.154292       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:33:54.154316879Z W1024 14:33:54.154296       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:33:54.154316879Z W1024 14:33:54.154299       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T14:33:54.154316879Z W1024 14:33:54.154302       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T14:33:54.190264839Z I1024 14:33:54.190158       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 16 to 17 because static pod is ready
2024-10-24T14:33:54.199859669Z I1024 14:33:54.199777       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T14:27:16Z","message":"NodeInstallerProgressing: 1 node is at revision 16; 2 nodes are at revision 17","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 16; 2 nodes are at revision 17","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T14:33:54.224483439Z I1024 14:33:54.224389       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 16; 1 node is at revision 17" to "NodeInstallerProgressing: 1 node is at revision 16; 2 nodes are at revision 17",Available message changed from "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 16; 1 node is at revision 17" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 16; 2 nodes are at revision 17"
2024-10-24T14:33:54.542344597Z I1024 14:33:54.542257       1 request.go:700] Waited for 1.317845252s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:33:54.807086776Z I1024 14:33:54.806949       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX
2024-10-24T14:33:55.542460611Z I1024 14:33:55.542370       1 request.go:700] Waited for 1.352178312s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:33:56.543078646Z I1024 14:33:56.542973       1 request.go:700] Waited for 2.349439507s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:33:57.743295968Z I1024 14:33:57.743196       1 request.go:700] Waited for 2.790147733s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:33:58.743636293Z I1024 14:33:58.743560       1 request.go:700] Waited for 2.792157043s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:33:59.942529105Z I1024 14:33:59.942469       1 request.go:700] Waited for 2.790444023s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:34:01.143263709Z I1024 14:34:01.143186       1 request.go:700] Waited for 1.592587711s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:34:02.342562031Z I1024 14:34:02.342451       1 request.go:700] Waited for 1.188542592s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:34:03.950982852Z I1024 14:34:03.950845       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T14:34:03.950982852Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T14:34:03.950982852Z  CurrentRevision: (int32) 17,
2024-10-24T14:34:03.950982852Z  TargetRevision: (int32) 0,
2024-10-24T14:34:03.950982852Z  LastFailedRevision: (int32) 0,
2024-10-24T14:34:03.950982852Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T14:34:03.950982852Z  LastFailedReason: (string) "",
2024-10-24T14:34:03.950982852Z  LastFailedCount: (int) 0,
2024-10-24T14:34:03.950982852Z  LastFallbackCount: (int) 0,
2024-10-24T14:34:03.950982852Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T14:34:03.950982852Z }
2024-10-24T14:34:03.950982852Z  because static pod is ready
2024-10-24T14:34:03.953289212Z I1024 14:34:03.953199       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 16 to 17 because static pod is ready
2024-10-24T14:34:09.150561731Z I1024 14:34:09.150467       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-2 with revision 16 is the oldest and needs new revision 17
2024-10-24T14:34:09.150561731Z I1024 14:34:09.150551       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T14:34:09.150561731Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T14:34:09.150561731Z  CurrentRevision: (int32) 16,
2024-10-24T14:34:09.150561731Z  TargetRevision: (int32) 17,
2024-10-24T14:34:09.150561731Z  LastFailedRevision: (int32) 0,
2024-10-24T14:34:09.150561731Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T14:34:09.150561731Z  LastFailedReason: (string) "",
2024-10-24T14:34:09.150561731Z  LastFailedCount: (int) 0,
2024-10-24T14:34:09.150561731Z  LastFallbackCount: (int) 0,
2024-10-24T14:34:09.150561731Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T14:34:09.150561731Z }
2024-10-24T14:34:09.152836462Z W1024 14:34:09.152770       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:34:09.152836462Z W1024 14:34:09.152791       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:34:09.152836462Z W1024 14:34:09.152796       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:34:09.152836462Z W1024 14:34:09.152800       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:34:09.152836462Z W1024 14:34:09.152803       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T14:34:09.152836462Z W1024 14:34:09.152806       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T14:34:09.185554161Z I1024 14:34:09.185453       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 16 to 17 because node ci-op-2fcpj5j6-f6035-2lklf-master-2 with revision 16 is the oldest
2024-10-24T14:34:10.343214315Z I1024 14:34:10.343134       1 request.go:700] Waited for 1.154524954s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T14:34:11.543108658Z I1024 14:34:11.543040       1 request.go:700] Waited for 2.347865357s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-17-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:34:12.742885211Z I1024 14:34:12.742734       1 request.go:700] Waited for 2.791742084s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:34:13.942939564Z I1024 14:34:13.942864       1 request.go:700] Waited for 2.790537683s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:34:15.142864887Z I1024 14:34:15.142707       1 request.go:700] Waited for 2.790694633s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:34:16.342632699Z I1024 14:34:16.342568       1 request.go:700] Waited for 1.392575812s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:34:17.343390503Z I1024 14:34:17.343322       1 request.go:700] Waited for 1.191210572s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-10-24T14:34:17.980229779Z I1024 14:34:17.980141       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-17-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-apiserver because it was missing
2024-10-24T14:34:18.942231624Z I1024 14:34:18.942157       1 request.go:700] Waited for 1.090289694s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:34:19.551858040Z I1024 14:34:19.551792       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 17, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T14:34:20.143022107Z I1024 14:34:20.142937       1 request.go:700] Waited for 2.161296778s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:34:21.143143461Z I1024 14:34:21.143064       1 request.go:700] Waited for 2.588177225s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:34:22.343165523Z I1024 14:34:22.343103       1 request.go:700] Waited for 2.391237716s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:34:23.542893466Z I1024 14:34:23.542810       1 request.go:700] Waited for 2.191772417s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:34:24.543000560Z I1024 14:34:24.542918       1 request.go:700] Waited for 1.388214162s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-10-24T14:34:26.951763156Z I1024 14:34:26.951651       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 17, but has not made progress because installer is not finished, but in Running phase
2024-10-24T14:34:29.957543838Z I1024 14:34:29.957464       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 17, but has not made progress because installer is not finished, but in Running phase
2024-10-24T14:34:56.645379050Z I1024 14:34:56.645296       1 termination_observer.go:236] Observed event "TerminationPreShutdownHooksFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2" (last termination at 2024-10-24 14:19:30 +0000 UTC) at 2024-10-24 14:34:56 +0000 UTC
2024-10-24T14:34:59.541571984Z I1024 14:34:59.541486       1 request.go:700] Waited for 1.127228944s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:35:00.542024568Z I1024 14:35:00.541932       1 request.go:700] Waited for 1.991343218s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:35:01.350005673Z I1024 14:35:01.349933       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 17, but has not made progress because waiting for static pod of revision 17, found 16
2024-10-24T14:35:03.950601447Z I1024 14:35:03.950518       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 17, but has not made progress because waiting for static pod of revision 17, found 16
2024-10-24T14:35:09.971202172Z I1024 14:35:09.971122       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 17, but has not made progress because waiting for static pod of revision 17, found 16
2024-10-24T14:36:08.605786819Z I1024 14:36:08.605673       1 termination_observer.go:236] Observed event "TerminationGracefulTerminationFinished" for API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2" (last termination at 2024-10-24 14:19:30 +0000 UTC) at 2024-10-24 14:36:08 +0000 UTC
2024-10-24T14:36:21.115988625Z I1024 14:36:21.115892       1 termination_observer.go:130] Observed termination of API server pod "kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2" at 2024-10-24 14:36:20 +0000 UTC
2024-10-24T14:36:22.066555750Z I1024 14:36:22.066485       1 request.go:700] Waited for 1.144167373s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:36:23.265806313Z I1024 14:36:23.265688       1 request.go:700] Waited for 1.964946358s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:36:24.266042647Z I1024 14:36:24.265976       1 request.go:700] Waited for 1.987117868s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:36:25.266802221Z I1024 14:36:25.266717       1 request.go:700] Waited for 1.984312688s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:36:26.466577244Z I1024 14:36:26.466435       1 request.go:700] Waited for 2.191150137s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:36:27.466587318Z I1024 14:36:27.466501       1 request.go:700] Waited for 2.182876277s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:36:28.666156081Z I1024 14:36:28.666071       1 request.go:700] Waited for 1.990115008s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:36:29.865877374Z I1024 14:36:29.865799       1 request.go:700] Waited for 1.991207428s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:36:29.874194734Z I1024 14:36:29.874095       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 17, but has not made progress because static pod is pending
2024-10-24T14:36:30.866733968Z I1024 14:36:30.866658       1 request.go:700] Waited for 1.991537518s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:36:32.065891892Z I1024 14:36:32.065802       1 request.go:700] Waited for 1.992525068s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:36:34.275905398Z I1024 14:36:34.275827       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 17, but has not made progress because static pod is pending
2024-10-24T14:36:42.164002242Z I1024 14:36:42.163922       1 request.go:700] Waited for 1.185959283s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:36:43.164351406Z I1024 14:36:43.164256       1 request.go:700] Waited for 1.59196057s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:36:44.364028159Z I1024 14:36:44.363956       1 request.go:700] Waited for 1.392756692s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:36:45.763681200Z I1024 14:36:45.763588       1 request.go:700] Waited for 1.084667103s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T14:36:46.763654785Z I1024 14:36:46.763593       1 request.go:700] Waited for 1.691312471s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:36:47.764347979Z I1024 14:36:47.764252       1 request.go:700] Waited for 1.89353363s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T14:36:48.963499712Z I1024 14:36:48.963401       1 request.go:700] Waited for 1.79217441s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:36:49.964182616Z I1024 14:36:49.964092       1 request.go:700] Waited for 1.791365899s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:36:50.964181641Z I1024 14:36:50.964104       1 request.go:700] Waited for 1.79180167s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:36:52.163540104Z I1024 14:36:52.163465       1 request.go:700] Waited for 1.79187522s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:37:10.070488190Z I1024 14:37:10.070411       1 installer_controller.go:515] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T14:37:10.070488190Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T14:37:10.070488190Z  CurrentRevision: (int32) 17,
2024-10-24T14:37:10.070488190Z  TargetRevision: (int32) 0,
2024-10-24T14:37:10.070488190Z  LastFailedRevision: (int32) 0,
2024-10-24T14:37:10.070488190Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T14:37:10.070488190Z  LastFailedReason: (string) "",
2024-10-24T14:37:10.070488190Z  LastFailedCount: (int) 0,
2024-10-24T14:37:10.070488190Z  LastFallbackCount: (int) 0,
2024-10-24T14:37:10.070488190Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T14:37:10.070488190Z }
2024-10-24T14:37:10.070488190Z  because static pod is ready
2024-10-24T14:37:10.072220540Z W1024 14:37:10.072176       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:37:10.072220540Z W1024 14:37:10.072195       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:37:10.072220540Z W1024 14:37:10.072203       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:37:10.072220540Z W1024 14:37:10.072209       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:37:10.072220540Z W1024 14:37:10.072215       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T14:37:10.133684839Z I1024 14:37:10.133579       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 16 to 17 because static pod is ready
2024-10-24T14:37:10.137469770Z I1024 14:37:10.137356       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T14:37:10Z","message":"NodeInstallerProgressing: 3 nodes are at revision 17","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 17","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T14:37:10.160781690Z I1024 14:37:10.157222       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing changed from True to False ("NodeInstallerProgressing: 3 nodes are at revision 17"),Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 16; 2 nodes are at revision 17" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 17"
2024-10-24T14:37:11.202504774Z I1024 14:37:11.202405       1 request.go:700] Waited for 1.065111685s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T14:37:12.401937097Z I1024 14:37:12.401871       1 request.go:700] Waited for 2.242668318s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-17
2024-10-24T14:37:13.402216721Z I1024 14:37:13.402132       1 request.go:700] Waited for 2.591738515s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:37:14.601594265Z I1024 14:37:14.601531       1 request.go:700] Waited for 2.791993844s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-17
2024-10-24T14:37:15.602180799Z I1024 14:37:15.602101       1 request.go:700] Waited for 2.592665125s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:37:16.602389423Z I1024 14:37:16.602305       1 request.go:700] Waited for 2.393112566s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-10-24T14:37:17.602440577Z I1024 14:37:17.602374       1 request.go:700] Waited for 2.392413146s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:37:18.802288271Z I1024 14:37:18.802184       1 request.go:700] Waited for 2.191496488s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-10-24T14:37:19.802454916Z I1024 14:37:19.802369       1 request.go:700] Waited for 2.582245946s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-17-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:37:21.001599340Z I1024 14:37:21.001522       1 request.go:700] Waited for 2.989506675s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:37:22.002500045Z I1024 14:37:22.002415       1 request.go:700] Waited for 2.991124615s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:37:23.202532089Z I1024 14:37:23.202457       1 request.go:700] Waited for 2.990591325s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T14:37:24.402135732Z I1024 14:37:24.402073       1 request.go:700] Waited for 2.992236863s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:37:25.602643196Z I1024 14:37:25.602572       1 request.go:700] Waited for 2.191683218s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:37:26.802495189Z I1024 14:37:26.802423       1 request.go:700] Waited for 2.390756407s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:37:28.002579613Z I1024 14:37:28.002507       1 request.go:700] Waited for 2.390077338s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-17
2024-10-24T14:37:29.201916807Z I1024 14:37:29.201843       1 request.go:700] Waited for 2.190646479s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:37:30.202346464Z I1024 14:37:30.202272       1 request.go:700] Waited for 2.192776261s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:37:31.402307668Z I1024 14:37:31.402240       1 request.go:700] Waited for 1.592355463s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:37:46.107941321Z I1024 14:37:46.107857       1 request.go:700] Waited for 1.035311754s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:37:47.308146073Z I1024 14:37:47.308031       1 request.go:700] Waited for 1.58670908s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-17
2024-10-24T14:37:48.308465678Z I1024 14:37:48.308389       1 request.go:700] Waited for 1.791364699s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-17
2024-10-24T14:37:49.508374480Z I1024 14:37:49.508303       1 request.go:700] Waited for 1.59219s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:37:50.508374274Z I1024 14:37:50.508305       1 request.go:700] Waited for 1.59267573s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:38:46.112189542Z I1024 14:38:46.112105       1 request.go:700] Waited for 1.038450114s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:38:47.112377086Z I1024 14:38:47.112290       1 request.go:700] Waited for 1.240759192s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T14:38:48.112798650Z I1024 14:38:48.112724       1 request.go:700] Waited for 1.392683852s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:38:49.112865854Z I1024 14:38:49.112794       1 request.go:700] Waited for 1.391467742s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:38:50.113187888Z I1024 14:38:50.113117       1 request.go:700] Waited for 1.392800072s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:39:46.281090411Z I1024 14:39:46.280948       1 request.go:700] Waited for 1.189239193s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-17
2024-10-24T14:39:47.281448965Z I1024 14:39:47.281352       1 request.go:700] Waited for 1.391427722s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:39:48.480865458Z I1024 14:39:48.480764       1 request.go:700] Waited for 1.188353564s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:40:46.281540892Z I1024 14:40:46.281462       1 request.go:700] Waited for 1.193109183s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-17
2024-10-24T14:40:47.481559725Z I1024 14:40:47.481489       1 request.go:700] Waited for 1.391040052s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-17
2024-10-24T14:40:48.681076818Z I1024 14:40:48.680997       1 request.go:700] Waited for 1.392559672s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-config-openshift-kube-apiserver
2024-10-24T14:41:46.282378075Z I1024 14:41:46.282274       1 request.go:700] Waited for 1.193189593s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-17
2024-10-24T14:41:47.482282787Z I1024 14:41:47.482207       1 request.go:700] Waited for 1.393109033s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:41:48.682685510Z I1024 14:41:48.682595       1 request.go:700] Waited for 1.393538301s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-config-openshift-kube-apiserver
2024-10-24T14:42:10.398804840Z I1024 14:42:10.398711       1 request.go:700] Waited for 1.174643663s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:42:11.598102983Z I1024 14:42:11.598022       1 request.go:700] Waited for 1.992055588s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:42:12.598505637Z I1024 14:42:12.598408       1 request.go:700] Waited for 2.190122127s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:42:13.797967860Z I1024 14:42:13.797884       1 request.go:700] Waited for 2.183569527s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:42:14.219972697Z I1024 14:42:14.219906       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/user-client-ca -n openshift-kube-apiserver because it was missing
2024-10-24T14:42:14.224741957Z I1024 14:42:14.224667       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-10-24T14:42:14.224741957Z   	... // 4 identical entries
2024-10-24T14:42:14.224741957Z   	"imagePolicyConfig": map[string]any{"internalRegistryHostname": string("image-registry.openshift-image-registry.svc:5000")},
2024-10-24T14:42:14.224741957Z   	"servicesSubnet":    string("172.30.0.0/16"),
2024-10-24T14:42:14.224741957Z   	"servingInfo": map[string]any{
2024-10-24T14:42:14.224741957Z   		... // 2 identical entries
2024-10-24T14:42:14.224741957Z   		"cipherSuites":  []any{string("TLS_AES_128_GCM_SHA256"), string("TLS_AES_256_GCM_SHA384"), string("TLS_CHACHA20_POLY1305_SHA256"), string("TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"), ...},
2024-10-24T14:42:14.224741957Z   		"minTLSVersion": string("VersionTLS12"),
2024-10-24T14:42:14.224741957Z   		"namedCertificates": []any{
2024-10-24T14:42:14.224741957Z   			... // 3 identical elements
2024-10-24T14:42:14.224741957Z   			map[string]any{"certFile": string("/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-s"...), "keyFile": string("/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-s"...)},
2024-10-24T14:42:14.224741957Z   			map[string]any{"certFile": string("/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-"...), "keyFile": string("/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-"...)},
2024-10-24T14:42:14.224741957Z - 			map[string]any{
2024-10-24T14:42:14.224741957Z - 				"certFile": string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-000/tls.crt"),
2024-10-24T14:42:14.224741957Z - 				"keyFile":  string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-000/tls.key"),
2024-10-24T14:42:14.224741957Z - 			},
2024-10-24T14:42:14.224741957Z - 			map[string]any{
2024-10-24T14:42:14.224741957Z - 				"certFile": string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-001/tls.crt"),
2024-10-24T14:42:14.224741957Z - 				"keyFile":  string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-001/tls.key"),
2024-10-24T14:42:14.224741957Z - 			},
2024-10-24T14:42:14.224741957Z - 			map[string]any{
2024-10-24T14:42:14.224741957Z - 				"certFile": string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-002/tls.crt"),
2024-10-24T14:42:14.224741957Z - 				"keyFile":  string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-002/tls.key"),
2024-10-24T14:42:14.224741957Z - 			},
2024-10-24T14:42:14.224741957Z   		},
2024-10-24T14:42:14.224741957Z   	},
2024-10-24T14:42:14.224741957Z   }
2024-10-24T14:42:14.276425827Z I1024 14:42:14.276338       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-10-24T14:42:14.276425827Z   	... // 4 identical entries
2024-10-24T14:42:14.276425827Z   	"imagePolicyConfig": map[string]any{"internalRegistryHostname": string("image-registry.openshift-image-registry.svc:5000")},
2024-10-24T14:42:14.276425827Z   	"servicesSubnet":    string("172.30.0.0/16"),
2024-10-24T14:42:14.276425827Z   	"servingInfo": map[string]any{
2024-10-24T14:42:14.276425827Z   		... // 2 identical entries
2024-10-24T14:42:14.276425827Z   		"cipherSuites":  []any{string("TLS_AES_128_GCM_SHA256"), string("TLS_AES_256_GCM_SHA384"), string("TLS_CHACHA20_POLY1305_SHA256"), string("TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"), ...},
2024-10-24T14:42:14.276425827Z   		"minTLSVersion": string("VersionTLS12"),
2024-10-24T14:42:14.276425827Z   		"namedCertificates": []any{
2024-10-24T14:42:14.276425827Z   			... // 3 identical elements
2024-10-24T14:42:14.276425827Z   			map[string]any{"certFile": string("/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-s"...), "keyFile": string("/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-s"...)},
2024-10-24T14:42:14.276425827Z   			map[string]any{"certFile": string("/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-"...), "keyFile": string("/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-"...)},
2024-10-24T14:42:14.276425827Z - 			map[string]any{
2024-10-24T14:42:14.276425827Z - 				"certFile": string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-000/tls.crt"),
2024-10-24T14:42:14.276425827Z - 				"keyFile":  string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-000/tls.key"),
2024-10-24T14:42:14.276425827Z - 			},
2024-10-24T14:42:14.276425827Z - 			map[string]any{
2024-10-24T14:42:14.276425827Z - 				"certFile": string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-001/tls.crt"),
2024-10-24T14:42:14.276425827Z - 				"keyFile":  string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-001/tls.key"),
2024-10-24T14:42:14.276425827Z - 			},
2024-10-24T14:42:14.276425827Z - 			map[string]any{
2024-10-24T14:42:14.276425827Z - 				"certFile": string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-002/tls.crt"),
2024-10-24T14:42:14.276425827Z - 				"keyFile":  string("/etc/kubernetes/static-pod-certs/secrets/user-serving-cert-002/tls.key"),
2024-10-24T14:42:14.276425827Z - 			},
2024-10-24T14:42:14.276425827Z   		},
2024-10-24T14:42:14.276425827Z   	},
2024-10-24T14:42:14.276425827Z   }
2024-10-24T14:42:14.798479054Z I1024 14:42:14.798387       1 request.go:700] Waited for 2.189015797s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-17
2024-10-24T14:42:15.798852128Z I1024 14:42:15.798710       1 request.go:700] Waited for 2.191451917s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:42:16.998249241Z I1024 14:42:16.998170       1 request.go:700] Waited for 2.726683894s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T14:42:18.198030304Z I1024 14:42:18.197932       1 request.go:700] Waited for 2.780465644s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:42:19.198769308Z I1024 14:42:19.198659       1 request.go:700] Waited for 2.792296834s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:42:19.771462775Z I1024 14:42:19.771374       1 tlsconfig.go:181] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"admin-kubeconfig-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:31 +0000 UTC to 2034-10-22 12:49:31 +0000 UTC (now=2024-10-24 14:42:19.771322854 +0000 UTC))"
2024-10-24T14:42:19.771462775Z I1024 14:42:19.771424       1 tlsconfig.go:181] "Loaded client CA" index=1 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2024-10-25 12:49:34 +0000 UTC (now=2024-10-24 14:42:19.771406385 +0000 UTC))"
2024-10-24T14:42:19.771462775Z I1024 14:42:19.771445       1 tlsconfig.go:181] "Loaded client CA" index=2 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-control-plane-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2025-10-24 12:49:34 +0000 UTC (now=2024-10-24 14:42:19.771431675 +0000 UTC))"
2024-10-24T14:42:19.771522175Z I1024 14:42:19.771463       1 tlsconfig.go:181] "Loaded client CA" index=3 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-apiserver-to-kubelet-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2025-10-24 12:49:34 +0000 UTC (now=2024-10-24 14:42:19.771451205 +0000 UTC))"
2024-10-24T14:42:19.771522175Z I1024 14:42:19.771482       1 tlsconfig.go:181] "Loaded client CA" index=4 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-bootstrap-kubeconfig-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:32 +0000 UTC to 2034-10-22 12:49:32 +0000 UTC (now=2024-10-24 14:42:19.771469095 +0000 UTC))"
2024-10-24T14:42:19.771522175Z I1024 14:42:19.771501       1 tlsconfig.go:181] "Loaded client CA" index=5 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-csr-signer_@1729775012\" [] issuer=\"kubelet-signer\" (2024-10-24 13:03:31 +0000 UTC to 2024-10-25 12:49:34 +0000 UTC (now=2024-10-24 14:42:19.771488465 +0000 UTC))"
2024-10-24T14:42:19.771536575Z I1024 14:42:19.771519       1 tlsconfig.go:181] "Loaded client CA" index=6 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_node-system-admin-signer@1729775011\" [] issuer=\"<self>\" (2024-10-24 13:03:30 +0000 UTC to 2025-10-24 13:03:31 +0000 UTC (now=2024-10-24 14:42:19.771506915 +0000 UTC))"
2024-10-24T14:42:19.771582764Z I1024 14:42:19.771544       1 tlsconfig.go:181] "Loaded client CA" index=7 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"TestUserClientCABundleRootCA_3120422217834922768\" [] issuer=\"<self>\" (2023-10-24 14:42:09 +0000 UTC to 2025-10-24 14:42:09 +0000 UTC (now=2024-10-24 14:42:19.771529384 +0000 UTC))"
2024-10-24T14:42:19.771607595Z I1024 14:42:19.771579       1 tlsconfig.go:181] "Loaded client CA" index=8 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"aggregator-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:32 +0000 UTC to 2024-10-25 12:49:32 +0000 UTC (now=2024-10-24 14:42:19.771566924 +0000 UTC))"
2024-10-24T14:42:19.771618595Z I1024 14:42:19.771610       1 tlsconfig.go:181] "Loaded client CA" index=9 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_aggregator-client-signer@1729777579\" [] issuer=\"<self>\" (2024-10-24 13:46:18 +0000 UTC to 2024-10-25 01:46:19 +0000 UTC (now=2024-10-24 14:42:19.771591135 +0000 UTC))"
2024-10-24T14:42:19.771944545Z I1024 14:42:19.771877       1 tlsconfig.go:203] "Loaded serving cert" certName="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key" certDetail="\"metrics.openshift-kube-apiserver-operator.svc\" [serving] validServingFor=[metrics.openshift-kube-apiserver-operator.svc,metrics.openshift-kube-apiserver-operator.svc.cluster.local] issuer=\"openshift-service-serving-signer@1729775010\" (2024-10-24 13:03:41 +0000 UTC to 2026-10-24 13:03:42 +0000 UTC (now=2024-10-24 14:42:19.771847674 +0000 UTC))"
2024-10-24T14:42:19.772072955Z I1024 14:42:19.772038       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1729775940\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1729775940\" (2024-10-24 12:19:00 +0000 UTC to 2025-10-24 12:19:00 +0000 UTC (now=2024-10-24 14:42:19.772015295 +0000 UTC))"
2024-10-24T14:42:20.199997482Z I1024 14:42:20.199088       1 request.go:700] Waited for 2.591138725s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:42:21.398411995Z I1024 14:42:21.398330       1 request.go:700] Waited for 2.191896167s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:42:22.212594440Z I1024 14:42:22.211031       1 core.go:352] ConfigMap "openshift-config-managed/kube-apiserver-client-ca" changes: {"data":{"ca-bundle.crt":"-----BEGIN CERTIFICATE-----\nMIIDMDCCAhigAwIBAgIIKD8vK0yX72AwDQYJKoZIhvcNAQELBQAwNjESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSAwHgYDVQQDExdhZG1pbi1rdWJlY29uZmlnLXNpZ25lcjAe\nFw0yNDEwMjQxMjQ5MzFaFw0zNDEwMjIxMjQ5MzFaMDYxEjAQBgNVBAsTCW9wZW5z\naGlmdDEgMB4GA1UEAxMXYWRtaW4ta3ViZWNvbmZpZy1zaWduZXIwggEiMA0GCSqG\nSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDSy81Zc/XDsuCN+rMxfd1WU8gvoU7Wq+zp\n+M98eW7XxN1HuOYqdBOA4fGf3C5lwB9n1jf0B9luXHd+d8KBFs1G+8UpIzqsA15O\n9XScU0RH6pLvNLBd2D4g/q25VBXP8iWbu45D9BPoBHGXmandjxvt3r0DqVi6kyP7\nT4i2pxRocTWmQbqAHR2Cu3K9cbbstQsQc3+f+gS4TzFAaKK5UxXKpV4NI03dYidH\ndSBgEklrhV5+bW/CG4+aEgbRO3Qxq8kRufD+P/bLgvDYQenCVzIOyxWdfB/S2Gbs\nnBjqm218ju8VYxnDK3TUf2x5zUhhKo7L+bzD+DUOlc0Ao3I/6Wk/AgMBAAGjQjBA\nMA4GA1UdDwEB/wQEAwICpDAPBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBQUQoiE\nabSz6jdokVyDS8l7W3E2NDANBgkqhkiG9w0BAQsFAAOCAQEAuW15NmNUpYH2aaGM\noJSEsvxgiwOOwRwqGEmd6ZYhWR8eSjs9MaIy+Kho5Zlx5415F6hZ1GB9Uqc0heOD\nYwZqw7XXuhiL3uxgUXPUSWNhRgupReMa+D9V1ElTAb7TybWWivsqmlPE96q/RtKv\ngfmsfjI5aw1IgsKeMJ+iQuoh22su98EVqo6q3YJNl5uppt3j5uzTGAQjIJ9IWRU6\nlME8kY/tOyNwl3QiCcpln8gJZiphTfFbCG+CB4oEJip2JavOKQgRZCH3EX5zF2NL\n67VsNrTB4BgAuIJOQFvr+RWQlsHrk/U0yqMFtmcJGy21S0vFwmu6/J8q4LfzM8DG\nQw2gdQ==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDODCCAiCgAwIBAgIIYcZky+VIU0cwDQYJKoZIhvcNAQELBQAwLTESMBAGA1UE\nCxMJb3BlbnNoaWZ0MRcwFQYDVQQDEw5rdWJlbGV0LXNpZ25lcjAeFw0yNDEwMjQx\nMzAzMzFaFw0yNDEwMjUxMjQ5MzRaMCYxJDAiBgNVBAMMG2t1YmUtY3NyLXNpZ25l\ncl9AMTcyOTc3NTAxMjCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAKz8\n2CJMWXvIgMxl+F31YWHRGJyMCVmEkuNmSuwDkJu5uYsYKKiEIreKGWyZDYThU1BY\ns5inIPiFKLss/lFK6dS3TxHqAyfHrUo5xmSIuqEe9K3Rbu+Uw8QRmbJL0pAwNsPH\nx6FP4ueIKDZ8fzxUxBJtttcx5bNupd/nLT6b1zkpv1yQRJXcQcXY8+UGUZ6A5IGq\ntFa1gwQFdsWD1J+F7i9+KNx9+Od8K1IMrk/EOuQ3qJerimlN5V7+SduFMUlkoYDQ\nYvIj19yi6I4zi0I8bEri8pxtILQSADubn9NeBh7BqvUjhW1YNtJcok2uKvAzIS1j\n+/x/PN3j1JMU4vwTkskCAwEAAaNjMGEwDgYDVR0PAQH/BAQDAgKkMA8GA1UdEwEB\n/wQFMAMBAf8wHQYDVR0OBBYEFAQgUptCf64AH7y7XkwPafOhYsC5MB8GA1UdIwQY\nMBaAFE11bLLwwCVD8U4AZJ96Vk1SK9SVMA0GCSqGSIb3DQEBCwUAA4IBAQBopLGj\nVxHtwVp827laS2c63TL0CbW3+XVuIDL34Pkgz+U2GVzohnho331Q9Rid+7sgpNxv\nE2YL7ZOBybhWZICExDOIDH8ElvOFYoLl5u0/Gg1+KybFKBB5pVmcVTre3FIfQLjO\nLbRWEPey4/3NXGFvbuWOyZUmwcMBELCVY9kxr+IsqVWT8cuHd3X2f8PUFKpKsKmK\nzUyrbKFKJozIxNtFNJms7sWRuiTeySBzsUrlEYtg2gmDfvxl+vEXExvOCajMbVy8\nAG2Q+vX2xppdxnpeZsonLKu4bbHdASz/QE2XgbDPmBUavgy5E7QwDv7N/UoYhv/b\nQGJ0MIkbTu3/GM1f\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDHjCCAgagAwIBAgIIDJSZyXXaqawwDQYJKoZIhvcNAQELBQAwLTESMBAGA1UE\nCxMJb3BlbnNoaWZ0MRcwFQYDVQQDEw5rdWJlbGV0LXNpZ25lcjAeFw0yNDEwMjQx\nMjQ5MzRaFw0yNDEwMjUxMjQ5MzRaMC0xEjAQBgNVBAsTCW9wZW5zaGlmdDEXMBUG\nA1UEAxMOa3ViZWxldC1zaWduZXIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEK\nAoIBAQC8ZDuE8a9kq/gkpHinMhFa8wrcHbBPfgxsXRsO528D/qMJEDScjxTvQ6CZ\nK/jANjKk5TB9pppNSiOXwyIIPhGxPoa/vJvONdHWNglNxFajpz4JdCPD/ocxd1A+\nImVuKJ7U7ft+e1OwOZ11yrU4C9PmQPhwIP14GWgwM9liAuUX4MzdECw6RhmivGGt\n82z3gHwJh9sDHRQrRvj4qwZ3VYVqVLeNut3R7GLpXIX1Bo5RicWjJNx8v/D1s9EI\nr6eou3GWq+8r3oYZBMIQkdEzXX+Sry4AkdGy2JhLp2/bufeFE/cpX1ajyJghYCpb\nJCOTJnb5qm0xyQjW+fWERt8NDKcHAgMBAAGjQjBAMA4GA1UdDwEB/wQEAwICpDAP\nBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBRNdWyy8MAlQ/FOAGSfelZNUivUlTAN\nBgkqhkiG9w0BAQsFAAOCAQEAJyPzK6aRYpJjWaGorWKZg3w5IUdfc6YF9Eh4kUWs\nKSuVqaHyLISam2Igs3SO1Ek4G5+s51Ge0H4OYkUUX+wh/+6EwtXTqLvBqmy4gmmH\nvpDEVofcPfi8CU7wQTwIFHV8SjeOUbzQkrQ/cxeIBrVV/lf2SgdWLmId6DDhwMe2\nOLEBKIl5BzcBnAWCVDPXQ1aatrvgy8SPJNx8DZVZiOLso6pCK6A6i0yOPaPdVeub\nvfqEY3NmG3j//SFvcI7B4ET7dvI1Kafk97nNimLmNwCw6CzINXQdZcF8gHyurUeT\njzHqZjCIAEG8nK3/w67TYu8wf8KEP39PqpKYVqBqlxgIzg==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDQjCCAiqgAwIBAgIIIgBseiSWV6owDQYJKoZIhvcNAQELBQAwPzESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSkwJwYDVQQDEyBrdWJlLWFwaXNlcnZlci10by1rdWJlbGV0\nLXNpZ25lcjAeFw0yNDEwMjQxMjQ5MzRaFw0yNTEwMjQxMjQ5MzRaMD8xEjAQBgNV\nBAsTCW9wZW5zaGlmdDEpMCcGA1UEAxMga3ViZS1hcGlzZXJ2ZXItdG8ta3ViZWxl\ndC1zaWduZXIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDlVXO22DeG\nAeTZxLN/B82Kq5vVAOCGsfmxaRzvX2iR8reLVW0qBWqepmgMiYn3hWLDZ8kFSo/A\n27SX7cy+73H5l2foiv9lWDiG7HE9CUeZ0d3daRd5x7+dm9GWDHHQf9VlV0GMN4op\n4PM5cNkSf6KRcQa1Sz5cWDjVv0Bk31Dcrp4sSOhXcPQ4hhj9+K5EQ06zdaJ07mzL\nGGWJc6Xzd26kvQ0iK1YGq6RD1O8bq2C/2Ni6Oi54RZAAHKcbmnlez7yG4kPoKrjF\n3RTp1ruEyWq7av6C+kg8hWbKT0zqnJEKnoSfr/JXfWhwW2PRr7xkf3QXs3UwkQvL\nmw9xDrh28fXtAgMBAAGjQjBAMA4GA1UdDwEB/wQEAwICpDAPBgNVHRMBAf8EBTAD\nAQH/MB0GA1UdDgQWBBRlmmf8ji8J6xxD1bFp0i6684LyFDANBgkqhkiG9w0BAQsF\nAAOCAQEAs9OqLAdq7kOMJvkcOfTSWbbp3zeZ1OTGhXtHkg3zG8LQithOQAQc6XFE\n4ESxBenwnIqR94vVfVz3qtx+ieuu8VhRcNc/uHVD+Ywm9Ep4Krs285zpTRgK5hOS\nR8YpSyZaJAX6W1B0oJxaDzv3IQ1KftrR7cQnNHxLo8d6ZjGZbQZ714eLIZVSjbGO\nZvipuWsqlUfW/7MCom6fM4+iUiGRrgDFKJp6huTj2I+j013B+mAxL0J6OWxuKWCB\nPvcdPaQjvx1yZQy04RIw53i3JnBVd5NiZ19YiTZaMg9s9mmii3FoobvqZtcnugax\nU1Zmat96zSEq55TFjwnuxud41FBUzg==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDNDCCAhygAwIBAgIIX9+YZ8stdGMwDQYJKoZIhvcNAQELBQAwODESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSIwIAYDVQQDExlrdWJlLWNvbnRyb2wtcGxhbmUtc2lnbmVy\nMB4XDTI0MTAyNDEyNDkzNFoXDTI1MTAyNDEyNDkzNFowODESMBAGA1UECxMJb3Bl\nbnNoaWZ0MSIwIAYDVQQDExlrdWJlLWNvbnRyb2wtcGxhbmUtc2lnbmVyMIIBIjAN\nBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvJ4Ozu5GmdsVCYHQXe4bJ9Psetgu\nNM4u1DcVFI8isazuqTabJ+HoX5myu8Z3fH4ByUUxqiZhPR+pQzkfep/V+HWtLnPh\niSP6bouQ6uLILc6dm9Me02BWEKavsYEJtcraat5unOkFmz4S0WXb9bxC4c88TPhV\nTeRELAcNV9ppC0+/aNDucZJVyTrL23dWdj55EQR5Qbw7hrFLkX/dlsacbrum5FGI\n06md6/z3IBMQdu6jRgGNsYR4FfTu9U9shJTcJFhtcyeavYdFn3E6jln40psIrrlE\n9y5hEb6IHMhc+WEIeTYsjeFOt+6PMztm07/DlR/TdPV1ZwQYlKLeIcS9zwIDAQAB\no0IwQDAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQU\nAHHcAKEWg0AykllPyrh5YlVqTREwDQYJKoZIhvcNAQELBQADggEBAEHrMBG1K2/T\nODtEE8OKKqQhmxep1/t3l+PxAwY1q/qKmOSdqzR/XWpjxnWr4NKcQ6z5/I2OmTsT\nQR5rPa6QFdidie6o+w3vK94aigaLaJh6sfRRhLGxQPLHvzgm6mH+qyNLZ9/L01qn\noLSl65xXjZU7A0NiPS41jAAxDdLfnpJ0b5993yJl823EdCv7RR4abAXKV1CZ5uRA\n9/psJzQfY3oRgQs8X0JLJTD87aygUIjKritPUJq3+eRIt6gDZVbdFjni+IskhbwX\n2jdq96aMyepUky3WvLk/lDH+ObsVhFU8dGwNdYmVyeaK1jOZCgLTCApIdlXninmz\n49++6WDY9GY=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDOjCCAiKgAwIBAgIIK033eXNJgxAwDQYJKoZIhvcNAQELBQAwOzE5MDcGA1UE\nAwwwVGVzdFVzZXJDbGllbnRDQUJ1bmRsZVJvb3RDQV8zMTIwNDIyMjE3ODM0OTIy\nNzY4MB4XDTIzMTAyNDE0NDIwOVoXDTI1MTAyNDE0NDIwOVowOzE5MDcGA1UEAwww\nVGVzdFVzZXJDbGllbnRDQUJ1bmRsZVJvb3RDQV8zMTIwNDIyMjE3ODM0OTIyNzY4\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA5N9751pTg40lCekACzl0\nO21ldWystOPp2kYimOyvfkcKFn/j93JBqqcCdMK2Poaap/vFvj3jeiuGyVFriutK\nS5M76OwEfIBP6d6liJA24QlaeNgQ4nmNrSgfxXOEFTJmxGvXRhGWu7BnmeWBw2TM\nTqbcP2SmHZIPV4ljgKByf51sFQlSphbtMF4rOz6wFQ3ihJ1u0rWEHCK9sCfMFAVk\ngwzA87LVwvcXdrIvqlatoro6wTW0CVUAdNxQFlIK0e32Kf9kF+FbkshipVl2GvsQ\nF9mkVIIEGHKwju71EsnZqawh9SZjaolI2UbSlvJ2mlM1WIGoVj8DDiZWzUnOlPBA\nZwIDAQABo0IwQDAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/BAUwAwEB/zAdBgNV\nHQ4EFgQU1cl+IVo3ESsElayuXv6rUIjFIy4wDQYJKoZIhvcNAQELBQADggEBAKhO\n3dpFfLGJUDfSO1y0eBW5ZBzJtIjEh5Uc5EESuMn5T9K88KhRQGoiD0owvpEmC+T4\ntIGUrjaRaLJnCfHs655hB4MSSbMFvplzguGDqrerLmPUojRotwgBNGk+RCSQLj2k\nZfhZXKC0eSOwihQ2/oJUxlz2vGEjJN0PWX8xTNBvTrjLFOqCuqo2nhcr/XGI8wsh\nP3NLT2M5PBsSacfk8+WQqEW9OOvDeuxB6wYbxZRv2HhdtjOYAqsB5pMwgC7mTA7X\nJn8hVlEMc1Xhg1plutgiPSz0hmyepGP1lhtetXbzNAeqFj4f53nvv2+sOtJz/glZ\nEUHtB4m6dcF+REqkkX0=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDSDCCAjCgAwIBAgIIfLx9YwB4GnYwDQYJKoZIhvcNAQELBQAwQjESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSwwKgYDVQQDEyNrdWJlbGV0LWJvb3RzdHJhcC1rdWJlY29u\nZmlnLXNpZ25lcjAeFw0yNDEwMjQxMjQ5MzJaFw0zNDEwMjIxMjQ5MzJaMEIxEjAQ\nBgNVBAsTCW9wZW5zaGlmdDEsMCoGA1UEAxMja3ViZWxldC1ib290c3RyYXAta3Vi\nZWNvbmZpZy1zaWduZXIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDm\nY3WOK6mc00bqmADeGDIwpdqodyLvdwIRu6QVSIAGYevh9wS1xldkkyXzl+I2uSmX\n2QVATv6si2x+j8kw8bkQywB9FuGTAjYhLJeZKZvS5XVlzE2rwpdTdiLz7YPwsvjA\ne2HfEDdpRYs/KMNe2Q5jkXxZ1aE0/+rkRLbOXGEBWyc8uGCeLENLvQD4JP+0myR/\n14uG/h1E5NV3ZxbXF7DhCZoR9s1sAg6jWyZ4UfanKHNAtWc9IJs2bXc0a+Qo85nE\nnyNCzaj3px9IOzry09za41usQ1x4REG8wU2uyzq12UMpJsPQLXPyOlrBGA5vKpUh\no4PS07kCWJqSfMULkkjXAgMBAAGjQjBAMA4GA1UdDwEB/wQEAwICpDAPBgNVHRMB\nAf8EBTADAQH/MB0GA1UdDgQWBBRSmNqjIChvurEDBbBgQp4FgUip6DANBgkqhkiG\n9w0BAQsFAAOCAQEAglc4Sl2P+uGbmcosZx7EqMLkWAubCJS4GV/eYhb6cr7MsG8R\nG6xI8twLTe5M27hBVegHjvBhCkmJRykKipDcmdFQEDOnYs17vBzSx4jE8x6J9w8v\nl1aycBwSb51wsMLiLybT7ZnmffZyW48y631LEq+U9bQXSo1maGKQlReugmaIC/3H\nxZR5sQdhWKI37bI7S+6Ch2DmHAxvf4Pt4xJXcJVR3E4Vl10xTh4i7+6i5dFFBySt\n9+6wP6jBX/2nThuVU+YzczdnyQGwhjrAhhw6SBi2OYorGO0T57fWolrwins9H7VU\nG8HL94fUHZPmtCxg0zfxDp/HqTRIzdy8MzSk+g==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDhTCCAm2gAwIBAgIIbLwL36EOiOowDQYJKoZIhvcNAQELBQAwUDFOMEwGA1UE\nAwxFb3BlbnNoaWZ0LWt1YmUtYXBpc2VydmVyLW9wZXJhdG9yX25vZGUtc3lzdGVt\nLWFkbWluLXNpZ25lckAxNzI5Nzc1MDExMB4XDTI0MTAyNDEzMDMzMFoXDTI1MTAy\nNDEzMDMzMVowUDFOMEwGA1UEAwxFb3BlbnNoaWZ0LWt1YmUtYXBpc2VydmVyLW9w\nZXJhdG9yX25vZGUtc3lzdGVtLWFkbWluLXNpZ25lckAxNzI5Nzc1MDExMIIBIjAN\nBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA0rwLgZyX7Ck9N4YXVdlJMkDFf+U2\n3W2ZkDGvqzEVck9Zy+7shyke4DlSMbu0arrhMvhhnMBe4dAQsB9Yca7tE2SobJ/S\nxlfFDS3YdeZ1gEZthB6c5m3yzATpX/HSJjZVOLdDKjQAaEyAFNGClPgLBTLxzXdb\nqCIyrt5rCzLrwFvt8E1WEqDg6Xw7xHiijD/YxBfDtGBpOvFqarj1M16P0izQj2FE\niK4b37dxau7cBxpCNOoEHFX7i5MPtDfHs9+CNMdlLnCE+umP0MPhmtwJJqn/4PnP\nJemqNWJggiG7GoHD+RBvzqH5wxVwhVF+ZrE97IB7RBWMewzi/WJHCBzl7wIDAQAB\no2MwYTAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQU\nZqGk2rMImW2jow19uGgRPv72rLMwHwYDVR0jBBgwFoAUZqGk2rMImW2jow19uGgR\nPv72rLMwDQYJKoZIhvcNAQELBQADggEBAKTgEbJ8eMwbwWCadRrdpHMJjxYrHBsI\njSoORNqgsSyNefbQDCtRmi/sLmfg4+2S9Vq6TqUaK1rnrcO7vC8Olp2zoAWVbx+p\nNK6fsSruwXsDAiVuzt6PITwvc7kPHYLMUdMDlL+BS4Q9GIaudixe5l9M+RcF51DM\nXXJt18jKEijbwuBu6SDM5RlZIWdvr083pNDWF27F2oENcgsxDQw8bYeE/BDAdKgY\n/OUb2PAflN8ZMoFHkVJ5Krvvdlv+Zi90+D+ps5CKqhTNZ0Jedojp73j11UYs+HI2\nRdRpwfsWa1qrlBcR/mk9lD0YetMrG0YNWpLHEYW45AtPqYKYV/ZnBas=\n-----END CERTIFICATE-----\n"},"metadata":{"creationTimestamp":"2024-10-24T13:04:50Z","managedFields":[{"apiVersion":"v1","fieldsType":"FieldsV1","fieldsV1":{"f:data":{".":{},"f:ca-bundle.crt":{}},"f:metadata":{"f:annotations":{".":{},"f:openshift.io/owning-component":{}}}},"manager":"cluster-kube-apiserver-operator","operation":"Update","time":"2024-10-24T14:42:19Z"}],"resourceVersion":null,"uid":"2334d5ec-c98f-4489-b76a-11b72ef76a50"}}
2024-10-24T14:42:22.217088730Z I1024 14:42:22.217035       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/kube-apiserver-client-ca -n openshift-config-managed:
2024-10-24T14:42:22.217088730Z cause by changes in data.ca-bundle.crt
2024-10-24T14:42:22.398986519Z I1024 14:42:22.398917       1 request.go:700] Waited for 2.699805214s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:42:23.598985632Z I1024 14:42:23.598903       1 request.go:700] Waited for 2.784523874s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:42:24.798896005Z I1024 14:42:24.798694       1 request.go:700] Waited for 2.576739824s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/user-client-ca
2024-10-24T14:42:24.821097274Z I1024 14:42:24.821028       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveAdditionalCORSAllowedOrigins' corsAllowedOrigins changed to ["//127\\.0\\.0\\.1(:|$)" "//localhost(:|$)" "//valid.domain.com(:|$)"]
2024-10-24T14:42:24.824219075Z I1024 14:42:24.824129       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-10-24T14:42:24.824219075Z   	"admission":          map[string]any{"pluginConfig": map[string]any{"PodSecurity": map[string]any{"configuration": map[string]any{"defaults": map[string]any{"audit": string("restricted"), "audit-version": string("latest"), "enforce": string("restricted"), "enforce-version": string("latest"), ...}}}, "network.openshift.io/ExternalIPRanger": map[string]any{"configuration": map[string]any{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]any{"configuration": map[string]any{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []any{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2024-10-24T14:42:24.824219075Z   	"apiServerArguments": map[string]any{"api-audiences": []any{string("https://kubernetes.default.svc")}, "authentication-token-webhook-config-file": []any{string("/etc/kubernetes/static-pod-resources/secrets/webhook-authenticat"...)}, "authentication-token-webhook-version": []any{string("v1")}, "encryption-provider-config": []any{string("/etc/kubernetes/static-pod-resources/secrets/encryption-config/e"...)}, ...},
2024-10-24T14:42:24.824219075Z   	"authConfig":         map[string]any{"oauthMetadataFile": string("/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/o"...)},
2024-10-24T14:42:24.824219075Z   	"corsAllowedOrigins": []any{
2024-10-24T14:42:24.824219075Z   		string(`//127\.0\.0\.1(:|$)`),
2024-10-24T14:42:24.824219075Z   		string("//localhost(:|$)"),
2024-10-24T14:42:24.824219075Z + 		string("//valid.domain.com(:|$)"),
2024-10-24T14:42:24.824219075Z   	},
2024-10-24T14:42:24.824219075Z   	"imagePolicyConfig": map[string]any{"internalRegistryHostname": string("image-registry.openshift-image-registry.svc:5000")},
2024-10-24T14:42:24.824219075Z   	"servicesSubnet":    string("172.30.0.0/16"),
2024-10-24T14:42:24.824219075Z   	"servingInfo":       map[string]any{"bindAddress": string("0.0.0.0:6443"), "bindNetwork": string("tcp4"), "cipherSuites": []any{string("TLS_AES_128_GCM_SHA256"), string("TLS_AES_256_GCM_SHA384"), string("TLS_CHACHA20_POLY1305_SHA256"), string("TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"), ...}, "minTLSVersion": string("VersionTLS12"), ...},
2024-10-24T14:42:24.824219075Z   }
2024-10-24T14:42:24.872372504Z I1024 14:42:24.872300       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveAdditionalCORSAllowedOrigins' corsAllowedOrigins changed to ["//127\\.0\\.0\\.1(:|$)" "//localhost(:|$)" "//valid.domain.com(:|$)"]
2024-10-24T14:42:24.877334024Z I1024 14:42:24.877238       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-10-24T14:42:24.877334024Z   	"admission":          map[string]any{"pluginConfig": map[string]any{"PodSecurity": map[string]any{"configuration": map[string]any{"defaults": map[string]any{"audit": string("restricted"), "audit-version": string("latest"), "enforce": string("restricted"), "enforce-version": string("latest"), ...}}}, "network.openshift.io/ExternalIPRanger": map[string]any{"configuration": map[string]any{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]any{"configuration": map[string]any{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []any{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2024-10-24T14:42:24.877334024Z   	"apiServerArguments": map[string]any{"api-audiences": []any{string("https://kubernetes.default.svc")}, "authentication-token-webhook-config-file": []any{string("/etc/kubernetes/static-pod-resources/secrets/webhook-authenticat"...)}, "authentication-token-webhook-version": []any{string("v1")}, "encryption-provider-config": []any{string("/etc/kubernetes/static-pod-resources/secrets/encryption-config/e"...)}, ...},
2024-10-24T14:42:24.877334024Z   	"authConfig":         map[string]any{"oauthMetadataFile": string("/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/o"...)},
2024-10-24T14:42:24.877334024Z   	"corsAllowedOrigins": []any{
2024-10-24T14:42:24.877334024Z   		string(`//127\.0\.0\.1(:|$)`),
2024-10-24T14:42:24.877334024Z   		string("//localhost(:|$)"),
2024-10-24T14:42:24.877334024Z + 		string("//valid.domain.com(:|$)"),
2024-10-24T14:42:24.877334024Z   	},
2024-10-24T14:42:24.877334024Z   	"imagePolicyConfig": map[string]any{"internalRegistryHostname": string("image-registry.openshift-image-registry.svc:5000")},
2024-10-24T14:42:24.877334024Z   	"servicesSubnet":    string("172.30.0.0/16"),
2024-10-24T14:42:24.877334024Z   	"servingInfo":       map[string]any{"bindAddress": string("0.0.0.0:6443"), "bindNetwork": string("tcp4"), "cipherSuites": []any{string("TLS_AES_128_GCM_SHA256"), string("TLS_AES_256_GCM_SHA384"), string("TLS_CHACHA20_POLY1305_SHA256"), string("TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"), ...}, "minTLSVersion": string("VersionTLS12"), ...},
2024-10-24T14:42:24.877334024Z   }
2024-10-24T14:42:25.361414391Z I1024 14:42:25.361348       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveAdditionalCORSAllowedOrigins' corsAllowedOrigins changed to ["//127\\.0\\.0\\.1(:|$)" "//domain.foreign.it(:|$)" "//localhost(:|$)" "//something.*.now(:|$)"]
2024-10-24T14:42:25.368219241Z I1024 14:42:25.368112       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-10-24T14:42:25.368219241Z   	"admission":          map[string]any{"pluginConfig": map[string]any{"PodSecurity": map[string]any{"configuration": map[string]any{"defaults": map[string]any{"audit": string("restricted"), "audit-version": string("latest"), "enforce": string("restricted"), "enforce-version": string("latest"), ...}}}, "network.openshift.io/ExternalIPRanger": map[string]any{"configuration": map[string]any{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]any{"configuration": map[string]any{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []any{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2024-10-24T14:42:25.368219241Z   	"apiServerArguments": map[string]any{"api-audiences": []any{string("https://kubernetes.default.svc")}, "authentication-token-webhook-config-file": []any{string("/etc/kubernetes/static-pod-resources/secrets/webhook-authenticat"...)}, "authentication-token-webhook-version": []any{string("v1")}, "encryption-provider-config": []any{string("/etc/kubernetes/static-pod-resources/secrets/encryption-config/e"...)}, ...},
2024-10-24T14:42:25.368219241Z   	"authConfig":         map[string]any{"oauthMetadataFile": string("/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/o"...)},
2024-10-24T14:42:25.368219241Z   	"corsAllowedOrigins": []any{
2024-10-24T14:42:25.368219241Z   		string(`//127\.0\.0\.1(:|$)`),
2024-10-24T14:42:25.368219241Z + 		string("//domain.foreign.it(:|$)"),
2024-10-24T14:42:25.368219241Z   		string("//localhost(:|$)"),
2024-10-24T14:42:25.368219241Z - 		string("//valid.domain.com(:|$)"),
2024-10-24T14:42:25.368219241Z + 		string("//something.*.now(:|$)"),
2024-10-24T14:42:25.368219241Z   	},
2024-10-24T14:42:25.368219241Z   	"imagePolicyConfig": map[string]any{"internalRegistryHostname": string("image-registry.openshift-image-registry.svc:5000")},
2024-10-24T14:42:25.368219241Z   	"servicesSubnet":    string("172.30.0.0/16"),
2024-10-24T14:42:25.368219241Z   	"servingInfo":       map[string]any{"bindAddress": string("0.0.0.0:6443"), "bindNetwork": string("tcp4"), "cipherSuites": []any{string("TLS_AES_128_GCM_SHA256"), string("TLS_AES_256_GCM_SHA384"), string("TLS_CHACHA20_POLY1305_SHA256"), string("TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"), ...}, "minTLSVersion": string("VersionTLS12"), ...},
2024-10-24T14:42:25.368219241Z   }
2024-10-24T14:42:25.536023710Z I1024 14:42:25.535968       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveAdditionalCORSAllowedOrigins' corsAllowedOrigins changed to ["//127\\.0\\.0\\.1(:|$)" "//localhost(:|$)"]
2024-10-24T14:42:25.537002460Z I1024 14:42:25.536971       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-10-24T14:42:25.537002460Z   	"admission":          map[string]any{"pluginConfig": map[string]any{"PodSecurity": map[string]any{"configuration": map[string]any{"defaults": map[string]any{"audit": string("restricted"), "audit-version": string("latest"), "enforce": string("restricted"), "enforce-version": string("latest"), ...}}}, "network.openshift.io/ExternalIPRanger": map[string]any{"configuration": map[string]any{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]any{"configuration": map[string]any{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []any{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2024-10-24T14:42:25.537002460Z   	"apiServerArguments": map[string]any{"api-audiences": []any{string("https://kubernetes.default.svc")}, "authentication-token-webhook-config-file": []any{string("/etc/kubernetes/static-pod-resources/secrets/webhook-authenticat"...)}, "authentication-token-webhook-version": []any{string("v1")}, "encryption-provider-config": []any{string("/etc/kubernetes/static-pod-resources/secrets/encryption-config/e"...)}, ...},
2024-10-24T14:42:25.537002460Z   	"authConfig":         map[string]any{"oauthMetadataFile": string("/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/o"...)},
2024-10-24T14:42:25.537002460Z   	"corsAllowedOrigins": []any{
2024-10-24T14:42:25.537002460Z   		string(`//127\.0\.0\.1(:|$)`),
2024-10-24T14:42:25.537002460Z - 		string("//domain.foreign.it(:|$)"),
2024-10-24T14:42:25.537002460Z   		string("//localhost(:|$)"),
2024-10-24T14:42:25.537002460Z - 		string("//something.*.now(:|$)"),
2024-10-24T14:42:25.537002460Z   	},
2024-10-24T14:42:25.537002460Z   	"imagePolicyConfig": map[string]any{"internalRegistryHostname": string("image-registry.openshift-image-registry.svc:5000")},
2024-10-24T14:42:25.537002460Z   	"servicesSubnet":    string("172.30.0.0/16"),
2024-10-24T14:42:25.537002460Z   	"servingInfo":       map[string]any{"bindAddress": string("0.0.0.0:6443"), "bindNetwork": string("tcp4"), "cipherSuites": []any{string("TLS_AES_128_GCM_SHA256"), string("TLS_AES_256_GCM_SHA384"), string("TLS_CHACHA20_POLY1305_SHA256"), string("TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"), ...}, "minTLSVersion": string("VersionTLS12"), ...},
2024-10-24T14:42:25.537002460Z   }
2024-10-24T14:42:25.602908620Z I1024 14:42:25.602828       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveAdditionalCORSAllowedOrigins' corsAllowedOrigins changed to ["//127\\.0\\.0\\.1(:|$)" "//localhost(:|$)"]
2024-10-24T14:42:25.603312470Z I1024 14:42:25.603251       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-10-24T14:42:25.603312470Z   	"admission":          map[string]any{"pluginConfig": map[string]any{"PodSecurity": map[string]any{"configuration": map[string]any{"defaults": map[string]any{"audit": string("restricted"), "audit-version": string("latest"), "enforce": string("restricted"), "enforce-version": string("latest"), ...}}}, "network.openshift.io/ExternalIPRanger": map[string]any{"configuration": map[string]any{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]any{"configuration": map[string]any{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []any{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2024-10-24T14:42:25.603312470Z   	"apiServerArguments": map[string]any{"api-audiences": []any{string("https://kubernetes.default.svc")}, "authentication-token-webhook-config-file": []any{string("/etc/kubernetes/static-pod-resources/secrets/webhook-authenticat"...)}, "authentication-token-webhook-version": []any{string("v1")}, "encryption-provider-config": []any{string("/etc/kubernetes/static-pod-resources/secrets/encryption-config/e"...)}, ...},
2024-10-24T14:42:25.603312470Z   	"authConfig":         map[string]any{"oauthMetadataFile": string("/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/o"...)},
2024-10-24T14:42:25.603312470Z   	"corsAllowedOrigins": []any{
2024-10-24T14:42:25.603312470Z   		string(`//127\.0\.0\.1(:|$)`),
2024-10-24T14:42:25.603312470Z - 		string("//domain.foreign.it(:|$)"),
2024-10-24T14:42:25.603312470Z   		string("//localhost(:|$)"),
2024-10-24T14:42:25.603312470Z - 		string("//something.*.now(:|$)"),
2024-10-24T14:42:25.603312470Z   	},
2024-10-24T14:42:25.603312470Z   	"imagePolicyConfig": map[string]any{"internalRegistryHostname": string("image-registry.openshift-image-registry.svc:5000")},
2024-10-24T14:42:25.603312470Z   	"servicesSubnet":    string("172.30.0.0/16"),
2024-10-24T14:42:25.603312470Z   	"servingInfo":       map[string]any{"bindAddress": string("0.0.0.0:6443"), "bindNetwork": string("tcp4"), "cipherSuites": []any{string("TLS_AES_128_GCM_SHA256"), string("TLS_AES_256_GCM_SHA384"), string("TLS_CHACHA20_POLY1305_SHA256"), string("TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"), ...}, "minTLSVersion": string("VersionTLS12"), ...},
2024-10-24T14:42:25.603312470Z   }
2024-10-24T14:42:25.998988838Z I1024 14:42:25.998930       1 request.go:700] Waited for 2.392210916s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2024-10-24T14:42:27.198692120Z I1024 14:42:27.198621       1 request.go:700] Waited for 2.384290795s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:42:28.198737295Z I1024 14:42:28.198674       1 request.go:700] Waited for 2.786993503s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:42:29.398334807Z I1024 14:42:29.398261       1 request.go:700] Waited for 2.790890793s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:42:30.398341341Z I1024 14:42:30.398274       1 request.go:700] Waited for 2.782614093s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T14:42:31.399127095Z I1024 14:42:31.399031       1 request.go:700] Waited for 2.789920213s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:42:31.625460734Z I1024 14:42:31.625385       1 core.go:352] ConfigMap "openshift-kube-apiserver/config" changes: {"apiVersion":"v1","data":{"config.yaml":"{\"admission\":{\"pluginConfig\":{\"PodSecurity\":{\"configuration\":{\"apiVersion\":\"pod-security.admission.config.k8s.io/v1\",\"defaults\":{\"audit\":\"restricted\",\"audit-version\":\"latest\",\"enforce\":\"restricted\",\"enforce-version\":\"latest\",\"warn\":\"restricted\",\"warn-version\":\"latest\"},\"exemptions\":{\"usernames\":[\"system:serviceaccount:openshift-infra:build-controller\"]},\"kind\":\"PodSecurityConfiguration\"}},\"network.openshift.io/ExternalIPRanger\":{\"configuration\":{\"allowIngressIP\":false,\"apiVersion\":\"network.openshift.io/v1\",\"externalIPNetworkCIDRs\":null,\"kind\":\"ExternalIPRangerAdmissionConfig\"},\"location\":\"\"},\"network.openshift.io/RestrictedEndpointsAdmission\":{\"configuration\":{\"apiVersion\":\"network.openshift.io/v1\",\"kind\":\"RestrictedEndpointsAdmissionConfig\",\"restrictedCIDRs\":[\"10.128.0.0/14\",\"172.30.0.0/16\"]}}}},\"apiServerArguments\":{\"allow-privileged\":[\"true\"],\"anonymous-auth\":[\"true\"],\"api-audiences\":[\"https://kubernetes.default.svc\"],\"audit-log-format\":[\"json\"],\"audit-log-maxbackup\":[\"10\"],\"audit-log-maxsize\":[\"200\"],\"audit-log-path\":[\"/var/log/kube-apiserver/audit.log\"],\"audit-policy-file\":[\"/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-audit-policies/policy.yaml\"],\"authentication-token-webhook-config-file\":[\"/etc/kubernetes/static-pod-resources/secrets/webhook-authenticator/kubeConfig\"],\"authentication-token-webhook-version\":[\"v1\"],\"authorization-mode\":[\"Scope\",\"SystemMasters\",\"RBAC\",\"Node\"],\"client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/client-ca/ca-bundle.crt\"],\"enable-admission-plugins\":[\"CertificateApproval\",\"CertificateSigning\",\"CertificateSubjectRestriction\",\"DefaultIngressClass\",\"DefaultStorageClass\",\"DefaultTolerationSeconds\",\"LimitRanger\",\"MutatingAdmissionWebhook\",\"NamespaceLifecycle\",\"NodeRestriction\",\"OwnerReferencesPermissionEnforcement\",\"PersistentVolumeClaimResize\",\"PodNodeSelector\",\"PodTolerationRestriction\",\"Priority\",\"ResourceQuota\",\"RuntimeClass\",\"ServiceAccount\",\"StorageObjectInUseProtection\",\"TaintNodesByCondition\",\"ValidatingAdmissionWebhook\",\"ValidatingAdmissionPolicy\",\"authorization.openshift.io/RestrictSubjectBindings\",\"authorization.openshift.io/ValidateRoleBindingRestriction\",\"config.openshift.io/DenyDeleteClusterConfiguration\",\"config.openshift.io/ValidateAPIServer\",\"config.openshift.io/ValidateAuthentication\",\"config.openshift.io/ValidateConsole\",\"config.openshift.io/ValidateFeatureGate\",\"config.openshift.io/ValidateImage\",\"config.openshift.io/ValidateOAuth\",\"config.openshift.io/ValidateProject\",\"config.openshift.io/ValidateScheduler\",\"image.openshift.io/ImagePolicy\",\"network.openshift.io/ExternalIPRanger\",\"network.openshift.io/RestrictedEndpointsAdmission\",\"quota.openshift.io/ClusterResourceQuota\",\"quota.openshift.io/ValidateClusterResourceQuota\",\"route.openshift.io/IngressAdmission\",\"scheduling.openshift.io/OriginPodNodeEnvironment\",\"security.openshift.io/DefaultSecurityContextConstraints\",\"security.openshift.io/SCCExecRestrictions\",\"security.openshift.io/SecurityContextConstraint\",\"security.openshift.io/ValidateSecurityContextConstraints\",\"storage.openshift.io/CSIInlineVolumeSecurity\"],\"enable-aggregator-routing\":[\"true\"],\"enable-logs-handler\":[\"false\"],\"encryption-provider-config\":[\"/etc/kubernetes/static-pod-resources/secrets/encryption-config/encryption-config\"],\"endpoint-reconciler-type\":[\"lease\"],\"etcd-cafile\":[\"/etc/kubernetes/static-pod-resources/configmaps/etcd-serving-ca/ca-bundle.crt\"],\"etcd-certfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.crt\"],\"etcd-healthcheck-timeout\":[\"9s\"],\"etcd-keyfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.key\"],\"etcd-prefix\":[\"kubernetes.io\"],\"etcd-readycheck-timeout\":[\"9s\"],\"etcd-servers\":[\"https://10.0.0.3:2379\",\"https://10.0.0.4:2379\",\"https://10.0.0.6:2379\",\"https://localhost:2379\"],\"event-ttl\":[\"3h\"],\"feature-gates\":[\"AWSEFSDriverVolumeMetrics=true\",\"AdminNetworkPolicy=true\",\"AlibabaPlatform=true\",\"AzureWorkloadIdentity=true\",\"BareMetalLoadBalancer=true\",\"BuildCSIVolumes=true\",\"ChunkSizeMiB=true\",\"CloudDualStackNodeIPs=true\",\"DisableKubeletCloudCredentialProviders=true\",\"GCPLabelsTags=true\",\"HardwareSpeed=true\",\"IngressControllerLBSubnetsAWS=true\",\"KMSv1=true\",\"ManagedBootImages=true\",\"MetricsServer=true\",\"MultiArchInstallAWS=true\",\"MultiArchInstallGCP=true\",\"NetworkDiagnosticsConfig=true\",\"NetworkLiveMigration=true\",\"NodeDisruptionPolicy=true\",\"OpenShiftPodSecurityAdmission=true\",\"PrivateHostedZoneAWS=true\",\"SetEIPForNLBIngressController=true\",\"VSphereControlPlaneMachineSet=true\",\"VSphereDriverConfiguration=true\",\"VSphereStaticIPs=true\",\"ValidatingAdmissionPolicy=true\",\"AWSClusterHostedDNS=false\",\"AdditionalRoutingCapabilities=false\",\"AutomatedEtcdBackup=false\",\"BootcNodeManagement=false\",\"CSIDriverSharedResource=false\",\"ClusterAPIInstall=false\",\"ClusterAPIInstallIBMCloud=false\",\"ClusterMonitoringConfig=false\",\"DNSNameResolver=false\",\"DynamicResourceAllocation=false\",\"EtcdBackendQuota=false\",\"EventedPLEG=false\",\"Example=false\",\"ExternalOIDC=false\",\"GCPClusterHostedDNS=false\",\"GatewayAPI=false\",\"ImageStreamImportMode=false\",\"IngressControllerDynamicConfigurationManager=false\",\"InsightsConfig=false\",\"InsightsConfigAPI=false\",\"InsightsOnDemandDataGather=false\",\"InsightsRuntimeExtractor=false\",\"MachineAPIMigration=false\",\"MachineAPIOperatorDisableMachineHealthCheckController=false\",\"MachineAPIProviderOpenStack=false\",\"MachineConfigNodes=false\",\"ManagedBootImagesAWS=false\",\"MaxUnavailableStatefulSet=false\",\"MetricsCollectionProfiles=false\",\"MixedCPUsAllocation=false\",\"MultiArchInstallAzure=false\",\"NetworkSegmentation=false\",\"NewOLM=false\",\"NodeSwap=false\",\"OVNObservability=false\",\"OnClusterBuild=false\",\"PersistentIPsForVirtualization=false\",\"PinnedImages=false\",\"PlatformOperators=false\",\"ProcMountType=false\",\"RouteAdvertisements=false\",\"RouteExternalCertificate=false\",\"ServiceAccountTokenNodeBinding=false\",\"SignatureStores=false\",\"SigstoreImageVerification=false\",\"TranslateStreamCloseWebsocketRequests=false\",\"UpgradeStatus=false\",\"UserNamespacesPodSecurityStandards=false\",\"UserNamespacesSupport=false\",\"VSphereMultiNetworks=false\",\"VSphereMultiVCenters=false\",\"VolumeGroupSnapshot=false\"],\"goaway-chance\":[\"0\"],\"http2-max-streams-per-connection\":[\"2000\"],\"kubelet-certificate-authority\":[\"/etc/kubernetes/static-pod-resources/configmaps/kubelet-serving-ca/ca-bundle.crt\"],\"kubelet-client-certificate\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.crt\"],\"kubelet-client-key\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.key\"],\"kubelet-preferred-address-types\":[\"InternalIP\"],\"kubelet-read-only-port\":[\"0\"],\"kubernetes-service-node-port\":[\"0\"],\"max-mutating-requests-inflight\":[\"1000\"],\"max-requests-inflight\":[\"3000\"],\"min-request-timeout\":[\"3600\"],\"proxy-client-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.crt\"],\"proxy-client-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.key\"],\"requestheader-allowed-names\":[\"kube-apiserver-proxy\",\"system:kube-apiserver-proxy\",\"system:openshift-aggregator\"],\"requestheader-client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/aggregator-client-ca/ca-bundle.crt\"],\"requestheader-extra-headers-prefix\":[\"X-Remote-Extra-\"],\"requestheader-group-headers\":[\"X-Remote-Group\"],\"requestheader-username-headers\":[\"X-Remote-User\"],\"runtime-config\":[\"admissionregistration.k8s.io/v1beta1=true\"],\"send-retry-after-while-not-ready-once\":[\"false\"],\"service-account-issuer\":[\"https://kubernetes.default.svc\"],\"service-account-jwks-uri\":[\"https://api.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX:6443/openid/v1/jwks\"],\"service-account-lookup\":[\"true\"],\"service-account-signing-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/bound-service-account-signing-key/service-account.key\"],\"service-node-port-range\":[\"30000-32767\"],\"shutdown-delay-duration\":[\"70s\"],\"shutdown-send-retry-after\":[\"true\"],\"storage-backend\":[\"etcd3\"],\"storage-media-type\":[\"application/vnd.kubernetes.protobuf\"],\"strict-transport-security-directives\":[\"max-age=31536000,includeSubDomains,preload\"],\"tls-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\"],\"tls-private-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"]},\"apiVersion\":\"kubecontrolplane.config.openshift.io/v1\",\"authConfig\":{\"oauthMetadataFile\":\"/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/oauthMetadata\"},\"consolePublicURL\":\"\",\"corsAllowedOrigins\":[\"//127\\\\.0\\\\.0\\\\.1(:|$)\",\"//localhost(:|$)\"],\"imagePolicyConfig\":{\"internalRegistryHostname\":\"image-registry.openshift-image-registry.svc:5000\"},\"kind\":\"KubeAPIServerConfig\",\"projectConfig\":{\"defaultNodeSelector\":\"\"},\"serviceAccountPublicKeyFiles\":[\"/etc/kubernetes/static-pod-resources/configmaps/sa-token-signing-certs\",\"/etc/kubernetes/static-pod-resources/configmaps/bound-sa-token-signing-certs\"],\"servicesSubnet\":\"172.30.0.0/16\",\"servingInfo\":{\"bindAddress\":\"0.0.0.0:6443\",\"bindNetwork\":\"tcp4\",\"cipherSuites\":[\"TLS_AES_128_GCM_SHA256\",\"TLS_AES_256_GCM_SHA384\",\"TLS_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"],\"minTLSVersion\":\"VersionTLS12\",\"namedCertificates\":[{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.key\"}]}}"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T14:42:31.626963454Z I1024 14:42:31.626922       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/config -n openshift-kube-apiserver:
2024-10-24T14:42:31.626963454Z cause by changes in data.config.yaml
2024-10-24T14:42:31.630343954Z I1024 14:42:31.630288       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 18 triggered by "required configmap/config has changed"
2024-10-24T14:42:32.598447748Z I1024 14:42:32.598378       1 request.go:700] Waited for 2.887689934s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/configmaps/kube-apiserver-client-ca
2024-10-24T14:42:32.617822238Z I1024 14:42:32.617716       1 core.go:352] ConfigMap "openshift-config-managed/kube-apiserver-client-ca" changes: {"data":{"ca-bundle.crt":"-----BEGIN CERTIFICATE-----\nMIIDMDCCAhigAwIBAgIIKD8vK0yX72AwDQYJKoZIhvcNAQELBQAwNjESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSAwHgYDVQQDExdhZG1pbi1rdWJlY29uZmlnLXNpZ25lcjAe\nFw0yNDEwMjQxMjQ5MzFaFw0zNDEwMjIxMjQ5MzFaMDYxEjAQBgNVBAsTCW9wZW5z\naGlmdDEgMB4GA1UEAxMXYWRtaW4ta3ViZWNvbmZpZy1zaWduZXIwggEiMA0GCSqG\nSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDSy81Zc/XDsuCN+rMxfd1WU8gvoU7Wq+zp\n+M98eW7XxN1HuOYqdBOA4fGf3C5lwB9n1jf0B9luXHd+d8KBFs1G+8UpIzqsA15O\n9XScU0RH6pLvNLBd2D4g/q25VBXP8iWbu45D9BPoBHGXmandjxvt3r0DqVi6kyP7\nT4i2pxRocTWmQbqAHR2Cu3K9cbbstQsQc3+f+gS4TzFAaKK5UxXKpV4NI03dYidH\ndSBgEklrhV5+bW/CG4+aEgbRO3Qxq8kRufD+P/bLgvDYQenCVzIOyxWdfB/S2Gbs\nnBjqm218ju8VYxnDK3TUf2x5zUhhKo7L+bzD+DUOlc0Ao3I/6Wk/AgMBAAGjQjBA\nMA4GA1UdDwEB/wQEAwICpDAPBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBQUQoiE\nabSz6jdokVyDS8l7W3E2NDANBgkqhkiG9w0BAQsFAAOCAQEAuW15NmNUpYH2aaGM\noJSEsvxgiwOOwRwqGEmd6ZYhWR8eSjs9MaIy+Kho5Zlx5415F6hZ1GB9Uqc0heOD\nYwZqw7XXuhiL3uxgUXPUSWNhRgupReMa+D9V1ElTAb7TybWWivsqmlPE96q/RtKv\ngfmsfjI5aw1IgsKeMJ+iQuoh22su98EVqo6q3YJNl5uppt3j5uzTGAQjIJ9IWRU6\nlME8kY/tOyNwl3QiCcpln8gJZiphTfFbCG+CB4oEJip2JavOKQgRZCH3EX5zF2NL\n67VsNrTB4BgAuIJOQFvr+RWQlsHrk/U0yqMFtmcJGy21S0vFwmu6/J8q4LfzM8DG\nQw2gdQ==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDODCCAiCgAwIBAgIIYcZky+VIU0cwDQYJKoZIhvcNAQELBQAwLTESMBAGA1UE\nCxMJb3BlbnNoaWZ0MRcwFQYDVQQDEw5rdWJlbGV0LXNpZ25lcjAeFw0yNDEwMjQx\nMzAzMzFaFw0yNDEwMjUxMjQ5MzRaMCYxJDAiBgNVBAMMG2t1YmUtY3NyLXNpZ25l\ncl9AMTcyOTc3NTAxMjCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAKz8\n2CJMWXvIgMxl+F31YWHRGJyMCVmEkuNmSuwDkJu5uYsYKKiEIreKGWyZDYThU1BY\ns5inIPiFKLss/lFK6dS3TxHqAyfHrUo5xmSIuqEe9K3Rbu+Uw8QRmbJL0pAwNsPH\nx6FP4ueIKDZ8fzxUxBJtttcx5bNupd/nLT6b1zkpv1yQRJXcQcXY8+UGUZ6A5IGq\ntFa1gwQFdsWD1J+F7i9+KNx9+Od8K1IMrk/EOuQ3qJerimlN5V7+SduFMUlkoYDQ\nYvIj19yi6I4zi0I8bEri8pxtILQSADubn9NeBh7BqvUjhW1YNtJcok2uKvAzIS1j\n+/x/PN3j1JMU4vwTkskCAwEAAaNjMGEwDgYDVR0PAQH/BAQDAgKkMA8GA1UdEwEB\n/wQFMAMBAf8wHQYDVR0OBBYEFAQgUptCf64AH7y7XkwPafOhYsC5MB8GA1UdIwQY\nMBaAFE11bLLwwCVD8U4AZJ96Vk1SK9SVMA0GCSqGSIb3DQEBCwUAA4IBAQBopLGj\nVxHtwVp827laS2c63TL0CbW3+XVuIDL34Pkgz+U2GVzohnho331Q9Rid+7sgpNxv\nE2YL7ZOBybhWZICExDOIDH8ElvOFYoLl5u0/Gg1+KybFKBB5pVmcVTre3FIfQLjO\nLbRWEPey4/3NXGFvbuWOyZUmwcMBELCVY9kxr+IsqVWT8cuHd3X2f8PUFKpKsKmK\nzUyrbKFKJozIxNtFNJms7sWRuiTeySBzsUrlEYtg2gmDfvxl+vEXExvOCajMbVy8\nAG2Q+vX2xppdxnpeZsonLKu4bbHdASz/QE2XgbDPmBUavgy5E7QwDv7N/UoYhv/b\nQGJ0MIkbTu3/GM1f\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDHjCCAgagAwIBAgIIDJSZyXXaqawwDQYJKoZIhvcNAQELBQAwLTESMBAGA1UE\nCxMJb3BlbnNoaWZ0MRcwFQYDVQQDEw5rdWJlbGV0LXNpZ25lcjAeFw0yNDEwMjQx\nMjQ5MzRaFw0yNDEwMjUxMjQ5MzRaMC0xEjAQBgNVBAsTCW9wZW5zaGlmdDEXMBUG\nA1UEAxMOa3ViZWxldC1zaWduZXIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEK\nAoIBAQC8ZDuE8a9kq/gkpHinMhFa8wrcHbBPfgxsXRsO528D/qMJEDScjxTvQ6CZ\nK/jANjKk5TB9pppNSiOXwyIIPhGxPoa/vJvONdHWNglNxFajpz4JdCPD/ocxd1A+\nImVuKJ7U7ft+e1OwOZ11yrU4C9PmQPhwIP14GWgwM9liAuUX4MzdECw6RhmivGGt\n82z3gHwJh9sDHRQrRvj4qwZ3VYVqVLeNut3R7GLpXIX1Bo5RicWjJNx8v/D1s9EI\nr6eou3GWq+8r3oYZBMIQkdEzXX+Sry4AkdGy2JhLp2/bufeFE/cpX1ajyJghYCpb\nJCOTJnb5qm0xyQjW+fWERt8NDKcHAgMBAAGjQjBAMA4GA1UdDwEB/wQEAwICpDAP\nBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBRNdWyy8MAlQ/FOAGSfelZNUivUlTAN\nBgkqhkiG9w0BAQsFAAOCAQEAJyPzK6aRYpJjWaGorWKZg3w5IUdfc6YF9Eh4kUWs\nKSuVqaHyLISam2Igs3SO1Ek4G5+s51Ge0H4OYkUUX+wh/+6EwtXTqLvBqmy4gmmH\nvpDEVofcPfi8CU7wQTwIFHV8SjeOUbzQkrQ/cxeIBrVV/lf2SgdWLmId6DDhwMe2\nOLEBKIl5BzcBnAWCVDPXQ1aatrvgy8SPJNx8DZVZiOLso6pCK6A6i0yOPaPdVeub\nvfqEY3NmG3j//SFvcI7B4ET7dvI1Kafk97nNimLmNwCw6CzINXQdZcF8gHyurUeT\njzHqZjCIAEG8nK3/w67TYu8wf8KEP39PqpKYVqBqlxgIzg==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDQjCCAiqgAwIBAgIIIgBseiSWV6owDQYJKoZIhvcNAQELBQAwPzESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSkwJwYDVQQDEyBrdWJlLWFwaXNlcnZlci10by1rdWJlbGV0\nLXNpZ25lcjAeFw0yNDEwMjQxMjQ5MzRaFw0yNTEwMjQxMjQ5MzRaMD8xEjAQBgNV\nBAsTCW9wZW5zaGlmdDEpMCcGA1UEAxMga3ViZS1hcGlzZXJ2ZXItdG8ta3ViZWxl\ndC1zaWduZXIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDlVXO22DeG\nAeTZxLN/B82Kq5vVAOCGsfmxaRzvX2iR8reLVW0qBWqepmgMiYn3hWLDZ8kFSo/A\n27SX7cy+73H5l2foiv9lWDiG7HE9CUeZ0d3daRd5x7+dm9GWDHHQf9VlV0GMN4op\n4PM5cNkSf6KRcQa1Sz5cWDjVv0Bk31Dcrp4sSOhXcPQ4hhj9+K5EQ06zdaJ07mzL\nGGWJc6Xzd26kvQ0iK1YGq6RD1O8bq2C/2Ni6Oi54RZAAHKcbmnlez7yG4kPoKrjF\n3RTp1ruEyWq7av6C+kg8hWbKT0zqnJEKnoSfr/JXfWhwW2PRr7xkf3QXs3UwkQvL\nmw9xDrh28fXtAgMBAAGjQjBAMA4GA1UdDwEB/wQEAwICpDAPBgNVHRMBAf8EBTAD\nAQH/MB0GA1UdDgQWBBRlmmf8ji8J6xxD1bFp0i6684LyFDANBgkqhkiG9w0BAQsF\nAAOCAQEAs9OqLAdq7kOMJvkcOfTSWbbp3zeZ1OTGhXtHkg3zG8LQithOQAQc6XFE\n4ESxBenwnIqR94vVfVz3qtx+ieuu8VhRcNc/uHVD+Ywm9Ep4Krs285zpTRgK5hOS\nR8YpSyZaJAX6W1B0oJxaDzv3IQ1KftrR7cQnNHxLo8d6ZjGZbQZ714eLIZVSjbGO\nZvipuWsqlUfW/7MCom6fM4+iUiGRrgDFKJp6huTj2I+j013B+mAxL0J6OWxuKWCB\nPvcdPaQjvx1yZQy04RIw53i3JnBVd5NiZ19YiTZaMg9s9mmii3FoobvqZtcnugax\nU1Zmat96zSEq55TFjwnuxud41FBUzg==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDNDCCAhygAwIBAgIIX9+YZ8stdGMwDQYJKoZIhvcNAQELBQAwODESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSIwIAYDVQQDExlrdWJlLWNvbnRyb2wtcGxhbmUtc2lnbmVy\nMB4XDTI0MTAyNDEyNDkzNFoXDTI1MTAyNDEyNDkzNFowODESMBAGA1UECxMJb3Bl\nbnNoaWZ0MSIwIAYDVQQDExlrdWJlLWNvbnRyb2wtcGxhbmUtc2lnbmVyMIIBIjAN\nBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvJ4Ozu5GmdsVCYHQXe4bJ9Psetgu\nNM4u1DcVFI8isazuqTabJ+HoX5myu8Z3fH4ByUUxqiZhPR+pQzkfep/V+HWtLnPh\niSP6bouQ6uLILc6dm9Me02BWEKavsYEJtcraat5unOkFmz4S0WXb9bxC4c88TPhV\nTeRELAcNV9ppC0+/aNDucZJVyTrL23dWdj55EQR5Qbw7hrFLkX/dlsacbrum5FGI\n06md6/z3IBMQdu6jRgGNsYR4FfTu9U9shJTcJFhtcyeavYdFn3E6jln40psIrrlE\n9y5hEb6IHMhc+WEIeTYsjeFOt+6PMztm07/DlR/TdPV1ZwQYlKLeIcS9zwIDAQAB\no0IwQDAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQU\nAHHcAKEWg0AykllPyrh5YlVqTREwDQYJKoZIhvcNAQELBQADggEBAEHrMBG1K2/T\nODtEE8OKKqQhmxep1/t3l+PxAwY1q/qKmOSdqzR/XWpjxnWr4NKcQ6z5/I2OmTsT\nQR5rPa6QFdidie6o+w3vK94aigaLaJh6sfRRhLGxQPLHvzgm6mH+qyNLZ9/L01qn\noLSl65xXjZU7A0NiPS41jAAxDdLfnpJ0b5993yJl823EdCv7RR4abAXKV1CZ5uRA\n9/psJzQfY3oRgQs8X0JLJTD87aygUIjKritPUJq3+eRIt6gDZVbdFjni+IskhbwX\n2jdq96aMyepUky3WvLk/lDH+ObsVhFU8dGwNdYmVyeaK1jOZCgLTCApIdlXninmz\n49++6WDY9GY=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDSDCCAjCgAwIBAgIIfLx9YwB4GnYwDQYJKoZIhvcNAQELBQAwQjESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSwwKgYDVQQDEyNrdWJlbGV0LWJvb3RzdHJhcC1rdWJlY29u\nZmlnLXNpZ25lcjAeFw0yNDEwMjQxMjQ5MzJaFw0zNDEwMjIxMjQ5MzJaMEIxEjAQ\nBgNVBAsTCW9wZW5zaGlmdDEsMCoGA1UEAxMja3ViZWxldC1ib290c3RyYXAta3Vi\nZWNvbmZpZy1zaWduZXIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDm\nY3WOK6mc00bqmADeGDIwpdqodyLvdwIRu6QVSIAGYevh9wS1xldkkyXzl+I2uSmX\n2QVATv6si2x+j8kw8bkQywB9FuGTAjYhLJeZKZvS5XVlzE2rwpdTdiLz7YPwsvjA\ne2HfEDdpRYs/KMNe2Q5jkXxZ1aE0/+rkRLbOXGEBWyc8uGCeLENLvQD4JP+0myR/\n14uG/h1E5NV3ZxbXF7DhCZoR9s1sAg6jWyZ4UfanKHNAtWc9IJs2bXc0a+Qo85nE\nnyNCzaj3px9IOzry09za41usQ1x4REG8wU2uyzq12UMpJsPQLXPyOlrBGA5vKpUh\no4PS07kCWJqSfMULkkjXAgMBAAGjQjBAMA4GA1UdDwEB/wQEAwICpDAPBgNVHRMB\nAf8EBTADAQH/MB0GA1UdDgQWBBRSmNqjIChvurEDBbBgQp4FgUip6DANBgkqhkiG\n9w0BAQsFAAOCAQEAglc4Sl2P+uGbmcosZx7EqMLkWAubCJS4GV/eYhb6cr7MsG8R\nG6xI8twLTe5M27hBVegHjvBhCkmJRykKipDcmdFQEDOnYs17vBzSx4jE8x6J9w8v\nl1aycBwSb51wsMLiLybT7ZnmffZyW48y631LEq+U9bQXSo1maGKQlReugmaIC/3H\nxZR5sQdhWKI37bI7S+6Ch2DmHAxvf4Pt4xJXcJVR3E4Vl10xTh4i7+6i5dFFBySt\n9+6wP6jBX/2nThuVU+YzczdnyQGwhjrAhhw6SBi2OYorGO0T57fWolrwins9H7VU\nG8HL94fUHZPmtCxg0zfxDp/HqTRIzdy8MzSk+g==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDhTCCAm2gAwIBAgIIbLwL36EOiOowDQYJKoZIhvcNAQELBQAwUDFOMEwGA1UE\nAwxFb3BlbnNoaWZ0LWt1YmUtYXBpc2VydmVyLW9wZXJhdG9yX25vZGUtc3lzdGVt\nLWFkbWluLXNpZ25lckAxNzI5Nzc1MDExMB4XDTI0MTAyNDEzMDMzMFoXDTI1MTAy\nNDEzMDMzMVowUDFOMEwGA1UEAwxFb3BlbnNoaWZ0LWt1YmUtYXBpc2VydmVyLW9w\nZXJhdG9yX25vZGUtc3lzdGVtLWFkbWluLXNpZ25lckAxNzI5Nzc1MDExMIIBIjAN\nBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA0rwLgZyX7Ck9N4YXVdlJMkDFf+U2\n3W2ZkDGvqzEVck9Zy+7shyke4DlSMbu0arrhMvhhnMBe4dAQsB9Yca7tE2SobJ/S\nxlfFDS3YdeZ1gEZthB6c5m3yzATpX/HSJjZVOLdDKjQAaEyAFNGClPgLBTLxzXdb\nqCIyrt5rCzLrwFvt8E1WEqDg6Xw7xHiijD/YxBfDtGBpOvFqarj1M16P0izQj2FE\niK4b37dxau7cBxpCNOoEHFX7i5MPtDfHs9+CNMdlLnCE+umP0MPhmtwJJqn/4PnP\nJemqNWJggiG7GoHD+RBvzqH5wxVwhVF+ZrE97IB7RBWMewzi/WJHCBzl7wIDAQAB\no2MwYTAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQU\nZqGk2rMImW2jow19uGgRPv72rLMwHwYDVR0jBBgwFoAUZqGk2rMImW2jow19uGgR\nPv72rLMwDQYJKoZIhvcNAQELBQADggEBAKTgEbJ8eMwbwWCadRrdpHMJjxYrHBsI\njSoORNqgsSyNefbQDCtRmi/sLmfg4+2S9Vq6TqUaK1rnrcO7vC8Olp2zoAWVbx+p\nNK6fsSruwXsDAiVuzt6PITwvc7kPHYLMUdMDlL+BS4Q9GIaudixe5l9M+RcF51DM\nXXJt18jKEijbwuBu6SDM5RlZIWdvr083pNDWF27F2oENcgsxDQw8bYeE/BDAdKgY\n/OUb2PAflN8ZMoFHkVJ5Krvvdlv+Zi90+D+ps5CKqhTNZ0Jedojp73j11UYs+HI2\nRdRpwfsWa1qrlBcR/mk9lD0YetMrG0YNWpLHEYW45AtPqYKYV/ZnBas=\n-----END CERTIFICATE-----\n"},"metadata":{"creationTimestamp":"2024-10-24T13:04:50Z","managedFields":[{"apiVersion":"v1","fieldsType":"FieldsV1","fieldsV1":{"f:data":{".":{},"f:ca-bundle.crt":{}},"f:metadata":{"f:annotations":{".":{},"f:openshift.io/owning-component":{}}}},"manager":"cluster-kube-apiserver-operator","operation":"Update","time":"2024-10-24T14:42:29Z"}],"resourceVersion":null,"uid":"2334d5ec-c98f-4489-b76a-11b72ef76a50"}}
2024-10-24T14:42:32.618859738Z I1024 14:42:32.618679       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/kube-apiserver-client-ca -n openshift-config-managed:
2024-10-24T14:42:32.618859738Z cause by changes in data.ca-bundle.crt
2024-10-24T14:42:33.598894513Z I1024 14:42:33.598811       1 request.go:700] Waited for 2.692579584s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T14:42:34.798143205Z I1024 14:42:34.798062       1 request.go:700] Waited for 2.986472112s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:42:35.798839149Z I1024 14:42:35.798738       1 request.go:700] Waited for 2.784351923s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:42:37.002944972Z I1024 14:42:37.002891       1 request.go:700] Waited for 2.795162724s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:42:37.414471620Z I1024 14:42:37.414388       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-18 -n openshift-kube-apiserver because it was missing
2024-10-24T14:42:38.198366325Z I1024 14:42:38.198301       1 request.go:700] Waited for 2.589812325s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:42:39.398434828Z I1024 14:42:39.398337       1 request.go:700] Waited for 2.591591505s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-17
2024-10-24T14:42:40.011227874Z I1024 14:42:40.011148       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-18 -n openshift-kube-apiserver because it was missing
2024-10-24T14:42:40.598050381Z I1024 14:42:40.597980       1 request.go:700] Waited for 2.589623005s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-17-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:42:41.598514115Z I1024 14:42:41.598432       1 request.go:700] Waited for 2.492738635s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T14:42:42.608008149Z I1024 14:42:42.607940       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-18 -n openshift-kube-apiserver because it was missing
2024-10-24T14:42:42.797981668Z I1024 14:42:42.797914       1 request.go:700] Waited for 2.591272735s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:42:43.998291320Z I1024 14:42:43.998224       1 request.go:700] Waited for 2.391742406s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:42:44.816191505Z I1024 14:42:44.816097       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/oauth-metadata-18 -n openshift-kube-apiserver because it was missing
2024-10-24T14:42:44.999013784Z I1024 14:42:44.998936       1 request.go:700] Waited for 2.193266717s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:42:46.198540667Z I1024 14:42:46.198476       1 request.go:700] Waited for 2.115987667s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:42:46.808623474Z I1024 14:42:46.808555       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-18 -n openshift-kube-apiserver because it was missing
2024-10-24T14:42:47.198575311Z I1024 14:42:47.198508       1 request.go:700] Waited for 2.123494967s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:42:48.198774005Z I1024 14:42:48.198677       1 request.go:700] Waited for 3.115690151s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:42:48.755514732Z I1024 14:42:48.755411       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2024-10-24T14:42:49.398350868Z I1024 14:42:49.398256       1 request.go:700] Waited for 3.083967712s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-10-24T14:42:49.808440816Z I1024 14:42:49.808383       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-18 -n openshift-kube-apiserver because it was missing
2024-10-24T14:42:50.398775322Z I1024 14:42:50.398674       1 request.go:700] Waited for 2.790938413s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-17
2024-10-24T14:42:51.598136216Z I1024 14:42:51.598072       1 request.go:700] Waited for 2.788670463s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:42:52.609672040Z I1024 14:42:52.609520       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-18 -n openshift-kube-apiserver because it was missing
2024-10-24T14:42:52.798162799Z I1024 14:42:52.798097       1 request.go:700] Waited for 2.791372953s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:42:53.798808503Z I1024 14:42:53.798713       1 request.go:700] Waited for 2.790106863s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:42:54.998896635Z I1024 14:42:54.998805       1 request.go:700] Waited for 2.717183304s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:42:55.410691743Z I1024 14:42:55.410630       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-18 -n openshift-kube-apiserver because it was missing
2024-10-24T14:42:56.198771748Z I1024 14:42:56.198678       1 request.go:700] Waited for 2.788972313s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:42:57.398081671Z I1024 14:42:57.398004       1 request.go:700] Waited for 2.590129344s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:42:58.009823407Z I1024 14:42:58.009721       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-18 -n openshift-kube-apiserver because it was missing
2024-10-24T14:42:58.398101655Z I1024 14:42:58.398009       1 request.go:700] Waited for 2.588297285s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-17
2024-10-24T14:42:59.398430649Z I1024 14:42:59.398363       1 request.go:700] Waited for 2.591981234s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-17-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:43:00.599061962Z I1024 14:43:00.598982       1 request.go:700] Waited for 2.589331635s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-10-24T14:43:00.612089292Z I1024 14:43:00.611973       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-18 -n openshift-kube-apiserver because it was missing
2024-10-24T14:43:01.798386324Z I1024 14:43:01.798307       1 request.go:700] Waited for 2.590827225s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:43:02.998961147Z I1024 14:43:02.998896       1 request.go:700] Waited for 2.584477594s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:43:03.213999646Z I1024 14:43:03.213822       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-18 -n openshift-kube-apiserver because it was missing
2024-10-24T14:43:04.198896960Z I1024 14:43:04.198829       1 request.go:700] Waited for 2.192506637s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-17-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:43:05.398699283Z I1024 14:43:05.398610       1 request.go:700] Waited for 2.186871057s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets
2024-10-24T14:43:05.411013023Z I1024 14:43:05.410935       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/encryption-config-18 -n openshift-kube-apiserver because it was missing
2024-10-24T14:43:06.399153277Z I1024 14:43:06.399071       1 request.go:700] Waited for 2.592547684s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:43:07.599059020Z I1024 14:43:07.598981       1 request.go:700] Waited for 2.592236004s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:43:08.011224658Z I1024 14:43:08.011152       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-18 -n openshift-kube-apiserver because it was missing
2024-10-24T14:43:08.798461403Z I1024 14:43:08.798381       1 request.go:700] Waited for 2.588622105s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:43:09.798648717Z I1024 14:43:09.798584       1 request.go:700] Waited for 2.391694536s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:43:10.412613593Z I1024 14:43:10.412536       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-18 -n openshift-kube-apiserver because it was missing
2024-10-24T14:43:10.798694341Z I1024 14:43:10.798635       1 request.go:700] Waited for 2.393855256s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:43:11.998826554Z I1024 14:43:11.998764       1 request.go:700] Waited for 2.191238127s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:43:12.612128990Z I1024 14:43:12.611338       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-18 -n openshift-kube-apiserver because it was missing
2024-10-24T14:43:13.198347437Z I1024 14:43:13.198271       1 request.go:700] Waited for 2.341374006s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T14:43:14.198875231Z I1024 14:43:14.198787       1 request.go:700] Waited for 2.384616116s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:43:15.009713496Z I1024 14:43:15.009624       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 18 triggered by "required configmap/config has changed"
2024-10-24T14:43:15.011123326Z W1024 14:43:15.011079       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:43:15.011123326Z W1024 14:43:15.011105       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:43:15.043068216Z W1024 14:43:15.043004       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:43:15.043625836Z W1024 14:43:15.043574       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:43:15.398794954Z I1024 14:43:15.398720       1 request.go:700] Waited for 2.390140525s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-17
2024-10-24T14:43:16.598918436Z I1024 14:43:16.598860       1 request.go:700] Waited for 2.591827324s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:43:17.798792629Z I1024 14:43:17.798711       1 request.go:700] Waited for 2.755944433s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:43:18.999053122Z I1024 14:43:18.998979       1 request.go:700] Waited for 2.792307984s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:43:20.198041275Z I1024 14:43:20.197956       1 request.go:700] Waited for 2.786695643s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:43:21.198249519Z I1024 14:43:21.198184       1 request.go:700] Waited for 2.590541995s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-17
2024-10-24T14:43:22.198783863Z I1024 14:43:22.198684       1 request.go:700] Waited for 2.193460407s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:43:23.397996496Z I1024 14:43:23.397930       1 request.go:700] Waited for 2.192066567s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:43:24.398555280Z I1024 14:43:24.398431       1 request.go:700] Waited for 2.118861967s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:43:25.600816963Z I1024 14:43:25.599079       1 request.go:700] Waited for 1.990472239s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:43:26.798858226Z I1024 14:43:26.798785       1 request.go:700] Waited for 1.993218788s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods
2024-10-24T14:43:26.829978166Z I1024 14:43:26.829921       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-18-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-apiserver because it was missing
2024-10-24T14:43:27.998995809Z I1024 14:43:27.998933       1 request.go:700] Waited for 1.167977563s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:43:29.198324772Z I1024 14:43:29.198247       1 request.go:700] Waited for 2.361070826s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:43:30.018791207Z I1024 14:43:30.018696       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-18-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-apiserver because it was missing
2024-10-24T14:43:30.398710235Z I1024 14:43:30.398652       1 request.go:700] Waited for 2.385507376s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-10-24T14:43:31.398927699Z I1024 14:43:31.398816       1 request.go:700] Waited for 2.718381134s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-10-24T14:43:32.599084502Z I1024 14:43:32.599006       1 request.go:700] Waited for 2.791850873s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-10-24T14:43:33.798814604Z I1024 14:43:33.798721       1 request.go:700] Waited for 2.792952463s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:43:34.998653027Z I1024 14:43:34.998589       1 request.go:700] Waited for 2.790676723s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T14:43:35.615999464Z I1024 14:43:35.615922       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-18-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-apiserver because it was missing
2024-10-24T14:43:36.198100440Z I1024 14:43:36.198026       1 request.go:700] Waited for 2.792696053s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-config-openshift-kube-apiserver
2024-10-24T14:43:37.199089974Z I1024 14:43:37.198991       1 request.go:700] Waited for 2.984530092s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-10-24T14:43:38.014151259Z I1024 14:43:38.013814       1 installer_controller.go:537] node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 17 is the oldest and needs new revision 18
2024-10-24T14:43:38.014151259Z I1024 14:43:38.013937       1 installer_controller.go:545] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T14:43:38.014151259Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T14:43:38.014151259Z  CurrentRevision: (int32) 17,
2024-10-24T14:43:38.014151259Z  TargetRevision: (int32) 18,
2024-10-24T14:43:38.014151259Z  LastFailedRevision: (int32) 10,
2024-10-24T14:43:38.014151259Z  LastFailedTime: (*v1.Time)(0xc005aa4d08)(2024-10-24 13:30:03 +0000 UTC),
2024-10-24T14:43:38.014151259Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T14:43:38.014151259Z  LastFailedCount: (int) 1,
2024-10-24T14:43:38.014151259Z  LastFallbackCount: (int) 0,
2024-10-24T14:43:38.014151259Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T14:43:38.014151259Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:44.055363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:54.056329       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:04.056500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:14.056228       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.056670       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:28:24.058084       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:28:24.058164       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T14:43:38.014151259Z  }
2024-10-24T14:43:38.014151259Z }
2024-10-24T14:43:38.017208009Z W1024 14:43:38.016684       1 dynamic_operator_client.go:352] .status.conditions["InstallerControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:43:38.017208009Z W1024 14:43:38.016709       1 dynamic_operator_client.go:355] .status.conditions["InstallerControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:43:38.017208009Z W1024 14:43:38.016716       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T14:43:38.017208009Z W1024 14:43:38.016723       1 dynamic_operator_client.go:355] .status.conditions["NodeInstallerDegraded"].message is missing; this will eventually be fatal
2024-10-24T14:43:38.017208009Z W1024 14:43:38.016728       1 dynamic_operator_client.go:352] .status.conditions["NodeInstallerProgressing"].reason is missing; this will eventually be fatal
2024-10-24T14:43:38.017208009Z W1024 14:43:38.016732       1 dynamic_operator_client.go:352] .status.conditions["StaticPodsAvailable"].reason is missing; this will eventually be fatal
2024-10-24T14:43:38.072907979Z I1024 14:43:38.071094       1 status_controller.go:225] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:36:32Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T14:43:38Z","message":"NodeInstallerProgressing: 3 nodes are at revision 17; 0 nodes have achieved new revision 18","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:33:49Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 17; 0 nodes have achieved new revision 18","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:46:19Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-10-24T14:43:38.078099599Z I1024 14:43:38.078046       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 17 to 18 because node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 17 is the oldest
2024-10-24T14:43:38.095196219Z I1024 14:43:38.095115       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing changed from False to True ("NodeInstallerProgressing: 3 nodes are at revision 17; 0 nodes have achieved new revision 18"),Available message changed from "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 17" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 17; 0 nodes have achieved new revision 18"
2024-10-24T14:43:38.398574177Z I1024 14:43:38.398506       1 request.go:700] Waited for 2.991633242s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2024-10-24T14:43:39.598910070Z I1024 14:43:39.598844       1 request.go:700] Waited for 2.990147852s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-17
2024-10-24T14:43:40.599030284Z I1024 14:43:40.598970       1 request.go:700] Waited for 2.787377434s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-17
2024-10-24T14:43:41.797985957Z I1024 14:43:41.797908       1 request.go:700] Waited for 3.191719801s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T14:43:42.798257071Z I1024 14:43:42.798180       1 request.go:700] Waited for 3.187367391s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:43:43.798865025Z I1024 14:43:43.798778       1 request.go:700] Waited for 3.189784591s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:43:44.801984819Z I1024 14:43:44.801917       1 request.go:700] Waited for 3.191013051s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-10-24T14:43:45.999025272Z I1024 14:43:45.998937       1 request.go:700] Waited for 2.900191963s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:43:47.198176654Z I1024 14:43:47.198070       1 request.go:700] Waited for 2.788435774s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:43:48.198821949Z I1024 14:43:48.198762       1 request.go:700] Waited for 2.863278653s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T14:43:49.398945722Z I1024 14:43:49.398863       1 request.go:700] Waited for 2.993738832s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:43:50.398992446Z I1024 14:43:50.398922       1 request.go:700] Waited for 2.592722264s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-10-24T14:43:51.598677768Z I1024 14:43:51.598593       1 request.go:700] Waited for 2.593214174s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-10-24T14:43:52.598837052Z I1024 14:43:52.598775       1 request.go:700] Waited for 2.591673574s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods
2024-10-24T14:43:52.612741172Z I1024 14:43:52.612602       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"25c703bd-fced-4623-ab7c-91be89cc0822", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-18-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-apiserver because it was missing
2024-10-24T14:43:53.798078805Z I1024 14:43:53.797992       1 request.go:700] Waited for 2.123946017s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-10-24T14:43:54.798644799Z I1024 14:43:54.798549       1 request.go:700] Waited for 2.543106364s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:43:54.807744999Z I1024 14:43:54.807680       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX
2024-10-24T14:43:55.205095367Z I1024 14:43:55.205016       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 18, but has not made progress because installer is not finished, but in Running phase
2024-10-24T14:43:55.798786373Z I1024 14:43:55.798705       1 request.go:700] Waited for 2.992180942s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:43:56.998550106Z I1024 14:43:56.998468       1 request.go:700] Waited for 2.987190302s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:43:58.198236419Z I1024 14:43:58.198121       1 request.go:700] Waited for 2.990646302s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:43:59.198333653Z I1024 14:43:59.198248       1 request.go:700] Waited for 2.990741252s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets/encryption-config-openshift-kube-apiserver
2024-10-24T14:44:00.198481927Z I1024 14:44:00.198415       1 request.go:700] Waited for 2.948146353s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
2024-10-24T14:44:01.198901801Z I1024 14:44:01.198837       1 request.go:700] Waited for 2.390357286s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:44:02.398193444Z I1024 14:44:02.398111       1 request.go:700] Waited for 2.387567356s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=apiserver%3Dtrue
2024-10-24T14:44:03.399028788Z I1024 14:44:03.398952       1 request.go:700] Waited for 2.189045427s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:44:04.599003351Z I1024 14:44:04.598899       1 request.go:700] Waited for 1.991403078s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-17
2024-10-24T14:44:05.800481734Z I1024 14:44:05.800399       1 request.go:700] Waited for 1.868928659s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-10-24T14:44:06.998379376Z I1024 14:44:06.998273       1 request.go:700] Waited for 1.992287728s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-18-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:44:07.006102446Z I1024 14:44:07.006021       1 installer_controller.go:525] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 18, but has not made progress because installer is not finished, but in Running phase
2024-10-24T14:44:07.998866940Z I1024 14:44:07.998744       1 request.go:700] Waited for 1.388942342s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?labelSelector=encryption.apiserver.operator.openshift.io%2Fcomponent%3Dopenshift-kube-apiserver
