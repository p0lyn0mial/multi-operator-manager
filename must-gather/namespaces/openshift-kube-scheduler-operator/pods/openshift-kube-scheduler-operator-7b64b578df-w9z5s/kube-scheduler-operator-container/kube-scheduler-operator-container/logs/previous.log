2024-10-24T13:04:44.521604186Z I1024 13:04:44.521506       1 cmd.go:250] Using service-serving-cert provided certificates
2024-10-24T13:04:44.521778376Z I1024 13:04:44.521730       1 leaderelection.go:121] The leader election gives 4 retries and allows for 30s of clock skew. The kube-apiserver downtime tolerance is 78s. Worst non-graceful lease acquisition is 2m43s. Worst graceful lease acquisition is {26s}.
2024-10-24T13:04:44.522087746Z I1024 13:04:44.522061       1 observer_polling.go:159] Starting file observer
2024-10-24T13:04:44.537734265Z I1024 13:04:44.537685       1 builder.go:298] openshift-cluster-kube-scheduler-operator version v0.0.1-964-g56e6c13-56e6c1360
2024-10-24T13:04:44.941902726Z I1024 13:04:44.941856       1 secure_serving.go:57] Forcing use of http/1.1 only
2024-10-24T13:04:44.941902726Z W1024 13:04:44.941884       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256' detected.
2024-10-24T13:04:44.941902726Z W1024 13:04:44.941891       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256' detected.
2024-10-24T13:04:44.941902726Z W1024 13:04:44.941897       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_128_GCM_SHA256' detected.
2024-10-24T13:04:44.941948776Z W1024 13:04:44.941902       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_256_GCM_SHA384' detected.
2024-10-24T13:04:44.941948776Z W1024 13:04:44.941906       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_128_CBC_SHA' detected.
2024-10-24T13:04:44.941948776Z W1024 13:04:44.941909       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_256_CBC_SHA' detected.
2024-10-24T13:04:44.945700706Z I1024 13:04:44.945657       1 requestheader_controller.go:172] Starting RequestHeaderAuthRequestController
2024-10-24T13:04:44.945728676Z I1024 13:04:44.945697       1 shared_informer.go:313] Waiting for caches to sync for RequestHeaderAuthRequestController
2024-10-24T13:04:44.945801256Z I1024 13:04:44.945735       1 configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2024-10-24T13:04:44.945891426Z I1024 13:04:44.945876       1 shared_informer.go:313] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-10-24T13:04:44.945983166Z I1024 13:04:44.945959       1 configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2024-10-24T13:04:44.946037756Z I1024 13:04:44.946024       1 shared_informer.go:313] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-10-24T13:04:44.946152556Z I1024 13:04:44.946128       1 secure_serving.go:213] Serving securely on [::]:8443
2024-10-24T13:04:44.946198856Z I1024 13:04:44.946173       1 dynamic_serving_content.go:135] "Starting controller" name="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key"
2024-10-24T13:04:44.946336466Z I1024 13:04:44.946312       1 tlsconfig.go:243] "Starting DynamicServingCertificateController"
2024-10-24T13:04:44.946573886Z I1024 13:04:44.946321       1 leaderelection.go:254] attempting to acquire leader lease openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock...
2024-10-24T13:04:44.957039086Z I1024 13:04:44.957011       1 leaderelection.go:268] successfully acquired lease openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock
2024-10-24T13:04:44.957364616Z I1024 13:04:44.957318       1 event.go:377] Event(v1.ObjectReference{Kind:"Lease", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-cluster-kube-scheduler-operator-lock", UID:"7a445fd6-9764-47db-a21b-814c111c88dc", APIVersion:"coordination.k8s.io/v1", ResourceVersion:"10167", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' openshift-kube-scheduler-operator-7b64b578df-w9z5s_34e613fa-99a2-4b2b-bbe7-7329b76a5b4f became leader
2024-10-24T13:04:44.957987166Z I1024 13:04:44.957967       1 simple_featuregate_reader.go:171] Starting feature-gate-detector
2024-10-24T13:04:44.961061986Z I1024 13:04:44.961026       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'FeatureGatesInitialized' FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AWSEFSDriverVolumeMetrics", "AdminNetworkPolicy", "AlibabaPlatform", "AzureWorkloadIdentity", "BareMetalLoadBalancer", "BuildCSIVolumes", "ChunkSizeMiB", "CloudDualStackNodeIPs", "DisableKubeletCloudCredentialProviders", "GCPLabelsTags", "HardwareSpeed", "IngressControllerLBSubnetsAWS", "KMSv1", "ManagedBootImages", "MetricsServer", "MultiArchInstallAWS", "MultiArchInstallGCP", "NetworkDiagnosticsConfig", "NetworkLiveMigration", "NodeDisruptionPolicy", "OpenShiftPodSecurityAdmission", "PrivateHostedZoneAWS", "SetEIPForNLBIngressController", "VSphereControlPlaneMachineSet", "VSphereDriverConfiguration", "VSphereStaticIPs", "ValidatingAdmissionPolicy"}, Disabled:[]v1.FeatureGateName{"AWSClusterHostedDNS", "AdditionalRoutingCapabilities", "AutomatedEtcdBackup", "BootcNodeManagement", "CSIDriverSharedResource", "ClusterAPIInstall", "ClusterAPIInstallIBMCloud", "ClusterMonitoringConfig", "DNSNameResolver", "DynamicResourceAllocation", "EtcdBackendQuota", "EventedPLEG", "Example", "ExternalOIDC", "GCPClusterHostedDNS", "GatewayAPI", "ImageStreamImportMode", "IngressControllerDynamicConfigurationManager", "InsightsConfig", "InsightsConfigAPI", "InsightsOnDemandDataGather", "InsightsRuntimeExtractor", "MachineAPIMigration", "MachineAPIOperatorDisableMachineHealthCheckController", "MachineAPIProviderOpenStack", "MachineConfigNodes", "ManagedBootImagesAWS", "MaxUnavailableStatefulSet", "MetricsCollectionProfiles", "MixedCPUsAllocation", "MultiArchInstallAzure", "NetworkSegmentation", "NewOLM", "NodeSwap", "OVNObservability", "OnClusterBuild", "PersistentIPsForVirtualization", "PinnedImages", "PlatformOperators", "ProcMountType", "RouteAdvertisements", "RouteExternalCertificate", "ServiceAccountTokenNodeBinding", "SignatureStores", "SigstoreImageVerification", "TranslateStreamCloseWebsocketRequests", "UpgradeStatus", "UserNamespacesPodSecurityStandards", "UserNamespacesSupport", "VSphereMultiNetworks", "VSphereMultiVCenters", "VolumeGroupSnapshot"}}
2024-10-24T13:04:44.961090206Z I1024 13:04:44.961022       1 starter.go:89] FeatureGates initialized: knownFeatureGates=[AWSEFSDriverVolumeMetrics AdminNetworkPolicy AlibabaPlatform AzureWorkloadIdentity BareMetalLoadBalancer BuildCSIVolumes ChunkSizeMiB CloudDualStackNodeIPs DisableKubeletCloudCredentialProviders GCPLabelsTags HardwareSpeed IngressControllerLBSubnetsAWS KMSv1 ManagedBootImages MetricsServer MultiArchInstallAWS MultiArchInstallGCP NetworkDiagnosticsConfig NetworkLiveMigration NodeDisruptionPolicy OpenShiftPodSecurityAdmission PrivateHostedZoneAWS SetEIPForNLBIngressController VSphereControlPlaneMachineSet VSphereDriverConfiguration VSphereStaticIPs ValidatingAdmissionPolicy AWSClusterHostedDNS AdditionalRoutingCapabilities AutomatedEtcdBackup BootcNodeManagement CSIDriverSharedResource ClusterAPIInstall ClusterAPIInstallIBMCloud ClusterMonitoringConfig DNSNameResolver DynamicResourceAllocation EtcdBackendQuota EventedPLEG Example ExternalOIDC GCPClusterHostedDNS GatewayAPI ImageStreamImportMode IngressControllerDynamicConfigurationManager InsightsConfig InsightsConfigAPI InsightsOnDemandDataGather InsightsRuntimeExtractor MachineAPIMigration MachineAPIOperatorDisableMachineHealthCheckController MachineAPIProviderOpenStack MachineConfigNodes ManagedBootImagesAWS MaxUnavailableStatefulSet MetricsCollectionProfiles MixedCPUsAllocation MultiArchInstallAzure NetworkSegmentation NewOLM NodeSwap OVNObservability OnClusterBuild PersistentIPsForVirtualization PinnedImages PlatformOperators ProcMountType RouteAdvertisements RouteExternalCertificate ServiceAccountTokenNodeBinding SignatureStores SigstoreImageVerification TranslateStreamCloseWebsocketRequests UpgradeStatus UserNamespacesPodSecurityStandards UserNamespacesSupport VSphereMultiNetworks VSphereMultiVCenters VolumeGroupSnapshot]
2024-10-24T13:04:44.974139376Z I1024 13:04:44.974061       1 base_controller.go:68] Waiting for caches to sync for RemoveStaleConditionsController
2024-10-24T13:04:44.976343146Z I1024 13:04:44.976310       1 base_controller.go:68] Waiting for caches to sync for MissingStaticPodController
2024-10-24T13:04:44.976434106Z I1024 13:04:44.976401       1 base_controller.go:68] Waiting for caches to sync for NodeController
2024-10-24T13:04:44.976529256Z I1024 13:04:44.976489       1 base_controller.go:68] Waiting for caches to sync for RevisionController
2024-10-24T13:04:44.976900236Z I1024 13:04:44.976420       1 base_controller.go:68] Waiting for caches to sync for TargetConfigController
2024-10-24T13:04:44.976900236Z I1024 13:04:44.976516       1 base_controller.go:68] Waiting for caches to sync for GuardController
2024-10-24T13:04:44.976951596Z I1024 13:04:44.976364       1 base_controller.go:68] Waiting for caches to sync for kube-scheduler-InstallerState
2024-10-24T13:04:44.977002576Z I1024 13:04:44.976373       1 base_controller.go:68] Waiting for caches to sync for StaticPodStateController
2024-10-24T13:04:44.977279036Z I1024 13:04:44.976435       1 base_controller.go:68] Waiting for caches to sync for ConfigObserver
2024-10-24T13:04:44.977347676Z I1024 13:04:44.976524       1 base_controller.go:68] Waiting for caches to sync for UnsupportedConfigOverridesController
2024-10-24T13:04:44.977426176Z I1024 13:04:44.976532       1 base_controller.go:68] Waiting for caches to sync for LoggingSyncer
2024-10-24T13:04:44.977484266Z I1024 13:04:44.976553       1 base_controller.go:68] Waiting for caches to sync for StatusSyncer_kube-scheduler
2024-10-24T13:04:44.977541266Z I1024 13:04:44.976350       1 base_controller.go:68] Waiting for caches to sync for PruneController
2024-10-24T13:04:44.977599816Z I1024 13:04:44.976576       1 base_controller.go:68] Waiting for caches to sync for kube-scheduler
2024-10-24T13:04:44.977650726Z I1024 13:04:44.976934       1 base_controller.go:68] Waiting for caches to sync for InstallerController
2024-10-24T13:04:44.977703926Z I1024 13:04:44.977534       1 base_controller.go:68] Waiting for caches to sync for BackingResourceController-StaticResources
2024-10-24T13:04:44.978186806Z I1024 13:04:44.978153       1 base_controller.go:68] Waiting for caches to sync for KubeControllerManagerStaticResources-StaticResources
2024-10-24T13:04:45.046137246Z I1024 13:04:45.046060       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-10-24T13:04:45.046137246Z I1024 13:04:45.046087       1 shared_informer.go:320] Caches are synced for RequestHeaderAuthRequestController
2024-10-24T13:04:45.046137246Z I1024 13:04:45.046115       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-10-24T13:04:45.074371736Z I1024 13:04:45.074326       1 base_controller.go:74] Caches are synced for RemoveStaleConditionsController 
2024-10-24T13:04:45.074451816Z I1024 13:04:45.074437       1 base_controller.go:111] Starting #1 worker of RemoveStaleConditionsController controller ...
2024-10-24T13:04:45.076627316Z I1024 13:04:45.076584       1 base_controller.go:74] Caches are synced for MissingStaticPodController 
2024-10-24T13:04:45.076627316Z I1024 13:04:45.076613       1 base_controller.go:111] Starting #1 worker of MissingStaticPodController controller ...
2024-10-24T13:04:45.077699196Z I1024 13:04:45.077669       1 base_controller.go:74] Caches are synced for kube-scheduler-InstallerState 
2024-10-24T13:04:45.077786086Z I1024 13:04:45.077734       1 base_controller.go:74] Caches are synced for InstallerController 
2024-10-24T13:04:45.077917536Z I1024 13:04:45.077900       1 base_controller.go:111] Starting #1 worker of InstallerController controller ...
2024-10-24T13:04:45.077971596Z I1024 13:04:45.077734       1 base_controller.go:74] Caches are synced for StatusSyncer_kube-scheduler 
2024-10-24T13:04:45.077971596Z I1024 13:04:45.077962       1 base_controller.go:111] Starting #1 worker of StatusSyncer_kube-scheduler controller ...
2024-10-24T13:04:45.078009716Z I1024 13:04:45.077704       1 base_controller.go:74] Caches are synced for UnsupportedConfigOverridesController 
2024-10-24T13:04:45.078009716Z I1024 13:04:45.078001       1 base_controller.go:111] Starting #1 worker of UnsupportedConfigOverridesController controller ...
2024-10-24T13:04:45.078213456Z I1024 13:04:45.077711       1 base_controller.go:74] Caches are synced for StaticPodStateController 
2024-10-24T13:04:45.078266226Z I1024 13:04:45.078252       1 base_controller.go:111] Starting #1 worker of StaticPodStateController controller ...
2024-10-24T13:04:45.078302106Z I1024 13:04:45.077720       1 base_controller.go:74] Caches are synced for PruneController 
2024-10-24T13:04:45.078336916Z I1024 13:04:45.078324       1 base_controller.go:111] Starting #1 worker of PruneController controller ...
2024-10-24T13:04:45.078384706Z I1024 13:04:45.077726       1 base_controller.go:74] Caches are synced for LoggingSyncer 
2024-10-24T13:04:45.078384706Z I1024 13:04:45.078377       1 base_controller.go:111] Starting #1 worker of LoggingSyncer controller ...
2024-10-24T13:04:45.078520856Z I1024 13:04:45.077737       1 base_controller.go:111] Starting #1 worker of kube-scheduler-InstallerState controller ...
2024-10-24T13:04:45.078520856Z I1024 13:04:45.077692       1 base_controller.go:74] Caches are synced for RevisionController 
2024-10-24T13:04:45.078536436Z I1024 13:04:45.078520       1 base_controller.go:111] Starting #1 worker of RevisionController controller ...
2024-10-24T13:04:45.078587996Z I1024 13:04:45.078572       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:45.177420406Z I1024 13:04:45.177374       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:04:45.277623297Z I1024 13:04:45.277576       1 base_controller.go:74] Caches are synced for NodeController 
2024-10-24T13:04:45.277623297Z I1024 13:04:45.277603       1 base_controller.go:111] Starting #1 worker of NodeController controller ...
2024-10-24T13:04:45.278221857Z I1024 13:04:45.278179       1 base_controller.go:74] Caches are synced for GuardController 
2024-10-24T13:04:45.278221857Z I1024 13:04:45.278199       1 base_controller.go:111] Starting #1 worker of GuardController controller ...
2024-10-24T13:04:45.377230726Z I1024 13:04:45.377183       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:04:45.378511926Z I1024 13:04:45.378110       1 base_controller.go:74] Caches are synced for BackingResourceController-StaticResources 
2024-10-24T13:04:45.378511926Z I1024 13:04:45.378132       1 base_controller.go:111] Starting #1 worker of BackingResourceController-StaticResources controller ...
2024-10-24T13:04:45.378556806Z I1024 13:04:45.378519       1 base_controller.go:74] Caches are synced for KubeControllerManagerStaticResources-StaticResources 
2024-10-24T13:04:45.378556806Z I1024 13:04:45.378530       1 base_controller.go:111] Starting #1 worker of KubeControllerManagerStaticResources-StaticResources controller ...
2024-10-24T13:04:45.577209797Z I1024 13:04:45.577144       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:04:45.777131517Z I1024 13:04:45.777074       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:04:45.976984857Z I1024 13:04:45.976928       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:04:45.977924097Z I1024 13:04:45.977878       1 base_controller.go:74] Caches are synced for kube-scheduler 
2024-10-24T13:04:45.977924097Z I1024 13:04:45.977888       1 base_controller.go:74] Caches are synced for ConfigObserver 
2024-10-24T13:04:45.977924097Z I1024 13:04:45.977900       1 base_controller.go:111] Starting #1 worker of ConfigObserver controller ...
2024-10-24T13:04:45.977924097Z I1024 13:04:45.977891       1 base_controller.go:111] Starting #1 worker of kube-scheduler controller ...
2024-10-24T13:04:46.077043998Z I1024 13:04:46.076972       1 base_controller.go:74] Caches are synced for TargetConfigController 
2024-10-24T13:04:46.077043998Z I1024 13:04:46.076996       1 base_controller.go:111] Starting #1 worker of TargetConfigController controller ...
2024-10-24T13:04:46.174442088Z I1024 13:04:46.174382       1 request.go:700] Waited for 1.095833871s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:04:47.175035348Z I1024 13:04:47.174694       1 request.go:700] Waited for 1.795832193s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler
2024-10-24T13:04:48.779921081Z I1024 13:04:48.779877       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 2, but has not made progress because static pod is pending
2024-10-24T13:04:48.983795301Z W1024 13:04:48.983729       1 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
2024-10-24T13:04:48.983957521Z E1024 13:04:48.983940       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:04:48.984006161Z E1024 13:04:48.983993       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:04:48.984284231Z I1024 13:04:48.984251       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-scheduler because it was missing
2024-10-24T13:04:49.003438701Z E1024 13:04:49.003373       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:04:49.004444151Z I1024 13:04:49.004402       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:49.004948681Z I1024 13:04:49.004915       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:04:49.005344241Z E1024 13:04:49.005325       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:04:49.015591511Z I1024 13:04:49.015550       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:04:50.174979362Z I1024 13:04:50.174932       1 request.go:700] Waited for 1.169522181s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa
2024-10-24T13:04:51.376590734Z I1024 13:04:51.375211       1 request.go:700] Waited for 1.394985682s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-2-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:04:51.588255914Z I1024 13:04:51.588204       1 core.go:220] Pod "openshift-kube-scheduler/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0" changes: {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{"k8s.ovn.org/pod-networks":null,"k8s.v1.cni.cncf.io/network-status":null,"target.workload.openshift.io/management":"{\"effect\": \"PreferredDuringScheduling\"}"},"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null},"spec":{"containers":[{"args":["-c","# properly handle TERM and exit as soon as it is signaled\nset -euo pipefail\ntrap 'jobs -p | xargs -r kill; exit 0' TERM\nsleep infinity \u0026 wait\n"],"command":["/bin/bash"],"image":"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:7f1ef4ec397a7c90b5c3c5f9235d635ab8818ca402ce8de9bade295053038571","imagePullPolicy":"IfNotPresent","name":"guard","readinessProbe":{"failureThreshold":3,"httpGet":{"host":"10.0.0.3","path":"healthz","port":10259,"scheme":"HTTPS"},"periodSeconds":5,"successThreshold":1,"timeoutSeconds":5},"resources":{"requests":{"cpu":"10m","memory":"5Mi"}},"terminationMessagePolicy":"FallbackToLogsOnError"}],"dnsPolicy":null,"enableServiceLinks":null,"preemptionPolicy":null,"priority":null,"restartPolicy":null,"schedulerName":null,"securityContext":null,"serviceAccount":null,"serviceAccountName":null,"volumes":null},"status":{"conditions":null,"containerStatuses":null,"hostIP":null,"hostIPs":null,"phase":null,"podIP":null,"podIPs":null,"qosClass":null,"startTime":null}}
2024-10-24T13:04:52.575402795Z I1024 13:04:52.575055       1 request.go:700] Waited for 1.187215491s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:04:52.580424365Z I1024 13:04:52.580356       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 2, but has not made progress because static pod is pending
2024-10-24T13:04:52.786858865Z E1024 13:04:52.786744       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:04:52.787329915Z I1024 13:04:52.787222       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-scheduler because it changed
2024-10-24T13:04:52.788643185Z E1024 13:04:52.788581       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:04:53.774900267Z I1024 13:04:53.774840       1 request.go:700] Waited for 1.190872902s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-2-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:04:54.974611738Z I1024 13:04:54.974563       1 request.go:700] Waited for 1.194782031s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-2-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:04:55.179260459Z E1024 13:04:55.179205       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:04:55.179260459Z E1024 13:04:55.179237       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:04:55.180378548Z E1024 13:04:55.180343       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:04:55.979913020Z I1024 13:04:55.979848       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 2, but has not made progress because static pod is pending
2024-10-24T13:04:56.979007611Z E1024 13:04:56.978692       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:04:56.979007611Z E1024 13:04:56.978971       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:04:56.979701001Z E1024 13:04:56.979664       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:04:56.981056901Z E1024 13:04:56.981006       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:04:56.981056901Z E1024 13:04:56.981029       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:04:57.185375711Z I1024 13:04:57.185313       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:57.185649541Z I1024 13:04:57.185571       1 core.go:352] ConfigMap "openshift-kube-scheduler/serviceaccount-ca" changes: {"data":{"ca-bundle.crt":"-----BEGIN CERTIFICATE-----\nMIIDMjCCAhqgAwIBAgIIOlelAZRIRJQwDQYJKoZIhvcNAQELBQAwNzESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSEwHwYDVQQDExhrdWJlLWFwaXNlcnZlci1sYi1zaWduZXIw\nHhcNMjQxMDI0MTI0OTMyWhcNMzQxMDIyMTI0OTMyWjA3MRIwEAYDVQQLEwlvcGVu\nc2hpZnQxITAfBgNVBAMTGGt1YmUtYXBpc2VydmVyLWxiLXNpZ25lcjCCASIwDQYJ\nKoZIhvcNAQEBBQADggEPADCCAQoCggEBAOcnMnNp8mbJzP0YRtfP2eQLUaxDRCWh\nwLjXPeI+RJNc5XRTf8K7cnFvZM+VxeDvt3vvHmK+v6eeT2vM4sTe1Fi4y3+N+52E\nAZfAsx5jZkOLMqXmYCEtcM0iE5hCDlqj+iqz3+N9/h9r/wlkGcuLjFatvfYPe2aD\norY3S/xWccWpBmPNNb6g+JgNbFkZtwSgP2rA0DgJQNm+SElSVXsOD4z6NJeQYUGS\n3S+3muL/R0tqHU6oqJUUS5i+SI0zUtGXSPF71/SZwp0ZzlqJOnF1+oKwvLwVYenJ\n1chzH2ooswTzIl2GbrriQiiFXcNatw5HPYAUj/u5mxc2UFdq0BS/kS8CAwEAAaNC\nMEAwDgYDVR0PAQH/BAQDAgKkMA8GA1UdEwEB/wQFMAMBAf8wHQYDVR0OBBYEFHl2\n38/JZPz+0k/JseyNGSSnxIWbMA0GCSqGSIb3DQEBCwUAA4IBAQCt/f91wvEf5yXB\nM6iVHyYS5quVkgKOyW/VlOiWBrC3nzumzbyKBKCCDVFV0ObFBUJ94uhYGCM32OLe\nkOF3g/sNMtjj+z8OWauQqQ8goczpC+NJb/ANaAtdFN+el5gLy13sXPsu8/gidAOb\njapZ7wk8Px33n/sQbsvM7eSuW3mWsEWCznXMAiXzkt4R2jLxYslFcqzAyjqYXOeI\n8hYcgmLVk5R2ZTKtgN6K0H1BRIPNPZ76GKjK0KpguzyRHJN8y6iD/Oe4779z0t1k\nsLOsY8mzi1bRHEV31Og7s6nFy42ECM5WZb/btqdJn2K/AQF3WCtdX6U9+rSuScOB\n5fOatgOb\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDQDCCAiigAwIBAgIIaxpuJ4b9n/wwDQYJKoZIhvcNAQELBQAwPjESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSgwJgYDVQQDEx9rdWJlLWFwaXNlcnZlci1sb2NhbGhvc3Qt\nc2lnbmVyMB4XDTI0MTAyNDEyNDkzMVoXDTM0MTAyMjEyNDkzMVowPjESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSgwJgYDVQQDEx9rdWJlLWFwaXNlcnZlci1sb2NhbGhvc3Qt\nc2lnbmVyMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvCLC4H8c9qPx\niqEgtyn9mblELDIJA//g3A6vuhVprmVxFKdR+SLdN7iuPXWJyNJoMujRpLh4O8Tx\nynHOHASH3NZu20NBxPNwM7cM2YN35rYKMwgGMg6H/mFCyMnXo2wTbpG0kVbk1I+D\npQDuCCd5Nwa8MyFMRmxC7FWSD/NXyJN96+TywP62d9UBwp8F2TV0IwEYJPp7QMBK\nTDef+8mWKaMjYpaTbDTh/ce6B6faSfliGhBqsKSWfUPBss/4nlWsDKOLagoDHQTt\nuFYyqXveH3lieKd0eu/mCUioLzq1GQ9oIdNHbqYf+zWB3hiJPwbxfRq01+NB+1Ga\nHtT4qKkLiQIDAQABo0IwQDAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/BAUwAwEB\n/zAdBgNVHQ4EFgQUAoX0QNb/ygmPyFVnWrPc/3lKS+4wDQYJKoZIhvcNAQELBQAD\nggEBAFnjav9JNB6NSH2HgOlj2mvqXSYOKmLD1c6WluJXOSh2YOE9iGDZJEpNGfx3\nsXdk3PKp9vheMdfBIWDme2H7ocJiPUl7HlzP0PvSl5f/9Jad3KEl5koJMxaobHMg\n86BT5Lg3TQ3H369Bw9yedYuw6Wakl8zGgYsHRdDiBsQFYheObHYcbWsZmsMM38uq\n8oXuysYM7Lvm1YceS5083X0W22yqnzIGsbclB6MaNO3GGOaUSM/jS+1ngse1nuFD\nX7ao+N0irLEUdy8/yoJe4/aV9tJlLqPJ+6tNTvLBU7I6pIo8lRqe79cMUXkfcdSB\n/jkfSdUQBBv/qdvCnP3Dz2dNsT4=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDTDCCAjSgAwIBAgIINVjIWQIi1JIwDQYJKoZIhvcNAQELBQAwRDESMBAGA1UE\nCxMJb3BlbnNoaWZ0MS4wLAYDVQQDEyVrdWJlLWFwaXNlcnZlci1zZXJ2aWNlLW5l\ndHdvcmstc2lnbmVyMB4XDTI0MTAyNDEyNDkzMVoXDTM0MTAyMjEyNDkzMVowRDES\nMBAGA1UECxMJb3BlbnNoaWZ0MS4wLAYDVQQDEyVrdWJlLWFwaXNlcnZlci1zZXJ2\naWNlLW5ldHdvcmstc2lnbmVyMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKC\nAQEAuZZryAJp0pIRsH8v0/cE4aX+NTYYQ/quEDW2uF9UuD18KBNm17UGUadohlFB\n8MZFqxyEUE3doAzNNNn+mlb1tdffMyrPCKuue/+uL283ESHexPCUipD2NZCJMLxP\n4cFBNY24XxsyCgP4GW0CLK6jzNDRUpmqAvuAtPaGpwoMmdHYEbiYfD+kQpeSEpe7\n65W04BdcW93RWcU8Pcq8mj5ryRy37PXOSKv6cD20zs3o3swhJQjXJ7S7HPNiIPJu\nWAIDXMTbmlE5oT7fawQUVEzZAMTxHwz386X+PnqivblZW10wCaew9ixkzgnBtyzR\njInePtAOofQ+OAZRjfjK7tbwYQIDAQABo0IwQDAOBgNVHQ8BAf8EBAMCAqQwDwYD\nVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQUV9YpeGN1ZV9lrUjasKNrI8densowDQYJ\nKoZIhvcNAQELBQADggEBABWprtX9/Bmt/SDZMR++58OVDOHeN5IM5XmJTg1L9Y71\nwZ52OrAJTiHykyf0ZgdA1WFs4XCKRygK58Q0zh5TaN1Fbmt/ziKs6TfHpHr1EI9M\n8q5UN2en8KBnnkM5baV4pbs41Pj7LIzmuBdullsTzjWKz/+LiBYiUtEIViyLrAzS\nqmritaAg3r4ZguaL+KCWTRLpBJkmupaokwdo9rCJtY5qH70FaoNbdIofWE5Hi5Rx\nWZFOqIheZBTRD/bbhLUBCIgqacvwaIS0LDdHgPrpc5I0LUFZ/l4Te9TsY4sjYQQf\nOK4o1aud8IMYecdfB1khOkhpEQzsBcjTOyKTP0+zrq0=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDlzCCAn+gAwIBAgIIFwQ1KsBW4yQwDQYJKoZIhvcNAQELBQAwWTFXMFUGA1UE\nAwxOb3BlbnNoaWZ0LWt1YmUtYXBpc2VydmVyLW9wZXJhdG9yX2xvY2FsaG9zdC1y\nZWNvdmVyeS1zZXJ2aW5nLXNpZ25lckAxNzI5Nzc1MDExMB4XDTI0MTAyNDEzMDMz\nMFoXDTM0MTAyMjEzMDMzMVowWTFXMFUGA1UEAwxOb3BlbnNoaWZ0LWt1YmUtYXBp\nc2VydmVyLW9wZXJhdG9yX2xvY2FsaG9zdC1yZWNvdmVyeS1zZXJ2aW5nLXNpZ25l\nckAxNzI5Nzc1MDExMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAzml1\nSjsUKDZX7It4x6PImlu6eePhmNdUxp+1TGyUvU3BKiv/JsbyjYBOg3dip58nPBq9\nreTr4t3ZNnVMAbnaWmpwPR8sbkdjkoHETi0ipIPqEIQ47Yn2MHsY54AsXMcDS/3Z\nkVSbJhRPJaZq4+ZBZC0AGgDgAQd8bKyX1O2ybBp+/np/MoZB+3MTfKa77/2dqUDL\ny8mOG6V9/W7Z96Yvt+GJXSkTKaSD8ADbXIZ7MM7DFlMi3+s2paooWgpZIroZB08S\nrl8L6r22ncV/3CjlDm3KkoKHl1to1WdxKot8b8bSGC/tyc/zYBTc8lKek2BvdrK+\nmeiC+ghVASGtHowSXQIDAQABo2MwYTAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/\nBAUwAwEB/zAdBgNVHQ4EFgQUmszbl4eL8cP9ms1ey+CdkVsPpeowHwYDVR0jBBgw\nFoAUmszbl4eL8cP9ms1ey+CdkVsPpeowDQYJKoZIhvcNAQELBQADggEBAJ2S6HTb\n3PyIvKsTvhCx3YPsRyZgL76ffg3oiYvyc+UnOkm8Qy0wwS2I0byXy+KOITmabJZQ\n6OdkkJB+h9CqWxuWPhmTmzVlP6/kJxRKUJutc7Qxxbv9mQ4MOGh1QmsYPaFwyajn\nfGz6OeVrYCGunB97m65sKBEcqAV7ECBM51aY8EYUQLb0w67g//YJPhWmPukm0gVa\n5KQ97kxl7dxuwrVr7VOeZMawHSQPUcN6kGhablM7MNRblC+dddiw+8uJX6q3xbYH\nmRgoGDhXTB4wj2bz5Zk7sFGt82QoUY+Tg2x8CBpZkNgJAGijwxrXy3dkRAoNJ1rg\nU1KCNil9uJyZHR8=\n-----END CERTIFICATE-----\n"},"metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:04:57.185860531Z I1024 13:04:57.185807       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/serviceaccount-ca -n openshift-kube-scheduler:
2024-10-24T13:04:57.185860531Z cause by changes in data.ca-bundle.crt
2024-10-24T13:04:57.187325041Z I1024 13:04:57.187285       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 3 triggered by "required configmap/serviceaccount-ca has changed"
2024-10-24T13:04:58.375279623Z I1024 13:04:58.374847       1 request.go:700] Waited for 1.187598301s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps
2024-10-24T13:04:58.383178243Z I1024 13:04:58.383146       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:58.779410393Z I1024 13:04:58.779346       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 2, but has not made progress because static pod is pending
2024-10-24T13:04:58.980582383Z E1024 13:04:58.980541       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:04:58.981905193Z E1024 13:04:58.981867       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:04:58.981905193Z E1024 13:04:58.981891       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:04:59.574398644Z I1024 13:04:59.574352       1 request.go:700] Waited for 1.190627971s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps
2024-10-24T13:04:59.587257244Z I1024 13:04:59.587219       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:59.587375274Z I1024 13:04:59.587261       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-scheduler-pod-3 -n openshift-kube-scheduler because it was missing
2024-10-24T13:05:00.582874575Z I1024 13:05:00.582564       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:00.582874575Z I1024 13:05:00.582692       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-3 -n openshift-kube-scheduler because it was missing
2024-10-24T13:05:00.980042986Z E1024 13:05:00.979740       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:01.585872706Z I1024 13:05:01.585818       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-3 -n openshift-kube-scheduler because it was missing
2024-10-24T13:05:01.585948496Z I1024 13:05:01.585914       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:01.780502637Z I1024 13:05:01.780434       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 2, but has not made progress because static pod is pending
2024-10-24T13:05:02.582052368Z I1024 13:05:02.582008       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:02.582363898Z I1024 13:05:02.582330       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/scheduler-kubeconfig-3 -n openshift-kube-scheduler because it was missing
2024-10-24T13:05:02.981578238Z E1024 13:05:02.981532       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:02.981578238Z E1024 13:05:02.981559       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:02.982368848Z E1024 13:05:02.982340       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:03.580894669Z I1024 13:05:03.580843       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:03.580991099Z I1024 13:05:03.580932       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-scheduler-cert-syncer-kubeconfig-3 -n openshift-kube-scheduler because it was missing
2024-10-24T13:05:04.584872140Z I1024 13:05:04.584802       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-3 -n openshift-kube-scheduler because it was missing
2024-10-24T13:05:04.779868101Z I1024 13:05:04.779796       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 2, but has not made progress because static pod is pending
2024-10-24T13:05:04.983387671Z E1024 13:05:04.983019       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:04.983387671Z E1024 13:05:04.983045       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:04.983854051Z E1024 13:05:04.983820       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:04.985243051Z E1024 13:05:04.985198       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:05.585887332Z I1024 13:05:05.585819       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-3 -n openshift-kube-scheduler because it was missing
2024-10-24T13:05:06.582527953Z I1024 13:05:06.582083       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:06.582527953Z I1024 13:05:06.582304       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 3 triggered by "required configmap/serviceaccount-ca has changed"
2024-10-24T13:05:06.583468773Z W1024 13:05:06.583422       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:05:06.583468773Z W1024 13:05:06.583450       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:05:06.600297563Z I1024 13:05:06.600257       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:06.600497563Z W1024 13:05:06.600464       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:05:06.600557773Z W1024 13:05:06.600541       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:05:06.980295333Z E1024 13:05:06.980240       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:06.982319804Z E1024 13:05:06.982270       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:06.984192574Z E1024 13:05:06.984148       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:06.984192574Z E1024 13:05:06.984172       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:07.774680955Z I1024 13:05:07.774606       1 request.go:700] Waited for 1.174295942s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:07.979492465Z I1024 13:05:07.979429       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 2, but has not made progress because static pod is pending
2024-10-24T13:05:07.999669805Z I1024 13:05:07.999634       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:07.999801275Z I1024 13:05:07.999776       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:05:08.011852555Z I1024 13:05:08.011797       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3"
2024-10-24T13:05:08.979885876Z I1024 13:05:08.979823       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:05:08.979885876Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:05:08.979885876Z  CurrentRevision: (int32) 0,
2024-10-24T13:05:08.979885876Z  TargetRevision: (int32) 3,
2024-10-24T13:05:08.979885876Z  LastFailedRevision: (int32) 0,
2024-10-24T13:05:08.979885876Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:05:08.979885876Z  LastFailedReason: (string) "",
2024-10-24T13:05:08.979885876Z  LastFailedCount: (int) 0,
2024-10-24T13:05:08.979885876Z  LastFallbackCount: (int) 0,
2024-10-24T13:05:08.979885876Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:05:08.979885876Z }
2024-10-24T13:05:08.979885876Z  because new revision pending
2024-10-24T13:05:08.996677306Z I1024 13:05:08.996621       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:09.174364306Z I1024 13:05:09.174257       1 request.go:700] Waited for 1.174453781s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa
2024-10-24T13:05:09.380486366Z E1024 13:05:09.380436       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:10.174885558Z I1024 13:05:10.174819       1 request.go:700] Waited for 1.178334261s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-2-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:10.180022268Z I1024 13:05:10.179970       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:05:10.180022268Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:05:10.180022268Z  CurrentRevision: (int32) 0,
2024-10-24T13:05:10.180022268Z  TargetRevision: (int32) 3,
2024-10-24T13:05:10.180022268Z  LastFailedRevision: (int32) 0,
2024-10-24T13:05:10.180022268Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:05:10.180022268Z  LastFailedReason: (string) "",
2024-10-24T13:05:10.180022268Z  LastFailedCount: (int) 0,
2024-10-24T13:05:10.180022268Z  LastFallbackCount: (int) 0,
2024-10-24T13:05:10.180022268Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:05:10.180022268Z }
2024-10-24T13:05:10.180022268Z  because new revision pending
2024-10-24T13:05:11.175244279Z I1024 13:05:11.174829       1 request.go:700] Waited for 1.196099232s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:11.583560409Z E1024 13:05:11.583519       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:11.583638919Z E1024 13:05:11.583624       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:11.584654719Z E1024 13:05:11.584608       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:12.394979190Z I1024 13:05:12.394911       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-3-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-scheduler because it was missing
2024-10-24T13:05:13.379662991Z I1024 13:05:13.379598       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:05:13.574804652Z I1024 13:05:13.574744       1 request.go:700] Waited for 1.179801982s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2024-10-24T13:05:13.780514602Z E1024 13:05:13.780431       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:13.780514602Z E1024 13:05:13.780478       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:13.781335122Z E1024 13:05:13.781287       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:14.774969833Z I1024 13:05:14.774913       1 request.go:700] Waited for 1.194232552s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2024-10-24T13:05:15.582305814Z I1024 13:05:15.582249       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:05:15.779534854Z E1024 13:05:15.779477       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:15.779534854Z E1024 13:05:15.779499       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:15.780331894Z E1024 13:05:15.780289       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:19.848455670Z E1024 13:05:19.847977       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:19.848564990Z E1024 13:05:19.848519       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:19.849792240Z E1024 13:05:19.849725       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:24.702491565Z E1024 13:05:24.702031       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:24.702556565Z E1024 13:05:24.702541       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:24.703583445Z E1024 13:05:24.703559       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:29.634173911Z E1024 13:05:29.633745       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:29.634173911Z E1024 13:05:29.634145       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:29.634995571Z E1024 13:05:29.634928       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:30.666065012Z E1024 13:05:30.666016       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:30.666065012Z E1024 13:05:30.666041       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:30.667088232Z E1024 13:05:30.667034       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:35.685958468Z E1024 13:05:35.685519       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:35.686486178Z E1024 13:05:35.686459       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:35.703347318Z E1024 13:05:35.703283       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:35.900367808Z I1024 13:05:35.899887       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:05:35.919015799Z I1024 13:05:35.918964       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded changed from False to True ("GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]")
2024-10-24T13:05:35.924033098Z I1024 13:05:35.923998       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:05:35.932047059Z E1024 13:05:35.932013       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:05:39.775952658Z E1024 13:05:39.775485       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:39.776075638Z E1024 13:05:39.776055       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:39.777667258Z E1024 13:05:39.777643       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:40.518806435Z E1024 13:05:40.511921       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:40.523673615Z E1024 13:05:40.523624       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:40.525117455Z E1024 13:05:40.525042       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:40.875851125Z E1024 13:05:40.875805       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:40.875851125Z E1024 13:05:40.875835       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:40.877024434Z E1024 13:05:40.876979       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:42.076800294Z E1024 13:05:42.076445       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:42.076865594Z E1024 13:05:42.076796       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:42.077571234Z E1024 13:05:42.077523       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:42.276035453Z I1024 13:05:42.275961       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:05:43.729961178Z E1024 13:05:43.729817       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:43.729961178Z E1024 13:05:43.729839       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:43.730928928Z E1024 13:05:43.730877       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:44.489506454Z E1024 13:05:44.489449       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:44.489506454Z E1024 13:05:44.489470       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:44.490408574Z E1024 13:05:44.490382       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:44.491134834Z I1024 13:05:44.491107       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:05:47.271092672Z I1024 13:05:47.270632       1 request.go:700] Waited for 1.02931191s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:48.076671915Z E1024 13:05:48.076623       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:48.076671915Z E1024 13:05:48.076654       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:48.077714465Z E1024 13:05:48.077672       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:48.483569971Z I1024 13:05:48.483478       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because waiting for static pod of revision 3, found 2
2024-10-24T13:05:50.744227160Z E1024 13:05:50.743947       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:50.744227160Z E1024 13:05:50.744210       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:50.745044490Z E1024 13:05:50.744998       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:54.343545230Z E1024 13:05:54.343301       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:54.343545230Z E1024 13:05:54.343514       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:54.344176790Z E1024 13:05:54.344131       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:54.348720650Z I1024 13:05:54.348678       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because waiting for static pod of revision 3, found 2
2024-10-24T13:05:57.527837505Z E1024 13:05:57.527502       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:57.527837505Z E1024 13:05:57.527808       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:57.528643515Z E1024 13:05:57.528580       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:57.530103244Z E1024 13:05:57.530027       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:57.530103244Z E1024 13:05:57.530053       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:57.530103244Z E1024 13:05:57.530063       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:57.675452996Z I1024 13:05:57.675388       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:05:57.676867136Z E1024 13:05:57.676824       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:57.676980156Z I1024 13:05:57.676943       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:57.677994126Z I1024 13:05:57.677961       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:05:57.772226020Z E1024 13:05:57.772174       1 guard_controller.go:300] Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:57.772226020Z E1024 13:05:57.772213       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:57.772274820Z E1024 13:05:57.772229       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:57.773574570Z I1024 13:05:57.773535       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]" to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:57.872536665Z E1024 13:05:57.872491       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:57.873343104Z I1024 13:05:57.873303       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:57.874528944Z I1024 13:05:57.874464       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:05:57.974450979Z I1024 13:05:57.974389       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]" to "GuardControllerDegraded: [Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:58.780595362Z I1024 13:05:58.780540       1 request.go:700] Waited for 1.008358821s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:59.981103482Z I1024 13:05:59.981040       1 request.go:700] Waited for 1.346393351s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:00.386678408Z I1024 13:06:00.386180       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:06:01.180649492Z I1024 13:06:01.180510       1 request.go:700] Waited for 1.193262611s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:01.186479942Z E1024 13:06:01.186391       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:01.186479942Z E1024 13:06:01.186451       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:01.209048950Z E1024 13:06:01.208987       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:01.209350490Z I1024 13:06:01.209317       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:01.210072780Z I1024 13:06:01.210017       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:06:01.210577650Z E1024 13:06:01.210506       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:01.225285529Z I1024 13:06:01.225221       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]" to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:02.380206192Z I1024 13:06:02.380134       1 request.go:700] Waited for 1.168932912s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:03.385018113Z E1024 13:06:03.384968       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:03.385986723Z E1024 13:06:03.385935       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:03.787247440Z I1024 13:06:03.787170       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:06:06.187070270Z I1024 13:06:06.186676       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:06:10.515600577Z E1024 13:06:10.515122       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:10.515600577Z E1024 13:06:10.515571       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:10.516599387Z E1024 13:06:10.516549       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:11.041962687Z E1024 13:06:11.041889       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:11.041962687Z E1024 13:06:11.041922       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:11.042990526Z E1024 13:06:11.042961       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:14.649307616Z E1024 13:06:14.648944       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:14.649307616Z E1024 13:06:14.649278       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:14.650335006Z E1024 13:06:14.650278       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:21.264494379Z E1024 13:06:21.264015       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:21.264494379Z E1024 13:06:21.264475       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:21.265284749Z E1024 13:06:21.265242       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:27.270007550Z I1024 13:06:27.269558       1 core.go:352] ConfigMap "openshift-kube-scheduler/serviceaccount-ca" changes: {"data":{"ca-bundle.crt":"-----BEGIN CERTIFICATE-----\nMIIDMjCCAhqgAwIBAgIIOlelAZRIRJQwDQYJKoZIhvcNAQELBQAwNzESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSEwHwYDVQQDExhrdWJlLWFwaXNlcnZlci1sYi1zaWduZXIw\nHhcNMjQxMDI0MTI0OTMyWhcNMzQxMDIyMTI0OTMyWjA3MRIwEAYDVQQLEwlvcGVu\nc2hpZnQxITAfBgNVBAMTGGt1YmUtYXBpc2VydmVyLWxiLXNpZ25lcjCCASIwDQYJ\nKoZIhvcNAQEBBQADggEPADCCAQoCggEBAOcnMnNp8mbJzP0YRtfP2eQLUaxDRCWh\nwLjXPeI+RJNc5XRTf8K7cnFvZM+VxeDvt3vvHmK+v6eeT2vM4sTe1Fi4y3+N+52E\nAZfAsx5jZkOLMqXmYCEtcM0iE5hCDlqj+iqz3+N9/h9r/wlkGcuLjFatvfYPe2aD\norY3S/xWccWpBmPNNb6g+JgNbFkZtwSgP2rA0DgJQNm+SElSVXsOD4z6NJeQYUGS\n3S+3muL/R0tqHU6oqJUUS5i+SI0zUtGXSPF71/SZwp0ZzlqJOnF1+oKwvLwVYenJ\n1chzH2ooswTzIl2GbrriQiiFXcNatw5HPYAUj/u5mxc2UFdq0BS/kS8CAwEAAaNC\nMEAwDgYDVR0PAQH/BAQDAgKkMA8GA1UdEwEB/wQFMAMBAf8wHQYDVR0OBBYEFHl2\n38/JZPz+0k/JseyNGSSnxIWbMA0GCSqGSIb3DQEBCwUAA4IBAQCt/f91wvEf5yXB\nM6iVHyYS5quVkgKOyW/VlOiWBrC3nzumzbyKBKCCDVFV0ObFBUJ94uhYGCM32OLe\nkOF3g/sNMtjj+z8OWauQqQ8goczpC+NJb/ANaAtdFN+el5gLy13sXPsu8/gidAOb\njapZ7wk8Px33n/sQbsvM7eSuW3mWsEWCznXMAiXzkt4R2jLxYslFcqzAyjqYXOeI\n8hYcgmLVk5R2ZTKtgN6K0H1BRIPNPZ76GKjK0KpguzyRHJN8y6iD/Oe4779z0t1k\nsLOsY8mzi1bRHEV31Og7s6nFy42ECM5WZb/btqdJn2K/AQF3WCtdX6U9+rSuScOB\n5fOatgOb\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDQDCCAiigAwIBAgIIaxpuJ4b9n/wwDQYJKoZIhvcNAQELBQAwPjESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSgwJgYDVQQDEx9rdWJlLWFwaXNlcnZlci1sb2NhbGhvc3Qt\nc2lnbmVyMB4XDTI0MTAyNDEyNDkzMVoXDTM0MTAyMjEyNDkzMVowPjESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSgwJgYDVQQDEx9rdWJlLWFwaXNlcnZlci1sb2NhbGhvc3Qt\nc2lnbmVyMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvCLC4H8c9qPx\niqEgtyn9mblELDIJA//g3A6vuhVprmVxFKdR+SLdN7iuPXWJyNJoMujRpLh4O8Tx\nynHOHASH3NZu20NBxPNwM7cM2YN35rYKMwgGMg6H/mFCyMnXo2wTbpG0kVbk1I+D\npQDuCCd5Nwa8MyFMRmxC7FWSD/NXyJN96+TywP62d9UBwp8F2TV0IwEYJPp7QMBK\nTDef+8mWKaMjYpaTbDTh/ce6B6faSfliGhBqsKSWfUPBss/4nlWsDKOLagoDHQTt\nuFYyqXveH3lieKd0eu/mCUioLzq1GQ9oIdNHbqYf+zWB3hiJPwbxfRq01+NB+1Ga\nHtT4qKkLiQIDAQABo0IwQDAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/BAUwAwEB\n/zAdBgNVHQ4EFgQUAoX0QNb/ygmPyFVnWrPc/3lKS+4wDQYJKoZIhvcNAQELBQAD\nggEBAFnjav9JNB6NSH2HgOlj2mvqXSYOKmLD1c6WluJXOSh2YOE9iGDZJEpNGfx3\nsXdk3PKp9vheMdfBIWDme2H7ocJiPUl7HlzP0PvSl5f/9Jad3KEl5koJMxaobHMg\n86BT5Lg3TQ3H369Bw9yedYuw6Wakl8zGgYsHRdDiBsQFYheObHYcbWsZmsMM38uq\n8oXuysYM7Lvm1YceS5083X0W22yqnzIGsbclB6MaNO3GGOaUSM/jS+1ngse1nuFD\nX7ao+N0irLEUdy8/yoJe4/aV9tJlLqPJ+6tNTvLBU7I6pIo8lRqe79cMUXkfcdSB\n/jkfSdUQBBv/qdvCnP3Dz2dNsT4=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDTDCCAjSgAwIBAgIINVjIWQIi1JIwDQYJKoZIhvcNAQELBQAwRDESMBAGA1UE\nCxMJb3BlbnNoaWZ0MS4wLAYDVQQDEyVrdWJlLWFwaXNlcnZlci1zZXJ2aWNlLW5l\ndHdvcmstc2lnbmVyMB4XDTI0MTAyNDEyNDkzMVoXDTM0MTAyMjEyNDkzMVowRDES\nMBAGA1UECxMJb3BlbnNoaWZ0MS4wLAYDVQQDEyVrdWJlLWFwaXNlcnZlci1zZXJ2\naWNlLW5ldHdvcmstc2lnbmVyMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKC\nAQEAuZZryAJp0pIRsH8v0/cE4aX+NTYYQ/quEDW2uF9UuD18KBNm17UGUadohlFB\n8MZFqxyEUE3doAzNNNn+mlb1tdffMyrPCKuue/+uL283ESHexPCUipD2NZCJMLxP\n4cFBNY24XxsyCgP4GW0CLK6jzNDRUpmqAvuAtPaGpwoMmdHYEbiYfD+kQpeSEpe7\n65W04BdcW93RWcU8Pcq8mj5ryRy37PXOSKv6cD20zs3o3swhJQjXJ7S7HPNiIPJu\nWAIDXMTbmlE5oT7fawQUVEzZAMTxHwz386X+PnqivblZW10wCaew9ixkzgnBtyzR\njInePtAOofQ+OAZRjfjK7tbwYQIDAQABo0IwQDAOBgNVHQ8BAf8EBAMCAqQwDwYD\nVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQUV9YpeGN1ZV9lrUjasKNrI8densowDQYJ\nKoZIhvcNAQELBQADggEBABWprtX9/Bmt/SDZMR++58OVDOHeN5IM5XmJTg1L9Y71\nwZ52OrAJTiHykyf0ZgdA1WFs4XCKRygK58Q0zh5TaN1Fbmt/ziKs6TfHpHr1EI9M\n8q5UN2en8KBnnkM5baV4pbs41Pj7LIzmuBdullsTzjWKz/+LiBYiUtEIViyLrAzS\nqmritaAg3r4ZguaL+KCWTRLpBJkmupaokwdo9rCJtY5qH70FaoNbdIofWE5Hi5Rx\nWZFOqIheZBTRD/bbhLUBCIgqacvwaIS0LDdHgPrpc5I0LUFZ/l4Te9TsY4sjYQQf\nOK4o1aud8IMYecdfB1khOkhpEQzsBcjTOyKTP0+zrq0=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDlzCCAn+gAwIBAgIIFwQ1KsBW4yQwDQYJKoZIhvcNAQELBQAwWTFXMFUGA1UE\nAwxOb3BlbnNoaWZ0LWt1YmUtYXBpc2VydmVyLW9wZXJhdG9yX2xvY2FsaG9zdC1y\nZWNvdmVyeS1zZXJ2aW5nLXNpZ25lckAxNzI5Nzc1MDExMB4XDTI0MTAyNDEzMDMz\nMFoXDTM0MTAyMjEzMDMzMVowWTFXMFUGA1UEAwxOb3BlbnNoaWZ0LWt1YmUtYXBp\nc2VydmVyLW9wZXJhdG9yX2xvY2FsaG9zdC1yZWNvdmVyeS1zZXJ2aW5nLXNpZ25l\nckAxNzI5Nzc1MDExMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAzml1\nSjsUKDZX7It4x6PImlu6eePhmNdUxp+1TGyUvU3BKiv/JsbyjYBOg3dip58nPBq9\nreTr4t3ZNnVMAbnaWmpwPR8sbkdjkoHETi0ipIPqEIQ47Yn2MHsY54AsXMcDS/3Z\nkVSbJhRPJaZq4+ZBZC0AGgDgAQd8bKyX1O2ybBp+/np/MoZB+3MTfKa77/2dqUDL\ny8mOG6V9/W7Z96Yvt+GJXSkTKaSD8ADbXIZ7MM7DFlMi3+s2paooWgpZIroZB08S\nrl8L6r22ncV/3CjlDm3KkoKHl1to1WdxKot8b8bSGC/tyc/zYBTc8lKek2BvdrK+\nmeiC+ghVASGtHowSXQIDAQABo2MwYTAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/\nBAUwAwEB/zAdBgNVHQ4EFgQUmszbl4eL8cP9ms1ey+CdkVsPpeowHwYDVR0jBBgw\nFoAUmszbl4eL8cP9ms1ey+CdkVsPpeowDQYJKoZIhvcNAQELBQADggEBAJ2S6HTb\n3PyIvKsTvhCx3YPsRyZgL76ffg3oiYvyc+UnOkm8Qy0wwS2I0byXy+KOITmabJZQ\n6OdkkJB+h9CqWxuWPhmTmzVlP6/kJxRKUJutc7Qxxbv9mQ4MOGh1QmsYPaFwyajn\nfGz6OeVrYCGunB97m65sKBEcqAV7ECBM51aY8EYUQLb0w67g//YJPhWmPukm0gVa\n5KQ97kxl7dxuwrVr7VOeZMawHSQPUcN6kGhablM7MNRblC+dddiw+8uJX6q3xbYH\nmRgoGDhXTB4wj2bz5Zk7sFGt82QoUY+Tg2x8CBpZkNgJAGijwxrXy3dkRAoNJ1rg\nU1KCNil9uJyZHR8=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDmzCCAoOgAwIBAgIIGVifAwvO2bwwDQYJKoZIhvcNAQELBQAwJjEkMCIGA1UE\nAwwbaW5ncmVzcy1vcGVyYXRvckAxNzI5Nzc1MTg0MB4XDTI0MTAyNDEzMDYyNVoX\nDTI2MTAyNDEzMDYyNlowPTE7MDkGA1UEAwwyKi5hcHBzLmNpLW9wLTJmY3BqNWo2\nLWY2MDM1LmdjcC0zLmNpLm9wZW5zaGlmdC5vcmcwggEiMA0GCSqGSIb3DQEBAQUA\nA4IBDwAwggEKAoIBAQC5lBc/sd7Gm0FTBzfdSyoBN8jwz3jgKfmoRokTrzKWv//t\nbnHmepkOL3q/ibK2FnCTvkcEqYTRdPtYzW7VMSo2V8kvKkPdgW5z7LrKP8bFq0qC\nR7YOSCcUJflYFfCvhEqgIiLN05U1hJMYw1meMH3Y3VBLAf83Nu+o9ktpjzTqTwBX\naQjP7XDZs4Zw3mBYlknT4VgSmEY0BlwQtX2PNuoup3jC28SS6HfkC5Uws6o0EzoU\nxCb9EogTtzByEpTY25RorJhPr83v2gkY4GSRItNNU2WUz+IVFWQsZKy+3zcWZBVx\nkbwR3ymiAvd+sVkEl0rwcyEwhEgYbxnW0o25rUjjAgMBAAGjgbUwgbIwDgYDVR0P\nAQH/BAQDAgWgMBMGA1UdJQQMMAoGCCsGAQUFBwMBMAwGA1UdEwEB/wQCMAAwHQYD\nVR0OBBYEFB+MJoBnDQ7h918tfRvplOuBHN0qMB8GA1UdIwQYMBaAFNDcJhKdybkO\nCinYNyXbwuDtUgWTMD0GA1UdEQQ2MDSCMiouYXBwcy5jaS1vcC0yZmNwajVqNi1m\nNjAzNS5nY3AtMy5jaS5vcGVuc2hpZnQub3JnMA0GCSqGSIb3DQEBCwUAA4IBAQC9\n0ODyOuqGU56uqhdFQilwfnfAJsaKGgcE4LMILjSOLYU5afb2aje3K7UrAI8KGUoy\nBn0O+9KVu/knkjtoWq7XLXPb8MpGSo1TPKSJFm9tjgdkgBnRIgBS8JXsPGF322fF\nO5mK5z7SEPfxvCTIG8yj3d3m4F/aIzg0/+VUXHMDof8pkC1yEYNiP7ij1ItPCbNQ\nfGw6Uq/7tvU+Sc/bVVbogPoD/WHJlywt1TEhI/K6Wil2RQZFC7WGQpqgIr6PSdHR\nRMjvQikEVrSzDNbCsb6FvJdabM/kKiI0HakvMqWqOfkeHUvpZ35xxgYi+6flQ4ln\n4XnZO6EssN3W8l8Hnf98\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDDDCCAfSgAwIBAgIBATANBgkqhkiG9w0BAQsFADAmMSQwIgYDVQQDDBtpbmdy\nZXNzLW9wZXJhdG9yQDE3Mjk3NzUxODQwHhcNMjQxMDI0MTMwNjIzWhcNMjYxMDI0\nMTMwNjI0WjAmMSQwIgYDVQQDDBtpbmdyZXNzLW9wZXJhdG9yQDE3Mjk3NzUxODQw\nggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDdActzMlPVmjtASy3hCJDs\nBWYHKHTYimlFhLYN9AkyiN/3VwqRk+hVzGFBCpkDigPAeF0yv5CKh9O5pB8lBOOD\nAa7GwwuIztdTq8fQuHhzfvlo3+i8Nw78yJm1ar3uwxJKmaLFPi8TTaQCWRKpfS1j\nk9mMMj1uQVH0nJGeHGTPFbux9ZekXS3oEC8DD17rZKPM9TH7Q4mTy+Va4knoPlls\nFiNxPDnGLWGCdWFEFqoiEkzy868lleA0FyjXZHksjG+ih/l+89UBQh/Lx9Czsd2u\nkapMb/DhU9qMsfSner3JrxNEQopQisyNN4U3MVsCZSq3ZuhSCfVJeX82Lrx84IuH\nAgMBAAGjRTBDMA4GA1UdDwEB/wQEAwICpDASBgNVHRMBAf8ECDAGAQH/AgEAMB0G\nA1UdDgQWBBTQ3CYSncm5Dgop2Dcl28Lg7VIFkzANBgkqhkiG9w0BAQsFAAOCAQEA\nIujqg0CbwLyhfAHo/FFqfv2mSlhkzZ7hqYNTlkzor2/Lvujh3CKb8rX1CgcA3mhX\nM1SofVaZap5cfP2wOlEOrhd7BtYzEcJR1AkhdQoSZBf66aSbFK6R3VJgdbh8upWz\nMjyf1UaBmWmNQsnVG9P+0oQXUgMvMyPZO7nrMv7chDCF0NYLRqVeZg8eCHZ/D0BZ\nJso6ceiATZzYr+Khqtc+to6O/x14q9o7hzL7WGAb6UeviigEBPRA+C/L7Wndu0EZ\nCDNWzot4v1sVEjJ12zEjtg7+DwubY4pmaVlOC/FpcNReGKbgnUczUS8ahZ20ziQd\nQua4z9iRfzKlLRT0nSYXgQ==\n-----END CERTIFICATE-----\n"},"metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:06:27.270578480Z I1024 13:06:27.269653       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:27.270578480Z I1024 13:06:27.270562       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/serviceaccount-ca -n openshift-kube-scheduler:
2024-10-24T13:06:27.270578480Z cause by changes in data.ca-bundle.crt
2024-10-24T13:06:27.271637260Z I1024 13:06:27.271586       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 4 triggered by "required configmap/serviceaccount-ca has changed"
2024-10-24T13:06:28.070323383Z I1024 13:06:28.070274       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:28.791285701Z E1024 13:06:28.791240       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:28.870256036Z I1024 13:06:28.870189       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-scheduler-pod-4 -n openshift-kube-scheduler because it was missing
2024-10-24T13:06:28.870378436Z I1024 13:06:28.870220       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:29.465340922Z I1024 13:06:29.465286       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:06:29.861186528Z I1024 13:06:29.861138       1 request.go:700] Waited for 1.069896697s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:30.269452905Z I1024 13:06:30.269397       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-4 -n openshift-kube-scheduler because it was missing
2024-10-24T13:06:30.269780495Z I1024 13:06:30.269725       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:31.061312399Z I1024 13:06:31.061013       1 request.go:700] Waited for 1.260721567s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2024-10-24T13:06:31.465144895Z E1024 13:06:31.465089       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:31.465863935Z E1024 13:06:31.465826       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:31.670097483Z I1024 13:06:31.670044       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-4 -n openshift-kube-scheduler because it was missing
2024-10-24T13:06:31.670154293Z I1024 13:06:31.670091       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:32.260394189Z I1024 13:06:32.260327       1 request.go:700] Waited for 1.394935519s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-3-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:32.876910773Z I1024 13:06:32.876837       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:32.877260822Z I1024 13:06:32.877185       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/scheduler-kubeconfig-4 -n openshift-kube-scheduler because it was missing
2024-10-24T13:06:33.260591580Z I1024 13:06:33.260522       1 request.go:700] Waited for 1.19483937s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config
2024-10-24T13:06:33.466067218Z I1024 13:06:33.466004       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:06:33.865221755Z E1024 13:06:33.865162       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:33.865221755Z E1024 13:06:33.865182       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:33.865959405Z E1024 13:06:33.865924       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:34.066989203Z I1024 13:06:34.066946       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:34.067309413Z I1024 13:06:34.067261       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-scheduler-cert-syncer-kubeconfig-4 -n openshift-kube-scheduler because it was missing
2024-10-24T13:06:34.461091450Z I1024 13:06:34.461032       1 request.go:700] Waited for 1.19670297s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/serviceaccount-ca
2024-10-24T13:06:35.071007645Z I1024 13:06:35.070912       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-4 -n openshift-kube-scheduler because it was missing
2024-10-24T13:06:36.069234206Z I1024 13:06:36.069145       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-4 -n openshift-kube-scheduler because it was missing
2024-10-24T13:06:36.665364192Z I1024 13:06:36.665297       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:06:36.866725750Z I1024 13:06:36.866648       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:36.866863370Z I1024 13:06:36.866821       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 4 triggered by "required configmap/serviceaccount-ca has changed"
2024-10-24T13:06:36.867434200Z W1024 13:06:36.867373       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:06:36.867434200Z W1024 13:06:36.867391       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:06:36.883527149Z I1024 13:06:36.883474       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:39.265496890Z I1024 13:06:39.265136       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:06:39.281399879Z I1024 13:06:39.281365       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:06:39.281618809Z I1024 13:06:39.281399       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:39.295810948Z I1024 13:06:39.293226       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4"
2024-10-24T13:06:40.066165343Z I1024 13:06:40.065864       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:06:40.066165343Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:06:40.066165343Z  CurrentRevision: (int32) 0,
2024-10-24T13:06:40.066165343Z  TargetRevision: (int32) 4,
2024-10-24T13:06:40.066165343Z  LastFailedRevision: (int32) 0,
2024-10-24T13:06:40.066165343Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:06:40.066165343Z  LastFailedReason: (string) "",
2024-10-24T13:06:40.066165343Z  LastFailedCount: (int) 0,
2024-10-24T13:06:40.066165343Z  LastFallbackCount: (int) 0,
2024-10-24T13:06:40.066165343Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:06:40.066165343Z }
2024-10-24T13:06:40.066165343Z  because new revision pending
2024-10-24T13:06:40.084053792Z I1024 13:06:40.084019       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:40.960924861Z E1024 13:06:40.960862       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:42.060936987Z I1024 13:06:42.060886       1 request.go:700] Waited for 1.099318066s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:42.273568454Z I1024 13:06:42.273474       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-scheduler because it was missing
2024-10-24T13:06:43.066931321Z E1024 13:06:43.066870       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:43.067676641Z E1024 13:06:43.067642       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:43.264716537Z I1024 13:06:43.264662       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 4, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:06:43.460714293Z I1024 13:06:43.460363       1 request.go:700] Waited for 1.186669539s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2024-10-24T13:06:44.461023263Z I1024 13:06:44.460971       1 request.go:700] Waited for 1.195255497s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:45.466263374Z E1024 13:06:45.466203       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:45.466263374Z E1024 13:06:45.466228       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:45.466992594Z E1024 13:06:45.466940       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:45.468455384Z E1024 13:06:45.468394       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:45.660325421Z I1024 13:06:45.660263       1 request.go:700] Waited for 1.194446167s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:45.665228440Z I1024 13:06:45.665158       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:06:46.661165141Z I1024 13:06:46.661115       1 request.go:700] Waited for 1.281741135s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler
2024-10-24T13:06:47.861384738Z I1024 13:06:47.861063       1 request.go:700] Waited for 1.180205328s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler
2024-10-24T13:06:48.065328054Z E1024 13:06:48.065273       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:48.066305744Z E1024 13:06:48.066272       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:48.067661644Z E1024 13:06:48.067634       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:48.265124530Z I1024 13:06:48.265085       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:06:49.061064185Z I1024 13:06:49.061006       1 request.go:700] Waited for 1.195470487s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa
2024-10-24T13:06:50.265152612Z E1024 13:06:50.264875       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:50.266119661Z E1024 13:06:50.266089       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:50.461209938Z I1024 13:06:50.461158       1 request.go:700] Waited for 1.097493599s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2024-10-24T13:06:50.665364564Z I1024 13:06:50.665302       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:06:51.859703591Z I1024 13:06:51.859655       1 tlsconfig.go:181] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"admin-kubeconfig-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:31 +0000 UTC to 2034-10-22 12:49:31 +0000 UTC (now=2024-10-24 13:06:51.859557271 +0000 UTC))"
2024-10-24T13:06:51.859859341Z I1024 13:06:51.859838       1 tlsconfig.go:181] "Loaded client CA" index=1 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2024-10-25 12:49:34 +0000 UTC (now=2024-10-24 13:06:51.859805431 +0000 UTC))"
2024-10-24T13:06:51.859934471Z I1024 13:06:51.859917       1 tlsconfig.go:181] "Loaded client CA" index=2 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-control-plane-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2025-10-24 12:49:34 +0000 UTC (now=2024-10-24 13:06:51.859892691 +0000 UTC))"
2024-10-24T13:06:51.859992871Z I1024 13:06:51.859977       1 tlsconfig.go:181] "Loaded client CA" index=3 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-apiserver-to-kubelet-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2025-10-24 12:49:34 +0000 UTC (now=2024-10-24 13:06:51.859958881 +0000 UTC))"
2024-10-24T13:06:51.860077311Z I1024 13:06:51.860042       1 tlsconfig.go:181] "Loaded client CA" index=4 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-bootstrap-kubeconfig-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:32 +0000 UTC to 2034-10-22 12:49:32 +0000 UTC (now=2024-10-24 13:06:51.860024721 +0000 UTC))"
2024-10-24T13:06:51.860132591Z I1024 13:06:51.860117       1 tlsconfig.go:181] "Loaded client CA" index=5 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-csr-signer_@1729775012\" [] issuer=\"kubelet-signer\" (2024-10-24 13:03:31 +0000 UTC to 2024-10-25 12:49:34 +0000 UTC (now=2024-10-24 13:06:51.860101401 +0000 UTC))"
2024-10-24T13:06:51.860190371Z I1024 13:06:51.860174       1 tlsconfig.go:181] "Loaded client CA" index=6 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_node-system-admin-signer@1729775011\" [] issuer=\"<self>\" (2024-10-24 13:03:30 +0000 UTC to 2025-10-24 13:03:31 +0000 UTC (now=2024-10-24 13:06:51.860153451 +0000 UTC))"
2024-10-24T13:06:51.860256651Z I1024 13:06:51.860231       1 tlsconfig.go:181] "Loaded client CA" index=7 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"aggregator-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:32 +0000 UTC to 2024-10-25 12:49:32 +0000 UTC (now=2024-10-24 13:06:51.860213851 +0000 UTC))"
2024-10-24T13:06:51.860626211Z I1024 13:06:51.860601       1 tlsconfig.go:203] "Loaded serving cert" certName="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key" certDetail="\"metrics.openshift-kube-scheduler-operator.svc\" [serving] validServingFor=[metrics.openshift-kube-scheduler-operator.svc,metrics.openshift-kube-scheduler-operator.svc.cluster.local] issuer=\"openshift-service-serving-signer@1729775010\" (2024-10-24 13:03:41 +0000 UTC to 2026-10-24 13:03:42 +0000 UTC (now=2024-10-24 13:06:51.860576611 +0000 UTC))"
2024-10-24T13:06:51.860899821Z I1024 13:06:51.860857       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1729775084\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1729775084\" (2024-10-24 12:04:44 +0000 UTC to 2025-10-24 12:04:44 +0000 UTC (now=2024-10-24 13:06:51.860811531 +0000 UTC))"
2024-10-24T13:06:52.066257507Z E1024 13:06:52.065795       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:52.066257507Z E1024 13:06:52.065813       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:52.066550057Z E1024 13:06:52.066504       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:52.265233453Z I1024 13:06:52.265168       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:06:53.265838864Z E1024 13:06:53.265800       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:53.265838864Z E1024 13:06:53.265821       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:53.266530694Z E1024 13:06:53.266482       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:55.567068390Z E1024 13:06:55.563286       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:55.567068390Z E1024 13:06:55.563545       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:55.576045250Z E1024 13:06:55.575993       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:01.786587311Z E1024 13:07:01.785965       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:01.786587311Z E1024 13:07:01.786500       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:01.788058681Z E1024 13:07:01.788009       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:15.119402716Z E1024 13:07:15.119035       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:15.119402716Z E1024 13:07:15.119360       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:15.130236396Z I1024 13:07:15.130197       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:07:15.131173806Z E1024 13:07:15.131122       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:16.131565477Z E1024 13:07:16.131511       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:16.131667747Z E1024 13:07:16.131652       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:16.142887647Z E1024 13:07:16.142741       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:16.300363384Z E1024 13:07:16.300321       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:16.300363384Z E1024 13:07:16.300339       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:16.301195524Z E1024 13:07:16.301149       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:16.924427382Z I1024 13:07:16.924359       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 4, but has not made progress because waiting for static pod of revision 4, found 3
2024-10-24T13:07:24.340717011Z E1024 13:07:24.340307       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:24.340717011Z E1024 13:07:24.340701       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:24.341395281Z E1024 13:07:24.341361       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:24.344103410Z I1024 13:07:24.344044       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 4, but has not made progress because waiting for static pod of revision 4, found 3
2024-10-24T13:07:26.148080986Z E1024 13:07:26.147591       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:26.160281616Z E1024 13:07:26.160246       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:26.161092246Z E1024 13:07:26.161056       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:26.162767815Z E1024 13:07:26.162680       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:26.162834786Z E1024 13:07:26.162812       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:07:26.162834786Z E1024 13:07:26.162829       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:26.164948856Z I1024 13:07:26.164928       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 4, but has not made progress because static pod is pending
2024-10-24T13:07:26.179844605Z E1024 13:07:26.179813       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:26.181410045Z E1024 13:07:26.181385       1 guard_controller.go:300] Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:07:26.181433895Z E1024 13:07:26.181411       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:26.181433895Z E1024 13:07:26.181421       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:26.182933965Z I1024 13:07:26.182914       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:07:26.185051655Z I1024 13:07:26.185012       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:07:26.195810225Z I1024 13:07:26.195183       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]" to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:26.198621275Z E1024 13:07:26.198591       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:26.200141925Z I1024 13:07:26.200111       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:07:26.200942015Z I1024 13:07:26.200915       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:07:26.212516554Z I1024 13:07:26.212470       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]" to "GuardControllerDegraded: [Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:26.511472159Z E1024 13:07:26.508416       1 guard_controller.go:300] Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:07:26.511472159Z E1024 13:07:26.508452       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:26.511472159Z E1024 13:07:26.508463       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:26.511472159Z E1024 13:07:26.509489       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:27.348578763Z I1024 13:07:27.348190       1 request.go:700] Waited for 1.162991178s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler
2024-10-24T13:07:28.547840470Z I1024 13:07:28.547776       1 request.go:700] Waited for 1.368095183s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:07:29.153778428Z I1024 13:07:29.153681       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 4, but has not made progress because static pod is pending
2024-10-24T13:07:29.547895390Z I1024 13:07:29.547834       1 request.go:700] Waited for 1.194296148s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2024-10-24T13:07:29.753027667Z E1024 13:07:29.752963       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:29.753027667Z E1024 13:07:29.752984       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:29.770217276Z E1024 13:07:29.770156       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:29.771700956Z I1024 13:07:29.771649       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:07:29.773712436Z I1024 13:07:29.773681       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:07:29.784999026Z I1024 13:07:29.784954       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]" to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:30.748049237Z I1024 13:07:30.747964       1 request.go:700] Waited for 1.194033797s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2024-10-24T13:07:31.748346467Z I1024 13:07:31.748260       1 request.go:700] Waited for 1.394809462s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:07:32.152696060Z E1024 13:07:32.152636       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:32.152696060Z E1024 13:07:32.152654       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:32.153562159Z E1024 13:07:32.153527       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:32.154908419Z E1024 13:07:32.154873       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:32.755098368Z I1024 13:07:32.754993       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 4, but has not made progress because static pod is pending
2024-10-24T13:07:34.153297901Z E1024 13:07:34.153257       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:34.154046811Z E1024 13:07:34.154016       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:35.753203100Z I1024 13:07:35.753139       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 4, but has not made progress because static pod is pending
2024-10-24T13:07:36.151909943Z E1024 13:07:36.151853       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:36.151909943Z E1024 13:07:36.151875       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:36.152606483Z E1024 13:07:36.152583       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:36.731203552Z E1024 13:07:36.731157       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:36.731355082Z E1024 13:07:36.731287       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:37.953595599Z E1024 13:07:37.953536       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:42.952327392Z E1024 13:07:42.952258       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:42.952327392Z E1024 13:07:42.952281       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:42.953030572Z E1024 13:07:42.952997       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:46.910289276Z E1024 13:07:46.910152       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:46.910289276Z E1024 13:07:46.910178       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:46.911411216Z E1024 13:07:46.911374       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:52.400121791Z E1024 13:07:52.399311       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:52.400121791Z E1024 13:07:52.399351       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:52.400449421Z E1024 13:07:52.400393       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:08:00.868365985Z I1024 13:08:00.868302       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 4, but has not made progress because static pod is pending
2024-10-24T13:08:02.069515897Z E1024 13:08:02.069459       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:08:02.069515897Z E1024 13:08:02.069485       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:02.070418588Z E1024 13:08:02.070393       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:08:02.071833298Z E1024 13:08:02.071793       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:08:02.071833298Z E1024 13:08:02.071817       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:03.269016230Z I1024 13:08:03.268965       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 4, but has not made progress because static pod is pending
2024-10-24T13:08:03.668821928Z E1024 13:08:03.668767       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:08:03.670153878Z E1024 13:08:03.670102       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:08:03.670153878Z E1024 13:08:03.670122       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:04.871281431Z E1024 13:08:04.871177       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:08:07.689727296Z E1024 13:08:07.689685       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:07.702119647Z E1024 13:08:07.701997       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:08:07.704802777Z E1024 13:08:07.703533       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:08:18.602388739Z E1024 13:08:18.602340       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:08:18.602492929Z E1024 13:08:18.602443       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:18.603654099Z E1024 13:08:18.603620       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:08:30.215800009Z E1024 13:08:30.215726       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:08:30.215800009Z E1024 13:08:30.215772       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:30.216980890Z E1024 13:08:30.216931       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:08:40.086965805Z E1024 13:08:40.086884       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:08:40.087495865Z E1024 13:08:40.087476       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:40.104267167Z E1024 13:08:40.104214       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:08:40.717889784Z E1024 13:08:40.717840       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:40.752110268Z E1024 13:08:40.752036       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:08:40.753126498Z E1024 13:08:40.753001       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:08:40.831637515Z E1024 13:08:40.831561       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:08:40.831739485Z E1024 13:08:40.831725       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:40.850049307Z E1024 13:08:40.849999       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:08:50.027680438Z E1024 13:08:50.027601       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:08:50.027806987Z E1024 13:08:50.027790       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:50.040693089Z E1024 13:08:50.040636       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:08:50.246263458Z E1024 13:08:50.246191       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:08:50.246263458Z E1024 13:08:50.246221       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:50.247367518Z E1024 13:08:50.247264       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:08:53.104130241Z I1024 13:08:53.104028       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:08:53.119052221Z I1024 13:08:53.117064       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 4, but has not made progress because static pod is pending
2024-10-24T13:08:53.208707374Z I1024 13:08:53.208640       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:08:53.716900552Z I1024 13:08:53.716852       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:08:53.717166092Z I1024 13:08:53.717103       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-scheduler-pod-5 -n openshift-kube-scheduler because it was missing
2024-10-24T13:08:54.154602207Z I1024 13:08:54.154549       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:08:54.505554069Z I1024 13:08:54.505478       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-5 -n openshift-kube-scheduler because it was missing
2024-10-24T13:08:54.505554069Z I1024 13:08:54.505531       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:08:55.306856837Z I1024 13:08:55.306769       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-5 -n openshift-kube-scheduler because it was missing
2024-10-24T13:08:55.306899057Z I1024 13:08:55.306851       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:08:55.504151954Z I1024 13:08:55.504093       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 4, but has not made progress because static pod is pending
2024-10-24T13:08:56.107332475Z I1024 13:08:56.107290       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:08:56.107453045Z I1024 13:08:56.107395       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/scheduler-kubeconfig-5 -n openshift-kube-scheduler because it was missing
2024-10-24T13:08:56.907937483Z I1024 13:08:56.907862       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:08:56.908495303Z I1024 13:08:56.908444       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-scheduler-cert-syncer-kubeconfig-5 -n openshift-kube-scheduler because it was missing
2024-10-24T13:08:57.710242320Z I1024 13:08:57.710152       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-5 -n openshift-kube-scheduler because it was missing
2024-10-24T13:08:57.912252177Z I1024 13:08:57.912169       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 4, but has not made progress because static pod is pending
2024-10-24T13:08:58.510523098Z I1024 13:08:58.510419       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-5 -n openshift-kube-scheduler because it was missing
2024-10-24T13:08:59.307680796Z I1024 13:08:59.306920       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:08:59.307895386Z I1024 13:08:59.307829       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 5 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:08:59.308138446Z W1024 13:08:59.308100       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:08:59.308138446Z W1024 13:08:59.308128       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:08:59.324624896Z I1024 13:08:59.324593       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:09:00.503468807Z I1024 13:09:00.503386       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 4, but has not made progress because static pod is pending
2024-10-24T13:09:00.520137238Z I1024 13:09:00.520084       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:09:00.520435268Z I1024 13:09:00.520407       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:09:00.534243129Z I1024 13:09:00.534191       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5"
2024-10-24T13:09:01.509491592Z I1024 13:09:01.509435       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:09:01.509491592Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:09:01.509491592Z  CurrentRevision: (int32) 0,
2024-10-24T13:09:01.509491592Z  TargetRevision: (int32) 5,
2024-10-24T13:09:01.509491592Z  LastFailedRevision: (int32) 0,
2024-10-24T13:09:01.509491592Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:09:01.509491592Z  LastFailedReason: (string) "",
2024-10-24T13:09:01.509491592Z  LastFailedCount: (int) 0,
2024-10-24T13:09:01.509491592Z  LastFallbackCount: (int) 0,
2024-10-24T13:09:01.509491592Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:09:01.509491592Z }
2024-10-24T13:09:01.509491592Z  because new revision pending
2024-10-24T13:09:01.526848703Z I1024 13:09:01.526800       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:09:01.698865188Z I1024 13:09:01.698795       1 request.go:700] Waited for 1.178233521s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa
2024-10-24T13:09:02.331388730Z I1024 13:09:02.329612       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:09:02.509840277Z E1024 13:09:02.507912       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:09:02.509840277Z E1024 13:09:02.507941       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:09:02.509840277Z E1024 13:09:02.509318       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:09:02.698853763Z I1024 13:09:02.698804       1 request.go:700] Waited for 1.1705115s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:09:03.739470940Z I1024 13:09:03.739345       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-scheduler because it was missing
2024-10-24T13:09:04.898975149Z I1024 13:09:04.898912       1 request.go:700] Waited for 1.1593095s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2024-10-24T13:09:04.900343370Z E1024 13:09:04.900293       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:05.038310204Z E1024 13:09:05.038235       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:09:05.039070384Z E1024 13:09:05.039021       1 leaderelection.go:436] error retrieving resource lock openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:05.099900566Z E1024 13:09:05.099847       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:09:05.099900566Z E1024 13:09:05.099877       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:09:05.101367136Z W1024 13:09:05.101304       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:05.101367136Z E1024 13:09:05.101343       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:09:05.700928387Z E1024 13:09:05.700876       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:05.901591614Z E1024 13:09:05.901528       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:06.101560321Z E1024 13:09:06.101508       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:06.301533058Z E1024 13:09:06.301474       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:06.700177881Z E1024 13:09:06.700117       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:07.500312259Z E1024 13:09:07.500254       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:08.100610901Z E1024 13:09:08.100553       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:08.300447227Z E1024 13:09:08.300384       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:09.100151246Z E1024 13:09:09.100111       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:09.301656282Z E1024 13:09:09.301599       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:09.899559003Z E1024 13:09:09.899491       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:10.301177047Z E1024 13:09:10.301103       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:10.508384614Z E1024 13:09:10.508314       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:10.701316601Z E1024 13:09:10.701249       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:11.100491774Z E1024 13:09:11.100438       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:11.499133168Z I1024 13:09:11.499077       1 request.go:700] Waited for 1.014528725s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:09:11.499739598Z E1024 13:09:11.499705       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:09:11.499739598Z E1024 13:09:11.499722       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:09:11.500944938Z W1024 13:09:11.500911       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:11.500962368Z E1024 13:09:11.500946       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:09:11.901019132Z I1024 13:09:11.900938       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:11.902001392Z E1024 13:09:11.901971       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:11.902162172Z E1024 13:09:11.902132       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{openshift-kube-scheduler-operator.180165848f45967a  openshift-kube-scheduler-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-scheduler-operator,Name:openshift-kube-scheduler-operator,UID:ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-kube-scheduler-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:11.900771962 +0000 UTC m=+267.418253068,LastTimestamp:2024-10-24 13:09:11.900771962 +0000 UTC m=+267.418253068,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-kube-scheduler-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:09:12.500304522Z E1024 13:09:12.500251       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:09:12.500304522Z E1024 13:09:12.500277       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:09:12.501594572Z W1024 13:09:12.501557       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:12.501617843Z E1024 13:09:12.501592       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:09:12.899484046Z I1024 13:09:12.899435       1 request.go:700] Waited for 1.157000019s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2024-10-24T13:09:12.900317636Z E1024 13:09:12.900279       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:13.100114103Z I1024 13:09:13.100048       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:13.101251923Z E1024 13:09:13.101201       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:13.302614790Z E1024 13:09:13.302559       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:13.702091734Z E1024 13:09:13.702024       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:13.899713690Z I1024 13:09:13.899630       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:13.900785510Z E1024 13:09:13.900725       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:14.700657158Z I1024 13:09:14.700596       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:14.701701228Z E1024 13:09:14.701663       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:15.100010102Z E1024 13:09:15.099934       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:15.301960099Z E1024 13:09:15.301890       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:15.700432982Z I1024 13:09:15.700372       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:15.701243752Z E1024 13:09:15.701203       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:16.301223704Z E1024 13:09:16.301164       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:16.500198241Z I1024 13:09:16.500133       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:16.501014980Z E1024 13:09:16.500984       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:16.701220948Z E1024 13:09:16.701167       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:17.300308728Z I1024 13:09:17.300204       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:17.301238018Z E1024 13:09:17.301208       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:18.100165096Z I1024 13:09:18.100089       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:18.101232156Z E1024 13:09:18.101197       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:18.500418330Z E1024 13:09:18.500364       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:18.900603113Z E1024 13:09:18.900549       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:19.100467900Z I1024 13:09:19.100383       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:19.101421301Z E1024 13:09:19.101370       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:19.501085844Z E1024 13:09:19.501037       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:19.901716548Z E1024 13:09:19.901658       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:20.100439695Z I1024 13:09:20.100370       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:20.101324725Z E1024 13:09:20.101289       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:21.099056370Z E1024 13:09:21.098992       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{openshift-kube-scheduler-operator.180165848f45967a  openshift-kube-scheduler-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-scheduler-operator,Name:openshift-kube-scheduler-operator,UID:ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-kube-scheduler-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:11.900771962 +0000 UTC m=+267.418253068,LastTimestamp:2024-10-24 13:09:11.900771962 +0000 UTC m=+267.418253068,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-kube-scheduler-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:09:21.100529091Z E1024 13:09:21.100423       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:22.501742759Z E1024 13:09:22.501680       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:22.701070856Z E1024 13:09:22.700997       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:22.901673223Z E1024 13:09:22.901612       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:24.300444402Z E1024 13:09:24.300395       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:24.900865013Z E1024 13:09:24.900798       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:25.101401200Z E1024 13:09:25.101343       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:25.899999327Z I1024 13:09:25.899925       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:25.900969797Z E1024 13:09:25.900923       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:26.101156104Z E1024 13:09:26.101093       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:26.901436842Z E1024 13:09:26.901386       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:27.701392980Z E1024 13:09:27.701311       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:28.700446624Z E1024 13:09:28.700389       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:29.100798908Z E1024 13:09:29.100714       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:29.701563449Z E1024 13:09:29.701498       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:31.040586165Z E1024 13:09:31.040500       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:09:31.041401915Z E1024 13:09:31.041363       1 leaderelection.go:436] error retrieving resource lock openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:31.100153637Z E1024 13:09:31.100092       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{openshift-kube-scheduler-operator.180165848f45967a  openshift-kube-scheduler-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-scheduler-operator,Name:openshift-kube-scheduler-operator,UID:ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-kube-scheduler-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:11.900771962 +0000 UTC m=+267.418253068,LastTimestamp:2024-10-24 13:09:11.900771962 +0000 UTC m=+267.418253068,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-kube-scheduler-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:09:31.100731587Z E1024 13:09:31.100689       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:31.701614568Z E1024 13:09:31.701560       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:31.901418925Z E1024 13:09:31.901321       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:33.502523820Z E1024 13:09:33.502448       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:33.700928867Z E1024 13:09:33.700872       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:34.900687049Z E1024 13:09:34.900624       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:35.100438045Z E1024 13:09:35.100370       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:36.101347420Z E1024 13:09:36.101292       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:36.499653024Z I1024 13:09:36.499590       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:36.500479113Z E1024 13:09:36.500450       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:36.900924197Z E1024 13:09:36.900866       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:41.101584713Z E1024 13:09:41.101532       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{openshift-kube-scheduler-operator.180165848f45967a  openshift-kube-scheduler-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-scheduler-operator,Name:openshift-kube-scheduler-operator,UID:ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-kube-scheduler-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:11.900771962 +0000 UTC m=+267.418253068,LastTimestamp:2024-10-24 13:09:11.900771962 +0000 UTC m=+267.418253068,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-kube-scheduler-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:09:41.346989371Z E1024 13:09:41.346927       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:42.028168324Z E1024 13:09:42.028120       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:45.081512126Z E1024 13:09:45.081386       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:45.083918976Z E1024 13:09:45.083853       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:45.383914407Z E1024 13:09:45.383863       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:45.387957037Z E1024 13:09:45.387914       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:45.392572137Z E1024 13:09:45.392533       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:45.406251968Z E1024 13:09:45.406204       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:45.484284551Z E1024 13:09:45.484223       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:45.683869787Z E1024 13:09:45.683813       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:45.883790964Z E1024 13:09:45.883700       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:46.084436771Z E1024 13:09:46.084379       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:46.884335258Z E1024 13:09:46.884273       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:47.882297613Z E1024 13:09:47.882240       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:48.084195540Z E1024 13:09:48.084131       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:48.283137247Z E1024 13:09:48.283073       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:49.369421554Z E1024 13:09:49.369361       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:51.102837564Z E1024 13:09:51.102796       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{openshift-kube-scheduler-operator.180165848f45967a  openshift-kube-scheduler-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-scheduler-operator,Name:openshift-kube-scheduler-operator,UID:ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-kube-scheduler-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:11.900771962 +0000 UTC m=+267.418253068,LastTimestamp:2024-10-24 13:09:11.900771962 +0000 UTC m=+267.418253068,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-kube-scheduler-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:09:51.934202102Z E1024 13:09:51.934065       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:52.275193493Z E1024 13:09:52.275134       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:55.583051627Z E1024 13:09:55.582988       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:56.984320984Z I1024 13:09:56.984251       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:56.985141734Z E1024 13:09:56.985102       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:57.040391015Z E1024 13:09:57.040322       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:09:57.040988135Z E1024 13:09:57.040937       1 leaderelection.go:436] error retrieving resource lock openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:57.058890625Z E1024 13:09:57.058840       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:01.104083371Z E1024 13:10:01.103993       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{openshift-kube-scheduler-operator.180165848f45967a  openshift-kube-scheduler-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-scheduler-operator,Name:openshift-kube-scheduler-operator,UID:ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-kube-scheduler-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:11.900771962 +0000 UTC m=+267.418253068,LastTimestamp:2024-10-24 13:09:11.900771962 +0000 UTC m=+267.418253068,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-kube-scheduler-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:10:01.832739258Z E1024 13:10:01.832683       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:07.304183448Z E1024 13:10:07.304115       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:11.105480659Z E1024 13:10:11.105420       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{openshift-kube-scheduler-operator.180165848f45967a  openshift-kube-scheduler-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-scheduler-operator,Name:openshift-kube-scheduler-operator,UID:ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-kube-scheduler-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:11.900771962 +0000 UTC m=+267.418253068,LastTimestamp:2024-10-24 13:09:11.900771962 +0000 UTC m=+267.418253068,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-kube-scheduler-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:10:21.107251377Z E1024 13:10:21.107187       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{openshift-kube-scheduler-operator.180165848f45967a  openshift-kube-scheduler-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-scheduler-operator,Name:openshift-kube-scheduler-operator,UID:ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-kube-scheduler-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:11.900771962 +0000 UTC m=+267.418253068,LastTimestamp:2024-10-24 13:09:11.900771962 +0000 UTC m=+267.418253068,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-kube-scheduler-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:10:23.040185253Z E1024 13:10:23.040105       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:10:23.040833653Z E1024 13:10:23.040780       1 leaderelection.go:436] error retrieving resource lock openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:27.790071726Z E1024 13:10:27.790008       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:29.253551301Z E1024 13:10:29.253489       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:31.108935865Z E1024 13:10:31.108883       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{openshift-kube-scheduler-operator.180165848f45967a  openshift-kube-scheduler-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-scheduler-operator,Name:openshift-kube-scheduler-operator,UID:ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-kube-scheduler-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:11.900771962 +0000 UTC m=+267.418253068,LastTimestamp:2024-10-24 13:09:11.900771962 +0000 UTC m=+267.418253068,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-kube-scheduler-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:10:33.247281046Z E1024 13:10:33.247216       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:37.948549338Z I1024 13:10:37.948476       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:37.949959778Z E1024 13:10:37.949900       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:11:23.665820881Z I1024 13:11:23.665728       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubeschedulers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:23.666591801Z I1024 13:11:23.666548       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:23.689286341Z I1024 13:11:23.689216       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 5, but has not made progress because static pod is pending
2024-10-24T13:11:23.698688871Z I1024 13:11:23.698644       1 reflector.go:368] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:23.705710511Z I1024 13:11:23.705656       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:29.329125661Z I1024 13:11:29.329058       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:33.153817091Z I1024 13:11:33.153727       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:33.209892782Z I1024 13:11:33.209432       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:34.073667041Z I1024 13:11:34.073607       1 reflector.go:368] Caches populated for *v1.Role from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:34.227071282Z I1024 13:11:34.227020       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:34.227267903Z I1024 13:11:34.227243       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:34.228045253Z I1024 13:11:34.228004       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:34.228318643Z I1024 13:11:34.228256       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:34.228454852Z I1024 13:11:34.228437       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:34.228594093Z I1024 13:11:34.228572       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:34.228770052Z I1024 13:11:34.228714       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:34.359938814Z I1024 13:11:34.359884       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 5, but has not made progress because static pod is pending
2024-10-24T13:11:35.956075081Z I1024 13:11:35.956001       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 5, but has not made progress because static pod is pending
2024-10-24T13:11:36.152623823Z I1024 13:11:36.152556       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:37.956827532Z I1024 13:11:37.956345       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:38.927158113Z I1024 13:11:38.927097       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:39.953788734Z I1024 13:11:39.953698       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:40.354370578Z I1024 13:11:40.354295       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:40.355867357Z I1024 13:11:40.355815       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 6 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:11:41.149630036Z I1024 13:11:41.149563       1 request.go:700] Waited for 1.195000772s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:11:41.758563383Z I1024 13:11:41.758448       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:42.153797517Z I1024 13:11:42.151859       1 request.go:700] Waited for 1.391693695s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2024-10-24T13:11:42.555735341Z E1024 13:11:42.555673       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:11:42.555735341Z E1024 13:11:42.555694       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:11:42.556568381Z E1024 13:11:42.556535       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:11:42.557980791Z E1024 13:11:42.557930       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:11:43.160279738Z I1024 13:11:43.160217       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:43.160874727Z I1024 13:11:43.160841       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-scheduler-pod-6 -n openshift-kube-scheduler because it was missing
2024-10-24T13:11:43.349575609Z I1024 13:11:43.349529       1 request.go:700] Waited for 1.362135484s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler
2024-10-24T13:11:43.956018966Z I1024 13:11:43.955980       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 5, but has not made progress because static pod is pending
2024-10-24T13:11:44.351319999Z I1024 13:11:44.350680       1 request.go:700] Waited for 1.190050622s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps
2024-10-24T13:11:44.359876290Z I1024 13:11:44.359842       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:44.361172670Z I1024 13:11:44.361125       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-6 -n openshift-kube-scheduler because it was missing
2024-10-24T13:11:44.956895026Z E1024 13:11:44.956826       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:11:44.957562676Z E1024 13:11:44.957531       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:11:45.549942732Z I1024 13:11:45.549885       1 request.go:700] Waited for 1.188784782s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps
2024-10-24T13:11:45.561542602Z I1024 13:11:45.561491       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:45.563301272Z I1024 13:11:45.563264       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-6 -n openshift-kube-scheduler because it was missing
2024-10-24T13:11:45.781984005Z I1024 13:11:45.781915       1 reflector.go:368] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:46.549974603Z I1024 13:11:46.549909       1 request.go:700] Waited for 1.194612903s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/secrets/localhost-recovery-client-token
2024-10-24T13:11:46.961443217Z I1024 13:11:46.961368       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:46.967261497Z I1024 13:11:46.967188       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/scheduler-kubeconfig-6 -n openshift-kube-scheduler because it was missing
2024-10-24T13:11:47.555923493Z I1024 13:11:47.555834       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 5, but has not made progress because static pod is pending
2024-10-24T13:11:47.749985275Z I1024 13:11:47.749917       1 request.go:700] Waited for 1.193805152s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/scheduler-kubeconfig
2024-10-24T13:11:47.957192258Z I1024 13:11:47.957110       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:47.957248068Z I1024 13:11:47.957213       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-scheduler-cert-syncer-kubeconfig-6 -n openshift-kube-scheduler because it was missing
2024-10-24T13:11:48.961428879Z I1024 13:11:48.961362       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-6 -n openshift-kube-scheduler because it was missing
2024-10-24T13:11:49.155963410Z I1024 13:11:49.155894       1 reflector.go:368] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:49.971025059Z I1024 13:11:49.970946       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-6 -n openshift-kube-scheduler because it was missing
2024-10-24T13:11:50.349858603Z I1024 13:11:50.349702       1 request.go:700] Waited for 1.00628342s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/configmaps?resourceVersion=16412
2024-10-24T13:11:50.367603133Z I1024 13:11:50.367550       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:50.760280467Z I1024 13:11:50.760210       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 5, but has not made progress because static pod is pending
2024-10-24T13:11:51.158293362Z I1024 13:11:51.158217       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:51.158820612Z I1024 13:11:51.158759       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 6 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:11:51.159289222Z I1024 13:11:51.159241       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:51.159533971Z W1024 13:11:51.159495       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:51.159533971Z W1024 13:11:51.159515       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:51.179569142Z W1024 13:11:51.179529       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:51.179569142Z W1024 13:11:51.179546       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:51.181936682Z I1024 13:11:51.181900       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:51.349900904Z I1024 13:11:51.349847       1 request.go:700] Waited for 1.192663153s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler
2024-10-24T13:11:51.953224310Z I1024 13:11:51.953157       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:52.350337934Z I1024 13:11:52.350226       1 request.go:700] Waited for 1.168204972s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:11:52.552955866Z I1024 13:11:52.552908       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:53.018222131Z I1024 13:11:53.018158       1 reflector.go:368] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:53.759834379Z I1024 13:11:53.759782       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 5, but has not made progress because static pod is pending
2024-10-24T13:11:53.780574260Z I1024 13:11:53.780533       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:53.780937790Z I1024 13:11:53.780887       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:53.792418110Z I1024 13:11:53.792373       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6"
2024-10-24T13:11:54.756349669Z I1024 13:11:54.756291       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:11:54.756349669Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:11:54.756349669Z  CurrentRevision: (int32) 0,
2024-10-24T13:11:54.756349669Z  TargetRevision: (int32) 6,
2024-10-24T13:11:54.756349669Z  LastFailedRevision: (int32) 0,
2024-10-24T13:11:54.756349669Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:11:54.756349669Z  LastFailedReason: (string) "",
2024-10-24T13:11:54.756349669Z  LastFailedCount: (int) 0,
2024-10-24T13:11:54.756349669Z  LastFallbackCount: (int) 0,
2024-10-24T13:11:54.756349669Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:11:54.756349669Z }
2024-10-24T13:11:54.756349669Z  because new revision pending
2024-10-24T13:11:55.749773680Z I1024 13:11:55.749705       1 request.go:700] Waited for 1.137721632s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services?resourceVersion=16112
2024-10-24T13:11:55.752513310Z I1024 13:11:55.752460       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:55.956872782Z I1024 13:11:55.956813       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:11:55.956872782Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:11:55.956872782Z  CurrentRevision: (int32) 0,
2024-10-24T13:11:55.956872782Z  TargetRevision: (int32) 6,
2024-10-24T13:11:55.956872782Z  LastFailedRevision: (int32) 0,
2024-10-24T13:11:55.956872782Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:11:55.956872782Z  LastFailedReason: (string) "",
2024-10-24T13:11:55.956872782Z  LastFailedCount: (int) 0,
2024-10-24T13:11:55.956872782Z  LastFallbackCount: (int) 0,
2024-10-24T13:11:55.956872782Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:11:55.956872782Z }
2024-10-24T13:11:55.956872782Z  because new revision pending
2024-10-24T13:11:56.750403421Z I1024 13:11:56.750308       1 request.go:700] Waited for 1.555435707s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config/configmaps?resourceVersion=16411
2024-10-24T13:11:56.754174971Z I1024 13:11:56.754148       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:57.567998120Z I1024 13:11:57.567905       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-6-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-scheduler because it was missing
2024-10-24T13:11:58.361185008Z I1024 13:11:58.361124       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-6-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-scheduler because it was missing
2024-10-24T13:11:58.749709462Z I1024 13:11:58.749661       1 request.go:700] Waited for 1.183979843s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:11:58.807255792Z I1024 13:11:58.807198       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:59.758263553Z I1024 13:11:59.758192       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:11:59.949958995Z I1024 13:11:59.949907       1 request.go:700] Waited for 1.391297955s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2024-10-24T13:12:00.153715297Z I1024 13:12:00.153673       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:00.359795589Z E1024 13:12:00.359711       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:12:00.359795589Z E1024 13:12:00.359736       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:12:00.360921279Z E1024 13:12:00.360878       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:12:00.362702419Z E1024 13:12:00.362678       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:12:00.562122661Z I1024 13:12:00.562070       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-6-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-scheduler because it was missing
2024-10-24T13:12:01.150897368Z I1024 13:12:01.150847       1 request.go:700] Waited for 1.588487657s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler
2024-10-24T13:12:02.349987420Z I1024 13:12:02.349938       1 request.go:700] Waited for 1.393756554s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:12:02.755849475Z I1024 13:12:02.755776       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:12:03.157326939Z E1024 13:12:03.156633       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:12:03.157668549Z E1024 13:12:03.157639       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:12:03.358362701Z I1024 13:12:03.358256       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-6-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-scheduler because it was missing
2024-10-24T13:12:03.550127663Z I1024 13:12:03.550070       1 request.go:700] Waited for 1.394504985s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/secrets/localhost-recovery-client-token
2024-10-24T13:12:04.550549443Z I1024 13:12:04.550486       1 request.go:700] Waited for 1.390582055s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:12:05.291983412Z I1024 13:12:05.291924       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:05.556921504Z I1024 13:12:05.556860       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:12:05.750061526Z I1024 13:12:05.750007       1 request.go:700] Waited for 1.391966654s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2024-10-24T13:12:05.959873058Z E1024 13:12:05.959820       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:12:05.959985039Z E1024 13:12:05.959964       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:12:05.961254158Z E1024 13:12:05.961213       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:12:06.750562446Z I1024 13:12:06.750502       1 request.go:700] Waited for 1.393767135s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler
2024-10-24T13:12:07.949722725Z I1024 13:12:07.949674       1 request.go:700] Waited for 1.169808538s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler
2024-10-24T13:12:08.157347652Z I1024 13:12:08.157286       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:12:08.358290170Z E1024 13:12:08.358244       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:12:08.358290170Z E1024 13:12:08.358266       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:12:08.359316890Z E1024 13:12:08.359248       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:12:08.949745793Z I1024 13:12:08.949690       1 request.go:700] Waited for 1.333512185s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2024-10-24T13:12:09.950521112Z I1024 13:12:09.950456       1 request.go:700] Waited for 1.393760055s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/revision-pruner-6-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:12:10.353803287Z I1024 13:12:10.353714       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:11.150504658Z I1024 13:12:11.150438       1 request.go:700] Waited for 1.592067821s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-6-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:12:11.157097928Z I1024 13:12:11.157015       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:12:11.355889555Z E1024 13:12:11.355839       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:12:11.355889555Z E1024 13:12:11.355862       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:12:11.356570075Z E1024 13:12:11.356536       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:12:11.398409595Z I1024 13:12:11.398368       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:11.553458333Z I1024 13:12:11.553392       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:12.350306304Z I1024 13:12:12.350226       1 request.go:700] Waited for 1.595452932s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:12:12.371388523Z I1024 13:12:12.371312       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:13.557060560Z I1024 13:12:13.557004       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:12:13.755320787Z E1024 13:12:13.755272       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:12:13.755320787Z E1024 13:12:13.755296       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:12:13.756394447Z E1024 13:12:13.756353       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:12:14.354919540Z I1024 13:12:14.354805       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:15.155873771Z E1024 13:12:15.155816       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:12:15.155873771Z E1024 13:12:15.155838       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:12:15.156629411Z E1024 13:12:15.156596       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:12:24.221794487Z E1024 13:12:24.221675       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:12:24.221794487Z E1024 13:12:24.221708       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:12:24.223252717Z E1024 13:12:24.223203       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:12:33.087633495Z E1024 13:12:33.087558       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:12:33.088250395Z E1024 13:12:33.088097       1 leaderelection.go:436] error retrieving resource lock openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:45.083429196Z E1024 13:12:45.083360       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:45.085506085Z E1024 13:12:45.085467       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:45.091532976Z E1024 13:12:45.091481       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:45.095105546Z E1024 13:12:45.095041       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:45.104291535Z E1024 13:12:45.104253       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:45.483512221Z E1024 13:12:45.483455       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:45.684607579Z E1024 13:12:45.684541       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:45.885869047Z E1024 13:12:45.885808       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:46.283567532Z E1024 13:12:46.283521       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:46.685579887Z E1024 13:12:46.685523       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:47.283583630Z E1024 13:12:47.283518       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:47.685959436Z E1024 13:12:47.685903       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:48.283322819Z E1024 13:12:48.283263       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:48.484260197Z E1024 13:12:48.484210       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:48.685063104Z E1024 13:12:48.685014       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:49.085393490Z E1024 13:12:49.085324       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:49.483037575Z E1024 13:12:49.482985       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:49.685281703Z E1024 13:12:49.685224       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:50.485409494Z E1024 13:12:50.485338       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:50.683809542Z E1024 13:12:50.683730       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:51.083647187Z E1024 13:12:51.083594       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:51.284376385Z E1024 13:12:51.284332       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:51.485713432Z E1024 13:12:51.485643       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:52.485329611Z E1024 13:12:52.485262       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:52.685405309Z E1024 13:12:52.685343       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:53.283985491Z E1024 13:12:53.283906       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:53.684879827Z E1024 13:12:53.684815       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:54.085178303Z E1024 13:12:54.085115       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:54.684535606Z E1024 13:12:54.684475       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:55.485108516Z E1024 13:12:55.485050       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:55.684651414Z E1024 13:12:55.684594       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:56.085059670Z E1024 13:12:56.085010       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:56.483008905Z E1024 13:12:56.482950       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:57.884925749Z E1024 13:12:57.884863       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:58.084383576Z E1024 13:12:58.084328       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:58.285716044Z E1024 13:12:58.285658       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:59.084929515Z E1024 13:12:59.084866       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:59.089969845Z E1024 13:12:59.089916       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:12:59.090431585Z E1024 13:12:59.090386       1 leaderelection.go:436] error retrieving resource lock openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:00.485633159Z E1024 13:13:00.485570       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:00.684287936Z E1024 13:13:00.684225       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:00.884580494Z E1024 13:13:00.884523       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:02.083669581Z E1024 13:13:02.083601       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:02.485089326Z E1024 13:13:02.485023       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:03.485249405Z E1024 13:13:03.485194       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:03.884904930Z E1024 13:13:03.884859       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:04.685910991Z E1024 13:13:04.685842       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:04.884915388Z E1024 13:13:04.884860       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:05.684129599Z E1024 13:13:05.684082       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:06.685202178Z E1024 13:13:06.685135       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:07.684145666Z E1024 13:13:07.684093       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:08.085311571Z E1024 13:13:08.085259       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:08.885079903Z E1024 13:13:08.885023       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:09.685341363Z E1024 13:13:09.685273       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:10.486082134Z E1024 13:13:10.486012       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:11.484397233Z E1024 13:13:11.484335       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:12.326064181Z E1024 13:13:12.325994       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:12.772059376Z E1024 13:13:12.771998       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:13.484587810Z E1024 13:13:13.484505       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:14.085138583Z E1024 13:13:14.085081       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:14.930440267Z E1024 13:13:14.930377       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:15.339511385Z E1024 13:13:15.339461       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:19.215412112Z E1024 13:13:19.215348       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:20.468352463Z E1024 13:13:20.468300       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:58.555103628Z I1024 13:13:58.555035       1 reflector.go:368] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:04.440098227Z I1024 13:14:04.440032       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:10.961123616Z I1024 13:14:10.961069       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:11.476303406Z I1024 13:14:11.476253       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:18.930033002Z I1024 13:14:18.929972       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:21.987444505Z I1024 13:14:21.987374       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:22.562363044Z I1024 13:14:22.562309       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:24.142594717Z E1024 13:14:24.142207       1 leaderelection.go:429] Failed to update lock optimitically: rpc error: code = DeadlineExceeded desc = context deadline exceeded, falling back to slow path
2024-10-24T13:14:25.226999398Z I1024 13:14:25.226907       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:26.335632677Z I1024 13:14:26.335577       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:26.391663194Z I1024 13:14:26.391611       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:27.022101160Z I1024 13:14:27.022064       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:28.928929856Z I1024 13:14:28.928891       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:32.137767570Z I1024 13:14:32.137684       1 reflector.go:368] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:33.548724873Z I1024 13:14:33.548681       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:33.890986764Z I1024 13:14:33.890942       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:35.202835513Z I1024 13:14:35.202791       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:36.439603795Z I1024 13:14:36.439547       1 reflector.go:368] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:36.786737686Z I1024 13:14:36.786680       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:39.854656358Z I1024 13:14:39.854530       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:42.312198364Z I1024 13:14:42.312128       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:51.955052817Z I1024 13:14:51.954994       1 reflector.go:368] Caches populated for *v1.Role from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:54.305534758Z I1024 13:14:54.305495       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:55.822927946Z I1024 13:14:55.822867       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:18.302625767Z I1024 13:15:18.302572       1 trace.go:236] Trace[1723917469]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:14:42.629) (total time: 35673ms):
2024-10-24T13:15:18.302625767Z Trace[1723917469]: ---"Objects listed" error:<nil> 35673ms (13:15:18.302)
2024-10-24T13:15:18.302625767Z Trace[1723917469]: [35.6733958s] [35.6733958s] END
2024-10-24T13:15:18.302625767Z I1024 13:15:18.302593       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubeschedulers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:18.637417879Z I1024 13:15:18.637373       1 trace.go:236] Trace[139423194]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:14:56.284) (total time: 22352ms):
2024-10-24T13:15:18.637417879Z Trace[139423194]: ---"Objects listed" error:<nil> 22352ms (13:15:18.637)
2024-10-24T13:15:18.637417879Z Trace[139423194]: [22.352476968s] [22.352476968s] END
2024-10-24T13:15:18.637516439Z I1024 13:15:18.637496       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:18.667247247Z I1024 13:15:18.667210       1 reflector.go:368] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:19.177562009Z E1024 13:15:19.177502       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: synthetic requeue request"
2024-10-24T13:15:19.178642189Z I1024 13:15:19.178607       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nTargetConfigControllerDegraded: \"configmap\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type","reason":"GuardController_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:19.327215011Z I1024 13:15:19.327084       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]" to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nTargetConfigControllerDegraded: \"configmap\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type"
2024-10-24T13:15:19.476298503Z I1024 13:15:19.475131       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler)\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type","reason":"GuardController_SyncError::KubeControllerManagerStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:19.506077741Z E1024 13:15:19.506028       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: \"assets/kube-scheduler/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler)"
2024-10-24T13:15:19.750713528Z E1024 13:15:19.750650       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:19.757837068Z I1024 13:15:19.757739       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler)\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type","reason":"GuardController_SyncError::KubeControllerManagerStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:19.789895516Z I1024 13:15:19.789798       1 trace.go:236] Trace[365574623]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:15:05.080) (total time: 14708ms):
2024-10-24T13:15:19.789895516Z Trace[365574623]: ---"Objects listed" error:<nil> 14708ms (13:15:19.789)
2024-10-24T13:15:19.789895516Z Trace[365574623]: [14.708902106s] [14.708902106s] END
2024-10-24T13:15:19.789895516Z I1024 13:15:19.789821       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:19.789895516Z I1024 13:15:19.789872       1 trace.go:236] Trace[1687840671]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:14:50.343) (total time: 29445ms):
2024-10-24T13:15:19.789895516Z Trace[1687840671]: ---"Objects listed" error:<nil> 29445ms (13:15:19.789)
2024-10-24T13:15:19.789895516Z Trace[1687840671]: [29.445999351s] [29.445999351s] END
2024-10-24T13:15:19.789895516Z I1024 13:15:19.789884       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:19.791157646Z I1024 13:15:19.791113       1 trace.go:236] Trace[1194636746]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:14:57.031) (total time: 22759ms):
2024-10-24T13:15:19.791157646Z Trace[1194636746]: ---"Objects listed" error:<nil> 22759ms (13:15:19.791)
2024-10-24T13:15:19.791157646Z Trace[1194636746]: [22.759674216s] [22.759674216s] END
2024-10-24T13:15:19.791157646Z I1024 13:15:19.791131       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:19.973935886Z E1024 13:15:19.973873       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:19.986047555Z I1024 13:15:19.985997       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler)\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type","reason":"GuardController_SyncError::KubeControllerManagerStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:20.039923882Z E1024 13:15:20.039865       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:20.062011821Z I1024 13:15:20.061949       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler)\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type","reason":"GuardController_SyncError::KubeControllerManagerStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:20.157651736Z E1024 13:15:20.157577       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:20.159961776Z I1024 13:15:20.159918       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler)\nKubeControllerManagerStaticResourcesDegraded: ","reason":"GuardController_SyncError::KubeControllerManagerStaticResources_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:20.211930603Z E1024 13:15:20.211839       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:20.213722403Z I1024 13:15:20.213642       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler)\nKubeControllerManagerStaticResourcesDegraded: ","reason":"GuardController_SyncError::KubeControllerManagerStaticResources_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:20.265505680Z E1024 13:15:20.261572       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:20.293913158Z I1024 13:15:20.293839       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler)\nKubeControllerManagerStaticResourcesDegraded: ","reason":"GuardController_SyncError::KubeControllerManagerStaticResources_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:20.325409717Z I1024 13:15:20.325369       1 trace.go:236] Trace[368280067]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:14:59.291) (total time: 21033ms):
2024-10-24T13:15:20.325409717Z Trace[368280067]: ---"Objects listed" error:<nil> 21033ms (13:15:20.325)
2024-10-24T13:15:20.325409717Z Trace[368280067]: [21.033350931s] [21.033350931s] END
2024-10-24T13:15:20.325504717Z I1024 13:15:20.325472       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:20.455823170Z E1024 13:15:20.455775       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:20.779415702Z I1024 13:15:20.779331       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler)\nKubeControllerManagerStaticResourcesDegraded: ","reason":"GuardController_SyncError::KubeControllerManagerStaticResources_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:20.877881066Z E1024 13:15:20.877824       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:21.190509340Z E1024 13:15:21.190442       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:21.190509340Z E1024 13:15:21.190468       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:21.191689570Z E1024 13:15:21.191606       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:21.371268203Z I1024 13:15:21.371196       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-0" for revision 6 for the 1st time because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:21.371268203Z W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:21.371268203Z W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:21.371268203Z W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:21.371268203Z W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:21.371268203Z W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:21.371268203Z W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:21.371268203Z F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:15:21.371364062Z I1024 13:15:21.371333       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:15:21.371364062Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:15:21.371364062Z  CurrentRevision: (int32) 0,
2024-10-24T13:15:21.371364062Z  TargetRevision: (int32) 6,
2024-10-24T13:15:21.371364062Z  LastFailedRevision: (int32) 6,
2024-10-24T13:15:21.371364062Z  LastFailedTime: (*v1.Time)(0xc001ffe4f8)(2024-10-24 13:15:21.371167393 +0000 UTC m=+636.888648509),
2024-10-24T13:15:21.371364062Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:15:21.371364062Z  LastFailedCount: (int) 1,
2024-10-24T13:15:21.371364062Z  LastFallbackCount: (int) 0,
2024-10-24T13:15:21.371364062Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:15:21.371364062Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:15:21.371364062Z  }
2024-10-24T13:15:21.371364062Z }
2024-10-24T13:15:21.371364062Z  because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:21.371364062Z W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:21.371364062Z W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:21.371364062Z W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:21.371364062Z W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:21.371364062Z W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:21.371364062Z W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:21.371364062Z F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:15:21.371417863Z I1024 13:15:21.371360       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:21.371417863Z W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:21.371417863Z W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:21.371417863Z W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:21.371417863Z W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:21.371417863Z W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:21.371417863Z W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:21.371417863Z F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:15:21.520351946Z I1024 13:15:21.520285       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler)\nKubeControllerManagerStaticResourcesDegraded: ","reason":"GuardController_SyncError::KubeControllerManagerStaticResources_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:21.677210720Z E1024 13:15:21.677143       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:21.679243799Z I1024 13:15:21.679203       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-scheduler)\nKubeControllerManagerStaticResourcesDegraded: \nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::KubeControllerManagerStaticResources_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:21.727933207Z E1024 13:15:21.727867       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:21.836805593Z I1024 13:15:21.836728       1 request.go:700] Waited for 1.015263144s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/revision-pruner-6-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:22.281773283Z W1024 13:15:22.281669       1 dynamic_operator_client.go:355] .status.conditions["KubeControllerManagerStaticResourcesDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:15:22.366708660Z I1024 13:15:22.366635       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:22.459491546Z E1024 13:15:22.459446       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:22.838120770Z I1024 13:15:22.838052       1 request.go:700] Waited for 1.303744084s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa
2024-10-24T13:15:22.962712755Z I1024 13:15:22.960665       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:23.001155763Z E1024 13:15:23.001079       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:23.073998050Z I1024 13:15:23.073932       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:23.099941698Z E1024 13:15:23.099690       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:23.102534318Z I1024 13:15:23.102482       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:23.129814568Z E1024 13:15:23.129696       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:23.878862365Z E1024 13:15:23.878502       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:23.878862365Z E1024 13:15:23.878536       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:23.879935325Z E1024 13:15:23.879884       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:24.037123548Z I1024 13:15:24.037063       1 request.go:700] Waited for 1.345427952s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-6-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:15:24.116739825Z I1024 13:15:24.116687       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-0" for revision 6 for the 1st time because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:24.116739825Z W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:24.116739825Z W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:24.116739825Z W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:24.116739825Z W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:24.116739825Z W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:24.116739825Z W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:24.116739825Z F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:15:24.116858685Z I1024 13:15:24.116720       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:24.116858685Z W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:24.116858685Z W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:24.116858685Z W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:24.116858685Z W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:24.116858685Z W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:24.116858685Z W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:24.116858685Z F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:15:24.116858685Z I1024 13:15:24.116820       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:15:24.116858685Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:15:24.116858685Z  CurrentRevision: (int32) 0,
2024-10-24T13:15:24.116858685Z  TargetRevision: (int32) 6,
2024-10-24T13:15:24.116858685Z  LastFailedRevision: (int32) 6,
2024-10-24T13:15:24.116858685Z  LastFailedTime: (*v1.Time)(0xc001fe5890)(2024-10-24 13:15:24.116665195 +0000 UTC m=+639.634146301),
2024-10-24T13:15:24.116858685Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:15:24.116858685Z  LastFailedCount: (int) 1,
2024-10-24T13:15:24.116858685Z  LastFallbackCount: (int) 0,
2024-10-24T13:15:24.116858685Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:15:24.116858685Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:15:24.116858685Z  }
2024-10-24T13:15:24.116858685Z }
2024-10-24T13:15:24.116858685Z  because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:24.116858685Z W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:24.116858685Z W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:24.116858685Z W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:24.116858685Z W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:24.116858685Z W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:24.116858685Z W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:15:24.116858685Z F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:15:24.217770831Z I1024 13:15:24.217682       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:24.250938189Z E1024 13:15:24.250862       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:25.236784817Z I1024 13:15:25.236707       1 request.go:700] Waited for 1.353766602s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:15:26.437036195Z I1024 13:15:26.436984       1 request.go:700] Waited for 1.192737459s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:15:26.459611255Z E1024 13:15:26.459539       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:26.459611255Z E1024 13:15:26.459568       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:26.460924014Z E1024 13:15:26.460877       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:26.643699416Z I1024 13:15:26.643639       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:26.655403676Z E1024 13:15:26.655356       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:26.656976216Z I1024 13:15:26.656931       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:26.665375196Z E1024 13:15:26.665338       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:28.453404569Z E1024 13:15:28.453354       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:28.453404569Z E1024 13:15:28.453385       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:28.454300439Z E1024 13:15:28.454263       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:28.455641159Z E1024 13:15:28.455615       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:29.643911868Z I1024 13:15:29.643853       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:29.658397297Z E1024 13:15:29.658356       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:29.660067057Z I1024 13:15:29.660032       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:29.669809507Z E1024 13:15:29.669691       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:30.447380144Z E1024 13:15:30.447334       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:30.448379893Z E1024 13:15:30.448335       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:30.449881343Z E1024 13:15:30.449817       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:31.444252961Z E1024 13:15:31.444179       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:31.445290001Z E1024 13:15:31.445250       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:32.245208126Z E1024 13:15:32.245141       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:32.245208126Z E1024 13:15:32.245170       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:32.246339856Z E1024 13:15:32.246285       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:32.646046769Z E1024 13:15:32.646007       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:32.646046769Z E1024 13:15:32.646030       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:32.647094649Z E1024 13:15:32.647067       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:33.052979082Z E1024 13:15:33.052893       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:33.052979082Z E1024 13:15:33.052941       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:33.053798452Z E1024 13:15:33.053776       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:33.243125303Z I1024 13:15:33.243023       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:33.252233243Z E1024 13:15:33.252185       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:33.450536034Z E1024 13:15:33.450472       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:33.450536034Z E1024 13:15:33.450503       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:33.451512314Z E1024 13:15:33.451438       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:33.843992878Z E1024 13:15:33.843937       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:33.843992878Z E1024 13:15:33.843965       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:33.845257508Z E1024 13:15:33.845219       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:34.245435351Z E1024 13:15:34.245373       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:34.245435351Z E1024 13:15:34.245399       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:34.246204940Z E1024 13:15:34.246168       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:36.655539337Z E1024 13:15:36.655481       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:36.655539337Z E1024 13:15:36.655511       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:36.676171206Z E1024 13:15:36.676092       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:36.692087835Z E1024 13:15:36.692050       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:36.692138175Z E1024 13:15:36.692117       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:36.693072865Z E1024 13:15:36.693032       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:38.638397982Z E1024 13:15:38.638336       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:38.638397982Z E1024 13:15:38.638368       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:38.639332912Z E1024 13:15:38.639295       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:38.841460773Z E1024 13:15:38.840412       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:38.856520353Z E1024 13:15:38.856471       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:38.857544962Z E1024 13:15:38.857502       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:39.035737715Z I1024 13:15:39.035632       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-6-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-scheduler because it was missing
2024-10-24T13:15:39.055407934Z I1024 13:15:39.055359       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:15:41.069624138Z E1024 13:15:41.069572       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:41.069624138Z E1024 13:15:41.069600       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:41.070776298Z E1024 13:15:41.070727       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:41.098523487Z E1024 13:15:41.098469       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:41.098523487Z E1024 13:15:41.098492       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:41.099521956Z E1024 13:15:41.099459       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:41.162578004Z E1024 13:15:41.162525       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:41.162578004Z E1024 13:15:41.162557       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:41.163463944Z E1024 13:15:41.163396       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:41.224288371Z E1024 13:15:41.224215       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:41.224288371Z E1024 13:15:41.224252       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:41.225175601Z E1024 13:15:41.225126       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:41.304280708Z E1024 13:15:41.304235       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:41.304280708Z E1024 13:15:41.304253       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:41.305087578Z E1024 13:15:41.305026       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:41.687889981Z E1024 13:15:41.687827       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:41.687889981Z E1024 13:15:41.687850       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:41.688674311Z E1024 13:15:41.688615       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:42.246853097Z E1024 13:15:42.246800       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:42.246853097Z E1024 13:15:42.246824       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:42.247531678Z E1024 13:15:42.247489       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:42.265155437Z E1024 13:15:42.265085       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:42.265155437Z E1024 13:15:42.265118       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:42.265982447Z E1024 13:15:42.265932       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:42.641516000Z E1024 13:15:42.641458       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:42.641516000Z E1024 13:15:42.641483       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:42.642506040Z E1024 13:15:42.642470       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:43.219901596Z E1024 13:15:43.219840       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:43.219901596Z E1024 13:15:43.219866       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:43.220811705Z E1024 13:15:43.220770       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:45.084169446Z I1024 13:15:45.084095       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:45.094833015Z E1024 13:15:45.094784       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:45.106432255Z I1024 13:15:45.106368       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:45.116772464Z E1024 13:15:45.116717       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:45.118613104Z I1024 13:15:45.118532       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:45.127356604Z E1024 13:15:45.127306       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:46.725984675Z E1024 13:15:46.725922       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:46.725984675Z E1024 13:15:46.725944       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:46.726866356Z E1024 13:15:46.726840       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:47.090968100Z E1024 13:15:47.090913       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:47.090968100Z E1024 13:15:47.090936       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:47.091704150Z E1024 13:15:47.091663       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:48.946646480Z E1024 13:15:48.946457       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:48.946646480Z E1024 13:15:48.946491       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:48.963371130Z E1024 13:15:48.963320       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:49.183126390Z E1024 13:15:49.183064       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:15:49.183126390Z E1024 13:15:49.183092       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:49.184278840Z E1024 13:15:49.184222       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:15:51.532708970Z I1024 13:15:51.532641       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:53.044132575Z I1024 13:15:53.044054       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:54.690703514Z I1024 13:15:54.690653       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:56.071918205Z I1024 13:15:56.071873       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:57.556789261Z I1024 13:15:57.556698       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:59.892449421Z I1024 13:15:59.892387       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:00.983552844Z I1024 13:16:00.983491       1 reflector.go:368] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:03.743236645Z I1024 13:16:03.743153       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:04.549741561Z I1024 13:16:04.549695       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:05.428029773Z I1024 13:16:05.427978       1 reflector.go:368] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:06.207808170Z I1024 13:16:06.207710       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:06.226857539Z I1024 13:16:06.226723       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:06.777506586Z I1024 13:16:06.777439       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:07.834841600Z I1024 13:16:07.834780       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:11.384715898Z I1024 13:16:11.384668       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:14.755559834Z I1024 13:16:14.755501       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:15.709824892Z I1024 13:16:15.709785       1 reflector.go:368] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:16.418936582Z I1024 13:16:16.418886       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:16.527200428Z I1024 13:16:16.527122       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:16.528534027Z I1024 13:16:16.528135       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:16:16.682628141Z I1024 13:16:16.682582       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:16.682692321Z I1024 13:16:16.682639       1 reflector.go:368] Caches populated for *v1.Role from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:17.526782215Z I1024 13:16:17.526709       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:17.529003724Z I1024 13:16:17.528950       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 7 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:16:18.362370039Z I1024 13:16:18.361361       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:19.669639613Z E1024 13:16:19.669593       1 leaderelection.go:429] Failed to update lock optimitically: rpc error: code = DeadlineExceeded desc = context deadline exceeded, falling back to slow path
2024-10-24T13:16:34.560326396Z E1024 13:16:34.560248       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-scheduler-RevisionController\": rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:16:34.560326396Z I1024 13:16:34.560300       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 7: Internal error occurred: resource quota evaluation timed out
2024-10-24T13:16:34.562938285Z I1024 13:16:34.562872       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 7 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:16:39.161784554Z E1024 13:16:39.161706       1 event.go:359] "Server rejected event (will not retry!)" err="rpc error: code = DeadlineExceeded desc = context deadline exceeded" event="&Event{ObjectMeta:{openshift-kube-scheduler-operator.180165e7a8a7193e  openshift-kube-scheduler-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-scheduler-operator,Name:openshift-kube-scheduler-operator,UID:ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:StartingNewRevision,Message:new revision 7 triggered by \"required secret/localhost-recovery-client-token has changed\",Source:EventSource{Component:openshift-cluster-kube-scheduler-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:16:17.528355134 +0000 UTC m=+693.045836271,LastTimestamp:2024-10-24 13:16:17.528355134 +0000 UTC m=+693.045836271,Count:1,Type:Normal,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-kube-scheduler-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:16:50.544567921Z E1024 13:16:50.544504       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Timeout: request did not complete within requested timeout - context deadline exceeded"
2024-10-24T13:16:50.546392111Z I1024 13:16:50.546347       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:16:51.579116937Z E1024 13:16:51.579048       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-scheduler-RevisionController\": rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:16:51.579116937Z I1024 13:16:51.579090       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 7: Internal error occurred: resource quota evaluation timed out
2024-10-24T13:16:51.581868017Z I1024 13:16:51.581801       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 7 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:16:57.555317044Z E1024 13:16:57.555254       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:16:57.566650003Z E1024 13:16:57.566608       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: the server was unable to return a response in the time allotted, but may still be processing the request (get pods)"
2024-10-24T13:16:57.566681743Z E1024 13:16:57.566653       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:16:57.566681743Z E1024 13:16:57.566669       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:16:57.567453163Z I1024 13:16:57.567409       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 6 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": the server was unable to return a response in the time allotted, but may still be processing the request (get pods installer-6-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0)
2024-10-24T13:17:04.582816723Z E1024 13:17:04.582692       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: the server was unable to return a response in the time allotted, but may still be processing the request (get pods installer-6-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0)"
2024-10-24T13:17:04.585143913Z W1024 13:17:04.585099       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": rpc error: code = DeadlineExceeded desc = context deadline exceeded
2024-10-24T13:17:04.585175973Z E1024 13:17:04.585145       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2, the server was unable to return a response in the time allotted, but may still be processing the request (get pods openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0)]"
2024-10-24T13:17:04.586676113Z E1024 13:17:04.586600       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:17:04.586676113Z E1024 13:17:04.586637       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:17:08.599420629Z E1024 13:17:08.599356       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-scheduler-RevisionController\": rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:17:08.599468738Z I1024 13:17:08.599407       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 7: Internal error occurred: resource quota evaluation timed out
2024-10-24T13:17:08.601545308Z I1024 13:17:08.601494       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 7 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:17:13.165916838Z E1024 13:17:13.165846       1 event.go:359] "Server rejected event (will not retry!)" err="rpc error: code = DeadlineExceeded desc = context deadline exceeded" event="&Event{ObjectMeta:{openshift-kube-scheduler-operator.180165eb9fd46c24  openshift-kube-scheduler-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-scheduler-operator,Name:openshift-kube-scheduler-operator,UID:ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:RevisionCreateFailed,Message:Failed to create revision 7: Internal error occurred: resource quota evaluation timed out,Source:EventSource{Component:openshift-cluster-kube-scheduler-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:16:34.560199716 +0000 UTC m=+710.077680822,LastTimestamp:2024-10-24 13:16:34.560199716 +0000 UTC m=+710.077680822,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-kube-scheduler-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:17:16.429371264Z E1024 13:17:16.429318       1 base_controller.go:271] "Unhandled Error" err="PruneController reconciliation failed: the server was unable to return a response in the time allotted, but may still be processing the request (get pods revision-pruner-6-ci-op-2fcpj5j6-f6035-2lklf-master-0)"
2024-10-24T13:17:19.677546301Z E1024 13:17:19.677488       1 leaderelection.go:436] error retrieving resource lock openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock: the server was unable to return a response in the time allotted, but may still be processing the request (get leases.coordination.k8s.io openshift-cluster-kube-scheduler-operator-lock)
2024-10-24T13:17:25.618227681Z E1024 13:17:25.618182       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-scheduler-RevisionController\": rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:17:25.618303071Z I1024 13:17:25.618220       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 7: Internal error occurred: resource quota evaluation timed out
2024-10-24T13:17:25.620555001Z I1024 13:17:25.620479       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 7 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:17:31.570806029Z E1024 13:17:31.570713       1 event.go:359] "Server rejected event (will not retry!)" err="Timeout: request did not complete within requested timeout - context deadline exceeded" event="&Event{ObjectMeta:{openshift-kube-scheduler-operator.180165f0fb289791  openshift-kube-scheduler-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-scheduler-operator,Name:openshift-kube-scheduler-operator,UID:ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 6 count 1 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-0\": the server was unable to return a response in the time allotted, but may still be processing the request (get pods installer-6-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0),Source:EventSource{Component:openshift-cluster-kube-scheduler-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:16:57.567278993 +0000 UTC m=+733.084760109,LastTimestamp:2024-10-24 13:16:57.567278993 +0000 UTC m=+733.084760109,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-kube-scheduler-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:17:42.638127890Z E1024 13:17:42.638067       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-scheduler-RevisionController\": rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:17:42.638127890Z I1024 13:17:42.638105       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 7: Internal error occurred: resource quota evaluation timed out
2024-10-24T13:17:42.640126390Z I1024 13:17:42.640082       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 7 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:17:45.084874772Z I1024 13:17:45.084812       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:17:47.170525753Z E1024 13:17:47.170461       1 event.go:359] "Server rejected event (will not retry!)" err="Timeout: request did not complete within requested timeout - context deadline exceeded" event="&Event{ObjectMeta:{openshift-kube-scheduler-operator.180165e7a8a7193e  openshift-kube-scheduler-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-scheduler-operator,Name:openshift-kube-scheduler-operator,UID:ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:StartingNewRevision,Message:new revision 7 triggered by \"required secret/localhost-recovery-client-token has changed\",Source:EventSource{Component:openshift-cluster-kube-scheduler-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:16:17.528355134 +0000 UTC m=+693.045836271,LastTimestamp:2024-10-24 13:16:34.562737986 +0000 UTC m=+710.080219101,Count:2,Type:Normal,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-kube-scheduler-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:17:52.093605354Z E1024 13:17:52.093539       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:17:52.685301246Z E1024 13:17:52.685131       1 leaderelection.go:429] Failed to update lock optimitically: rpc error: code = DeadlineExceeded desc = context deadline exceeded, falling back to slow path
2024-10-24T13:17:57.572334220Z E1024 13:17:57.572270       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: the server was unable to return a response in the time allotted, but may still be processing the request (get pods)"
2024-10-24T13:17:59.644294903Z E1024 13:17:59.644206       1 leaderelection.go:436] error retrieving resource lock openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": context deadline exceeded
2024-10-24T13:17:59.644294903Z I1024 13:17:59.644259       1 leaderelection.go:297] failed to renew lease openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock: timed out waiting for the condition
2024-10-24T13:17:59.658046851Z E1024 13:17:59.657987       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-scheduler-RevisionController\": rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:17:59.658046851Z I1024 13:17:59.658027       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 7: Internal error occurred: resource quota evaluation timed out
2024-10-24T13:17:59.660654291Z I1024 13:17:59.660605       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 7 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:18:04.588944082Z I1024 13:18:04.588857       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 6 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": the server was unable to return a response in the time allotted, but may still be processing the request (get pods installer-6-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0)
2024-10-24T13:18:06.651810005Z E1024 13:18:06.651728       1 leaderelection.go:322] Failed to release lock: rpc error: code = DeadlineExceeded desc = context deadline exceeded
2024-10-24T13:18:06.651952745Z W1024 13:18:06.651907       1 leaderelection.go:84] leader election lost
