2024-10-24T13:18:07.221112899Z I1024 13:18:07.221012       1 cmd.go:250] Using service-serving-cert provided certificates
2024-10-24T13:18:07.221295929Z I1024 13:18:07.221264       1 leaderelection.go:121] The leader election gives 4 retries and allows for 30s of clock skew. The kube-apiserver downtime tolerance is 78s. Worst non-graceful lease acquisition is 2m43s. Worst graceful lease acquisition is {26s}.
2024-10-24T13:18:07.222039839Z I1024 13:18:07.221985       1 observer_polling.go:159] Starting file observer
2024-10-24T13:19:00.530310366Z I1024 13:19:00.529834       1 builder.go:298] openshift-cluster-kube-scheduler-operator version v0.0.1-964-g56e6c13-56e6c1360
2024-10-24T13:19:00.984235008Z I1024 13:19:00.984136       1 secure_serving.go:57] Forcing use of http/1.1 only
2024-10-24T13:19:00.984301818Z W1024 13:19:00.984240       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256' detected.
2024-10-24T13:19:00.984301818Z W1024 13:19:00.984247       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256' detected.
2024-10-24T13:19:00.984301818Z W1024 13:19:00.984252       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_128_GCM_SHA256' detected.
2024-10-24T13:19:00.984301818Z W1024 13:19:00.984256       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_256_GCM_SHA384' detected.
2024-10-24T13:19:00.984301818Z W1024 13:19:00.984260       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_128_CBC_SHA' detected.
2024-10-24T13:19:00.984301818Z W1024 13:19:00.984264       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_256_CBC_SHA' detected.
2024-10-24T13:19:00.990719798Z I1024 13:19:00.990658       1 leaderelection.go:254] attempting to acquire leader lease openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock...
2024-10-24T13:19:00.993805837Z I1024 13:19:00.993766       1 configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2024-10-24T13:19:00.994018018Z I1024 13:19:00.993979       1 shared_informer.go:313] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-10-24T13:19:00.994460027Z I1024 13:19:00.993902       1 configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2024-10-24T13:19:00.994543447Z I1024 13:19:00.994529       1 shared_informer.go:313] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-10-24T13:19:00.995151197Z I1024 13:19:00.995111       1 requestheader_controller.go:172] Starting RequestHeaderAuthRequestController
2024-10-24T13:19:00.995254117Z I1024 13:19:00.995240       1 shared_informer.go:313] Waiting for caches to sync for RequestHeaderAuthRequestController
2024-10-24T13:19:00.995966577Z I1024 13:19:00.995946       1 dynamic_serving_content.go:135] "Starting controller" name="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key"
2024-10-24T13:19:00.996630658Z I1024 13:19:00.996613       1 secure_serving.go:213] Serving securely on [::]:8443
2024-10-24T13:19:00.996734247Z I1024 13:19:00.996681       1 tlsconfig.go:243] "Starting DynamicServingCertificateController"
2024-10-24T13:19:01.095585896Z I1024 13:19:01.095500       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-10-24T13:19:01.095585896Z I1024 13:19:01.095500       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-10-24T13:19:01.095585896Z I1024 13:19:01.095549       1 shared_informer.go:320] Caches are synced for RequestHeaderAuthRequestController
2024-10-24T13:21:20.627465661Z I1024 13:21:20.627372       1 leaderelection.go:268] successfully acquired lease openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock
2024-10-24T13:21:20.627556481Z I1024 13:21:20.627480       1 event.go:377] Event(v1.ObjectReference{Kind:"Lease", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-cluster-kube-scheduler-operator-lock", UID:"7a445fd6-9764-47db-a21b-814c111c88dc", APIVersion:"coordination.k8s.io/v1", ResourceVersion:"22217", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' openshift-kube-scheduler-operator-7b64b578df-w9z5s_a5d85acd-0e5e-4ba7-8c30-82db8bd296f3 became leader
2024-10-24T13:21:20.628642991Z I1024 13:21:20.628604       1 simple_featuregate_reader.go:171] Starting feature-gate-detector
2024-10-24T13:21:20.639594902Z I1024 13:21:20.639502       1 starter.go:89] FeatureGates initialized: knownFeatureGates=[AWSEFSDriverVolumeMetrics AdminNetworkPolicy AlibabaPlatform AzureWorkloadIdentity BareMetalLoadBalancer BuildCSIVolumes ChunkSizeMiB CloudDualStackNodeIPs DisableKubeletCloudCredentialProviders GCPLabelsTags HardwareSpeed IngressControllerLBSubnetsAWS KMSv1 ManagedBootImages MetricsServer MultiArchInstallAWS MultiArchInstallGCP NetworkDiagnosticsConfig NetworkLiveMigration NodeDisruptionPolicy OpenShiftPodSecurityAdmission PrivateHostedZoneAWS SetEIPForNLBIngressController VSphereControlPlaneMachineSet VSphereDriverConfiguration VSphereStaticIPs ValidatingAdmissionPolicy AWSClusterHostedDNS AdditionalRoutingCapabilities AutomatedEtcdBackup BootcNodeManagement CSIDriverSharedResource ClusterAPIInstall ClusterAPIInstallIBMCloud ClusterMonitoringConfig DNSNameResolver DynamicResourceAllocation EtcdBackendQuota EventedPLEG Example ExternalOIDC GCPClusterHostedDNS GatewayAPI ImageStreamImportMode IngressControllerDynamicConfigurationManager InsightsConfig InsightsConfigAPI InsightsOnDemandDataGather InsightsRuntimeExtractor MachineAPIMigration MachineAPIOperatorDisableMachineHealthCheckController MachineAPIProviderOpenStack MachineConfigNodes ManagedBootImagesAWS MaxUnavailableStatefulSet MetricsCollectionProfiles MixedCPUsAllocation MultiArchInstallAzure NetworkSegmentation NewOLM NodeSwap OVNObservability OnClusterBuild PersistentIPsForVirtualization PinnedImages PlatformOperators ProcMountType RouteAdvertisements RouteExternalCertificate ServiceAccountTokenNodeBinding SignatureStores SigstoreImageVerification TranslateStreamCloseWebsocketRequests UpgradeStatus UserNamespacesPodSecurityStandards UserNamespacesSupport VSphereMultiNetworks VSphereMultiVCenters VolumeGroupSnapshot]
2024-10-24T13:21:20.639698492Z I1024 13:21:20.639515       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'FeatureGatesInitialized' FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AWSEFSDriverVolumeMetrics", "AdminNetworkPolicy", "AlibabaPlatform", "AzureWorkloadIdentity", "BareMetalLoadBalancer", "BuildCSIVolumes", "ChunkSizeMiB", "CloudDualStackNodeIPs", "DisableKubeletCloudCredentialProviders", "GCPLabelsTags", "HardwareSpeed", "IngressControllerLBSubnetsAWS", "KMSv1", "ManagedBootImages", "MetricsServer", "MultiArchInstallAWS", "MultiArchInstallGCP", "NetworkDiagnosticsConfig", "NetworkLiveMigration", "NodeDisruptionPolicy", "OpenShiftPodSecurityAdmission", "PrivateHostedZoneAWS", "SetEIPForNLBIngressController", "VSphereControlPlaneMachineSet", "VSphereDriverConfiguration", "VSphereStaticIPs", "ValidatingAdmissionPolicy"}, Disabled:[]v1.FeatureGateName{"AWSClusterHostedDNS", "AdditionalRoutingCapabilities", "AutomatedEtcdBackup", "BootcNodeManagement", "CSIDriverSharedResource", "ClusterAPIInstall", "ClusterAPIInstallIBMCloud", "ClusterMonitoringConfig", "DNSNameResolver", "DynamicResourceAllocation", "EtcdBackendQuota", "EventedPLEG", "Example", "ExternalOIDC", "GCPClusterHostedDNS", "GatewayAPI", "ImageStreamImportMode", "IngressControllerDynamicConfigurationManager", "InsightsConfig", "InsightsConfigAPI", "InsightsOnDemandDataGather", "InsightsRuntimeExtractor", "MachineAPIMigration", "MachineAPIOperatorDisableMachineHealthCheckController", "MachineAPIProviderOpenStack", "MachineConfigNodes", "ManagedBootImagesAWS", "MaxUnavailableStatefulSet", "MetricsCollectionProfiles", "MixedCPUsAllocation", "MultiArchInstallAzure", "NetworkSegmentation", "NewOLM", "NodeSwap", "OVNObservability", "OnClusterBuild", "PersistentIPsForVirtualization", "PinnedImages", "PlatformOperators", "ProcMountType", "RouteAdvertisements", "RouteExternalCertificate", "ServiceAccountTokenNodeBinding", "SignatureStores", "SigstoreImageVerification", "TranslateStreamCloseWebsocketRequests", "UpgradeStatus", "UserNamespacesPodSecurityStandards", "UserNamespacesSupport", "VSphereMultiNetworks", "VSphereMultiVCenters", "VolumeGroupSnapshot"}}
2024-10-24T13:21:20.651648012Z I1024 13:21:20.651594       1 base_controller.go:68] Waiting for caches to sync for RemoveStaleConditionsController
2024-10-24T13:21:20.652926892Z I1024 13:21:20.652889       1 base_controller.go:68] Waiting for caches to sync for MissingStaticPodController
2024-10-24T13:21:20.654075052Z I1024 13:21:20.654043       1 base_controller.go:68] Waiting for caches to sync for KubeControllerManagerStaticResources-StaticResources
2024-10-24T13:21:20.654336292Z I1024 13:21:20.654309       1 base_controller.go:68] Waiting for caches to sync for ConfigObserver
2024-10-24T13:21:20.654523002Z I1024 13:21:20.654484       1 base_controller.go:68] Waiting for caches to sync for GuardController
2024-10-24T13:21:20.654880202Z I1024 13:21:20.654121       1 base_controller.go:68] Waiting for caches to sync for LoggingSyncer
2024-10-24T13:21:20.655458922Z I1024 13:21:20.654190       1 base_controller.go:68] Waiting for caches to sync for kube-scheduler
2024-10-24T13:21:20.655458922Z I1024 13:21:20.654205       1 base_controller.go:68] Waiting for caches to sync for TargetConfigController
2024-10-24T13:21:20.655849022Z I1024 13:21:20.655804       1 base_controller.go:68] Waiting for caches to sync for StaticPodStateController
2024-10-24T13:21:20.655903822Z I1024 13:21:20.655872       1 base_controller.go:68] Waiting for caches to sync for kube-scheduler-InstallerState
2024-10-24T13:21:20.655973272Z I1024 13:21:20.655872       1 base_controller.go:68] Waiting for caches to sync for PruneController
2024-10-24T13:21:20.655973272Z I1024 13:21:20.655961       1 base_controller.go:68] Waiting for caches to sync for NodeController
2024-10-24T13:21:20.656026143Z I1024 13:21:20.655992       1 base_controller.go:68] Waiting for caches to sync for UnsupportedConfigOverridesController
2024-10-24T13:21:20.656042923Z I1024 13:21:20.656022       1 base_controller.go:68] Waiting for caches to sync for StatusSyncer_kube-scheduler
2024-10-24T13:21:20.656154843Z I1024 13:21:20.656114       1 base_controller.go:68] Waiting for caches to sync for BackingResourceController-StaticResources
2024-10-24T13:21:20.656154843Z I1024 13:21:20.656133       1 base_controller.go:68] Waiting for caches to sync for RevisionController
2024-10-24T13:21:20.656154843Z I1024 13:21:20.656120       1 base_controller.go:68] Waiting for caches to sync for InstallerController
2024-10-24T13:21:20.752431046Z I1024 13:21:20.752341       1 base_controller.go:74] Caches are synced for RemoveStaleConditionsController 
2024-10-24T13:21:20.752431046Z I1024 13:21:20.752408       1 base_controller.go:111] Starting #1 worker of RemoveStaleConditionsController controller ...
2024-10-24T13:21:20.753123786Z I1024 13:21:20.753090       1 base_controller.go:74] Caches are synced for MissingStaticPodController 
2024-10-24T13:21:20.753123786Z I1024 13:21:20.753107       1 base_controller.go:111] Starting #1 worker of MissingStaticPodController controller ...
2024-10-24T13:21:20.754734066Z I1024 13:21:20.754693       1 base_controller.go:74] Caches are synced for GuardController 
2024-10-24T13:21:20.754734066Z I1024 13:21:20.754725       1 base_controller.go:111] Starting #1 worker of GuardController controller ...
2024-10-24T13:21:20.756942026Z I1024 13:21:20.756897       1 base_controller.go:74] Caches are synced for BackingResourceController-StaticResources 
2024-10-24T13:21:20.756942026Z I1024 13:21:20.756916       1 base_controller.go:111] Starting #1 worker of BackingResourceController-StaticResources controller ...
2024-10-24T13:21:20.756988476Z I1024 13:21:20.756939       1 base_controller.go:74] Caches are synced for InstallerController 
2024-10-24T13:21:20.756988476Z I1024 13:21:20.756947       1 base_controller.go:74] Caches are synced for StaticPodStateController 
2024-10-24T13:21:20.756988476Z I1024 13:21:20.756957       1 base_controller.go:111] Starting #1 worker of StaticPodStateController controller ...
2024-10-24T13:21:20.756988476Z I1024 13:21:20.756968       1 base_controller.go:74] Caches are synced for PruneController 
2024-10-24T13:21:20.756988476Z I1024 13:21:20.756975       1 base_controller.go:74] Caches are synced for StatusSyncer_kube-scheduler 
2024-10-24T13:21:20.756988476Z I1024 13:21:20.756982       1 base_controller.go:111] Starting #1 worker of StatusSyncer_kube-scheduler controller ...
2024-10-24T13:21:20.757004626Z I1024 13:21:20.756985       1 base_controller.go:74] Caches are synced for NodeController 
2024-10-24T13:21:20.757004626Z I1024 13:21:20.756998       1 base_controller.go:74] Caches are synced for LoggingSyncer 
2024-10-24T13:21:20.757015286Z I1024 13:21:20.757005       1 base_controller.go:111] Starting #1 worker of LoggingSyncer controller ...
2024-10-24T13:21:20.757015286Z I1024 13:21:20.757006       1 base_controller.go:74] Caches are synced for UnsupportedConfigOverridesController 
2024-10-24T13:21:20.757025166Z I1024 13:21:20.757014       1 base_controller.go:111] Starting #1 worker of UnsupportedConfigOverridesController controller ...
2024-10-24T13:21:20.757183406Z I1024 13:21:20.757160       1 base_controller.go:74] Caches are synced for kube-scheduler-InstallerState 
2024-10-24T13:21:20.757226876Z I1024 13:21:20.757214       1 base_controller.go:111] Starting #1 worker of kube-scheduler-InstallerState controller ...
2024-10-24T13:21:20.757297446Z I1024 13:21:20.757282       1 base_controller.go:74] Caches are synced for RevisionController 
2024-10-24T13:21:20.757364546Z I1024 13:21:20.756956       1 base_controller.go:111] Starting #1 worker of InstallerController controller ...
2024-10-24T13:21:20.757454856Z I1024 13:21:20.756977       1 base_controller.go:111] Starting #1 worker of PruneController controller ...
2024-10-24T13:21:20.757974476Z I1024 13:21:20.757929       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:21:20.758146046Z I1024 13:21:20.756999       1 base_controller.go:111] Starting #1 worker of NodeController controller ...
2024-10-24T13:21:20.758276036Z I1024 13:21:20.757324       1 base_controller.go:111] Starting #1 worker of RevisionController controller ...
2024-10-24T13:21:20.776067687Z I1024 13:21:20.776001       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nTargetConfigControllerDegraded: \"configmap\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type" to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: "
2024-10-24T13:21:20.856153760Z I1024 13:21:20.856095       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:20.954730444Z I1024 13:21:20.954660       1 base_controller.go:74] Caches are synced for KubeControllerManagerStaticResources-StaticResources 
2024-10-24T13:21:20.954730444Z I1024 13:21:20.954687       1 base_controller.go:111] Starting #1 worker of KubeControllerManagerStaticResources-StaticResources controller ...
2024-10-24T13:21:21.056660168Z I1024 13:21:21.056594       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:21.268662216Z I1024 13:21:21.268592       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:21.355340359Z I1024 13:21:21.355273       1 base_controller.go:74] Caches are synced for ConfigObserver 
2024-10-24T13:21:21.355340359Z I1024 13:21:21.355300       1 base_controller.go:111] Starting #1 worker of ConfigObserver controller ...
2024-10-24T13:21:21.456131583Z I1024 13:21:21.456071       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:21.456278173Z I1024 13:21:21.456218       1 base_controller.go:74] Caches are synced for TargetConfigController 
2024-10-24T13:21:21.456278173Z I1024 13:21:21.456244       1 base_controller.go:111] Starting #1 worker of TargetConfigController controller ...
2024-10-24T13:21:21.655508141Z I1024 13:21:21.655431       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:21.656447661Z I1024 13:21:21.656400       1 base_controller.go:74] Caches are synced for kube-scheduler 
2024-10-24T13:21:21.656447661Z I1024 13:21:21.656426       1 base_controller.go:111] Starting #1 worker of kube-scheduler controller ...
2024-10-24T13:21:21.852877918Z I1024 13:21:21.852819       1 request.go:700] Waited for 1.097168522s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:21:23.052644155Z I1024 13:21:23.052575       1 request.go:700] Waited for 2.0974434s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler
2024-10-24T13:21:23.458767009Z E1024 13:21:23.458697       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:23.458767009Z E1024 13:21:23.458724       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:23.459615950Z E1024 13:21:23.459588       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:23.461050980Z E1024 13:21:23.461019       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:23.461083810Z E1024 13:21:23.461049       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:24.059356543Z I1024 13:21:24.059241       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-0" for revision 6 for the 2nd time because installer pod failed: installer: refixes: ([]string) (len=1 cap=1) {
2024-10-24T13:21:24.059356543Z   (string) (len=12) "serving-cert"
2024-10-24T13:21:24.059356543Z  },
2024-10-24T13:21:24.059356543Z  ConfigMapNamePrefixes: ([]string) (len=5 cap=8) {
2024-10-24T13:21:24.059356543Z   (string) (len=18) "kube-scheduler-pod",
2024-10-24T13:21:24.059356543Z   (string) (len=6) "config",
2024-10-24T13:21:24.059356543Z   (string) (len=17) "serviceaccount-ca",
2024-10-24T13:21:24.059356543Z   (string) (len=20) "scheduler-kubeconfig",
2024-10-24T13:21:24.059356543Z   (string) (len=37) "kube-scheduler-cert-syncer-kubeconfig"
2024-10-24T13:21:24.059356543Z  },
2024-10-24T13:21:24.059356543Z  OptionalConfigMapNamePrefixes: ([]string) (len=1 cap=1) {
2024-10-24T13:21:24.059356543Z   (string) (len=16) "policy-configmap"
2024-10-24T13:21:24.059356543Z  },
2024-10-24T13:21:24.059356543Z  CertSecretNames: ([]string) (len=1 cap=1) {
2024-10-24T13:21:24.059356543Z   (string) (len=30) "kube-scheduler-client-cert-key"
2024-10-24T13:21:24.059356543Z  },
2024-10-24T13:21:24.059356543Z  OptionalCertSecretNamePrefixes: ([]string) <nil>,
2024-10-24T13:21:24.059356543Z  CertConfigMapNamePrefixes: ([]string) <nil>,
2024-10-24T13:21:24.059356543Z  OptionalCertConfigMapNamePrefixes: ([]string) <nil>,
2024-10-24T13:21:24.059356543Z  CertDir: (string) (len=57) "/etc/kubernetes/static-pod-resources/kube-scheduler-certs",
2024-10-24T13:21:24.059356543Z  ResourceDir: (string) (len=36) "/etc/kubernetes/static-pod-resources",
2024-10-24T13:21:24.059356543Z  PodManifestDir: (string) (len=25) "/etc/kubernetes/manifests",
2024-10-24T13:21:24.059356543Z  Timeout: (time.Duration) 2m0s,
2024-10-24T13:21:24.059356543Z  StaticPodManifestsLockFile: (string) "",
2024-10-24T13:21:24.059356543Z  PodMutationFns: ([]installerpod.PodMutationFunc) <nil>,
2024-10-24T13:21:24.059356543Z  KubeletVersion: (string) ""
2024-10-24T13:21:24.059356543Z })
2024-10-24T13:21:24.059356543Z I1024 13:15:40.605843       1 cmd.go:409] Getting controller reference for node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:21:24.059356543Z I1024 13:15:40.620880       1 cmd.go:422] Waiting for installer revisions to settle for node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:21:24.059356543Z I1024 13:15:40.621111       1 envvar.go:172] "Feature gate default state" feature="WatchListClient" enabled=false
2024-10-24T13:21:24.059356543Z I1024 13:15:40.621191       1 envvar.go:172] "Feature gate default state" feature="InformerResourceVersion" enabled=false
2024-10-24T13:21:24.059356543Z I1024 13:15:40.629965       1 cmd.go:514] Waiting additional period after revisions have settled for node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:21:24.059356543Z I1024 13:16:10.632243       1 cmd.go:520] Getting installer pods for node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:21:24.059356543Z F1024 13:16:24.639340       1 cmd.go:105] Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": net/http: request canceled (Client.Timeout exceeded while awaiting headers)
2024-10-24T13:21:24.059446303Z I1024 13:21:24.059399       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:21:24.059446303Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:21:24.059446303Z  CurrentRevision: (int32) 0,
2024-10-24T13:21:24.059446303Z  TargetRevision: (int32) 6,
2024-10-24T13:21:24.059446303Z  LastFailedRevision: (int32) 6,
2024-10-24T13:21:24.059446303Z  LastFailedTime: (*v1.Time)(0xc000809ed8)(2024-10-24 13:21:24.059222522 +0000 UTC m=+196.898151251),
2024-10-24T13:21:24.059446303Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:21:24.059446303Z  LastFailedCount: (int) 2,
2024-10-24T13:21:24.059446303Z  LastFallbackCount: (int) 0,
2024-10-24T13:21:24.059446303Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:21:24.059446303Z   (string) (len=2059) "installer: refixes: ([]string) (len=1 cap=1) {\n  (string) (len=12) \"serving-cert\"\n },\n ConfigMapNamePrefixes: ([]string) (len=5 cap=8) {\n  (string) (len=18) \"kube-scheduler-pod\",\n  (string) (len=6) \"config\",\n  (string) (len=17) \"serviceaccount-ca\",\n  (string) (len=20) \"scheduler-kubeconfig\",\n  (string) (len=37) \"kube-scheduler-cert-syncer-kubeconfig\"\n },\n OptionalConfigMapNamePrefixes: ([]string) (len=1 cap=1) {\n  (string) (len=16) \"policy-configmap\"\n },\n CertSecretNames: ([]string) (len=1 cap=1) {\n  (string) (len=30) \"kube-scheduler-client-cert-key\"\n },\n OptionalCertSecretNamePrefixes: ([]string) <nil>,\n CertConfigMapNamePrefixes: ([]string) <nil>,\n OptionalCertConfigMapNamePrefixes: ([]string) <nil>,\n CertDir: (string) (len=57) \"/etc/kubernetes/static-pod-resources/kube-scheduler-certs\",\n ResourceDir: (string) (len=36) \"/etc/kubernetes/static-pod-resources\",\n PodManifestDir: (string) (len=25) \"/etc/kubernetes/manifests\",\n Timeout: (time.Duration) 2m0s,\n StaticPodManifestsLockFile: (string) \"\",\n PodMutationFns: ([]installerpod.PodMutationFunc) <nil>,\n KubeletVersion: (string) \"\"\n})\nI1024 13:15:40.605843       1 cmd.go:409] Getting controller reference for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nI1024 13:15:40.620880       1 cmd.go:422] Waiting for installer revisions to settle for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nI1024 13:15:40.621111       1 envvar.go:172] \"Feature gate default state\" feature=\"WatchListClient\" enabled=false\nI1024 13:15:40.621191       1 envvar.go:172] \"Feature gate default state\" feature=\"InformerResourceVersion\" enabled=false\nI1024 13:15:40.629965       1 cmd.go:514] Waiting additional period after revisions have settled for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nI1024 13:16:10.632243       1 cmd.go:520] Getting installer pods for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nF1024 13:16:24.639340       1 cmd.go:105] Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\n"
2024-10-24T13:21:24.059446303Z  }
2024-10-24T13:21:24.059446303Z }
2024-10-24T13:21:24.059446303Z  because installer pod failed: installer: refixes: ([]string) (len=1 cap=1) {
2024-10-24T13:21:24.059446303Z   (string) (len=12) "serving-cert"
2024-10-24T13:21:24.059446303Z  },
2024-10-24T13:21:24.059446303Z  ConfigMapNamePrefixes: ([]string) (len=5 cap=8) {
2024-10-24T13:21:24.059446303Z   (string) (len=18) "kube-scheduler-pod",
2024-10-24T13:21:24.059446303Z   (string) (len=6) "config",
2024-10-24T13:21:24.059446303Z   (string) (len=17) "serviceaccount-ca",
2024-10-24T13:21:24.059446303Z   (string) (len=20) "scheduler-kubeconfig",
2024-10-24T13:21:24.059446303Z   (string) (len=37) "kube-scheduler-cert-syncer-kubeconfig"
2024-10-24T13:21:24.059446303Z  },
2024-10-24T13:21:24.059446303Z  OptionalConfigMapNamePrefixes: ([]string) (len=1 cap=1) {
2024-10-24T13:21:24.059446303Z   (string) (len=16) "policy-configmap"
2024-10-24T13:21:24.059446303Z  },
2024-10-24T13:21:24.059446303Z  CertSecretNames: ([]string) (len=1 cap=1) {
2024-10-24T13:21:24.059446303Z   (string) (len=30) "kube-scheduler-client-cert-key"
2024-10-24T13:21:24.059446303Z  },
2024-10-24T13:21:24.059446303Z  OptionalCertSecretNamePrefixes: ([]string) <nil>,
2024-10-24T13:21:24.059446303Z  CertConfigMapNamePrefixes: ([]string) <nil>,
2024-10-24T13:21:24.059446303Z  OptionalCertConfigMapNamePrefixes: ([]string) <nil>,
2024-10-24T13:21:24.059446303Z  CertDir: (string) (len=57) "/etc/kubernetes/static-pod-resources/kube-scheduler-certs",
2024-10-24T13:21:24.059446303Z  ResourceDir: (string) (len=36) "/etc/kubernetes/static-pod-resources",
2024-10-24T13:21:24.059446303Z  PodManifestDir: (string) (len=25) "/etc/kubernetes/manifests",
2024-10-24T13:21:24.059446303Z  Timeout: (time.Duration) 2m0s,
2024-10-24T13:21:24.059446303Z  StaticPodManifestsLockFile: (string) "",
2024-10-24T13:21:24.059446303Z  PodMutationFns: ([]installerpod.PodMutationFunc) <nil>,
2024-10-24T13:21:24.059446303Z  KubeletVersion: (string) ""
2024-10-24T13:21:24.059446303Z })
2024-10-24T13:21:24.059446303Z I1024 13:15:40.605843       1 cmd.go:409] Getting controller reference for node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:21:24.059446303Z I1024 13:15:40.620880       1 cmd.go:422] Waiting for installer revisions to settle for node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:21:24.059446303Z I1024 13:15:40.621111       1 envvar.go:172] "Feature gate default state" feature="WatchListClient" enabled=false
2024-10-24T13:21:24.059446303Z I1024 13:15:40.621191       1 envvar.go:172] "Feature gate default state" feature="InformerResourceVersion" enabled=false
2024-10-24T13:21:24.059446303Z I1024 13:15:40.629965       1 cmd.go:514] Waiting additional period after revisions have settled for node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:21:24.059446303Z I1024 13:16:10.632243       1 cmd.go:520] Getting installer pods for node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:21:24.059446303Z F1024 13:16:24.639340       1 cmd.go:105] Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": net/http: request canceled (Client.Timeout exceeded while awaiting headers)
2024-10-24T13:21:24.059486503Z I1024 13:21:24.059427       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer: refixes: ([]string) (len=1 cap=1) {
2024-10-24T13:21:24.059486503Z   (string) (len=12) "serving-cert"
2024-10-24T13:21:24.059486503Z  },
2024-10-24T13:21:24.059486503Z  ConfigMapNamePrefixes: ([]string) (len=5 cap=8) {
2024-10-24T13:21:24.059486503Z   (string) (len=18) "kube-scheduler-pod",
2024-10-24T13:21:24.059486503Z   (string) (len=6) "config",
2024-10-24T13:21:24.059486503Z   (string) (len=17) "serviceaccount-ca",
2024-10-24T13:21:24.059486503Z   (string) (len=20) "scheduler-kubeconfig",
2024-10-24T13:21:24.059486503Z   (string) (len=37) "kube-scheduler-cert-syncer-kubeconfig"
2024-10-24T13:21:24.059486503Z  },
2024-10-24T13:21:24.059486503Z  OptionalConfigMapNamePrefixes: ([]string) (len=1 cap=1) {
2024-10-24T13:21:24.059486503Z   (string) (len=16) "policy-configmap"
2024-10-24T13:21:24.059486503Z  },
2024-10-24T13:21:24.059486503Z  CertSecretNames: ([]string) (len=1 cap=1) {
2024-10-24T13:21:24.059486503Z   (string) (len=30) "kube-scheduler-client-cert-key"
2024-10-24T13:21:24.059486503Z  },
2024-10-24T13:21:24.059486503Z  OptionalCertSecretNamePrefixes: ([]string) <nil>,
2024-10-24T13:21:24.059486503Z  CertConfigMapNamePrefixes: ([]string) <nil>,
2024-10-24T13:21:24.059486503Z  OptionalCertConfigMapNamePrefixes: ([]string) <nil>,
2024-10-24T13:21:24.059486503Z  CertDir: (string) (len=57) "/etc/kubernetes/static-pod-resources/kube-scheduler-certs",
2024-10-24T13:21:24.059486503Z  ResourceDir: (string) (len=36) "/etc/kubernetes/static-pod-resources",
2024-10-24T13:21:24.059486503Z  PodManifestDir: (string) (len=25) "/etc/kubernetes/manifests",
2024-10-24T13:21:24.059486503Z  Timeout: (time.Duration) 2m0s,
2024-10-24T13:21:24.059486503Z  StaticPodManifestsLockFile: (string) "",
2024-10-24T13:21:24.059486503Z  PodMutationFns: ([]installerpod.PodMutationFunc) <nil>,
2024-10-24T13:21:24.059486503Z  KubeletVersion: (string) ""
2024-10-24T13:21:24.059486503Z })
2024-10-24T13:21:24.059486503Z I1024 13:15:40.605843       1 cmd.go:409] Getting controller reference for node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:21:24.059486503Z I1024 13:15:40.620880       1 cmd.go:422] Waiting for installer revisions to settle for node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:21:24.059486503Z I1024 13:15:40.621111       1 envvar.go:172] "Feature gate default state" feature="WatchListClient" enabled=false
2024-10-24T13:21:24.059486503Z I1024 13:15:40.621191       1 envvar.go:172] "Feature gate default state" feature="InformerResourceVersion" enabled=false
2024-10-24T13:21:24.059486503Z I1024 13:15:40.629965       1 cmd.go:514] Waiting additional period after revisions have settled for node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:21:24.059486503Z I1024 13:16:10.632243       1 cmd.go:520] Getting installer pods for node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:21:24.059486503Z F1024 13:16:24.639340       1 cmd.go:105] Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": net/http: request canceled (Client.Timeout exceeded while awaiting headers)
2024-10-24T13:21:24.083633994Z I1024 13:21:24.083562       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: refixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=12) \"serving-cert\"\nNodeInstallerDegraded:  },\nNodeInstallerDegraded:  ConfigMapNamePrefixes: ([]string) (len=5 cap=8) {\nNodeInstallerDegraded:   (string) (len=18) \"kube-scheduler-pod\",\nNodeInstallerDegraded:   (string) (len=6) \"config\",\nNodeInstallerDegraded:   (string) (len=17) \"serviceaccount-ca\",\nNodeInstallerDegraded:   (string) (len=20) \"scheduler-kubeconfig\",\nNodeInstallerDegraded:   (string) (len=37) \"kube-scheduler-cert-syncer-kubeconfig\"\nNodeInstallerDegraded:  OptionalConfigMapNamePrefixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=16) \"policy-configmap\"\nNodeInstallerDegraded:  CertSecretNames: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=30) \"kube-scheduler-client-cert-key\"\nNodeInstallerDegraded:  OptionalCertSecretNamePrefixes: ([]string) \u003cnil\u003e,\nNodeInstallerDegraded:  CertConfigMapNamePrefixes: ([]string) \u003cnil\u003e,\nNodeInstallerDegraded:  OptionalCertConfigMapNamePrefixes: ([]string) \u003cnil\u003e,\nNodeInstallerDegraded:  CertDir: (string) (len=57) \"/etc/kubernetes/static-pod-resources/kube-scheduler-certs\",\nNodeInstallerDegraded:  ResourceDir: (string) (len=36) \"/etc/kubernetes/static-pod-resources\",\nNodeInstallerDegraded:  PodManifestDir: (string) (len=25) \"/etc/kubernetes/manifests\",\nNodeInstallerDegraded:  Timeout: (time.Duration) 2m0s,\nNodeInstallerDegraded:  StaticPodManifestsLockFile: (string) \"\",\nNodeInstallerDegraded:  PodMutationFns: ([]installerpod.PodMutationFunc) \u003cnil\u003e,\nNodeInstallerDegraded:  KubeletVersion: (string) \"\"\nNodeInstallerDegraded: })\nNodeInstallerDegraded: I1024 13:15:40.605843       1 cmd.go:409] Getting controller reference for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.620880       1 cmd.go:422] Waiting for installer revisions to settle for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.621111       1 envvar.go:172] \"Feature gate default state\" feature=\"WatchListClient\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.621191       1 envvar.go:172] \"Feature gate default state\" feature=\"InformerResourceVersion\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.629965       1 cmd.go:514] Waiting additional period after revisions have settled for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:16:10.632243       1 cmd.go:520] Getting installer pods for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: F1024 13:16:24.639340       1 cmd.go:105] Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:21:24.098394904Z I1024 13:21:24.098351       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:20.289363       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:30.289105       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:40.289375       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:12:50.290106       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.289783       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:13:00.291016       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:13:00.291101       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: " to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: refixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=12) \"serving-cert\"\nNodeInstallerDegraded:  },\nNodeInstallerDegraded:  ConfigMapNamePrefixes: ([]string) (len=5 cap=8) {\nNodeInstallerDegraded:   (string) (len=18) \"kube-scheduler-pod\",\nNodeInstallerDegraded:   (string) (len=6) \"config\",\nNodeInstallerDegraded:   (string) (len=17) \"serviceaccount-ca\",\nNodeInstallerDegraded:   (string) (len=20) \"scheduler-kubeconfig\",\nNodeInstallerDegraded:   (string) (len=37) \"kube-scheduler-cert-syncer-kubeconfig\"\nNodeInstallerDegraded:  OptionalConfigMapNamePrefixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=16) \"policy-configmap\"\nNodeInstallerDegraded:  CertSecretNames: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=30) \"kube-scheduler-client-cert-key\"\nNodeInstallerDegraded:  OptionalCertSecretNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  CertConfigMapNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  OptionalCertConfigMapNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  CertDir: (string) (len=57) \"/etc/kubernetes/static-pod-resources/kube-scheduler-certs\",\nNodeInstallerDegraded:  ResourceDir: (string) (len=36) \"/etc/kubernetes/static-pod-resources\",\nNodeInstallerDegraded:  PodManifestDir: (string) (len=25) \"/etc/kubernetes/manifests\",\nNodeInstallerDegraded:  Timeout: (time.Duration) 2m0s,\nNodeInstallerDegraded:  StaticPodManifestsLockFile: (string) \"\",\nNodeInstallerDegraded:  PodMutationFns: ([]installerpod.PodMutationFunc) <nil>,\nNodeInstallerDegraded:  KubeletVersion: (string) \"\"\nNodeInstallerDegraded: })\nNodeInstallerDegraded: I1024 13:15:40.605843       1 cmd.go:409] Getting controller reference for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.620880       1 cmd.go:422] Waiting for installer revisions to settle for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.621111       1 envvar.go:172] \"Feature gate default state\" feature=\"WatchListClient\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.621191       1 envvar.go:172] \"Feature gate default state\" feature=\"InformerResourceVersion\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.629965       1 cmd.go:514] Waiting additional period after revisions have settled for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:16:10.632243       1 cmd.go:520] Getting installer pods for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: F1024 13:16:24.639340       1 cmd.go:105] Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\nNodeInstallerDegraded: "
2024-10-24T13:21:24.252857470Z I1024 13:21:24.252797       1 request.go:700] Waited for 1.164917404s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler
2024-10-24T13:21:25.452226286Z I1024 13:21:25.452167       1 request.go:700] Waited for 1.192868386s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa
2024-10-24T13:21:25.861131842Z E1024 13:21:25.861074       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:25.862594452Z E1024 13:21:25.862548       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:27.862680538Z E1024 13:21:27.862619       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:27.863806318Z E1024 13:21:27.863770       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:29.459550730Z E1024 13:21:29.459492       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:29.459550730Z E1024 13:21:29.459521       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:29.460670020Z E1024 13:21:29.460614       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:30.459915628Z E1024 13:21:30.459860       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:30.459915628Z E1024 13:21:30.459885       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:30.460703969Z E1024 13:21:30.460664       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:31.261316169Z E1024 13:21:31.261223       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:31.261316169Z E1024 13:21:31.261253       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:31.262341179Z E1024 13:21:31.262310       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:32.061460710Z E1024 13:21:32.061397       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:32.061460710Z E1024 13:21:32.061440       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:32.062334200Z E1024 13:21:32.062297       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:32.063618600Z E1024 13:21:32.063586       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:32.063618600Z E1024 13:21:32.063602       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:32.660953103Z E1024 13:21:32.660906       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:33.060379158Z E1024 13:21:33.060335       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:33.060428158Z E1024 13:21:33.060377       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:33.061533808Z E1024 13:21:33.061488       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:33.302783087Z E1024 13:21:33.302702       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:33.458764484Z E1024 13:21:33.458696       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:33.459485514Z E1024 13:21:33.459452       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:36.021826062Z E1024 13:21:36.021776       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:36.021826062Z E1024 13:21:36.021797       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:36.041395983Z E1024 13:21:36.041303       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:37.490223809Z E1024 13:21:37.490171       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:37.490223809Z E1024 13:21:37.490203       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:37.491368869Z E1024 13:21:37.491342       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:41.142604429Z E1024 13:21:41.142542       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:41.142604429Z E1024 13:21:41.142573       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:41.143547509Z E1024 13:21:41.143521       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:41.177709650Z E1024 13:21:41.177636       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:41.177709650Z E1024 13:21:41.177655       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:41.178481971Z E1024 13:21:41.178457       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:41.714558641Z E1024 13:21:41.714515       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:41.732029482Z E1024 13:21:41.731971       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:41.733115672Z E1024 13:21:41.733080       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:42.021133133Z E1024 13:21:42.021077       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:42.021133133Z E1024 13:21:42.021095       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:42.021953153Z E1024 13:21:42.021906       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:46.534430726Z I1024 13:21:46.534372       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-6-retry-2-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-scheduler because it was missing
2024-10-24T13:21:46.539592636Z I1024 13:21:46.539545       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:21:46.553633157Z E1024 13:21:46.553585       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:46.553633157Z E1024 13:21:46.553608       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:46.554617377Z E1024 13:21:46.554572       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:46.909856891Z I1024 13:21:46.909809       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:21:47.910074979Z E1024 13:21:47.910020       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:47.910074979Z E1024 13:21:47.910048       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:47.911008909Z E1024 13:21:47.910948       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:48.509920362Z I1024 13:21:48.509841       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:21:49.508445941Z E1024 13:21:49.508393       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:49.508445941Z E1024 13:21:49.508422       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:49.509350831Z E1024 13:21:49.509325       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:49.910107796Z I1024 13:21:49.910044       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:21:50.512028619Z E1024 13:21:50.511961       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:50.512028619Z E1024 13:21:50.511984       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:50.513046479Z E1024 13:21:50.513005       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:52.097848060Z E1024 13:21:52.097769       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:52.097848060Z E1024 13:21:52.097800       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:52.098866890Z E1024 13:21:52.098828       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:52.217261815Z E1024 13:21:52.217185       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:52.217261815Z E1024 13:21:52.217219       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:52.218321565Z E1024 13:21:52.218282       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:55.989043649Z E1024 13:21:55.988461       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:55.989043649Z E1024 13:21:55.988485       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:56.732249228Z I1024 13:21:56.732185       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:21:57.338876201Z E1024 13:21:57.338261       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:21:58.313911608Z I1024 13:21:58.313860       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:21:58.909634581Z E1024 13:21:58.909597       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:58.909634581Z E1024 13:21:58.909616       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:21:58.910437901Z E1024 13:21:58.910398       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:03.113849402Z E1024 13:22:03.113802       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:03.113849402Z E1024 13:22:03.113828       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:03.114875002Z E1024 13:22:03.114832       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:04.109424130Z E1024 13:22:04.109362       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:04.109424130Z E1024 13:22:04.109390       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:04.110454980Z E1024 13:22:04.110408       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:04.923051521Z E1024 13:22:04.922462       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:04.923051521Z E1024 13:22:04.922498       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:04.924659061Z E1024 13:22:04.924191       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:05.711079041Z E1024 13:22:05.711021       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:05.711079041Z E1024 13:22:05.711046       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:05.711828142Z E1024 13:22:05.711800       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:11.627532458Z E1024 13:22:11.627455       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:11.627532458Z E1024 13:22:11.627484       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:11.628456888Z E1024 13:22:11.628395       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:12.531228833Z E1024 13:22:12.531177       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:12.531361983Z E1024 13:22:12.531337       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:12.532661272Z E1024 13:22:12.532626       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:13.020745591Z E1024 13:22:13.020672       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:13.020745591Z E1024 13:22:13.020702       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:13.021596731Z E1024 13:22:13.021573       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:13.331063563Z E1024 13:22:13.331003       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:13.331063563Z E1024 13:22:13.331036       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:13.332229563Z E1024 13:22:13.332177       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:19.392032975Z I1024 13:22:19.391969       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:22:19.398100045Z E1024 13:22:19.398052       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:19.398100045Z E1024 13:22:19.398089       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:19.399454595Z E1024 13:22:19.399384       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:20.718369816Z E1024 13:22:20.718300       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:20.718369816Z E1024 13:22:20.718324       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:20.719350266Z E1024 13:22:20.719282       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:20.730913237Z I1024 13:22:20.730836       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 6, but has not made progress because waiting for static pod of revision 6, found 5
2024-10-24T13:22:23.171872340Z E1024 13:22:23.171805       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:23.171872340Z E1024 13:22:23.171832       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:23.172654240Z E1024 13:22:23.172607       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:24.173209108Z E1024 13:22:24.173152       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:24.173209108Z E1024 13:22:24.173180       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:24.173951698Z E1024 13:22:24.173916       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:29.192340761Z E1024 13:22:29.192264       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:29.192340761Z E1024 13:22:29.192304       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:29.193479090Z E1024 13:22:29.193442       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:29.194884391Z E1024 13:22:29.194855       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:29.194929251Z E1024 13:22:29.194883       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:22:29.194929251Z E1024 13:22:29.194894       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:29.205446531Z I1024 13:22:29.205405       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 6, but has not made progress because static pod is pending
2024-10-24T13:22:29.227745382Z E1024 13:22:29.227688       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:29.228840922Z I1024 13:22:29.228782       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: refixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=12) \"serving-cert\"\nNodeInstallerDegraded:  },\nNodeInstallerDegraded:  ConfigMapNamePrefixes: ([]string) (len=5 cap=8) {\nNodeInstallerDegraded:   (string) (len=18) \"kube-scheduler-pod\",\nNodeInstallerDegraded:   (string) (len=6) \"config\",\nNodeInstallerDegraded:   (string) (len=17) \"serviceaccount-ca\",\nNodeInstallerDegraded:   (string) (len=20) \"scheduler-kubeconfig\",\nNodeInstallerDegraded:   (string) (len=37) \"kube-scheduler-cert-syncer-kubeconfig\"\nNodeInstallerDegraded:  OptionalConfigMapNamePrefixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=16) \"policy-configmap\"\nNodeInstallerDegraded:  CertSecretNames: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=30) \"kube-scheduler-client-cert-key\"\nNodeInstallerDegraded:  OptionalCertSecretNamePrefixes: ([]string) \u003cnil\u003e,\nNodeInstallerDegraded:  CertConfigMapNamePrefixes: ([]string) \u003cnil\u003e,\nNodeInstallerDegraded:  OptionalCertConfigMapNamePrefixes: ([]string) \u003cnil\u003e,\nNodeInstallerDegraded:  CertDir: (string) (len=57) \"/etc/kubernetes/static-pod-resources/kube-scheduler-certs\",\nNodeInstallerDegraded:  ResourceDir: (string) (len=36) \"/etc/kubernetes/static-pod-resources\",\nNodeInstallerDegraded:  PodManifestDir: (string) (len=25) \"/etc/kubernetes/manifests\",\nNodeInstallerDegraded:  Timeout: (time.Duration) 2m0s,\nNodeInstallerDegraded:  StaticPodManifestsLockFile: (string) \"\",\nNodeInstallerDegraded:  PodMutationFns: ([]installerpod.PodMutationFunc) \u003cnil\u003e,\nNodeInstallerDegraded:  KubeletVersion: (string) \"\"\nNodeInstallerDegraded: })\nNodeInstallerDegraded: I1024 13:15:40.605843       1 cmd.go:409] Getting controller reference for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.620880       1 cmd.go:422] Waiting for installer revisions to settle for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.621111       1 envvar.go:172] \"Feature gate default state\" feature=\"WatchListClient\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.621191       1 envvar.go:172] \"Feature gate default state\" feature=\"InformerResourceVersion\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.629965       1 cmd.go:514] Waiting additional period after revisions have settled for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:16:10.632243       1 cmd.go:520] Getting installer pods for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: F1024 13:16:24.639340       1 cmd.go:105] Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:22:29.239344402Z E1024 13:22:29.239290       1 guard_controller.go:300] Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:22:29.240071382Z E1024 13:22:29.240049       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:29.240141692Z E1024 13:22:29.240126       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:29.245439342Z I1024 13:22:29.245364       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: refixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=12) \"serving-cert\"\nNodeInstallerDegraded:  },\nNodeInstallerDegraded:  ConfigMapNamePrefixes: ([]string) (len=5 cap=8) {\nNodeInstallerDegraded:   (string) (len=18) \"kube-scheduler-pod\",\nNodeInstallerDegraded:   (string) (len=6) \"config\",\nNodeInstallerDegraded:   (string) (len=17) \"serviceaccount-ca\",\nNodeInstallerDegraded:   (string) (len=20) \"scheduler-kubeconfig\",\nNodeInstallerDegraded:   (string) (len=37) \"kube-scheduler-cert-syncer-kubeconfig\"\nNodeInstallerDegraded:  OptionalConfigMapNamePrefixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=16) \"policy-configmap\"\nNodeInstallerDegraded:  CertSecretNames: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=30) \"kube-scheduler-client-cert-key\"\nNodeInstallerDegraded:  OptionalCertSecretNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  CertConfigMapNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  OptionalCertConfigMapNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  CertDir: (string) (len=57) \"/etc/kubernetes/static-pod-resources/kube-scheduler-certs\",\nNodeInstallerDegraded:  ResourceDir: (string) (len=36) \"/etc/kubernetes/static-pod-resources\",\nNodeInstallerDegraded:  PodManifestDir: (string) (len=25) \"/etc/kubernetes/manifests\",\nNodeInstallerDegraded:  Timeout: (time.Duration) 2m0s,\nNodeInstallerDegraded:  StaticPodManifestsLockFile: (string) \"\",\nNodeInstallerDegraded:  PodMutationFns: ([]installerpod.PodMutationFunc) <nil>,\nNodeInstallerDegraded:  KubeletVersion: (string) \"\"\nNodeInstallerDegraded: })\nNodeInstallerDegraded: I1024 13:15:40.605843       1 cmd.go:409] Getting controller reference for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.620880       1 cmd.go:422] Waiting for installer revisions to settle for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.621111       1 envvar.go:172] \"Feature gate default state\" feature=\"WatchListClient\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.621191       1 envvar.go:172] \"Feature gate default state\" feature=\"InformerResourceVersion\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.629965       1 cmd.go:514] Waiting additional period after revisions have settled for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:16:10.632243       1 cmd.go:520] Getting installer pods for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: F1024 13:16:24.639340       1 cmd.go:105] Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\nNodeInstallerDegraded: " to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: refixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=12) \"serving-cert\"\nNodeInstallerDegraded:  },\nNodeInstallerDegraded:  ConfigMapNamePrefixes: ([]string) (len=5 cap=8) {\nNodeInstallerDegraded:   (string) (len=18) \"kube-scheduler-pod\",\nNodeInstallerDegraded:   (string) (len=6) \"config\",\nNodeInstallerDegraded:   (string) (len=17) \"serviceaccount-ca\",\nNodeInstallerDegraded:   (string) (len=20) \"scheduler-kubeconfig\",\nNodeInstallerDegraded:   (string) (len=37) \"kube-scheduler-cert-syncer-kubeconfig\"\nNodeInstallerDegraded:  OptionalConfigMapNamePrefixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=16) \"policy-configmap\"\nNodeInstallerDegraded:  CertSecretNames: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=30) \"kube-scheduler-client-cert-key\"\nNodeInstallerDegraded:  OptionalCertSecretNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  CertConfigMapNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  OptionalCertConfigMapNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  CertDir: (string) (len=57) \"/etc/kubernetes/static-pod-resources/kube-scheduler-certs\",\nNodeInstallerDegraded:  ResourceDir: (string) (len=36) \"/etc/kubernetes/static-pod-resources\",\nNodeInstallerDegraded:  PodManifestDir: (string) (len=25) \"/etc/kubernetes/manifests\",\nNodeInstallerDegraded:  Timeout: (time.Duration) 2m0s,\nNodeInstallerDegraded:  StaticPodManifestsLockFile: (string) \"\",\nNodeInstallerDegraded:  PodMutationFns: ([]installerpod.PodMutationFunc) <nil>,\nNodeInstallerDegraded:  KubeletVersion: (string) \"\"\nNodeInstallerDegraded: })\nNodeInstallerDegraded: I1024 13:15:40.605843       1 cmd.go:409] Getting controller reference for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.620880       1 cmd.go:422] Waiting for installer revisions to settle for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.621111       1 envvar.go:172] \"Feature gate default state\" feature=\"WatchListClient\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.621191       1 envvar.go:172] \"Feature gate default state\" feature=\"InformerResourceVersion\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.629965       1 cmd.go:514] Waiting additional period after revisions have settled for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:16:10.632243       1 cmd.go:520] Getting installer pods for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: F1024 13:16:24.639340       1 cmd.go:105] Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\nNodeInstallerDegraded: "
2024-10-24T13:22:29.272134543Z I1024 13:22:29.272055       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: refixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=12) \"serving-cert\"\nNodeInstallerDegraded:  },\nNodeInstallerDegraded:  ConfigMapNamePrefixes: ([]string) (len=5 cap=8) {\nNodeInstallerDegraded:   (string) (len=18) \"kube-scheduler-pod\",\nNodeInstallerDegraded:   (string) (len=6) \"config\",\nNodeInstallerDegraded:   (string) (len=17) \"serviceaccount-ca\",\nNodeInstallerDegraded:   (string) (len=20) \"scheduler-kubeconfig\",\nNodeInstallerDegraded:   (string) (len=37) \"kube-scheduler-cert-syncer-kubeconfig\"\nNodeInstallerDegraded:  OptionalConfigMapNamePrefixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=16) \"policy-configmap\"\nNodeInstallerDegraded:  CertSecretNames: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=30) \"kube-scheduler-client-cert-key\"\nNodeInstallerDegraded:  OptionalCertSecretNamePrefixes: ([]string) \u003cnil\u003e,\nNodeInstallerDegraded:  CertConfigMapNamePrefixes: ([]string) \u003cnil\u003e,\nNodeInstallerDegraded:  OptionalCertConfigMapNamePrefixes: ([]string) \u003cnil\u003e,\nNodeInstallerDegraded:  CertDir: (string) (len=57) \"/etc/kubernetes/static-pod-resources/kube-scheduler-certs\",\nNodeInstallerDegraded:  ResourceDir: (string) (len=36) \"/etc/kubernetes/static-pod-resources\",\nNodeInstallerDegraded:  PodManifestDir: (string) (len=25) \"/etc/kubernetes/manifests\",\nNodeInstallerDegraded:  Timeout: (time.Duration) 2m0s,\nNodeInstallerDegraded:  StaticPodManifestsLockFile: (string) \"\",\nNodeInstallerDegraded:  PodMutationFns: ([]installerpod.PodMutationFunc) \u003cnil\u003e,\nNodeInstallerDegraded:  KubeletVersion: (string) \"\"\nNodeInstallerDegraded: })\nNodeInstallerDegraded: I1024 13:15:40.605843       1 cmd.go:409] Getting controller reference for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.620880       1 cmd.go:422] Waiting for installer revisions to settle for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.621111       1 envvar.go:172] \"Feature gate default state\" feature=\"WatchListClient\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.621191       1 envvar.go:172] \"Feature gate default state\" feature=\"InformerResourceVersion\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.629965       1 cmd.go:514] Waiting additional period after revisions have settled for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:16:10.632243       1 cmd.go:520] Getting installer pods for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: F1024 13:16:24.639340       1 cmd.go:105] Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:22:29.272546024Z E1024 13:22:29.272490       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:29.294059264Z I1024 13:22:29.293948       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: refixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=12) \"serving-cert\"\nNodeInstallerDegraded:  },\nNodeInstallerDegraded:  ConfigMapNamePrefixes: ([]string) (len=5 cap=8) {\nNodeInstallerDegraded:   (string) (len=18) \"kube-scheduler-pod\",\nNodeInstallerDegraded:   (string) (len=6) \"config\",\nNodeInstallerDegraded:   (string) (len=17) \"serviceaccount-ca\",\nNodeInstallerDegraded:   (string) (len=20) \"scheduler-kubeconfig\",\nNodeInstallerDegraded:   (string) (len=37) \"kube-scheduler-cert-syncer-kubeconfig\"\nNodeInstallerDegraded:  OptionalConfigMapNamePrefixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=16) \"policy-configmap\"\nNodeInstallerDegraded:  CertSecretNames: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=30) \"kube-scheduler-client-cert-key\"\nNodeInstallerDegraded:  OptionalCertSecretNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  CertConfigMapNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  OptionalCertConfigMapNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  CertDir: (string) (len=57) \"/etc/kubernetes/static-pod-resources/kube-scheduler-certs\",\nNodeInstallerDegraded:  ResourceDir: (string) (len=36) \"/etc/kubernetes/static-pod-resources\",\nNodeInstallerDegraded:  PodManifestDir: (string) (len=25) \"/etc/kubernetes/manifests\",\nNodeInstallerDegraded:  Timeout: (time.Duration) 2m0s,\nNodeInstallerDegraded:  StaticPodManifestsLockFile: (string) \"\",\nNodeInstallerDegraded:  PodMutationFns: ([]installerpod.PodMutationFunc) <nil>,\nNodeInstallerDegraded:  KubeletVersion: (string) \"\"\nNodeInstallerDegraded: })\nNodeInstallerDegraded: I1024 13:15:40.605843       1 cmd.go:409] Getting controller reference for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.620880       1 cmd.go:422] Waiting for installer revisions to settle for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.621111       1 envvar.go:172] \"Feature gate default state\" feature=\"WatchListClient\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.621191       1 envvar.go:172] \"Feature gate default state\" feature=\"InformerResourceVersion\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.629965       1 cmd.go:514] Waiting additional period after revisions have settled for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:16:10.632243       1 cmd.go:520] Getting installer pods for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: F1024 13:16:24.639340       1 cmd.go:105] Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\nNodeInstallerDegraded: " to "GuardControllerDegraded: [Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: refixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=12) \"serving-cert\"\nNodeInstallerDegraded:  },\nNodeInstallerDegraded:  ConfigMapNamePrefixes: ([]string) (len=5 cap=8) {\nNodeInstallerDegraded:   (string) (len=18) \"kube-scheduler-pod\",\nNodeInstallerDegraded:   (string) (len=6) \"config\",\nNodeInstallerDegraded:   (string) (len=17) \"serviceaccount-ca\",\nNodeInstallerDegraded:   (string) (len=20) \"scheduler-kubeconfig\",\nNodeInstallerDegraded:   (string) (len=37) \"kube-scheduler-cert-syncer-kubeconfig\"\nNodeInstallerDegraded:  OptionalConfigMapNamePrefixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=16) \"policy-configmap\"\nNodeInstallerDegraded:  CertSecretNames: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=30) \"kube-scheduler-client-cert-key\"\nNodeInstallerDegraded:  OptionalCertSecretNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  CertConfigMapNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  OptionalCertConfigMapNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  CertDir: (string) (len=57) \"/etc/kubernetes/static-pod-resources/kube-scheduler-certs\",\nNodeInstallerDegraded:  ResourceDir: (string) (len=36) \"/etc/kubernetes/static-pod-resources\",\nNodeInstallerDegraded:  PodManifestDir: (string) (len=25) \"/etc/kubernetes/manifests\",\nNodeInstallerDegraded:  Timeout: (time.Duration) 2m0s,\nNodeInstallerDegraded:  StaticPodManifestsLockFile: (string) \"\",\nNodeInstallerDegraded:  PodMutationFns: ([]installerpod.PodMutationFunc) <nil>,\nNodeInstallerDegraded:  KubeletVersion: (string) \"\"\nNodeInstallerDegraded: })\nNodeInstallerDegraded: I1024 13:15:40.605843       1 cmd.go:409] Getting controller reference for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.620880       1 cmd.go:422] Waiting for installer revisions to settle for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.621111       1 envvar.go:172] \"Feature gate default state\" feature=\"WatchListClient\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.621191       1 envvar.go:172] \"Feature gate default state\" feature=\"InformerResourceVersion\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.629965       1 cmd.go:514] Waiting additional period after revisions have settled for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:16:10.632243       1 cmd.go:520] Getting installer pods for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: F1024 13:16:24.639340       1 cmd.go:105] Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\nNodeInstallerDegraded: "
2024-10-24T13:22:29.345833436Z E1024 13:22:29.345740       1 guard_controller.go:300] Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:22:29.345833436Z E1024 13:22:29.345803       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:29.345833436Z E1024 13:22:29.345812       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:29.346724217Z E1024 13:22:29.346695       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:30.358582165Z I1024 13:22:30.358529       1 request.go:700] Waited for 1.128972593s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/revision-pruner-6-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:22:31.558957371Z I1024 13:22:31.558894       1 request.go:700] Waited for 1.58023821s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa
2024-10-24T13:22:32.367990502Z I1024 13:22:32.367934       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 6, but has not made progress because static pod is pending
2024-10-24T13:22:32.559174060Z I1024 13:22:32.559106       1 request.go:700] Waited for 1.533124979s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:22:32.577017800Z E1024 13:22:32.576964       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:32.577147290Z E1024 13:22:32.577103       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:32.608011911Z E1024 13:22:32.607951       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:32.612930322Z I1024 13:22:32.612373       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: refixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=12) \"serving-cert\"\nNodeInstallerDegraded:  },\nNodeInstallerDegraded:  ConfigMapNamePrefixes: ([]string) (len=5 cap=8) {\nNodeInstallerDegraded:   (string) (len=18) \"kube-scheduler-pod\",\nNodeInstallerDegraded:   (string) (len=6) \"config\",\nNodeInstallerDegraded:   (string) (len=17) \"serviceaccount-ca\",\nNodeInstallerDegraded:   (string) (len=20) \"scheduler-kubeconfig\",\nNodeInstallerDegraded:   (string) (len=37) \"kube-scheduler-cert-syncer-kubeconfig\"\nNodeInstallerDegraded:  OptionalConfigMapNamePrefixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=16) \"policy-configmap\"\nNodeInstallerDegraded:  CertSecretNames: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=30) \"kube-scheduler-client-cert-key\"\nNodeInstallerDegraded:  OptionalCertSecretNamePrefixes: ([]string) \u003cnil\u003e,\nNodeInstallerDegraded:  CertConfigMapNamePrefixes: ([]string) \u003cnil\u003e,\nNodeInstallerDegraded:  OptionalCertConfigMapNamePrefixes: ([]string) \u003cnil\u003e,\nNodeInstallerDegraded:  CertDir: (string) (len=57) \"/etc/kubernetes/static-pod-resources/kube-scheduler-certs\",\nNodeInstallerDegraded:  ResourceDir: (string) (len=36) \"/etc/kubernetes/static-pod-resources\",\nNodeInstallerDegraded:  PodManifestDir: (string) (len=25) \"/etc/kubernetes/manifests\",\nNodeInstallerDegraded:  Timeout: (time.Duration) 2m0s,\nNodeInstallerDegraded:  StaticPodManifestsLockFile: (string) \"\",\nNodeInstallerDegraded:  PodMutationFns: ([]installerpod.PodMutationFunc) \u003cnil\u003e,\nNodeInstallerDegraded:  KubeletVersion: (string) \"\"\nNodeInstallerDegraded: })\nNodeInstallerDegraded: I1024 13:15:40.605843       1 cmd.go:409] Getting controller reference for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.620880       1 cmd.go:422] Waiting for installer revisions to settle for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.621111       1 envvar.go:172] \"Feature gate default state\" feature=\"WatchListClient\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.621191       1 envvar.go:172] \"Feature gate default state\" feature=\"InformerResourceVersion\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.629965       1 cmd.go:514] Waiting additional period after revisions have settled for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:16:10.632243       1 cmd.go:520] Getting installer pods for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: F1024 13:16:24.639340       1 cmd.go:105] Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:22:32.636786282Z I1024 13:22:32.636699       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: refixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=12) \"serving-cert\"\nNodeInstallerDegraded:  },\nNodeInstallerDegraded:  ConfigMapNamePrefixes: ([]string) (len=5 cap=8) {\nNodeInstallerDegraded:   (string) (len=18) \"kube-scheduler-pod\",\nNodeInstallerDegraded:   (string) (len=6) \"config\",\nNodeInstallerDegraded:   (string) (len=17) \"serviceaccount-ca\",\nNodeInstallerDegraded:   (string) (len=20) \"scheduler-kubeconfig\",\nNodeInstallerDegraded:   (string) (len=37) \"kube-scheduler-cert-syncer-kubeconfig\"\nNodeInstallerDegraded:  OptionalConfigMapNamePrefixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=16) \"policy-configmap\"\nNodeInstallerDegraded:  CertSecretNames: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=30) \"kube-scheduler-client-cert-key\"\nNodeInstallerDegraded:  OptionalCertSecretNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  CertConfigMapNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  OptionalCertConfigMapNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  CertDir: (string) (len=57) \"/etc/kubernetes/static-pod-resources/kube-scheduler-certs\",\nNodeInstallerDegraded:  ResourceDir: (string) (len=36) \"/etc/kubernetes/static-pod-resources\",\nNodeInstallerDegraded:  PodManifestDir: (string) (len=25) \"/etc/kubernetes/manifests\",\nNodeInstallerDegraded:  Timeout: (time.Duration) 2m0s,\nNodeInstallerDegraded:  StaticPodManifestsLockFile: (string) \"\",\nNodeInstallerDegraded:  PodMutationFns: ([]installerpod.PodMutationFunc) <nil>,\nNodeInstallerDegraded:  KubeletVersion: (string) \"\"\nNodeInstallerDegraded: })\nNodeInstallerDegraded: I1024 13:15:40.605843       1 cmd.go:409] Getting controller reference for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.620880       1 cmd.go:422] Waiting for installer revisions to settle for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.621111       1 envvar.go:172] \"Feature gate default state\" feature=\"WatchListClient\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.621191       1 envvar.go:172] \"Feature gate default state\" feature=\"InformerResourceVersion\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.629965       1 cmd.go:514] Waiting additional period after revisions have settled for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:16:10.632243       1 cmd.go:520] Getting installer pods for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: F1024 13:16:24.639340       1 cmd.go:105] Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\nNodeInstallerDegraded: " to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: refixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=12) \"serving-cert\"\nNodeInstallerDegraded:  },\nNodeInstallerDegraded:  ConfigMapNamePrefixes: ([]string) (len=5 cap=8) {\nNodeInstallerDegraded:   (string) (len=18) \"kube-scheduler-pod\",\nNodeInstallerDegraded:   (string) (len=6) \"config\",\nNodeInstallerDegraded:   (string) (len=17) \"serviceaccount-ca\",\nNodeInstallerDegraded:   (string) (len=20) \"scheduler-kubeconfig\",\nNodeInstallerDegraded:   (string) (len=37) \"kube-scheduler-cert-syncer-kubeconfig\"\nNodeInstallerDegraded:  OptionalConfigMapNamePrefixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=16) \"policy-configmap\"\nNodeInstallerDegraded:  CertSecretNames: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=30) \"kube-scheduler-client-cert-key\"\nNodeInstallerDegraded:  OptionalCertSecretNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  CertConfigMapNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  OptionalCertConfigMapNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  CertDir: (string) (len=57) \"/etc/kubernetes/static-pod-resources/kube-scheduler-certs\",\nNodeInstallerDegraded:  ResourceDir: (string) (len=36) \"/etc/kubernetes/static-pod-resources\",\nNodeInstallerDegraded:  PodManifestDir: (string) (len=25) \"/etc/kubernetes/manifests\",\nNodeInstallerDegraded:  Timeout: (time.Duration) 2m0s,\nNodeInstallerDegraded:  StaticPodManifestsLockFile: (string) \"\",\nNodeInstallerDegraded:  PodMutationFns: ([]installerpod.PodMutationFunc) <nil>,\nNodeInstallerDegraded:  KubeletVersion: (string) \"\"\nNodeInstallerDegraded: })\nNodeInstallerDegraded: I1024 13:15:40.605843       1 cmd.go:409] Getting controller reference for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.620880       1 cmd.go:422] Waiting for installer revisions to settle for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.621111       1 envvar.go:172] \"Feature gate default state\" feature=\"WatchListClient\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.621191       1 envvar.go:172] \"Feature gate default state\" feature=\"InformerResourceVersion\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.629965       1 cmd.go:514] Waiting additional period after revisions have settled for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:16:10.632243       1 cmd.go:520] Getting installer pods for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: F1024 13:16:24.639340       1 cmd.go:105] Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\nNodeInstallerDegraded: "
2024-10-24T13:22:33.758789635Z I1024 13:22:33.758717       1 request.go:700] Waited for 1.389819643s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-6-retry-2-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:22:34.958191351Z I1024 13:22:34.958123       1 request.go:700] Waited for 1.59175271s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/revision-pruner-6-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:22:35.366064777Z E1024 13:22:35.366019       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:35.366064777Z E1024 13:22:35.366042       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:35.367262317Z E1024 13:22:35.367201       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:35.958898639Z I1024 13:22:35.958840       1 request.go:700] Waited for 1.379756732s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler
2024-10-24T13:22:36.567787473Z I1024 13:22:36.567684       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 6, but has not made progress because static pod is pending
2024-10-24T13:22:36.959333878Z I1024 13:22:36.959246       1 request.go:700] Waited for 1.193710866s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:38.158887644Z I1024 13:22:38.158824       1 request.go:700] Waited for 1.178108105s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:22:38.169992334Z E1024 13:22:38.169944       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:38.169992334Z E1024 13:22:38.169963       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:38.170957704Z E1024 13:22:38.170929       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:39.569304348Z I1024 13:22:39.569233       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 6, but has not made progress because static pod is pending
2024-10-24T13:22:42.570021303Z E1024 13:22:42.569952       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:42.570021303Z E1024 13:22:42.569984       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:42.570992123Z E1024 13:22:42.570950       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:43.230129668Z E1024 13:22:43.230073       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:43.230129668Z E1024 13:22:43.230097       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:43.231180908Z E1024 13:22:43.231093       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:43.383067084Z E1024 13:22:43.383018       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:43.383067084Z E1024 13:22:43.383043       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:43.384155054Z E1024 13:22:43.384032       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:43.705641146Z E1024 13:22:43.705574       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:43.705641146Z E1024 13:22:43.705610       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:43.706432216Z E1024 13:22:43.706390       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:43.920791775Z E1024 13:22:43.920707       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:43.920791775Z E1024 13:22:43.920733       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:43.921604295Z E1024 13:22:43.921565       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:22:54.065666124Z E1024 13:22:54.065615       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:54.085405295Z E1024 13:22:54.085350       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:22:54.086657544Z E1024 13:22:54.086610       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:02.388806259Z E1024 13:23:02.388765       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:02.388883959Z E1024 13:23:02.388867       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:02.410011049Z E1024 13:23:02.409949       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:04.412916265Z E1024 13:23:04.412586       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:04.412916265Z E1024 13:23:04.412623       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:04.434635596Z E1024 13:23:04.434575       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:12.536169863Z E1024 13:23:12.536117       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:12.536212143Z E1024 13:23:12.536177       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:12.537052563Z E1024 13:23:12.537018       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:14.045782328Z E1024 13:23:14.045722       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:14.045881228Z E1024 13:23:14.045865       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:14.047032378Z E1024 13:23:14.046949       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:14.193929421Z E1024 13:23:14.193881       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:14.194027801Z E1024 13:23:14.194011       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:14.218673842Z E1024 13:23:14.218566       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:19.284904719Z E1024 13:23:19.284823       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:19.284904719Z E1024 13:23:19.284854       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:19.308909760Z E1024 13:23:19.308848       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:19.312937040Z I1024 13:23:19.312725       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:23:19.312937040Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:23:19.312937040Z  CurrentRevision: (int32) 6,
2024-10-24T13:23:19.312937040Z  TargetRevision: (int32) 0,
2024-10-24T13:23:19.312937040Z  LastFailedRevision: (int32) 6,
2024-10-24T13:23:19.312937040Z  LastFailedTime: (*v1.Time)(0xc0024d5b48)(2024-10-24 13:21:24 +0000 UTC),
2024-10-24T13:23:19.312937040Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:23:19.312937040Z  LastFailedCount: (int) 2,
2024-10-24T13:23:19.312937040Z  LastFallbackCount: (int) 0,
2024-10-24T13:23:19.312937040Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:23:19.312937040Z   (string) (len=2059) "installer: refixes: ([]string) (len=1 cap=1) {\n  (string) (len=12) \"serving-cert\"\n },\n ConfigMapNamePrefixes: ([]string) (len=5 cap=8) {\n  (string) (len=18) \"kube-scheduler-pod\",\n  (string) (len=6) \"config\",\n  (string) (len=17) \"serviceaccount-ca\",\n  (string) (len=20) \"scheduler-kubeconfig\",\n  (string) (len=37) \"kube-scheduler-cert-syncer-kubeconfig\"\n },\n OptionalConfigMapNamePrefixes: ([]string) (len=1 cap=1) {\n  (string) (len=16) \"policy-configmap\"\n },\n CertSecretNames: ([]string) (len=1 cap=1) {\n  (string) (len=30) \"kube-scheduler-client-cert-key\"\n },\n OptionalCertSecretNamePrefixes: ([]string) <nil>,\n CertConfigMapNamePrefixes: ([]string) <nil>,\n OptionalCertConfigMapNamePrefixes: ([]string) <nil>,\n CertDir: (string) (len=57) \"/etc/kubernetes/static-pod-resources/kube-scheduler-certs\",\n ResourceDir: (string) (len=36) \"/etc/kubernetes/static-pod-resources\",\n PodManifestDir: (string) (len=25) \"/etc/kubernetes/manifests\",\n Timeout: (time.Duration) 2m0s,\n StaticPodManifestsLockFile: (string) \"\",\n PodMutationFns: ([]installerpod.PodMutationFunc) <nil>,\n KubeletVersion: (string) \"\"\n})\nI1024 13:15:40.605843       1 cmd.go:409] Getting controller reference for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nI1024 13:15:40.620880       1 cmd.go:422] Waiting for installer revisions to settle for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nI1024 13:15:40.621111       1 envvar.go:172] \"Feature gate default state\" feature=\"WatchListClient\" enabled=false\nI1024 13:15:40.621191       1 envvar.go:172] \"Feature gate default state\" feature=\"InformerResourceVersion\" enabled=false\nI1024 13:15:40.629965       1 cmd.go:514] Waiting additional period after revisions have settled for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nI1024 13:16:10.632243       1 cmd.go:520] Getting installer pods for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nF1024 13:16:24.639340       1 cmd.go:105] Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\n"
2024-10-24T13:23:19.312937040Z  }
2024-10-24T13:23:19.312937040Z }
2024-10-24T13:23:19.312937040Z  because static pod is ready
2024-10-24T13:23:19.335118951Z I1024 13:23:19.335039       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 0 to 6 because static pod is ready
2024-10-24T13:23:19.336575610Z I1024 13:23:19.336534       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:23:19.354497871Z I1024 13:23:19.354440       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: refixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=12) \"serving-cert\"\nNodeInstallerDegraded:  },\nNodeInstallerDegraded:  ConfigMapNamePrefixes: ([]string) (len=5 cap=8) {\nNodeInstallerDegraded:   (string) (len=18) \"kube-scheduler-pod\",\nNodeInstallerDegraded:   (string) (len=6) \"config\",\nNodeInstallerDegraded:   (string) (len=17) \"serviceaccount-ca\",\nNodeInstallerDegraded:   (string) (len=20) \"scheduler-kubeconfig\",\nNodeInstallerDegraded:   (string) (len=37) \"kube-scheduler-cert-syncer-kubeconfig\"\nNodeInstallerDegraded:  OptionalConfigMapNamePrefixes: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=16) \"policy-configmap\"\nNodeInstallerDegraded:  CertSecretNames: ([]string) (len=1 cap=1) {\nNodeInstallerDegraded:   (string) (len=30) \"kube-scheduler-client-cert-key\"\nNodeInstallerDegraded:  OptionalCertSecretNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  CertConfigMapNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  OptionalCertConfigMapNamePrefixes: ([]string) <nil>,\nNodeInstallerDegraded:  CertDir: (string) (len=57) \"/etc/kubernetes/static-pod-resources/kube-scheduler-certs\",\nNodeInstallerDegraded:  ResourceDir: (string) (len=36) \"/etc/kubernetes/static-pod-resources\",\nNodeInstallerDegraded:  PodManifestDir: (string) (len=25) \"/etc/kubernetes/manifests\",\nNodeInstallerDegraded:  Timeout: (time.Duration) 2m0s,\nNodeInstallerDegraded:  StaticPodManifestsLockFile: (string) \"\",\nNodeInstallerDegraded:  PodMutationFns: ([]installerpod.PodMutationFunc) <nil>,\nNodeInstallerDegraded:  KubeletVersion: (string) \"\"\nNodeInstallerDegraded: })\nNodeInstallerDegraded: I1024 13:15:40.605843       1 cmd.go:409] Getting controller reference for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.620880       1 cmd.go:422] Waiting for installer revisions to settle for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:15:40.621111       1 envvar.go:172] \"Feature gate default state\" feature=\"WatchListClient\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.621191       1 envvar.go:172] \"Feature gate default state\" feature=\"InformerResourceVersion\" enabled=false\nNodeInstallerDegraded: I1024 13:15:40.629965       1 cmd.go:514] Waiting additional period after revisions have settled for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: I1024 13:16:10.632243       1 cmd.go:520] Getting installer pods for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: F1024 13:16:24.639340       1 cmd.go:105] Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\nNodeInstallerDegraded: " to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]",Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6" to "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6",Available changed from False to True ("StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6")
2024-10-24T13:23:20.485630997Z I1024 13:23:20.485540       1 request.go:700] Waited for 1.141744106s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:21.095574961Z I1024 13:23:21.095532       1 installer_controller.go:534] node ci-op-2fcpj5j6-f6035-2lklf-master-1 static pod not found and needs new revision 6
2024-10-24T13:23:21.095623211Z I1024 13:23:21.095572       1 installer_controller.go:542] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:23:21.095623211Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:23:21.095623211Z  CurrentRevision: (int32) 0,
2024-10-24T13:23:21.095623211Z  TargetRevision: (int32) 6,
2024-10-24T13:23:21.095623211Z  LastFailedRevision: (int32) 0,
2024-10-24T13:23:21.095623211Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:23:21.095623211Z  LastFailedReason: (string) "",
2024-10-24T13:23:21.095623211Z  LastFailedCount: (int) 0,
2024-10-24T13:23:21.095623211Z  LastFallbackCount: (int) 0,
2024-10-24T13:23:21.095623211Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:23:21.095623211Z }
2024-10-24T13:23:21.121386392Z I1024 13:23:21.121335       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 0 to 6 because node ci-op-2fcpj5j6-f6035-2lklf-master-1 static pod not found
2024-10-24T13:23:21.885912759Z I1024 13:23:21.885846       1 request.go:700] Waited for 1.127473527s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2024-10-24T13:23:23.085170167Z I1024 13:23:23.085116       1 request.go:700] Waited for 1.381733562s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client
2024-10-24T13:23:23.720457012Z I1024 13:23:23.720376       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-6-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-scheduler because it was missing
2024-10-24T13:23:24.285706365Z I1024 13:23:24.285653       1 request.go:700] Waited for 1.393250783s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:25.095888543Z I1024 13:23:25.095823       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:23:25.294764768Z E1024 13:23:25.294700       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:25.294764768Z E1024 13:23:25.294722       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:25.295587528Z E1024 13:23:25.295553       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:25.296983018Z E1024 13:23:25.296942       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:25.485464942Z I1024 13:23:25.485404       1 request.go:700] Waited for 1.391774393s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/scheduler-kubeconfig
2024-10-24T13:23:26.485714356Z I1024 13:23:26.485652       1 request.go:700] Waited for 1.388789323s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-6-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:27.495040169Z I1024 13:23:27.494978       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:23:27.696556284Z E1024 13:23:27.696467       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:27.697540944Z E1024 13:23:27.697519       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:33.867229736Z E1024 13:23:33.867159       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:33.867229736Z E1024 13:23:33.867190       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:33.868353356Z E1024 13:23:33.868302       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:35.239168478Z E1024 13:23:35.239077       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:35.239168478Z E1024 13:23:35.239107       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:35.258522258Z E1024 13:23:35.258456       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:23:56.718399584Z E1024 13:23:56.718324       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:23:56.719019114Z E1024 13:23:56.718960       1 leaderelection.go:436] error retrieving resource lock openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:20.759316060Z E1024 13:24:20.759252       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:20.761882990Z E1024 13:24:20.761843       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:20.761882990Z E1024 13:24:20.761871       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:20.767037890Z E1024 13:24:20.766991       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:20.772385400Z E1024 13:24:20.772305       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:20.773015540Z E1024 13:24:20.772932       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:20.959657575Z E1024 13:24:20.959600       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:21.362800924Z E1024 13:24:21.362700       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:21.759468803Z E1024 13:24:21.759393       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:22.163108422Z E1024 13:24:22.163043       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:22.720980215Z E1024 13:24:22.720910       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:24:22.721890275Z E1024 13:24:22.721848       1 leaderelection.go:436] error retrieving resource lock openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:22.760398416Z E1024 13:24:22.760324       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:22.961669951Z E1024 13:24:22.961613       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:23.163030545Z E1024 13:24:23.162959       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:23.559580405Z I1024 13:24:23.559516       1 request.go:700] Waited for 1.000189724s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa
2024-10-24T13:24:23.759936889Z E1024 13:24:23.759865       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:24.162204189Z E1024 13:24:24.162132       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:24.562071568Z E1024 13:24:24.561999       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:24.759847702Z E1024 13:24:24.759787       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:25.162345422Z E1024 13:24:25.162285       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:25.762064145Z E1024 13:24:25.762002       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:25.959564140Z E1024 13:24:25.959483       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:26.161080165Z E1024 13:24:26.160987       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:26.362427639Z E1024 13:24:26.362375       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:27.360348672Z E1024 13:24:27.360292       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:27.962179946Z E1024 13:24:27.962102       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:28.161945751Z E1024 13:24:28.161894       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:28.361526436Z E1024 13:24:28.361464       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:29.360538149Z E1024 13:24:29.360457       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:29.961416093Z E1024 13:24:29.961369       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:30.162836057Z E1024 13:24:30.162781       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:30.560794906Z E1024 13:24:30.560725       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:30.961851856Z E1024 13:24:30.961791       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:32.361134088Z E1024 13:24:32.361086       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:32.560223902Z E1024 13:24:32.560162       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:33.362358291Z E1024 13:24:33.362292       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:33.562147426Z E1024 13:24:33.562091       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:33.763984890Z E1024 13:24:33.763925       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:34.562100799Z E1024 13:24:34.562000       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:35.960934271Z E1024 13:24:35.960884       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:36.162108346Z E1024 13:24:36.162051       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:36.961120534Z E1024 13:24:36.961059       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:37.964294018Z E1024 13:24:37.964227       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:39.803657850Z E1024 13:24:39.803588       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: synthetic requeue request"
2024-10-24T13:25:25.985070182Z I1024 13:25:25.985008       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:31.225914204Z I1024 13:25:31.225849       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:31.546465122Z I1024 13:25:31.546405       1 reflector.go:368] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:32.519065519Z I1024 13:25:32.519007       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:32.632472939Z I1024 13:25:32.632420       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-1" for revision 6 for the 1st time because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:32.632472939Z W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:32.632472939Z W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:32.632472939Z W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:32.632472939Z W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:32.632472939Z W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:32.632472939Z W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:32.632472939Z F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:25:32.632819398Z I1024 13:25:32.632788       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:25:32.632819398Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:25:32.632819398Z  CurrentRevision: (int32) 0,
2024-10-24T13:25:32.632819398Z  TargetRevision: (int32) 6,
2024-10-24T13:25:32.632819398Z  LastFailedRevision: (int32) 6,
2024-10-24T13:25:32.632819398Z  LastFailedTime: (*v1.Time)(0xc0015e4be8)(2024-10-24 13:25:32.632400339 +0000 UTC m=+445.471329067),
2024-10-24T13:25:32.632819398Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:25:32.632819398Z  LastFailedCount: (int) 1,
2024-10-24T13:25:32.632819398Z  LastFallbackCount: (int) 0,
2024-10-24T13:25:32.632819398Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:25:32.632819398Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:25:32.632819398Z  }
2024-10-24T13:25:32.632819398Z }
2024-10-24T13:25:32.632819398Z  because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:32.632819398Z W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:32.632819398Z W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:32.632819398Z W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:32.632819398Z W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:32.632819398Z W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:32.632819398Z W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:32.632819398Z F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:25:32.633453079Z I1024 13:25:32.633402       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:32.633453079Z W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:32.633453079Z W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:32.633453079Z W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:32.633453079Z W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:32.633453079Z W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:32.633453079Z W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:32.633453079Z F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:25:32.670224418Z I1024 13:25:32.670177       1 helpers.go:260] lister was stale at resourceVersion=26658, live get showed resourceVersion=27203
2024-10-24T13:25:34.232978463Z I1024 13:25:34.232907       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-1" for revision 6 for the 1st time because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.232978463Z W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.232978463Z W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.232978463Z W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.232978463Z W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.232978463Z W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.232978463Z W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.232978463Z F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:25:34.233066163Z I1024 13:25:34.233002       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:25:34.233066163Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:25:34.233066163Z  CurrentRevision: (int32) 0,
2024-10-24T13:25:34.233066163Z  TargetRevision: (int32) 6,
2024-10-24T13:25:34.233066163Z  LastFailedRevision: (int32) 6,
2024-10-24T13:25:34.233066163Z  LastFailedTime: (*v1.Time)(0xc001e0aed0)(2024-10-24 13:25:34.232887693 +0000 UTC m=+447.071816411),
2024-10-24T13:25:34.233066163Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:25:34.233066163Z  LastFailedCount: (int) 1,
2024-10-24T13:25:34.233066163Z  LastFallbackCount: (int) 0,
2024-10-24T13:25:34.233066163Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:25:34.233066163Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:25:34.233066163Z  }
2024-10-24T13:25:34.233066163Z }
2024-10-24T13:25:34.233066163Z  because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.233066163Z W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.233066163Z W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.233066163Z W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.233066163Z W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.233066163Z W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.233066163Z W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.233066163Z F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:25:34.233106803Z I1024 13:25:34.233048       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.233106803Z W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.233106803Z W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.233106803Z W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.233106803Z W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.233106803Z W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.233106803Z W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:34.233106803Z F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:25:34.267622643Z I1024 13:25:34.267570       1 helpers.go:260] lister was stale at resourceVersion=26658, live get showed resourceVersion=27684
2024-10-24T13:25:34.582655772Z I1024 13:25:34.582563       1 reflector.go:368] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:34.644478891Z I1024 13:25:34.644402       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:35.433373359Z I1024 13:25:35.433285       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:36.226206356Z I1024 13:25:36.226138       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:36.627276754Z I1024 13:25:36.627200       1 request.go:700] Waited for 1.192813756s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:25:37.826982350Z I1024 13:25:37.826922       1 request.go:700] Waited for 1.191177407s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:25:37.837012540Z E1024 13:25:37.836957       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:25:37.837012540Z E1024 13:25:37.836988       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:25:37.837828781Z E1024 13:25:37.837785       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:25:37.979646900Z I1024 13:25:37.979582       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:38.032832320Z I1024 13:25:38.032783       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-1" for revision 6 for the 1st time because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:38.032832320Z W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:38.032832320Z W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:38.032832320Z W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:38.032832320Z W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:38.032832320Z W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:38.032832320Z W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:38.032832320Z F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:25:38.032916070Z I1024 13:25:38.032884       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:25:38.032916070Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:25:38.032916070Z  CurrentRevision: (int32) 0,
2024-10-24T13:25:38.032916070Z  TargetRevision: (int32) 6,
2024-10-24T13:25:38.032916070Z  LastFailedRevision: (int32) 6,
2024-10-24T13:25:38.032916070Z  LastFailedTime: (*v1.Time)(0xc000b4e3c0)(2024-10-24 13:25:38.03276457 +0000 UTC m=+450.871693298),
2024-10-24T13:25:38.032916070Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:25:38.032916070Z  LastFailedCount: (int) 1,
2024-10-24T13:25:38.032916070Z  LastFallbackCount: (int) 0,
2024-10-24T13:25:38.032916070Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:25:38.032916070Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:25:38.032916070Z  }
2024-10-24T13:25:38.032916070Z }
2024-10-24T13:25:38.032916070Z  because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:38.032916070Z W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:38.032916070Z W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:38.032916070Z W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:38.032916070Z W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:38.032916070Z W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:38.032916070Z W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:38.032916070Z F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:25:38.032963670Z I1024 13:25:38.032925       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:38.032963670Z W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:38.032963670Z W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:38.032963670Z W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:38.032963670Z W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:38.032963670Z W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:38.032963670Z W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:38.032963670Z F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:25:38.064328210Z I1024 13:25:38.064299       1 helpers.go:260] lister was stale at resourceVersion=26658, live get showed resourceVersion=27689
2024-10-24T13:25:39.426861315Z I1024 13:25:39.426779       1 request.go:700] Waited for 1.110351686s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/secrets?resourceVersion=26571
2024-10-24T13:25:39.430713765Z I1024 13:25:39.430646       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:40.033150113Z E1024 13:25:40.033072       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:25:40.033150113Z E1024 13:25:40.033097       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:25:40.033998163Z E1024 13:25:40.033949       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:25:40.235500912Z I1024 13:25:40.235430       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-1" for revision 6 for the 1st time because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:40.235500912Z W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:40.235500912Z W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:40.235500912Z W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:40.235500912Z W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:40.235500912Z W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:40.235500912Z W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:40.235500912Z F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:25:40.235632982Z I1024 13:25:40.235570       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:40.235632982Z W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:40.235632982Z W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:40.235632982Z W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:40.235632982Z W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:40.235632982Z W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:40.235632982Z W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:40.235632982Z F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:25:40.235632982Z I1024 13:25:40.235537       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:25:40.235632982Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:25:40.235632982Z  CurrentRevision: (int32) 0,
2024-10-24T13:25:40.235632982Z  TargetRevision: (int32) 6,
2024-10-24T13:25:40.235632982Z  LastFailedRevision: (int32) 6,
2024-10-24T13:25:40.235632982Z  LastFailedTime: (*v1.Time)(0xc000d8a438)(2024-10-24 13:25:40.235411872 +0000 UTC m=+453.074340600),
2024-10-24T13:25:40.235632982Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:25:40.235632982Z  LastFailedCount: (int) 1,
2024-10-24T13:25:40.235632982Z  LastFallbackCount: (int) 0,
2024-10-24T13:25:40.235632982Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:25:40.235632982Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:25:40.235632982Z  }
2024-10-24T13:25:40.235632982Z }
2024-10-24T13:25:40.235632982Z  because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:40.235632982Z W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:40.235632982Z W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:40.235632982Z W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:40.235632982Z W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:40.235632982Z W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:40.235632982Z W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:40.235632982Z F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:25:40.273597062Z I1024 13:25:40.273540       1 helpers.go:260] lister was stale at resourceVersion=26658, live get showed resourceVersion=27732
2024-10-24T13:25:40.426950951Z I1024 13:25:40.426855       1 request.go:700] Waited for 1.161321446s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/kube-system/configmaps?resourceVersion=26665
2024-10-24T13:25:40.430186861Z I1024 13:25:40.430121       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:40.591348491Z I1024 13:25:40.591249       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:41.138903779Z I1024 13:25:41.138851       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:42.037169595Z I1024 13:25:42.037116       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-1" for revision 6 for the 1st time because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:42.037169595Z W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:42.037169595Z W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:42.037169595Z W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:42.037169595Z W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:42.037169595Z W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:42.037169595Z W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:42.037169595Z F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:25:42.037230246Z I1024 13:25:42.037206       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:25:42.037230246Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:25:42.037230246Z  CurrentRevision: (int32) 0,
2024-10-24T13:25:42.037230246Z  TargetRevision: (int32) 6,
2024-10-24T13:25:42.037230246Z  LastFailedRevision: (int32) 6,
2024-10-24T13:25:42.037230246Z  LastFailedTime: (*v1.Time)(0xc0020d4168)(2024-10-24 13:25:42.037099176 +0000 UTC m=+454.876027904),
2024-10-24T13:25:42.037230246Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:25:42.037230246Z  LastFailedCount: (int) 1,
2024-10-24T13:25:42.037230246Z  LastFallbackCount: (int) 0,
2024-10-24T13:25:42.037230246Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:25:42.037230246Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:25:42.037230246Z  }
2024-10-24T13:25:42.037230246Z }
2024-10-24T13:25:42.037230246Z  because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:42.037230246Z W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:42.037230246Z W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:42.037230246Z W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:42.037230246Z W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:42.037230246Z W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:42.037230246Z W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:42.037230246Z F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:25:42.037303066Z I1024 13:25:42.037254       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:42.037303066Z W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:42.037303066Z W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:42.037303066Z W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:42.037303066Z W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:42.037303066Z W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:42.037303066Z W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:25:42.037303066Z F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:25:42.070516986Z I1024 13:25:42.070461       1 helpers.go:260] lister was stale at resourceVersion=26658, live get showed resourceVersion=27743
2024-10-24T13:25:42.430247254Z I1024 13:25:42.430166       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:43.030728882Z I1024 13:25:43.030683       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:43.679093330Z I1024 13:25:43.679030       1 reflector.go:368] Caches populated for *v1.Role from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:43.807254959Z I1024 13:25:43.807190       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:45.933814502Z I1024 13:25:45.933763       1 reflector.go:368] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:46.287408321Z I1024 13:25:46.287329       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubeschedulers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:46.298823831Z I1024 13:25:46.295047       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nTargetConfigControllerDegraded: \"configmap\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/serviceaccount-ca\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/serviceaccount-ca\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:46.313924661Z I1024 13:25:46.313848       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]" to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nTargetConfigControllerDegraded: \"configmap\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/serviceaccount-ca\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/serviceaccount-ca\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:25:46.458726870Z I1024 13:25:46.458678       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:46.474449370Z I1024 13:25:46.474383       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nTargetConfigControllerDegraded: \"configmap\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/serviceaccount-ca\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/serviceaccount-ca\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused" to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: "
2024-10-24T13:25:48.833220072Z I1024 13:25:48.833136       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:50.833077725Z E1024 13:25:50.833012       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:25:50.833077725Z E1024 13:25:50.833039       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:25:50.833977495Z E1024 13:25:50.833942       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:25:50.835512585Z E1024 13:25:50.835434       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:25:50.835512585Z E1024 13:25:50.835505       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:25:51.001371265Z I1024 13:25:51.001305       1 reflector.go:368] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:51.626976592Z I1024 13:25:51.626920       1 request.go:700] Waited for 1.078267526s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/configmaps?resourceVersion=26665
2024-10-24T13:25:51.645854902Z I1024 13:25:51.645785       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:52.214638010Z I1024 13:25:52.214581       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:52.627037109Z I1024 13:25:52.626952       1 request.go:700] Waited for 1.368414755s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler
2024-10-24T13:25:53.034592257Z E1024 13:25:53.034546       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:25:54.429271943Z I1024 13:25:54.429197       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:56.230600246Z I1024 13:25:56.230538       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:57.429528512Z I1024 13:25:57.429470       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:58.256566729Z I1024 13:25:58.256481       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-6-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-scheduler because it was missing
2024-10-24T13:25:58.622912377Z I1024 13:25:58.622860       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:58.634937467Z I1024 13:25:58.634885       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:58.834981917Z I1024 13:25:58.834902       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 6, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:25:59.427032645Z I1024 13:25:59.426963       1 request.go:700] Waited for 1.169955216s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:00.627090240Z I1024 13:26:00.627034       1 request.go:700] Waited for 1.193360426s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:00.637190370Z E1024 13:26:00.637142       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:00.637294920Z E1024 13:26:00.637281       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:00.640576860Z E1024 13:26:00.638375       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:26:00.642205140Z E1024 13:26:00.642182       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:01.232740058Z I1024 13:26:01.232669       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:26:01.827036686Z I1024 13:26:01.826973       1 request.go:700] Waited for 1.184396096s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:02.833502142Z E1024 13:26:02.833440       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:02.834363113Z E1024 13:26:02.834283       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:26:03.433241790Z I1024 13:26:03.433117       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:26:06.517615820Z E1024 13:26:06.517551       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:06.517615820Z E1024 13:26:06.517574       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:06.518705150Z E1024 13:26:06.518651       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:26:07.165913118Z I1024 13:26:07.165851       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:26:08.044698534Z E1024 13:26:08.044657       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:08.044788945Z E1024 13:26:08.044771       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:08.059735894Z E1024 13:26:08.059666       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:26:12.750823508Z I1024 13:26:12.750741       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:26:27.049338469Z E1024 13:26:27.048189       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:27.065691559Z E1024 13:26:27.065605       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:27.066993659Z E1024 13:26:27.066954       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:26:28.553200014Z E1024 13:26:28.553129       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:28.553200014Z E1024 13:26:28.553156       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:28.554462374Z E1024 13:26:28.554388       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:26:29.057675682Z E1024 13:26:29.057565       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:29.057675682Z E1024 13:26:29.057597       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:29.058882462Z E1024 13:26:29.058842       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:26:30.232647238Z E1024 13:26:30.232565       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:30.247011608Z I1024 13:26:30.246925       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:26:30.250471028Z E1024 13:26:30.250392       1 guard_controller.go:300] Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:30.272211488Z E1024 13:26:30.272151       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:26:30.276521398Z I1024 13:26:30.276477       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:26:30.293865088Z I1024 13:26:30.293735       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: " to "GuardControllerDegraded: [Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: "
2024-10-24T13:26:31.431851784Z I1024 13:26:31.431793       1 request.go:700] Waited for 1.119998796s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler
2024-10-24T13:26:31.638932113Z I1024 13:26:31.638871       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:26:32.432023310Z I1024 13:26:32.431976       1 request.go:700] Waited for 1.391156055s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:33.631849066Z I1024 13:26:33.631734       1 request.go:700] Waited for 1.392266415s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:34.493795273Z I1024 13:26:34.493635       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 7 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:26:34.631930053Z I1024 13:26:34.631882       1 request.go:700] Waited for 1.189750586s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2024-10-24T13:26:35.439594470Z I1024 13:26:35.439508       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 6, but has not made progress because static pod is pending
2024-10-24T13:26:35.831658349Z I1024 13:26:35.831588       1 request.go:700] Waited for 1.333513886s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler
2024-10-24T13:26:36.831683055Z I1024 13:26:36.831632       1 request.go:700] Waited for 1.190996266s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps
2024-10-24T13:26:36.843889885Z I1024 13:26:36.843807       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-scheduler-pod-7 -n openshift-kube-scheduler because it was missing
2024-10-24T13:26:37.444445423Z W1024 13:26:37.444391       1 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
2024-10-24T13:26:37.447856653Z E1024 13:26:37.447788       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:37.448286383Z I1024 13:26:37.448215       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-scheduler because it was missing
2024-10-24T13:26:37.470957223Z E1024 13:26:37.470878       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:26:37.473473473Z I1024 13:26:37.473398       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:26:37.492220723Z I1024 13:26:37.492131       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: " to "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: "
2024-10-24T13:26:37.832087872Z I1024 13:26:37.832030       1 request.go:700] Waited for 1.393472005s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/kube-scheduler-pod
2024-10-24T13:26:38.240402031Z I1024 13:26:38.240315       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-7 -n openshift-kube-scheduler because it was missing
2024-10-24T13:26:39.031364188Z I1024 13:26:39.031295       1 request.go:700] Waited for 1.558783055s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:39.840114015Z I1024 13:26:39.840052       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 6, but has not made progress because static pod is pending
2024-10-24T13:26:40.031891305Z I1024 13:26:40.031826       1 request.go:700] Waited for 1.791545044s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps
2024-10-24T13:26:40.043097515Z I1024 13:26:40.043041       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-7 -n openshift-kube-scheduler because it was missing
2024-10-24T13:26:41.231717770Z I1024 13:26:41.231667       1 request.go:700] Waited for 1.593204174s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/serviceaccount-ca
2024-10-24T13:26:41.642176209Z I1024 13:26:41.642113       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/scheduler-kubeconfig-7 -n openshift-kube-scheduler because it was missing
2024-10-24T13:26:42.432154076Z I1024 13:26:42.432071       1 request.go:700] Waited for 1.593677484s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:43.242103743Z I1024 13:26:43.242011       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-scheduler-cert-syncer-kubeconfig-7 -n openshift-kube-scheduler because it was missing
2024-10-24T13:26:43.631287762Z I1024 13:26:43.631218       1 request.go:700] Waited for 1.566689645s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler
2024-10-24T13:26:43.841199021Z I1024 13:26:43.841132       1 core.go:220] Pod "openshift-kube-scheduler/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1" changes: {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{"k8s.ovn.org/pod-networks":null,"k8s.v1.cni.cncf.io/network-status":null,"target.workload.openshift.io/management":"{\"effect\": \"PreferredDuringScheduling\"}"},"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null},"spec":{"containers":[{"args":["-c","# properly handle TERM and exit as soon as it is signaled\nset -euo pipefail\ntrap 'jobs -p | xargs -r kill; exit 0' TERM\nsleep infinity \u0026 wait\n"],"command":["/bin/bash"],"image":"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:7f1ef4ec397a7c90b5c3c5f9235d635ab8818ca402ce8de9bade295053038571","imagePullPolicy":"IfNotPresent","name":"guard","readinessProbe":{"failureThreshold":3,"httpGet":{"host":"10.0.0.4","path":"healthz","port":10259,"scheme":"HTTPS"},"periodSeconds":5,"successThreshold":1,"timeoutSeconds":5},"resources":{"requests":{"cpu":"10m","memory":"5Mi"}},"terminationMessagePolicy":"FallbackToLogsOnError"}],"dnsPolicy":null,"enableServiceLinks":null,"imagePullSecrets":null,"preemptionPolicy":null,"priority":null,"restartPolicy":null,"schedulerName":null,"securityContext":null,"serviceAccount":null,"serviceAccountName":null,"volumes":null},"status":{"conditions":null,"containerStatuses":null,"hostIP":null,"hostIPs":null,"phase":null,"podIP":null,"podIPs":null,"qosClass":null,"startTime":null}}
2024-10-24T13:26:44.438513129Z I1024 13:26:44.438451       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 6, but has not made progress because static pod is pending
2024-10-24T13:26:44.631851718Z I1024 13:26:44.631786       1 request.go:700] Waited for 1.389754585s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/secrets
2024-10-24T13:26:44.643097228Z I1024 13:26:44.643012       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-7 -n openshift-kube-scheduler because it was missing
2024-10-24T13:26:45.246005366Z E1024 13:26:45.245954       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:45.246230466Z I1024 13:26:45.246022       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-scheduler because it changed
2024-10-24T13:26:45.247363496Z E1024 13:26:45.247308       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:26:45.631902565Z I1024 13:26:45.631833       1 request.go:700] Waited for 1.392394405s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/scheduler-kubeconfig
2024-10-24T13:26:46.045190413Z I1024 13:26:46.045048       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-7 -n openshift-kube-scheduler because it was missing
2024-10-24T13:26:46.831792401Z I1024 13:26:46.831724       1 request.go:700] Waited for 1.582703845s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:47.644413808Z I1024 13:26:47.644346       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 7 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:26:47.645307848Z W1024 13:26:47.645282       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:26:47.645398508Z W1024 13:26:47.645354       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:26:47.668949568Z W1024 13:26:47.668879       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:26:47.668949568Z W1024 13:26:47.668910       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:26:48.031430887Z I1024 13:26:48.031339       1 request.go:700] Waited for 1.592378855s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler
2024-10-24T13:26:48.239345896Z E1024 13:26:48.239280       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:48.839005004Z I1024 13:26:48.838958       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 6, but has not made progress because static pod is pending
2024-10-24T13:26:48.863299464Z I1024 13:26:48.863228       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:26:48.878199564Z I1024 13:26:48.877585       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6" to "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7",Available message changed from "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6" to "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7"
2024-10-24T13:26:49.232049593Z I1024 13:26:49.231981       1 request.go:700] Waited for 1.392669536s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/revision-pruner-6-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:50.239278010Z I1024 13:26:50.239210       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:26:50.239278010Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:26:50.239278010Z  CurrentRevision: (int32) 0,
2024-10-24T13:26:50.239278010Z  TargetRevision: (int32) 7,
2024-10-24T13:26:50.239278010Z  LastFailedRevision: (int32) 6,
2024-10-24T13:26:50.239278010Z  LastFailedTime: (*v1.Time)(0xc001e75410)(2024-10-24 13:25:42 +0000 UTC),
2024-10-24T13:26:50.239278010Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:26:50.239278010Z  LastFailedCount: (int) 1,
2024-10-24T13:26:50.239278010Z  LastFallbackCount: (int) 0,
2024-10-24T13:26:50.239278010Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:26:50.239278010Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:26:50.239278010Z  }
2024-10-24T13:26:50.239278010Z }
2024-10-24T13:26:50.239278010Z  because new revision pending
2024-10-24T13:26:50.263224029Z I1024 13:26:50.263162       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:26:50.287440059Z I1024 13:26:50.287378       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: " to "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:26:50.431526159Z I1024 13:26:50.431440       1 request.go:700] Waited for 1.386156286s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa
2024-10-24T13:26:51.039632947Z E1024 13:26:51.039565       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:26:51.631614634Z I1024 13:26:51.631543       1 request.go:700] Waited for 1.368994964s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-6-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:51.639126034Z I1024 13:26:51.639066       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:26:51.639126034Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:26:51.639126034Z  CurrentRevision: (int32) 0,
2024-10-24T13:26:51.639126034Z  TargetRevision: (int32) 7,
2024-10-24T13:26:51.639126034Z  LastFailedRevision: (int32) 6,
2024-10-24T13:26:51.639126034Z  LastFailedTime: (*v1.Time)(0xc0023fc930)(2024-10-24 13:25:42 +0000 UTC),
2024-10-24T13:26:51.639126034Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:26:51.639126034Z  LastFailedCount: (int) 1,
2024-10-24T13:26:51.639126034Z  LastFallbackCount: (int) 0,
2024-10-24T13:26:51.639126034Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:26:51.639126034Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:23:45.364366       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:23:55.363740       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:05.364030       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:15.364193       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:25.364413       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:24:25.365130       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:24:25.365175       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:26:51.639126034Z  }
2024-10-24T13:26:51.639126034Z }
2024-10-24T13:26:51.639126034Z  because new revision pending
2024-10-24T13:26:52.051552343Z I1024 13:26:52.051459       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-7-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-scheduler because it was missing
2024-10-24T13:26:52.632137051Z I1024 13:26:52.632065       1 request.go:700] Waited for 1.390910995s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:53.831187087Z I1024 13:26:53.831112       1 request.go:700] Waited for 1.393161855s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:54.447239175Z I1024 13:26:54.447155       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-scheduler because it was missing
2024-10-24T13:26:54.832110294Z I1024 13:26:54.832037       1 request.go:700] Waited for 1.394187746s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods
2024-10-24T13:26:54.846580653Z I1024 13:26:54.846504       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-7-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-scheduler because it was missing
2024-10-24T13:26:55.838517000Z I1024 13:26:55.838444       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:26:56.031279699Z I1024 13:26:56.031203       1 request.go:700] Waited for 1.388842645s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2024-10-24T13:26:56.639089667Z E1024 13:26:56.639016       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:26:56.640036737Z E1024 13:26:56.640002       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:26:57.031448916Z I1024 13:26:57.031368       1 request.go:700] Waited for 1.390821805s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/secrets/serving-cert
2024-10-24T13:26:57.650505154Z I1024 13:26:57.650412       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-7-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-scheduler because it was missing
2024-10-24T13:26:58.231323191Z I1024 13:26:58.231254       1 request.go:700] Waited for 1.392800846s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:58.638886340Z I1024 13:26:58.638823       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:26:59.231988558Z I1024 13:26:59.231935       1 request.go:700] Waited for 1.193023476s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:59.240087328Z E1024 13:26:59.240027       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:00.431243983Z I1024 13:27:00.431169       1 request.go:700] Waited for 1.190670095s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:27:01.039182271Z I1024 13:27:01.039089       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:27:01.431390210Z I1024 13:27:01.431327       1 request.go:700] Waited for 1.190496536s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/revision-pruner-7-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:01.640043769Z E1024 13:27:01.639980       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:27:02.431546706Z I1024 13:27:02.431471       1 request.go:700] Waited for 1.189986935s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2024-10-24T13:27:03.239173274Z I1024 13:27:03.239113       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:27:03.638151012Z E1024 13:27:03.638092       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:05.040067438Z I1024 13:27:05.039990       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:27:05.239314497Z E1024 13:27:05.239241       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:27:09.647406103Z E1024 13:27:09.647347       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:09.682547203Z E1024 13:27:09.682486       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:27:20.587150477Z I1024 13:27:20.587101       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:27:20.598954117Z E1024 13:27:20.598886       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:20.599973277Z E1024 13:27:20.599922       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:27:28.351102509Z E1024 13:27:28.351022       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:28.352012049Z E1024 13:27:28.351965       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:27:30.157462268Z E1024 13:27:30.157388       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:30.173927578Z E1024 13:27:30.173878       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:27:32.978933851Z E1024 13:27:32.978879       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:32.980018701Z E1024 13:27:32.979988       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:27:32.981414621Z E1024 13:27:32.981383       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:33.012049301Z E1024 13:27:33.011974       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:27:40.352613615Z E1024 13:27:40.352570       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:40.353396575Z E1024 13:27:40.353358       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:27:50.807034240Z E1024 13:27:50.806956       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:27:50.807913210Z E1024 13:27:50.807744       1 leaderelection.go:436] error retrieving resource lock openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:16.810027121Z E1024 13:28:16.809954       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:28:16.810715831Z E1024 13:28:16.810675       1 leaderelection.go:436] error retrieving resource lock openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:20.762190026Z E1024 13:28:20.762111       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:20.765209946Z E1024 13:28:20.765169       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:20.765269736Z E1024 13:28:20.765217       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:20.769276236Z E1024 13:28:20.769224       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:20.774676026Z E1024 13:28:20.774644       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:20.775354386Z E1024 13:28:20.775311       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:20.962232975Z E1024 13:28:20.962159       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:21.365101052Z E1024 13:28:21.365041       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:21.762920370Z E1024 13:28:21.762861       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:22.165331247Z E1024 13:28:22.165265       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:22.762788124Z E1024 13:28:22.762722       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:22.963940183Z E1024 13:28:22.963877       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:23.164801302Z E1024 13:28:23.164708       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:23.762894338Z E1024 13:28:23.762820       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:24.167609835Z E1024 13:28:24.167562       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:24.564468413Z E1024 13:28:24.564391       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:24.762444162Z E1024 13:28:24.762386       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:25.164707449Z E1024 13:28:25.164647       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:25.763277765Z E1024 13:28:25.763213       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:25.961908104Z E1024 13:28:25.961848       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:26.163451912Z E1024 13:28:26.163366       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:26.364871661Z E1024 13:28:26.364808       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:27.362826885Z E1024 13:28:27.362745       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:27.965088651Z E1024 13:28:27.965027       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:28.164116090Z E1024 13:28:28.164053       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:28.364535589Z E1024 13:28:28.364491       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:29.362546042Z E1024 13:28:29.362490       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:29.963137258Z E1024 13:28:29.963074       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:30.164237478Z E1024 13:28:30.164192       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:30.563560945Z E1024 13:28:30.563496       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:30.964797272Z E1024 13:28:30.964677       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:32.364126514Z E1024 13:28:32.364041       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:32.562964002Z E1024 13:28:32.562899       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:33.365944087Z E1024 13:28:33.365887       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:33.564881226Z E1024 13:28:33.564828       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:33.764535324Z E1024 13:28:33.764482       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:34.563229490Z E1024 13:28:34.563160       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:35.964228891Z E1024 13:28:35.964161       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:36.163228470Z E1024 13:28:36.163164       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:36.963379755Z E1024 13:28:36.963321       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:37.964260120Z E1024 13:28:37.964204       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:38.162381668Z E1024 13:28:38.162319       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:38.963870213Z E1024 13:28:38.963814       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:39.164789812Z E1024 13:28:39.164707       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:40.163183115Z E1024 13:28:40.163125       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:40.564255683Z E1024 13:28:40.564211       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:41.364652458Z E1024 13:28:41.364589       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:42.364783252Z E1024 13:28:42.364712       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:42.809076319Z E1024 13:28:42.809020       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:28:42.810091829Z E1024 13:28:42.810026       1 leaderelection.go:436] error retrieving resource lock openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:43.163434807Z E1024 13:28:43.163378       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:43.763587024Z E1024 13:28:43.763527       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:44.964368587Z E1024 13:28:44.964316       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:45.363878674Z E1024 13:28:45.363810       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:46.363004998Z E1024 13:28:46.362952       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:47.164294793Z E1024 13:28:47.164228       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:48.163473128Z E1024 13:28:48.163415       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:48.405117646Z E1024 13:28:48.405060       1 base_controller.go:271] "Unhandled Error" err="kube-scheduler-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:48.963559583Z E1024 13:28:48.963496       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:49.410251390Z E1024 13:28:49.410200       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-scheduler-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:49.964219417Z E1024 13:28:49.964152       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:50.963966071Z E1024 13:28:50.963907       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:55.095304675Z E1024 13:28:55.095248       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:56.093221819Z E1024 13:28:56.093143       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:59.208533850Z E1024 13:28:59.208478       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:29:37.055575831Z I1024 13:29:37.055516       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:37.072125331Z I1024 13:29:37.072064       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:29:37.072125331Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:29:37.072125331Z  CurrentRevision: (int32) 0,
2024-10-24T13:29:37.072125331Z  TargetRevision: (int32) 7,
2024-10-24T13:29:37.072125331Z  LastFailedRevision: (int32) 7,
2024-10-24T13:29:37.072125331Z  LastFailedTime: (*v1.Time)(0xc001dc2de0)(2024-10-24 13:29:37.071974131 +0000 UTC m=+689.910902859),
2024-10-24T13:29:37.072125331Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:29:37.072125331Z  LastFailedCount: (int) 1,
2024-10-24T13:29:37.072125331Z  LastFallbackCount: (int) 0,
2024-10-24T13:29:37.072125331Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:29:37.072125331Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:29:37.072125331Z  }
2024-10-24T13:29:37.072125331Z }
2024-10-24T13:29:37.072125331Z  because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:37.072125331Z W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:37.072125331Z W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:37.072125331Z W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:37.072125331Z W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:37.072125331Z W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:37.072125331Z W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:37.072125331Z F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:29:37.072237891Z I1024 13:29:37.072200       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:37.072237891Z W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:37.072237891Z W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:37.072237891Z W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:37.072237891Z W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:37.072237891Z W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:37.072237891Z W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:37.072237891Z F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:29:38.457505322Z I1024 13:29:38.457437       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:29:38.457505322Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:29:38.457505322Z  CurrentRevision: (int32) 0,
2024-10-24T13:29:38.457505322Z  TargetRevision: (int32) 7,
2024-10-24T13:29:38.457505322Z  LastFailedRevision: (int32) 7,
2024-10-24T13:29:38.457505322Z  LastFailedTime: (*v1.Time)(0xc0021b1770)(2024-10-24 13:29:38.457347112 +0000 UTC m=+691.296275840),
2024-10-24T13:29:38.457505322Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:29:38.457505322Z  LastFailedCount: (int) 1,
2024-10-24T13:29:38.457505322Z  LastFallbackCount: (int) 0,
2024-10-24T13:29:38.457505322Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:29:38.457505322Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:29:38.457505322Z  }
2024-10-24T13:29:38.457505322Z }
2024-10-24T13:29:38.457505322Z  because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:38.457505322Z W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:38.457505322Z W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:38.457505322Z W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:38.457505322Z W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:38.457505322Z W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:38.457505322Z W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:38.457505322Z F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:29:38.457570832Z I1024 13:29:38.457518       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:38.457570832Z W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:38.457570832Z W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:38.457570832Z W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:38.457570832Z W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:38.457570832Z W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:38.457570832Z W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:38.457570832Z F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:29:38.492676082Z I1024 13:29:38.492611       1 helpers.go:260] lister was stale at resourceVersion=28836, live get showed resourceVersion=30130
2024-10-24T13:29:39.355156327Z I1024 13:29:39.355045       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:43.943950427Z I1024 13:29:43.943889       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:46.001447574Z I1024 13:29:46.001358       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:49.176515004Z I1024 13:29:49.176448       1 reflector.go:368] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:49.522218092Z I1024 13:29:49.522157       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:50.245090627Z I1024 13:29:50.245010       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:52.979901589Z I1024 13:29:52.979830       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:54.583265229Z I1024 13:29:54.583214       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:54.981375967Z I1024 13:29:54.981326       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:56.260228439Z I1024 13:29:56.260151       1 reflector.go:368] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:56.715545456Z I1024 13:29:56.715482       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:57.381948371Z I1024 13:29:57.381888       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:57.675813419Z I1024 13:29:57.675696       1 reflector.go:368] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:59.284932869Z I1024 13:29:59.284888       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:59.391685168Z I1024 13:29:59.391615       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.391685168Z W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.391685168Z W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.391685168Z W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.391685168Z W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.391685168Z W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.391685168Z W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.391685168Z F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:29:59.391825198Z I1024 13:29:59.391658       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:29:59.391825198Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:29:59.391825198Z  CurrentRevision: (int32) 0,
2024-10-24T13:29:59.391825198Z  TargetRevision: (int32) 7,
2024-10-24T13:29:59.391825198Z  LastFailedRevision: (int32) 7,
2024-10-24T13:29:59.391825198Z  LastFailedTime: (*v1.Time)(0xc00220a1f8)(2024-10-24 13:29:59.391452758 +0000 UTC m=+712.230381476),
2024-10-24T13:29:59.391825198Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:29:59.391825198Z  LastFailedCount: (int) 1,
2024-10-24T13:29:59.391825198Z  LastFallbackCount: (int) 0,
2024-10-24T13:29:59.391825198Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:29:59.391825198Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:29:59.391825198Z  }
2024-10-24T13:29:59.391825198Z }
2024-10-24T13:29:59.391825198Z  because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.391825198Z W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.391825198Z W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.391825198Z W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.391825198Z W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.391825198Z W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.391825198Z W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:59.391825198Z F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:29:59.437101488Z I1024 13:29:59.437050       1 helpers.go:260] lister was stale at resourceVersion=28836, live get showed resourceVersion=30138
2024-10-24T13:30:00.785506980Z E1024 13:30:00.785430       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:00.786662330Z E1024 13:30:00.786620       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:30:00.989351078Z I1024 13:30:00.989278       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:30:00.989351078Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:30:00.989351078Z  CurrentRevision: (int32) 0,
2024-10-24T13:30:00.989351078Z  TargetRevision: (int32) 7,
2024-10-24T13:30:00.989351078Z  LastFailedRevision: (int32) 7,
2024-10-24T13:30:00.989351078Z  LastFailedTime: (*v1.Time)(0xc00220a9c0)(2024-10-24 13:30:00.989186768 +0000 UTC m=+713.828115496),
2024-10-24T13:30:00.989351078Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:30:00.989351078Z  LastFailedCount: (int) 1,
2024-10-24T13:30:00.989351078Z  LastFallbackCount: (int) 0,
2024-10-24T13:30:00.989351078Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:30:00.989351078Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:30:00.989351078Z  }
2024-10-24T13:30:00.989351078Z }
2024-10-24T13:30:00.989351078Z  because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:00.989351078Z W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:00.989351078Z W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:00.989351078Z W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:00.989351078Z W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:00.989351078Z W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:00.989351078Z W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:00.989351078Z F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:30:00.990217958Z I1024 13:30:00.990145       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:00.990217958Z W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:00.990217958Z W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:00.990217958Z W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:00.990217958Z W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:00.990217958Z W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:00.990217958Z W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:00.990217958Z F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:30:01.032162638Z I1024 13:30:01.032115       1 helpers.go:260] lister was stale at resourceVersion=28836, live get showed resourceVersion=30421
2024-10-24T13:30:02.785083087Z E1024 13:30:02.784994       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:02.785857757Z E1024 13:30:02.785825       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:30:04.454735726Z I1024 13:30:04.454672       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:06.999590120Z I1024 13:30:06.999529       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:07.016013840Z E1024 13:30:07.015965       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:07.032792260Z E1024 13:30:07.032714       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:30:07.067899489Z E1024 13:30:07.067839       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:07.068712609Z E1024 13:30:07.068663       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:30:07.902127954Z E1024 13:30:07.902066       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:07.902941954Z E1024 13:30:07.902915       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:30:10.270935129Z I1024 13:30:10.270874       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:10.745669016Z E1024 13:30:10.745615       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:10.746445076Z E1024 13:30:10.746395       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:30:13.846209416Z E1024 13:30:13.846135       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:13.869348606Z E1024 13:30:13.869282       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:30:16.021919973Z I1024 13:30:16.021861       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:17.972009430Z E1024 13:30:17.971957       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:17.972991470Z E1024 13:30:17.972935       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:30:19.204641462Z I1024 13:30:19.204594       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:20.433385214Z I1024 13:30:20.433307       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:20.949541491Z I1024 13:30:20.949477       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:21.801662936Z I1024 13:30:21.801606       1 request.go:700] Waited for 1.039222074s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa
2024-10-24T13:30:22.010053345Z I1024 13:30:22.009987       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:30:22.010053345Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:30:22.010053345Z  CurrentRevision: (int32) 0,
2024-10-24T13:30:22.010053345Z  TargetRevision: (int32) 7,
2024-10-24T13:30:22.010053345Z  LastFailedRevision: (int32) 7,
2024-10-24T13:30:22.010053345Z  LastFailedTime: (*v1.Time)(0xc0023ef560)(2024-10-24 13:30:22.009871544 +0000 UTC m=+734.848800272),
2024-10-24T13:30:22.010053345Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:30:22.010053345Z  LastFailedCount: (int) 1,
2024-10-24T13:30:22.010053345Z  LastFallbackCount: (int) 0,
2024-10-24T13:30:22.010053345Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:30:22.010053345Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:30:22.010053345Z  }
2024-10-24T13:30:22.010053345Z }
2024-10-24T13:30:22.010053345Z  because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:22.010053345Z W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:22.010053345Z W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:22.010053345Z W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:22.010053345Z W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:22.010053345Z W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:22.010053345Z W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:22.010053345Z F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:30:22.010053345Z I1024 13:30:22.010002       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:22.010053345Z W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:22.010053345Z W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:22.010053345Z W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:22.010053345Z W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:22.010053345Z W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:22.010053345Z W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:22.010053345Z F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:30:22.046395014Z I1024 13:30:22.046330       1 helpers.go:260] lister was stale at resourceVersion=28836, live get showed resourceVersion=30455
2024-10-24T13:30:22.801964849Z I1024 13:30:22.801886       1 request.go:700] Waited for 1.192754362s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:30:23.006639408Z I1024 13:30:23.006567       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:24.001676282Z I1024 13:30:24.001624       1 request.go:700] Waited for 1.192362153s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:24.210360431Z I1024 13:30:24.210293       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:30:24.210360431Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:30:24.210360431Z  CurrentRevision: (int32) 0,
2024-10-24T13:30:24.210360431Z  TargetRevision: (int32) 7,
2024-10-24T13:30:24.210360431Z  LastFailedRevision: (int32) 7,
2024-10-24T13:30:24.210360431Z  LastFailedTime: (*v1.Time)(0xc001f6f650)(2024-10-24 13:30:24.210219941 +0000 UTC m=+737.049148669),
2024-10-24T13:30:24.210360431Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:30:24.210360431Z  LastFailedCount: (int) 1,
2024-10-24T13:30:24.210360431Z  LastFallbackCount: (int) 0,
2024-10-24T13:30:24.210360431Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:30:24.210360431Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:30:24.210360431Z  }
2024-10-24T13:30:24.210360431Z }
2024-10-24T13:30:24.210360431Z  because installer pod failed: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:24.210360431Z W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:24.210360431Z W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:24.210360431Z W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:24.210360431Z W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:24.210360431Z W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:24.210360431Z W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:24.210360431Z F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:30:24.210437951Z I1024 13:30:24.210343       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:24.210437951Z W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:24.210437951Z W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:24.210437951Z W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:24.210437951Z W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:24.210437951Z W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:24.210437951Z W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:30:24.210437951Z F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:30:24.252737100Z I1024 13:30:24.252686       1 helpers.go:260] lister was stale at resourceVersion=28836, live get showed resourceVersion=30729
2024-10-24T13:30:25.009965125Z E1024 13:30:25.009914       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:25.010849925Z E1024 13:30:25.010801       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:30:26.218151148Z I1024 13:30:26.218092       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:26.759604344Z I1024 13:30:26.759553       1 reflector.go:368] Caches populated for *v1.Role from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:27.183685172Z I1024 13:30:27.183630       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubeschedulers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:27.185025242Z I1024 13:30:27.184972       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:30:27.199189581Z I1024 13:30:27.197464       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2" to "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: "
2024-10-24T13:30:29.610386826Z I1024 13:30:29.610313       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:30:29.618683396Z E1024 13:30:29.618615       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:30:29.620510176Z I1024 13:30:29.620452       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:30:29.630486056Z E1024 13:30:29.630302       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:30:29.632292876Z I1024 13:30:29.632240       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:30:29.643260016Z E1024 13:30:29.643226       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:30:29.644864996Z I1024 13:30:29.644825       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:30:29.653993456Z E1024 13:30:29.653950       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:30:29.666122106Z I1024 13:30:29.666064       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:30:29.675059856Z E1024 13:30:29.675031       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:30:29.756996856Z I1024 13:30:29.756930       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:30:29.765706415Z E1024 13:30:29.765632       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:30:29.808840085Z I1024 13:30:29.808787       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:29.927888334Z I1024 13:30:29.927820       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:30:29.941580854Z E1024 13:30:29.941527       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:30:30.264541162Z I1024 13:30:30.264456       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:30:30.274675272Z E1024 13:30:30.274616       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:30:30.917579998Z I1024 13:30:30.917518       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:30:30.927335228Z E1024 13:30:30.927307       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:30:31.338261625Z E1024 13:30:31.338180       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:32.209478810Z I1024 13:30:32.209421       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:30:32.219115420Z E1024 13:30:32.219082       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:30:32.404271988Z I1024 13:30:32.404216       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:33.210857083Z E1024 13:30:33.210799       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:30:34.781043214Z I1024 13:30:34.780981       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:30:34.790963533Z E1024 13:30:34.790903       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:30:35.722695878Z I1024 13:30:35.722644       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:39.041565376Z I1024 13:30:39.041507       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-7-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-scheduler because it was missing
2024-10-24T13:30:39.051056396Z I1024 13:30:39.051007       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:30:39.409998844Z I1024 13:30:39.409916       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:30:40.010937030Z E1024 13:30:40.010869       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:40.011997710Z E1024 13:30:40.011957       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:30:41.011523444Z I1024 13:30:41.011466       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:30:42.411037745Z I1024 13:30:42.410968       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:30:42.810314102Z E1024 13:30:42.810256       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:42.811269812Z E1024 13:30:42.811227       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:30:44.010894334Z E1024 13:30:44.010740       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:44.011740644Z E1024 13:30:44.011667       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:30:44.811555149Z E1024 13:30:44.811489       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:44.812340810Z E1024 13:30:44.812305       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:30:48.865708514Z E1024 13:30:48.865616       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:48.866800974Z E1024 13:30:48.866738       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:30:52.444896751Z I1024 13:30:52.444837       1 reflector.go:368] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:52.584992740Z E1024 13:30:52.584945       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:30:52.654090540Z E1024 13:30:52.654035       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:31:04.988463680Z E1024 13:31:04.988403       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:04.989382090Z E1024 13:31:04.989338       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:31:09.443015721Z E1024 13:31:09.442972       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:09.480840231Z E1024 13:31:09.480792       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:31:11.499127648Z I1024 13:31:11.499070       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:31:11.506006788Z E1024 13:31:11.505940       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:11.506907928Z E1024 13:31:11.506881       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:31:12.740542470Z E1024 13:31:12.740469       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:13.489729695Z I1024 13:31:13.489677       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 6
2024-10-24T13:31:13.690276734Z E1024 13:31:13.690217       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:31:15.221157675Z E1024 13:31:15.221112       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:15.222193255Z E1024 13:31:15.222159       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:31:19.638125786Z E1024 13:31:19.638071       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:19.639388386Z E1024 13:31:19.639358       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:31:23.572134431Z I1024 13:31:23.572071       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 6
2024-10-24T13:31:24.170136807Z E1024 13:31:24.170071       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:24.170992517Z E1024 13:31:24.170946       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:31:26.570939692Z I1024 13:31:26.570861       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 7, but has not made progress because static pod is pending
2024-10-24T13:31:27.170500728Z E1024 13:31:27.170440       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:27.171554188Z E1024 13:31:27.171505       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:31:28.970905067Z I1024 13:31:28.970835       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 7, but has not made progress because static pod is pending
2024-10-24T13:31:29.970151160Z E1024 13:31:29.970082       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:29.971186090Z E1024 13:31:29.971147       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:31:30.771515815Z I1024 13:31:30.771454       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 7, but has not made progress because static pod is pending
2024-10-24T13:31:30.970470503Z E1024 13:31:30.970410       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:31.372179017Z E1024 13:31:31.372077       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:31:46.107408787Z E1024 13:31:46.107281       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:46.108904757Z E1024 13:31:46.108352       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:31:56.127020355Z E1024 13:31:56.126969       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:31:56.163698435Z E1024 13:31:56.163616       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:32:14.391551974Z I1024 13:32:14.391491       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:32:14.391551974Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:32:14.391551974Z  CurrentRevision: (int32) 7,
2024-10-24T13:32:14.391551974Z  TargetRevision: (int32) 0,
2024-10-24T13:32:14.391551974Z  LastFailedRevision: (int32) 7,
2024-10-24T13:32:14.391551974Z  LastFailedTime: (*v1.Time)(0xc001a98cf0)(2024-10-24 13:30:24 +0000 UTC),
2024-10-24T13:32:14.391551974Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:32:14.391551974Z  LastFailedCount: (int) 1,
2024-10-24T13:32:14.391551974Z  LastFallbackCount: (int) 0,
2024-10-24T13:32:14.391551974Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:32:14.391551974Z   (string) (len=2059) "installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:32:14.391551974Z  }
2024-10-24T13:32:14.391551974Z }
2024-10-24T13:32:14.391551974Z  because static pod is ready
2024-10-24T13:32:14.413310634Z I1024 13:32:14.413252       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 0 to 7 because static pod is ready
2024-10-24T13:32:14.419427284Z I1024 13:32:14.419373       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:32:14.439125424Z I1024 13:32:14.438982       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:    1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:16.272374       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:26.271495       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:36.271836       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:46.272336       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.271500       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:56.272431       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:27:56.272470       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: " to "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2",Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7" to "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7",Available message changed from "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 6; 0 nodes have achieved new revision 7" to "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7"
2024-10-24T13:32:14.576656392Z E1024 13:32:14.576590       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:32:14.577471342Z E1024 13:32:14.577445       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:32:15.571325947Z I1024 13:32:15.571258       1 request.go:700] Waited for 1.152578723s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler
2024-10-24T13:32:17.176638565Z I1024 13:32:17.176576       1 installer_controller.go:534] node ci-op-2fcpj5j6-f6035-2lklf-master-2 static pod not found and needs new revision 7
2024-10-24T13:32:17.176695124Z I1024 13:32:17.176634       1 installer_controller.go:542] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:32:17.176695124Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:32:17.176695124Z  CurrentRevision: (int32) 0,
2024-10-24T13:32:17.176695124Z  TargetRevision: (int32) 7,
2024-10-24T13:32:17.176695124Z  LastFailedRevision: (int32) 0,
2024-10-24T13:32:17.176695124Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:32:17.176695124Z  LastFailedReason: (string) "",
2024-10-24T13:32:17.176695124Z  LastFailedCount: (int) 0,
2024-10-24T13:32:17.176695124Z  LastFallbackCount: (int) 0,
2024-10-24T13:32:17.176695124Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:32:17.176695124Z }
2024-10-24T13:32:17.199866484Z I1024 13:32:17.199800       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 0 to 7 because node ci-op-2fcpj5j6-f6035-2lklf-master-2 static pod not found
2024-10-24T13:32:18.373919787Z I1024 13:32:18.373856       1 request.go:700] Waited for 1.173049233s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:32:19.401676883Z I1024 13:32:19.401601       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-scheduler because it was missing
2024-10-24T13:32:20.571050236Z I1024 13:32:20.570980       1 request.go:700] Waited for 1.170615653s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:32:20.777545623Z I1024 13:32:20.777502       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:32:21.571600812Z I1024 13:32:21.571525       1 request.go:700] Waited for 1.39391239s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:32:22.571627698Z I1024 13:32:22.571570       1 request.go:700] Waited for 1.591269418s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/kube-scheduler-pod
2024-10-24T13:32:23.576789603Z I1024 13:32:23.576692       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:32:23.771416150Z I1024 13:32:23.771352       1 request.go:700] Waited for 1.194080612s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config
2024-10-24T13:32:24.385205521Z E1024 13:32:24.385130       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:32:24.386267052Z E1024 13:32:24.386236       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:32:25.577279735Z I1024 13:32:25.577220       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:32:26.377645593Z E1024 13:32:26.377579       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:32:26.973045535Z E1024 13:32:26.972975       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:27.174019992Z W1024 13:32:27.173954       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:27.174019992Z E1024 13:32:27.174009       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:32:27.574354217Z E1024 13:32:27.574295       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:27.973394621Z E1024 13:32:27.973343       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:28.974526177Z E1024 13:32:28.974466       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:29.976446902Z E1024 13:32:29.976393       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:30.773724601Z E1024 13:32:30.773652       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:30.973233438Z E1024 13:32:30.973182       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:32.375270488Z E1024 13:32:32.375211       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:32.573347835Z E1024 13:32:32.573295       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:33.972764856Z E1024 13:32:33.972686       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:34.373024380Z E1024 13:32:34.372957       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:34.774210784Z E1024 13:32:34.774136       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:36.173324245Z E1024 13:32:36.173264       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:36.899111504Z E1024 13:32:36.899042       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:32:36.900436784Z E1024 13:32:36.900397       1 leaderelection.go:436] error retrieving resource lock openshift-kube-scheduler-operator/openshift-cluster-kube-scheduler-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler-operator/leases/openshift-cluster-kube-scheduler-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:36.972673443Z E1024 13:32:36.972615       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:37.173514720Z E1024 13:32:37.173462       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:37.973624239Z E1024 13:32:37.973571       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:39.574221826Z E1024 13:32:39.574162       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:39.772668783Z E1024 13:32:39.772602       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:39.974273500Z E1024 13:32:39.974193       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:41.574625618Z E1024 13:32:41.574563       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:42.173197169Z E1024 13:32:42.173133       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:42.573851954Z E1024 13:32:42.573796       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:43.574423300Z E1024 13:32:43.574368       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:44.573166675Z E1024 13:32:44.573094       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:44.973195219Z E1024 13:32:44.973134       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:45.973740995Z E1024 13:32:45.973680       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:46.574602187Z E1024 13:32:46.574545       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:48.418048141Z E1024 13:32:48.417987       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: synthetic requeue request"
2024-10-24T13:32:49.224253079Z E1024 13:32:49.224191       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:33:01.959184388Z I1024 13:33:01.959108       1 reflector.go:368] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:04.434266963Z I1024 13:33:04.434194       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:05.201335832Z I1024 13:33:05.201274       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:07.235857233Z I1024 13:33:07.235703       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:10.413673758Z I1024 13:33:10.413612       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:11.026827309Z I1024 13:33:11.026737       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:29.404486968Z I1024 13:33:29.404433       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:29.412296588Z I1024 13:33:29.412245       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:29.801338052Z I1024 13:33:29.801293       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 7, but has not made progress because static pod is pending
2024-10-24T13:33:30.598480121Z I1024 13:33:30.598418       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:30.720451010Z I1024 13:33:30.720390       1 reflector.go:368] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:32.405604785Z I1024 13:33:32.405543       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 7, but has not made progress because static pod is pending
2024-10-24T13:33:33.201118464Z I1024 13:33:33.201050       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:33.401210661Z I1024 13:33:33.401158       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:35.013879578Z I1024 13:33:35.013000       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:35.804710877Z E1024 13:33:35.804592       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:33:35.805595197Z E1024 13:33:35.805541       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:33:36.798379513Z I1024 13:33:36.798325       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:37.400395785Z I1024 13:33:37.400327       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:37.747374720Z I1024 13:33:37.747303       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:38.002631106Z E1024 13:33:38.002550       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:33:38.003643836Z E1024 13:33:38.003609       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:33:38.335086902Z I1024 13:33:38.335036       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:39.199946439Z I1024 13:33:39.199887       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:40.401535942Z I1024 13:33:40.401484       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:42.132571578Z I1024 13:33:42.132507       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:42.203705476Z E1024 13:33:42.203632       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:33:43.033672515Z I1024 13:33:43.033621       1 reflector.go:368] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:43.203051592Z I1024 13:33:43.202991       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 7, but has not made progress because static pod is pending
2024-10-24T13:33:43.608061676Z I1024 13:33:43.607998       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:43.806807444Z E1024 13:33:43.806703       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:33:44.040907780Z I1024 13:33:44.040833       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:44.196624258Z I1024 13:33:44.196572       1 request.go:700] Waited for 1.161736304s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler
2024-10-24T13:33:45.063869935Z I1024 13:33:45.061908       1 reflector.go:368] Caches populated for *v1.Role from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:45.196856914Z I1024 13:33:45.196618       1 request.go:700] Waited for 1.183578453s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa
2024-10-24T13:33:46.199195470Z I1024 13:33:46.199132       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:46.612799774Z I1024 13:33:46.612703       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 7, but has not made progress because static pod is pending
2024-10-24T13:33:47.031697828Z I1024 13:33:47.031642       1 reflector.go:368] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:47.946222054Z I1024 13:33:47.946162       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:48.409151128Z W1024 13:33:48.409092       1 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
2024-10-24T13:33:48.409382708Z I1024 13:33:48.409312       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-scheduler because it was missing
2024-10-24T13:33:49.596107961Z I1024 13:33:49.596040       1 request.go:700] Waited for 1.186537623s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:33:50.201040282Z I1024 13:33:50.200985       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:50.596127267Z I1024 13:33:50.596073       1 request.go:700] Waited for 1.365887711s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller
2024-10-24T13:33:51.003024191Z W1024 13:33:51.002968       1 dynamic_operator_client.go:355] .status.conditions["GuardControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:33:51.570926653Z I1024 13:33:51.570861       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubeschedulers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:51.571823403Z I1024 13:33:51.571777       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:33:51Z","message":"NodeControllerDegraded: All master nodes are ready\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/serviceaccount-ca\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/serviceaccount-ca\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/scheduler-kubeconfig\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/scheduler-kubeconfig\": dial tcp 172.30.0.1:443: connect: connection refused","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:51.589143613Z I1024 13:33:51.587446       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded changed from True to False ("NodeControllerDegraded: All master nodes are ready\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/serviceaccount-ca\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/serviceaccount-ca\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/scheduler-kubeconfig\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/scheduler-kubeconfig\": dial tcp 172.30.0.1:443: connect: connection refused")
2024-10-24T13:33:51.596609653Z I1024 13:33:51.596574       1 request.go:700] Waited for 1.189174783s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:33:51.602826353Z I1024 13:33:51.602786       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:33:51Z","message":"NodeControllerDegraded: All master nodes are ready\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/serviceaccount-ca\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/serviceaccount-ca\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/scheduler-kubeconfig\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/scheduler-kubeconfig\": dial tcp 172.30.0.1:443: connect: connection refused","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:51.609973942Z E1024 13:33:51.609907       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:51.611609862Z I1024 13:33:51.611568       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:33:51Z","message":"NodeControllerDegraded: All master nodes are ready\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/serviceaccount-ca\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/serviceaccount-ca\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/scheduler-kubeconfig\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/scheduler-kubeconfig\": dial tcp 172.30.0.1:443: connect: connection refused","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:51.618808162Z E1024 13:33:51.618682       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:51.620395552Z I1024 13:33:51.620341       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:33:51Z","message":"NodeControllerDegraded: All master nodes are ready\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/serviceaccount-ca\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/serviceaccount-ca\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/scheduler-kubeconfig\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/scheduler-kubeconfig\": dial tcp 172.30.0.1:443: connect: connection refused","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:51.631370712Z E1024 13:33:51.631340       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:51.633275552Z I1024 13:33:51.633197       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:33:51Z","message":"NodeControllerDegraded: All master nodes are ready\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/serviceaccount-ca\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/serviceaccount-ca\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/scheduler-kubeconfig\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/scheduler-kubeconfig\": dial tcp 172.30.0.1:443: connect: connection refused","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:51.644494302Z E1024 13:33:51.644458       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:51.653597062Z I1024 13:33:51.653555       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:33:51Z","message":"NodeControllerDegraded: All master nodes are ready\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/serviceaccount-ca\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/serviceaccount-ca\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/scheduler-kubeconfig\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/scheduler-kubeconfig\": dial tcp 172.30.0.1:443: connect: connection refused","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:51.660423692Z E1024 13:33:51.660387       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:51.742297281Z I1024 13:33:51.742238       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:33:51Z","message":"NodeControllerDegraded: All master nodes are ready\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/serviceaccount-ca\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/serviceaccount-ca\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/scheduler-kubeconfig\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/scheduler-kubeconfig\": dial tcp 172.30.0.1:443: connect: connection refused","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:51.749231321Z E1024 13:33:51.749175       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:51.911718308Z I1024 13:33:51.911659       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:33:51Z","message":"NodeControllerDegraded: All master nodes are ready\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/serviceaccount-ca\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/serviceaccount-ca\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/scheduler-kubeconfig\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/scheduler-kubeconfig\": dial tcp 172.30.0.1:443: connect: connection refused","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:51.922182068Z E1024 13:33:51.922127       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:52.005892187Z I1024 13:33:52.005817       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 7, but has not made progress because static pod is pending
2024-10-24T13:33:52.247813623Z I1024 13:33:52.246470       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:33:52Z","message":"NodeControllerDegraded: All master nodes are ready\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/serviceaccount-ca\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/serviceaccount-ca\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/scheduler-kubeconfig\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/scheduler-kubeconfig\": dial tcp 172.30.0.1:443: connect: connection refused","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:52.261656093Z E1024 13:33:52.261341       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:52.795971096Z I1024 13:33:52.795908       1 request.go:700] Waited for 1.224449872s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa
2024-10-24T13:33:52.904902644Z I1024 13:33:52.904836       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:33:52Z","message":"NodeControllerDegraded: All master nodes are ready\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/serviceaccount-ca\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/serviceaccount-ca\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/scheduler-kubeconfig\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/scheduler-kubeconfig\": dial tcp 172.30.0.1:443: connect: connection refused","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:52.912122954Z E1024 13:33:52.912078       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:53.796593571Z I1024 13:33:53.796534       1 request.go:700] Waited for 1.39185925s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/kube-scheduler-pod
2024-10-24T13:33:53.832482941Z I1024 13:33:53.832371       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:33:53Z","message":"NodeControllerDegraded: All master nodes are ready\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: ","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:53.845133991Z E1024 13:33:53.845054       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:54.193966166Z I1024 13:33:54.193909       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:33:54Z","message":"NodeControllerDegraded: All master nodes are ready\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: ","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:54.201644405Z E1024 13:33:54.201585       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-scheduler reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-scheduler\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:54.995846964Z I1024 13:33:54.995740       1 request.go:700] Waited for 1.164507313s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config
2024-10-24T13:33:55.403619769Z I1024 13:33:55.403540       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:55.404274489Z I1024 13:33:55.404230       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:33:51Z","message":"NodeControllerDegraded: All master nodes are ready\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: ","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:55.417992008Z I1024 13:33:55.417927       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/serviceaccount-ca\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/serviceaccount-ca\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"serviceaccount/localhost-recovery-client\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused\nTargetConfigControllerDegraded: \"configmap/scheduler-kubeconfig\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/scheduler-kubeconfig\": dial tcp 172.30.0.1:443: connect: connection refused" to "NodeControllerDegraded: All master nodes are ready\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: "
2024-10-24T13:33:55.995887890Z I1024 13:33:55.995831       1 request.go:700] Waited for 1.39087241s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:33:56.002207480Z I1024 13:33:56.002159       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 7, but has not made progress because static pod is pending
2024-10-24T13:33:56.606989361Z W1024 13:33:56.606937       1 dynamic_operator_client.go:355] .status.conditions["KubeControllerManagerStaticResourcesDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:33:56.633534171Z I1024 13:33:56.633487       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:33:51Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:56.648671761Z I1024 13:33:56.648628       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-scheduler\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/scheduler-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-scheduler:public-2\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/roles/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-scheduler/policyconfigmap-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-scheduler/rolebindings/system:openshift:sa-listing-configmaps\": dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded: " to "NodeControllerDegraded: All master nodes are ready"
2024-10-24T13:33:56.996044906Z I1024 13:33:56.995986       1 request.go:700] Waited for 1.190389243s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:33:58.196704259Z I1024 13:33:58.196645       1 request.go:700] Waited for 1.39374075s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/revision-pruner-7-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:33:58.806576270Z I1024 13:33:58.806501       1 core.go:220] Pod "openshift-kube-scheduler/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2" changes: {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{"k8s.ovn.org/pod-networks":null,"k8s.v1.cni.cncf.io/network-status":null,"target.workload.openshift.io/management":"{\"effect\": \"PreferredDuringScheduling\"}"},"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null},"spec":{"containers":[{"args":["-c","# properly handle TERM and exit as soon as it is signaled\nset -euo pipefail\ntrap 'jobs -p | xargs -r kill; exit 0' TERM\nsleep infinity \u0026 wait\n"],"command":["/bin/bash"],"image":"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:7f1ef4ec397a7c90b5c3c5f9235d635ab8818ca402ce8de9bade295053038571","imagePullPolicy":"IfNotPresent","name":"guard","readinessProbe":{"failureThreshold":3,"httpGet":{"host":"10.0.0.6","path":"healthz","port":10259,"scheme":"HTTPS"},"periodSeconds":5,"successThreshold":1,"timeoutSeconds":5},"resources":{"requests":{"cpu":"10m","memory":"5Mi"}},"terminationMessagePolicy":"FallbackToLogsOnError"}],"dnsPolicy":null,"enableServiceLinks":null,"imagePullSecrets":null,"preemptionPolicy":null,"priority":null,"restartPolicy":null,"schedulerName":null,"securityContext":null,"serviceAccount":null,"serviceAccountName":null,"volumes":null},"status":{"conditions":null,"containerStatuses":null,"hostIP":null,"hostIPs":null,"phase":null,"podIP":null,"podIPs":null,"qosClass":null,"startTime":null}}
2024-10-24T13:33:59.396735262Z I1024 13:33:59.396678       1 request.go:700] Waited for 1.193465562s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/revision-pruner-7-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:33:59.804684696Z I1024 13:33:59.804601       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 7, but has not made progress because static pod is pending
2024-10-24T13:34:00.010481622Z I1024 13:34:00.010395       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-scheduler because it changed
2024-10-24T13:34:00.595996884Z I1024 13:34:00.595920       1 request.go:700] Waited for 1.191200063s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/revision-pruner-7-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:34:01.796006487Z I1024 13:34:01.795934       1 request.go:700] Waited for 1.386823621s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client
2024-10-24T13:34:02.796065643Z I1024 13:34:02.796012       1 request.go:700] Waited for 1.191010313s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/kube-scheduler-pod
2024-10-24T13:34:03.602403022Z I1024 13:34:03.602335       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 7, but has not made progress because static pod is pending
2024-10-24T13:34:03.796706519Z I1024 13:34:03.796640       1 request.go:700] Waited for 1.189401053s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:34:06.605082459Z I1024 13:34:06.605012       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 7, but has not made progress because static pod is pending
2024-10-24T13:34:12.105405240Z I1024 13:34:12.105336       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:34:12.105405240Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:34:12.105405240Z  CurrentRevision: (int32) 7,
2024-10-24T13:34:12.105405240Z  TargetRevision: (int32) 0,
2024-10-24T13:34:12.105405240Z  LastFailedRevision: (int32) 0,
2024-10-24T13:34:12.105405240Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:34:12.105405240Z  LastFailedReason: (string) "",
2024-10-24T13:34:12.105405240Z  LastFailedCount: (int) 0,
2024-10-24T13:34:12.105405240Z  LastFallbackCount: (int) 0,
2024-10-24T13:34:12.105405240Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:34:12.105405240Z }
2024-10-24T13:34:12.105405240Z  because static pod is ready
2024-10-24T13:34:12.131274670Z I1024 13:34:12.131229       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:33:51Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:50Z","message":"NodeInstallerProgressing: 1 node is at revision 6; 2 nodes are at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 6; 2 nodes are at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:34:12.131517910Z I1024 13:34:12.131478       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 0 to 7 because static pod is ready
2024-10-24T13:34:12.147179830Z I1024 13:34:12.147085       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7" to "NodeInstallerProgressing: 1 node is at revision 6; 2 nodes are at revision 7",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 6; 1 node is at revision 7" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 6; 2 nodes are at revision 7"
2024-10-24T13:34:13.269495994Z I1024 13:34:13.269418       1 request.go:700] Waited for 1.137316294s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler
2024-10-24T13:34:14.269697420Z I1024 13:34:14.269634       1 request.go:700] Waited for 1.193287013s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/revision-pruner-7-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:34:15.469654783Z I1024 13:34:15.469590       1 request.go:700] Waited for 1.190950223s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/revision-pruner-7-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:34:17.677873381Z I1024 13:34:17.677818       1 installer_controller.go:534] node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 6 is the oldest and needs new revision 7
2024-10-24T13:34:17.677927481Z I1024 13:34:17.677917       1 installer_controller.go:542] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:34:17.677927481Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:34:17.677927481Z  CurrentRevision: (int32) 6,
2024-10-24T13:34:17.677927481Z  TargetRevision: (int32) 7,
2024-10-24T13:34:17.677927481Z  LastFailedRevision: (int32) 6,
2024-10-24T13:34:17.677927481Z  LastFailedTime: (*v1.Time)(0xc0015e4c00)(2024-10-24 13:21:24 +0000 UTC),
2024-10-24T13:34:17.677927481Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:34:17.677927481Z  LastFailedCount: (int) 2,
2024-10-24T13:34:17.677927481Z  LastFallbackCount: (int) 0,
2024-10-24T13:34:17.677927481Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:34:17.677927481Z   (string) (len=2059) "installer: refixes: ([]string) (len=1 cap=1) {\n  (string) (len=12) \"serving-cert\"\n },\n ConfigMapNamePrefixes: ([]string) (len=5 cap=8) {\n  (string) (len=18) \"kube-scheduler-pod\",\n  (string) (len=6) \"config\",\n  (string) (len=17) \"serviceaccount-ca\",\n  (string) (len=20) \"scheduler-kubeconfig\",\n  (string) (len=37) \"kube-scheduler-cert-syncer-kubeconfig\"\n },\n OptionalConfigMapNamePrefixes: ([]string) (len=1 cap=1) {\n  (string) (len=16) \"policy-configmap\"\n },\n CertSecretNames: ([]string) (len=1 cap=1) {\n  (string) (len=30) \"kube-scheduler-client-cert-key\"\n },\n OptionalCertSecretNamePrefixes: ([]string) <nil>,\n CertConfigMapNamePrefixes: ([]string) <nil>,\n OptionalCertConfigMapNamePrefixes: ([]string) <nil>,\n CertDir: (string) (len=57) \"/etc/kubernetes/static-pod-resources/kube-scheduler-certs\",\n ResourceDir: (string) (len=36) \"/etc/kubernetes/static-pod-resources\",\n PodManifestDir: (string) (len=25) \"/etc/kubernetes/manifests\",\n Timeout: (time.Duration) 2m0s,\n StaticPodManifestsLockFile: (string) \"\",\n PodMutationFns: ([]installerpod.PodMutationFunc) <nil>,\n KubeletVersion: (string) \"\"\n})\nI1024 13:15:40.605843       1 cmd.go:409] Getting controller reference for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nI1024 13:15:40.620880       1 cmd.go:422] Waiting for installer revisions to settle for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nI1024 13:15:40.621111       1 envvar.go:172] \"Feature gate default state\" feature=\"WatchListClient\" enabled=false\nI1024 13:15:40.621191       1 envvar.go:172] \"Feature gate default state\" feature=\"InformerResourceVersion\" enabled=false\nI1024 13:15:40.629965       1 cmd.go:514] Waiting additional period after revisions have settled for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nI1024 13:16:10.632243       1 cmd.go:520] Getting installer pods for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nF1024 13:16:24.639340       1 cmd.go:105] Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\n"
2024-10-24T13:34:17.677927481Z  }
2024-10-24T13:34:17.677927481Z }
2024-10-24T13:34:17.703801901Z I1024 13:34:17.703715       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 6 to 7 because node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 6 is the oldest
2024-10-24T13:34:18.868899075Z I1024 13:34:18.868837       1 request.go:700] Waited for 1.160235553s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:34:19.869477850Z I1024 13:34:19.869415       1 request.go:700] Waited for 1.39116885s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:34:20.096852007Z I1024 13:34:20.096768       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-scheduler because it was missing
2024-10-24T13:34:20.869789956Z I1024 13:34:20.869721       1 request.go:700] Waited for 1.195265063s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa
2024-10-24T13:34:21.477789707Z I1024 13:34:21.477697       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:34:22.069142509Z I1024 13:34:22.069080       1 request.go:700] Waited for 1.39164033s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:34:23.069211185Z I1024 13:34:23.069156       1 request.go:700] Waited for 1.590571818s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:34:24.076957910Z I1024 13:34:24.076902       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:34:53.350225014Z I1024 13:34:53.350142       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:34:56.540246949Z I1024 13:34:56.540198       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 6
2024-10-24T13:35:05.301953434Z I1024 13:35:05.301901       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 7, but has not made progress because static pod is pending
2024-10-24T13:35:07.701883310Z I1024 13:35:07.701817       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 7, but has not made progress because static pod is pending
2024-10-24T13:35:09.699538051Z I1024 13:35:09.699465       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 7, but has not made progress because static pod is pending
2024-10-24T13:35:11.699538573Z I1024 13:35:11.699477       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 7, but has not made progress because static pod is pending
2024-10-24T13:35:55.336467826Z I1024 13:35:55.336417       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:35:55.336467826Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:35:55.336467826Z  CurrentRevision: (int32) 7,
2024-10-24T13:35:55.336467826Z  TargetRevision: (int32) 0,
2024-10-24T13:35:55.336467826Z  LastFailedRevision: (int32) 6,
2024-10-24T13:35:55.336467826Z  LastFailedTime: (*v1.Time)(0xc001dc2810)(2024-10-24 13:21:24 +0000 UTC),
2024-10-24T13:35:55.336467826Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:35:55.336467826Z  LastFailedCount: (int) 2,
2024-10-24T13:35:55.336467826Z  LastFallbackCount: (int) 0,
2024-10-24T13:35:55.336467826Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:35:55.336467826Z   (string) (len=2059) "installer: refixes: ([]string) (len=1 cap=1) {\n  (string) (len=12) \"serving-cert\"\n },\n ConfigMapNamePrefixes: ([]string) (len=5 cap=8) {\n  (string) (len=18) \"kube-scheduler-pod\",\n  (string) (len=6) \"config\",\n  (string) (len=17) \"serviceaccount-ca\",\n  (string) (len=20) \"scheduler-kubeconfig\",\n  (string) (len=37) \"kube-scheduler-cert-syncer-kubeconfig\"\n },\n OptionalConfigMapNamePrefixes: ([]string) (len=1 cap=1) {\n  (string) (len=16) \"policy-configmap\"\n },\n CertSecretNames: ([]string) (len=1 cap=1) {\n  (string) (len=30) \"kube-scheduler-client-cert-key\"\n },\n OptionalCertSecretNamePrefixes: ([]string) <nil>,\n CertConfigMapNamePrefixes: ([]string) <nil>,\n OptionalCertConfigMapNamePrefixes: ([]string) <nil>,\n CertDir: (string) (len=57) \"/etc/kubernetes/static-pod-resources/kube-scheduler-certs\",\n ResourceDir: (string) (len=36) \"/etc/kubernetes/static-pod-resources\",\n PodManifestDir: (string) (len=25) \"/etc/kubernetes/manifests\",\n Timeout: (time.Duration) 2m0s,\n StaticPodManifestsLockFile: (string) \"\",\n PodMutationFns: ([]installerpod.PodMutationFunc) <nil>,\n KubeletVersion: (string) \"\"\n})\nI1024 13:15:40.605843       1 cmd.go:409] Getting controller reference for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nI1024 13:15:40.620880       1 cmd.go:422] Waiting for installer revisions to settle for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nI1024 13:15:40.621111       1 envvar.go:172] \"Feature gate default state\" feature=\"WatchListClient\" enabled=false\nI1024 13:15:40.621191       1 envvar.go:172] \"Feature gate default state\" feature=\"InformerResourceVersion\" enabled=false\nI1024 13:15:40.629965       1 cmd.go:514] Waiting additional period after revisions have settled for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nI1024 13:16:10.632243       1 cmd.go:520] Getting installer pods for node ci-op-2fcpj5j6-f6035-2lklf-master-0\nF1024 13:16:24.639340       1 cmd.go:105] Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods?labelSelector=app%3Dinstaller\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)\n"
2024-10-24T13:35:55.336467826Z  }
2024-10-24T13:35:55.336467826Z }
2024-10-24T13:35:55.336467826Z  because static pod is ready
2024-10-24T13:35:55.360326446Z I1024 13:35:55.360289       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 6 to 7 because static pod is ready
2024-10-24T13:35:55.363335625Z I1024 13:35:55.363273       1 status_controller.go:225] clusteroperator/kube-scheduler diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:33:51Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:35:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 7","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:23:19Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:35:55.379621164Z I1024 13:35:55.376794       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-scheduler-operator", Name:"openshift-kube-scheduler-operator", UID:"ee0262f0-84a4-48db-83ef-ab7bfbcc1cf5", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-scheduler changed: Progressing changed from True to False ("NodeInstallerProgressing: 3 nodes are at revision 7"),Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 6; 2 nodes are at revision 7" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 7"
2024-10-24T13:35:56.505078505Z I1024 13:35:56.505009       1 request.go:700] Waited for 1.14014593s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa
2024-10-24T13:35:57.505309101Z I1024 13:35:57.505254       1 request.go:700] Waited for 1.392353429s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/revision-pruner-7-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:35:58.505610807Z I1024 13:35:58.505547       1 request.go:700] Waited for 1.192315128s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa
2024-10-24T13:43:44.209143573Z I1024 13:43:44.207686       1 request.go:700] Waited for 1.172081776s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler
2024-10-24T13:43:45.407417579Z I1024 13:43:45.407337       1 request.go:700] Waited for 1.160068047s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler
2024-10-24T13:46:21.803734689Z I1024 13:46:21.802279       1 tlsconfig.go:181] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"admin-kubeconfig-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:31 +0000 UTC to 2034-10-22 12:49:31 +0000 UTC (now=2024-10-24 13:46:21.802226009 +0000 UTC))"
2024-10-24T13:46:21.803734689Z I1024 13:46:21.802366       1 tlsconfig.go:181] "Loaded client CA" index=1 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2024-10-25 12:49:34 +0000 UTC (now=2024-10-24 13:46:21.802311789 +0000 UTC))"
2024-10-24T13:46:21.803734689Z I1024 13:46:21.802388       1 tlsconfig.go:181] "Loaded client CA" index=2 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-control-plane-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2025-10-24 12:49:34 +0000 UTC (now=2024-10-24 13:46:21.802374799 +0000 UTC))"
2024-10-24T13:46:21.803734689Z I1024 13:46:21.802409       1 tlsconfig.go:181] "Loaded client CA" index=3 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-apiserver-to-kubelet-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2025-10-24 12:49:34 +0000 UTC (now=2024-10-24 13:46:21.802395799 +0000 UTC))"
2024-10-24T13:46:21.803734689Z I1024 13:46:21.802426       1 tlsconfig.go:181] "Loaded client CA" index=4 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-bootstrap-kubeconfig-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:32 +0000 UTC to 2034-10-22 12:49:32 +0000 UTC (now=2024-10-24 13:46:21.802414639 +0000 UTC))"
2024-10-24T13:46:21.803734689Z I1024 13:46:21.802445       1 tlsconfig.go:181] "Loaded client CA" index=5 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-csr-signer_@1729775012\" [] issuer=\"kubelet-signer\" (2024-10-24 13:03:31 +0000 UTC to 2024-10-25 12:49:34 +0000 UTC (now=2024-10-24 13:46:21.80243305 +0000 UTC))"
2024-10-24T13:46:21.803734689Z I1024 13:46:21.802463       1 tlsconfig.go:181] "Loaded client CA" index=6 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_node-system-admin-signer@1729775011\" [] issuer=\"<self>\" (2024-10-24 13:03:30 +0000 UTC to 2025-10-24 13:03:31 +0000 UTC (now=2024-10-24 13:46:21.80245053 +0000 UTC))"
2024-10-24T13:46:21.803734689Z I1024 13:46:21.802485       1 tlsconfig.go:181] "Loaded client CA" index=7 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"aggregator-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:32 +0000 UTC to 2024-10-25 12:49:32 +0000 UTC (now=2024-10-24 13:46:21.80247097 +0000 UTC))"
2024-10-24T13:46:21.803734689Z I1024 13:46:21.802507       1 tlsconfig.go:181] "Loaded client CA" index=8 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_aggregator-client-signer@1729777579\" [] issuer=\"<self>\" (2024-10-24 13:46:18 +0000 UTC to 2024-10-25 01:46:19 +0000 UTC (now=2024-10-24 13:46:21.80249179 +0000 UTC))"
2024-10-24T13:46:21.803734689Z I1024 13:46:21.802726       1 tlsconfig.go:203] "Loaded serving cert" certName="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key" certDetail="\"metrics.openshift-kube-scheduler-operator.svc\" [serving] validServingFor=[metrics.openshift-kube-scheduler-operator.svc,metrics.openshift-kube-scheduler-operator.svc.cluster.local] issuer=\"openshift-service-serving-signer@1729775010\" (2024-10-24 13:03:41 +0000 UTC to 2026-10-24 13:03:42 +0000 UTC (now=2024-10-24 13:46:21.802669729 +0000 UTC))"
2024-10-24T13:46:21.807302850Z I1024 13:46:21.807220       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1729775940\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1729775940\" (2024-10-24 12:19:00 +0000 UTC to 2025-10-24 12:19:00 +0000 UTC (now=2024-10-24 13:46:21.807142049 +0000 UTC))"
2024-10-24T13:50:51.574470373Z I1024 13:50:51.574312       1 reflector.go:368] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:50:51.902867330Z I1024 13:50:51.902815       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:50:51.922496670Z I1024 13:50:51.922426       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubeschedulers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:50:52.134372228Z I1024 13:50:52.134307       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:53:44.208328638Z I1024 13:53:44.208248       1 request.go:700] Waited for 1.171880551s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler
2024-10-24T13:53:45.408461480Z I1024 13:53:45.408377       1 request.go:700] Waited for 1.17002814s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler
2024-10-24T13:57:22.648261739Z I1024 13:57:22.648141       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:57:22.669919999Z I1024 13:57:22.669876       1 reflector.go:368] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:57:22.730154241Z I1024 13:57:22.730085       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:57:22.766112552Z I1024 13:57:22.766049       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubeschedulers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:57:23.166197552Z I1024 13:57:23.166138       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:57:23.431163439Z I1024 13:57:23.429911       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:57:23.781043718Z I1024 13:57:23.780981       1 request.go:700] Waited for 1.013526777s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler
2024-10-24T13:57:24.980090050Z I1024 13:57:24.980009       1 request.go:700] Waited for 1.15683965s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler
2024-10-24T13:57:25.980794736Z I1024 13:57:25.980699       1 request.go:700] Waited for 1.194235251s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/revision-pruner-7-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:03:44.209674591Z I1024 14:03:44.209555       1 request.go:700] Waited for 1.172544277s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler
2024-10-24T14:03:45.409132267Z I1024 14:03:45.409060       1 request.go:700] Waited for 1.162930216s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler
2024-10-24T14:04:28.218068282Z I1024 14:04:28.217988       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:04:28.227524002Z I1024 14:04:28.227473       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:04:28.265816852Z I1024 14:04:28.265413       1 reflector.go:368] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:04:29.145079200Z I1024 14:04:29.145007       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:04:30.304950487Z I1024 14:04:30.304851       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:08:21.786832515Z I1024 14:08:21.786740       1 request.go:700] Waited for 1.000166369s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:08:22.787142714Z I1024 14:08:22.787021       1 request.go:700] Waited for 1.3933074s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler
2024-10-24T14:13:26.669795791Z I1024 14:13:26.669712       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:13:27.089232880Z I1024 14:13:27.089170       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:13:27.542884918Z I1024 14:13:27.542796       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubeschedulers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:13:27.581621618Z I1024 14:13:27.581511       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:13:28.221241595Z I1024 14:13:28.221191       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:13:28.221516405Z I1024 14:13:28.221196       1 reflector.go:368] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:23:33.796341804Z I1024 14:23:33.796028       1 request.go:700] Waited for 1.001952106s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client
2024-10-24T14:23:44.185389734Z I1024 14:23:44.185311       1 request.go:700] Waited for 1.146535245s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler
2024-10-24T14:23:45.384609050Z I1024 14:23:45.384525       1 request.go:700] Waited for 1.160900416s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler
2024-10-24T14:29:29.163673060Z I1024 14:29:29.163400       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubeschedulers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:48.528825340Z I1024 14:32:48.528722       1 reflector.go:368] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:48.667329159Z I1024 14:32:48.667129       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:49.092155897Z I1024 14:32:49.092066       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:49.583983303Z I1024 14:32:49.583901       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:49.971009911Z I1024 14:32:49.970925       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:33:44.210095989Z I1024 14:33:44.209971       1 request.go:700] Waited for 1.170575343s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler
2024-10-24T14:33:45.409788422Z I1024 14:33:45.409655       1 request.go:700] Waited for 1.151017832s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler
2024-10-24T14:33:47.210513361Z I1024 14:33:47.210417       1 request.go:700] Waited for 1.005268064s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/configmaps/config
2024-10-24T14:42:19.768579465Z I1024 14:42:19.768503       1 tlsconfig.go:181] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"admin-kubeconfig-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:31 +0000 UTC to 2034-10-22 12:49:31 +0000 UTC (now=2024-10-24 14:42:19.763830555 +0000 UTC))"
2024-10-24T14:42:19.768724525Z I1024 14:42:19.768702       1 tlsconfig.go:181] "Loaded client CA" index=1 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2024-10-25 12:49:34 +0000 UTC (now=2024-10-24 14:42:19.768660475 +0000 UTC))"
2024-10-24T14:42:19.768817624Z I1024 14:42:19.768800       1 tlsconfig.go:181] "Loaded client CA" index=2 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-control-plane-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2025-10-24 12:49:34 +0000 UTC (now=2024-10-24 14:42:19.768773865 +0000 UTC))"
2024-10-24T14:42:19.768912855Z I1024 14:42:19.768894       1 tlsconfig.go:181] "Loaded client CA" index=3 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-apiserver-to-kubelet-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2025-10-24 12:49:34 +0000 UTC (now=2024-10-24 14:42:19.768871655 +0000 UTC))"
2024-10-24T14:42:19.768974725Z I1024 14:42:19.768960       1 tlsconfig.go:181] "Loaded client CA" index=4 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-bootstrap-kubeconfig-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:32 +0000 UTC to 2034-10-22 12:49:32 +0000 UTC (now=2024-10-24 14:42:19.768941285 +0000 UTC))"
2024-10-24T14:42:19.769030695Z I1024 14:42:19.769015       1 tlsconfig.go:181] "Loaded client CA" index=5 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-csr-signer_@1729775012\" [] issuer=\"kubelet-signer\" (2024-10-24 13:03:31 +0000 UTC to 2024-10-25 12:49:34 +0000 UTC (now=2024-10-24 14:42:19.768998155 +0000 UTC))"
2024-10-24T14:42:19.769103605Z I1024 14:42:19.769086       1 tlsconfig.go:181] "Loaded client CA" index=6 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_node-system-admin-signer@1729775011\" [] issuer=\"<self>\" (2024-10-24 13:03:30 +0000 UTC to 2025-10-24 13:03:31 +0000 UTC (now=2024-10-24 14:42:19.769064245 +0000 UTC))"
2024-10-24T14:42:19.769159565Z I1024 14:42:19.769145       1 tlsconfig.go:181] "Loaded client CA" index=7 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"TestUserClientCABundleRootCA_3120422217834922768\" [] issuer=\"<self>\" (2023-10-24 14:42:09 +0000 UTC to 2025-10-24 14:42:09 +0000 UTC (now=2024-10-24 14:42:19.769124914 +0000 UTC))"
2024-10-24T14:42:19.769214405Z I1024 14:42:19.769198       1 tlsconfig.go:181] "Loaded client CA" index=8 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"aggregator-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:32 +0000 UTC to 2024-10-25 12:49:32 +0000 UTC (now=2024-10-24 14:42:19.769182365 +0000 UTC))"
2024-10-24T14:42:19.769275415Z I1024 14:42:19.769261       1 tlsconfig.go:181] "Loaded client CA" index=9 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_aggregator-client-signer@1729777579\" [] issuer=\"<self>\" (2024-10-24 13:46:18 +0000 UTC to 2024-10-25 01:46:19 +0000 UTC (now=2024-10-24 14:42:19.769239945 +0000 UTC))"
2024-10-24T14:42:19.827328794Z I1024 14:42:19.827251       1 tlsconfig.go:203] "Loaded serving cert" certName="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key" certDetail="\"metrics.openshift-kube-scheduler-operator.svc\" [serving] validServingFor=[metrics.openshift-kube-scheduler-operator.svc,metrics.openshift-kube-scheduler-operator.svc.cluster.local] issuer=\"openshift-service-serving-signer@1729775010\" (2024-10-24 13:03:41 +0000 UTC to 2026-10-24 13:03:42 +0000 UTC (now=2024-10-24 14:42:19.827205004 +0000 UTC))"
2024-10-24T14:42:19.827517254Z I1024 14:42:19.827489       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1729775940\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1729775940\" (2024-10-24 12:19:00 +0000 UTC to 2025-10-24 12:19:00 +0000 UTC (now=2024-10-24 14:42:19.827449664 +0000 UTC))"
2024-10-24T14:43:44.080113253Z I1024 14:43:44.079975       1 request.go:700] Waited for 1.039570664s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/installer-sa
2024-10-24T14:43:45.080120927Z I1024 14:43:45.080045       1 request.go:700] Waited for 1.162009733s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/services/scheduler
2024-10-24T14:43:46.279724010Z I1024 14:43:46.279663       1 request.go:700] Waited for 1.189093373s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/openshift-kube-scheduler-sa
2024-10-24T14:43:47.479581733Z I1024 14:43:47.479483       1 request.go:700] Waited for 1.186829793s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts/localhost-recovery-client
