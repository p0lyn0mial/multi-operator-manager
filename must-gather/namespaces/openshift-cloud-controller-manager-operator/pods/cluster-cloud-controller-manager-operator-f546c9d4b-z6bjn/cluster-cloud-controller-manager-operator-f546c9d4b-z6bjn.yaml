---
apiVersion: v1
kind: Pod
metadata:
  annotations:
    kubectl.kubernetes.io/default-container: cluster-cloud-controller-manager
  creationTimestamp: "2024-10-24T13:00:10Z"
  generateName: cluster-cloud-controller-manager-operator-f546c9d4b-
  labels:
    k8s-app: cloud-manager-operator
    pod-template-hash: f546c9d4b
  managedFields:
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:kubectl.kubernetes.io/default-container: {}
          f:target.workload.openshift.io/management: {}
        f:generateName: {}
        f:labels:
          .: {}
          f:k8s-app: {}
          f:pod-template-hash: {}
        f:ownerReferences:
          .: {}
          k:{"uid":"2f0958f2-175e-4bf0-b6ba-c765399e9709"}: {}
      f:spec:
        f:containers:
          k:{"name":"cluster-cloud-controller-manager"}:
            .: {}
            f:command: {}
            f:env:
              .: {}
              k:{"name":"RELEASE_VERSION"}:
                .: {}
                f:name: {}
                f:value: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:ports:
              .: {}
              k:{"containerPort":9257,"protocol":"TCP"}:
                .: {}
                f:containerPort: {}
                f:hostPort: {}
                f:name: {}
                f:protocol: {}
              k:{"containerPort":9259,"protocol":"TCP"}:
                .: {}
                f:containerPort: {}
                f:hostPort: {}
                f:name: {}
                f:protocol: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/etc/cloud-controller-manager-config/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/etc/kubernetes"}:
                .: {}
                f:mountPath: {}
                f:name: {}
                f:readOnly: {}
          k:{"name":"config-sync-controllers"}:
            .: {}
            f:command: {}
            f:env:
              .: {}
              k:{"name":"RELEASE_VERSION"}:
                .: {}
                f:name: {}
                f:value: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:ports:
              .: {}
              k:{"containerPort":9260,"protocol":"TCP"}:
                .: {}
                f:containerPort: {}
                f:hostPort: {}
                f:name: {}
                f:protocol: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/etc/kubernetes"}:
                .: {}
                f:mountPath: {}
                f:name: {}
                f:readOnly: {}
          k:{"name":"kube-rbac-proxy"}:
            .: {}
            f:args: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:ports:
              .: {}
              k:{"containerPort":9258,"protocol":"TCP"}:
                .: {}
                f:containerPort: {}
                f:hostPort: {}
                f:name: {}
                f:protocol: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/etc/kube-rbac-proxy"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/etc/tls/private"}:
                .: {}
                f:mountPath: {}
                f:name: {}
        f:dnsPolicy: {}
        f:enableServiceLinks: {}
        f:hostNetwork: {}
        f:nodeSelector: {}
        f:priorityClassName: {}
        f:restartPolicy: {}
        f:schedulerName: {}
        f:securityContext: {}
        f:serviceAccount: {}
        f:serviceAccountName: {}
        f:terminationGracePeriodSeconds: {}
        f:tolerations: {}
        f:volumes:
          .: {}
          k:{"name":"auth-proxy-config"}:
            .: {}
            f:configMap:
              .: {}
              f:defaultMode: {}
              f:name: {}
            f:name: {}
          k:{"name":"cloud-controller-manager-operator-tls"}:
            .: {}
            f:name: {}
            f:secret:
              .: {}
              f:defaultMode: {}
              f:optional: {}
              f:secretName: {}
          k:{"name":"host-etc-kube"}:
            .: {}
            f:hostPath:
              .: {}
              f:path: {}
              f:type: {}
            f:name: {}
          k:{"name":"images"}:
            .: {}
            f:configMap:
              .: {}
              f:defaultMode: {}
              f:name: {}
            f:name: {}
    manager: kube-controller-manager
    operation: Update
    time: "2024-10-24T13:00:10Z"
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        f:conditions:
          k:{"type":"ContainersReady"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"Initialized"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"PodReadyToStartContainers"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"Ready"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
        f:containerStatuses: {}
        f:hostIP: {}
        f:hostIPs: {}
        f:phase: {}
        f:podIP: {}
        f:podIPs:
          .: {}
          k:{"ip":"10.0.0.4"}:
            .: {}
            f:ip: {}
        f:startTime: {}
    manager: kubelet
    operation: Update
    subresource: status
    time: "2024-10-24T13:18:59Z"
  name: cluster-cloud-controller-manager-operator-f546c9d4b-z6bjn
  namespace: openshift-cloud-controller-manager-operator
  ownerReferences:
  - apiVersion: apps/v1
    blockOwnerDeletion: true
    controller: true
    kind: ReplicaSet
    name: cluster-cloud-controller-manager-operator-f546c9d4b
    uid: 2f0958f2-175e-4bf0-b6ba-c765399e9709
  resourceVersion: "20874"
  uid: 703ce234-a244-49d0-88a0-4ed79d1ef3ab
spec:
  containers:
  - command:
    - /bin/bash
    - -c
    - |
      #!/bin/bash
      set -o allexport
      if [[ -f /etc/kubernetes/apiserver-url.env ]]; then
        source /etc/kubernetes/apiserver-url.env
      else
        URL_ONLY_KUBECONFIG=/etc/kubernetes/kubeconfig
      fi
      exec /cluster-controller-manager-operator \
      --leader-elect=true \
      --leader-elect-lease-duration=137s \
      --leader-elect-renew-deadline=107s \
      --leader-elect-retry-period=26s \
      --leader-elect-resource-namespace=openshift-cloud-controller-manager-operator \
      "--images-json=/etc/cloud-controller-manager-config/images.json" \
      --metrics-bind-address=127.0.0.1:9257 \
      --health-addr=127.0.0.1:9259
    env:
    - name: RELEASE_VERSION
      value: 4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest
    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:43c131e0ab4daf9b297d84bda92ba78bd5df8af483ad8e96e10d05d37cd4a08a
    imagePullPolicy: IfNotPresent
    name: cluster-cloud-controller-manager
    ports:
    - containerPort: 9257
      hostPort: 9257
      name: metrics
      protocol: TCP
    - containerPort: 9259
      hostPort: 9259
      name: healthz
      protocol: TCP
    resources:
      requests:
        cpu: 10m
        memory: 50Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/cloud-controller-manager-config/
      name: images
    - mountPath: /etc/kubernetes
      name: host-etc-kube
      readOnly: true
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-pj6xg
      readOnly: true
  - command:
    - /bin/bash
    - -c
    - |
      #!/bin/bash
      set -o allexport
      if [[ -f /etc/kubernetes/apiserver-url.env ]]; then
        source /etc/kubernetes/apiserver-url.env
      else
        URL_ONLY_KUBECONFIG=/etc/kubernetes/kubeconfig
      fi
      exec /config-sync-controllers \
      --leader-elect=true \
      --leader-elect-lease-duration=137s \
      --leader-elect-renew-deadline=107s \
      --leader-elect-retry-period=26s \
      --leader-elect-resource-namespace=openshift-cloud-controller-manager-operator \
      --health-addr=127.0.0.1:9260
    env:
    - name: RELEASE_VERSION
      value: 4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest
    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:43c131e0ab4daf9b297d84bda92ba78bd5df8af483ad8e96e10d05d37cd4a08a
    imagePullPolicy: IfNotPresent
    name: config-sync-controllers
    ports:
    - containerPort: 9260
      hostPort: 9260
      name: healthz
      protocol: TCP
    resources:
      requests:
        cpu: 10m
        memory: 25Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/kubernetes
      name: host-etc-kube
      readOnly: true
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-pj6xg
      readOnly: true
  - args:
    - --secure-listen-address=0.0.0.0:9258
    - --upstream=http://127.0.0.1:9257/
    - --tls-cert-file=/etc/tls/private/tls.crt
    - --tls-private-key-file=/etc/tls/private/tls.key
    - --config-file=/etc/kube-rbac-proxy/config-file.yaml
    - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
    - --logtostderr=true
    - --v=3
    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:ff7b9d9ed505a6b67f38f5a8c628d4fd03bd136119e29ee42d8368ef33f23e87
    imagePullPolicy: IfNotPresent
    name: kube-rbac-proxy
    ports:
    - containerPort: 9258
      hostPort: 9258
      name: https
      protocol: TCP
    resources:
      requests:
        cpu: 10m
        memory: 20Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/kube-rbac-proxy
      name: auth-proxy-config
    - mountPath: /etc/tls/private
      name: cloud-controller-manager-operator-tls
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-pj6xg
      readOnly: true
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  hostNetwork: true
  nodeName: ci-op-2fcpj5j6-f6035-2lklf-master-1
  nodeSelector:
    node-role.kubernetes.io/master: ""
  preemptionPolicy: PreemptLowerPriority
  priority: 2000001000
  priorityClassName: system-node-critical
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext: {}
  serviceAccount: cluster-cloud-controller-manager
  serviceAccountName: cluster-cloud-controller-manager
  terminationGracePeriodSeconds: 30
  tolerations:
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
    operator: Exists
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
    tolerationSeconds: 120
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
    tolerationSeconds: 120
  - effect: NoSchedule
    key: node.cloudprovider.kubernetes.io/uninitialized
    operator: Exists
  - effect: NoSchedule
    key: node.kubernetes.io/not-ready
    operator: Exists
  - effect: NoSchedule
    key: node.kubernetes.io/memory-pressure
    operator: Exists
  volumes:
  - configMap:
      defaultMode: 420
      name: cloud-controller-manager-images
    name: images
  - hostPath:
      path: /etc/kubernetes
      type: Directory
    name: host-etc-kube
  - configMap:
      defaultMode: 420
      name: kube-rbac-proxy
    name: auth-proxy-config
  - name: cloud-controller-manager-operator-tls
    secret:
      defaultMode: 420
      optional: true
      secretName: cloud-controller-manager-operator-tls
  - name: kube-api-access-pj6xg
    projected:
      defaultMode: 420
      sources:
      - serviceAccountToken:
          expirationSeconds: 3607
          path: token
      - configMap:
          items:
          - key: ca.crt
            path: ca.crt
          name: kube-root-ca.crt
      - downwardAPI:
          items:
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
            path: namespace
      - configMap:
          items:
          - key: service-ca.crt
            path: service-ca.crt
          name: openshift-service-ca.crt
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2024-10-24T13:00:11Z"
    status: "True"
    type: PodReadyToStartContainers
  - lastProbeTime: null
    lastTransitionTime: "2024-10-24T13:00:10Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2024-10-24T13:18:01Z"
    status: "True"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2024-10-24T13:18:01Z"
    status: "True"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2024-10-24T13:00:10Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - containerID: cri-o://c3ba8f9f37891449098bd59dedff1c4b5ebd446275c9b442d6631a7237b658d4
    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:43c131e0ab4daf9b297d84bda92ba78bd5df8af483ad8e96e10d05d37cd4a08a
    imageID: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:43c131e0ab4daf9b297d84bda92ba78bd5df8af483ad8e96e10d05d37cd4a08a
    lastState:
      terminated:
        containerID: cri-o://1a4a9c93a337b66b3a997c9588ac1b9b88fe012dee042f140632ab2ed4146615
        exitCode: 1
        finishedAt: "2024-10-24T13:18:00Z"
        message: |
          0] Failed to update lock optimitically: Put "https://api-int.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX:6443/apis/coordination.k8s.io/v1/namespaces/openshift-cloud-controller-manager-operator/leases/cluster-cloud-controller-manager-leader": dial tcp 10.0.0.2:6443: i/o timeout, falling back to slow path
          E1024 13:14:28.742208       1 leaderelection.go:340] Failed to update lock optimitically: rpc error: code = DeadlineExceeded desc = context deadline exceeded, falling back to slow path
          E1024 13:16:20.484157       1 leaderelection.go:340] Failed to update lock optimitically: rpc error: code = DeadlineExceeded desc = context deadline exceeded, falling back to slow path
          E1024 13:17:20.495560       1 leaderelection.go:347] error retrieving resource lock openshift-cloud-controller-manager-operator/cluster-cloud-controller-manager-leader: the server was unable to return a response in the time allotted, but may still be processing the request (get leases.coordination.k8s.io cluster-cloud-controller-manager-leader)
          E1024 13:17:53.504227       1 leaderelection.go:340] Failed to update lock optimitically: rpc error: code = DeadlineExceeded desc = context deadline exceeded, falling back to slow path
          E1024 13:18:00.421525       1 leaderelection.go:347] error retrieving resource lock openshift-cloud-controller-manager-operator/cluster-cloud-controller-manager-leader: Get "https://api-int.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX:6443/apis/coordination.k8s.io/v1/namespaces/openshift-cloud-controller-manager-operator/leases/cluster-cloud-controller-manager-leader": context deadline exceeded
          I1024 13:18:00.421643       1 leaderelection.go:285] failed to renew lease openshift-cloud-controller-manager-operator/cluster-cloud-controller-manager-leader: timed out waiting for the condition
          E1024 13:18:00.422207       1 main.go:227] "problem running manager" err="leader election lost" logger="CCMOperator.setup"
          I1024 13:18:00.422220       1 internal.go:525] "Stopping and waiting for non leader election runnables" logger="CCMOperator"
        reason: Error
        startedAt: "2024-10-24T13:00:39Z"
    name: cluster-cloud-controller-manager
    ready: true
    restartCount: 1
    started: true
    state:
      running:
        startedAt: "2024-10-24T13:18:00Z"
    volumeMounts:
    - mountPath: /etc/cloud-controller-manager-config/
      name: images
    - mountPath: /etc/kubernetes
      name: host-etc-kube
      readOnly: true
      recursiveReadOnly: Disabled
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-pj6xg
      readOnly: true
      recursiveReadOnly: Disabled
  - containerID: cri-o://62d5247f8eaa24c9bb86accc6421243f7c6cd09d31b8b9930c07f451d0d7af11
    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:43c131e0ab4daf9b297d84bda92ba78bd5df8af483ad8e96e10d05d37cd4a08a
    imageID: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:43c131e0ab4daf9b297d84bda92ba78bd5df8af483ad8e96e10d05d37cd4a08a
    lastState:
      terminated:
        containerID: cri-o://936b5396adb0b27725e488798143d5bc46fbaecf71a745690ef76c69ab8ce815
        exitCode: 1
        finishedAt: "2024-10-24T13:17:57Z"
        message: |
          perator/leases/cluster-cloud-config-sync-leader": dial tcp 10.0.0.2:6443: connect: connection refused
          E1024 13:13:23.289090       1 leaderelection.go:340] Failed to update lock optimitically: Put "https://api-int.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX:6443/apis/coordination.k8s.io/v1/namespaces/openshift-cloud-controller-manager-operator/leases/cluster-cloud-config-sync-leader": dial tcp 10.0.0.2:6443: i/o timeout, falling back to slow path
          E1024 13:14:32.697315       1 leaderelection.go:340] Failed to update lock optimitically: rpc error: code = DeadlineExceeded desc = context deadline exceeded, falling back to slow path
          E1024 13:16:17.605118       1 leaderelection.go:340] Failed to update lock optimitically: rpc error: code = DeadlineExceeded desc = context deadline exceeded, falling back to slow path
          E1024 13:17:17.608999       1 leaderelection.go:347] error retrieving resource lock openshift-cloud-controller-manager-operator/cluster-cloud-config-sync-leader: the server was unable to return a response in the time allotted, but may still be processing the request (get leases.coordination.k8s.io cluster-cloud-config-sync-leader)
          E1024 13:17:50.616265       1 leaderelection.go:340] Failed to update lock optimitically: rpc error: code = DeadlineExceeded desc = context deadline exceeded, falling back to slow path
          E1024 13:17:57.545001       1 leaderelection.go:347] error retrieving resource lock openshift-cloud-controller-manager-operator/cluster-cloud-config-sync-leader: Get "https://api-int.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX:6443/apis/coordination.k8s.io/v1/namespaces/openshift-cloud-controller-manager-operator/leases/cluster-cloud-config-sync-leader": context deadline exceeded
          I1024 13:17:57.545203       1 leaderelection.go:285] failed to renew lease openshift-cloud-controller-manager-operator/cluster-cloud-config-sync-leader: timed out waiting for the condition
          E1024 13:17:57.546403       1 main.go:172] "problem running manager" err="leader election lost" logger="CCCMOConfigSyncControllers.setup"
        reason: Error
        startedAt: "2024-10-24T13:00:39Z"
    name: config-sync-controllers
    ready: true
    restartCount: 1
    started: true
    state:
      running:
        startedAt: "2024-10-24T13:17:57Z"
    volumeMounts:
    - mountPath: /etc/kubernetes
      name: host-etc-kube
      readOnly: true
      recursiveReadOnly: Disabled
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-pj6xg
      readOnly: true
      recursiveReadOnly: Disabled
  - containerID: cri-o://9270b00282676d89f0bd27f1ace9f56df3acbdfa8a37c1bcd11c92809b644529
    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:ff7b9d9ed505a6b67f38f5a8c628d4fd03bd136119e29ee42d8368ef33f23e87
    imageID: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:38795c2c7e40968bb7758d62851c52ac25eb36c85f462481e64804699b9f6c0a
    lastState:
      terminated:
        containerID: cri-o://faf5351f8450fd65301eb076a5f8e8f78896ba1b20c865511c49a28d17a08658
        exitCode: 1
        finishedAt: "2024-10-24T13:02:16Z"
        message: "AG: --skip-log-headers=\"false\"\nI1024 13:02:16.403156       1
          flags.go:64] FLAG: --stderrthreshold=\"\"\nI1024 13:02:16.403159       1
          flags.go:64] FLAG: --tls-cert-file=\"/etc/tls/private/tls.crt\"\nI1024 13:02:16.403161
          \      1 flags.go:64] FLAG: --tls-cipher-suites=\"[TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305]\"\nI1024
          13:02:16.403169       1 flags.go:64] FLAG: --tls-min-version=\"VersionTLS12\"\nI1024
          13:02:16.403172       1 flags.go:64] FLAG: --tls-private-key-file=\"/etc/tls/private/tls.key\"\nI1024
          13:02:16.403175       1 flags.go:64] FLAG: --tls-reload-interval=\"1m0s\"\nI1024
          13:02:16.403179       1 flags.go:64] FLAG: --upstream=\"http://127.0.0.1:9257/\"\nI1024
          13:02:16.403182       1 flags.go:64] FLAG: --upstream-ca-file=\"\"\nI1024
          13:02:16.403184       1 flags.go:64] FLAG: --upstream-client-cert-file=\"\"\nI1024
          13:02:16.403187       1 flags.go:64] FLAG: --upstream-client-key-file=\"\"\nI1024
          13:02:16.403189       1 flags.go:64] FLAG: --upstream-force-h2c=\"false\"\nI1024
          13:02:16.403191       1 flags.go:64] FLAG: --v=\"3\"\nI1024 13:02:16.403194
          \      1 flags.go:64] FLAG: --version=\"false\"\nI1024 13:02:16.403198       1
          flags.go:64] FLAG: --vmodule=\"\"\nW1024 13:02:16.403208       1 deprecated.go:66]
          \n==== Removed Flag Warning ======================\n\nlogtostderr is removed
          in the k8s upstream and has no effect any more.\n\n===============================================\n\t\t\nI1024
          13:02:16.403216       1 kube-rbac-proxy.go:530] Reading config file: /etc/kube-rbac-proxy/config-file.yaml\nI1024
          13:02:16.403809       1 kube-rbac-proxy.go:233] Valid token audiences: \nI1024
          13:02:16.406328       1 kube-rbac-proxy.go:347] Reading certificate files\nE1024
          13:02:16.406400       1 run.go:72] \"command failed\" err=\"failed to initialize
          certificate reloader: error loading certificates: error loading certificate:
          open /etc/tls/private/tls.crt: no such file or directory\"\n"
        reason: Error
        startedAt: "2024-10-24T13:02:16Z"
    name: kube-rbac-proxy
    ready: true
    restartCount: 5
    started: true
    state:
      running:
        startedAt: "2024-10-24T13:03:49Z"
    volumeMounts:
    - mountPath: /etc/kube-rbac-proxy
      name: auth-proxy-config
    - mountPath: /etc/tls/private
      name: cloud-controller-manager-operator-tls
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-pj6xg
      readOnly: true
      recursiveReadOnly: Disabled
  hostIP: 10.0.0.4
  hostIPs:
  - ip: 10.0.0.4
  phase: Running
  podIP: 10.0.0.4
  podIPs:
  - ip: 10.0.0.4
  qosClass: Burstable
  startTime: "2024-10-24T13:00:10Z"
