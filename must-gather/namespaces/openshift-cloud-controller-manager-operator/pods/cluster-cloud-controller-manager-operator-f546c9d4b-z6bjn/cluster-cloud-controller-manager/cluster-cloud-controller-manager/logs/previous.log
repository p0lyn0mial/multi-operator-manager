2024-10-24T13:00:39.594695753Z I1024 13:00:39.594508       1 leaderelection.go:121] The leader election gives 4 retries and allows for 30s of clock skew. The kube-apiserver downtime tolerance is 78s. Worst non-graceful lease acquisition is 2m43s. Worst graceful lease acquisition is {26s}.
2024-10-24T13:00:39.614253832Z W1024 13:00:39.614189       1 main.go:172] unable to get owner reference (falling back to namespace): unable to setup event recorder as "POD_NAME" env variable is not set and there are no pods
2024-10-24T13:00:39.615204603Z I1024 13:00:39.615106       1 simple_featuregate_reader.go:171] Starting feature-gate-detector
2024-10-24T13:00:39.618837188Z I1024 13:00:39.618784       1 main.go:184] "FeatureGates changed" enabled=["AWSEFSDriverVolumeMetrics","AdminNetworkPolicy","AlibabaPlatform","AzureWorkloadIdentity","BareMetalLoadBalancer","BuildCSIVolumes","ChunkSizeMiB","CloudDualStackNodeIPs","DisableKubeletCloudCredentialProviders","GCPLabelsTags","HardwareSpeed","IngressControllerLBSubnetsAWS","KMSv1","ManagedBootImages","MetricsServer","MultiArchInstallAWS","MultiArchInstallGCP","NetworkDiagnosticsConfig","NetworkLiveMigration","NodeDisruptionPolicy","OpenShiftPodSecurityAdmission","PrivateHostedZoneAWS","SetEIPForNLBIngressController","VSphereControlPlaneMachineSet","VSphereDriverConfiguration","VSphereStaticIPs","ValidatingAdmissionPolicy"] disabled=["AWSClusterHostedDNS","AdditionalRoutingCapabilities","AutomatedEtcdBackup","BootcNodeManagement","CSIDriverSharedResource","ClusterAPIInstall","ClusterAPIInstallIBMCloud","ClusterMonitoringConfig","DNSNameResolver","DynamicResourceAllocation","EtcdBackendQuota","EventedPLEG","Example","ExternalOIDC","GCPClusterHostedDNS","GatewayAPI","ImageStreamImportMode","IngressControllerDynamicConfigurationManager","InsightsConfig","InsightsConfigAPI","InsightsOnDemandDataGather","InsightsRuntimeExtractor","MachineAPIMigration","MachineAPIOperatorDisableMachineHealthCheckController","MachineAPIProviderOpenStack","MachineConfigNodes","ManagedBootImagesAWS","MaxUnavailableStatefulSet","MetricsCollectionProfiles","MixedCPUsAllocation","MultiArchInstallAzure","NetworkSegmentation","NewOLM","NodeSwap","OVNObservability","OnClusterBuild","PersistentIPsForVirtualization","PinnedImages","PlatformOperators","ProcMountType","RouteAdvertisements","RouteExternalCertificate","ServiceAccountTokenNodeBinding","SignatureStores","SigstoreImageVerification","TranslateStreamCloseWebsocketRequests","UpgradeStatus","UserNamespacesPodSecurityStandards","UserNamespacesSupport","VSphereMultiNetworks","VSphereMultiVCenters","VolumeGroupSnapshot"]
2024-10-24T13:00:39.620624891Z I1024 13:00:39.620514       1 event.go:377] Event(v1.ObjectReference{Kind:"Namespace", Namespace:"openshift-cloud-controller-manager", Name:"openshift-cloud-controller-manager", UID:"", APIVersion:"v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'FeatureGatesInitialized' FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AWSEFSDriverVolumeMetrics", "AdminNetworkPolicy", "AlibabaPlatform", "AzureWorkloadIdentity", "BareMetalLoadBalancer", "BuildCSIVolumes", "ChunkSizeMiB", "CloudDualStackNodeIPs", "DisableKubeletCloudCredentialProviders", "GCPLabelsTags", "HardwareSpeed", "IngressControllerLBSubnetsAWS", "KMSv1", "ManagedBootImages", "MetricsServer", "MultiArchInstallAWS", "MultiArchInstallGCP", "NetworkDiagnosticsConfig", "NetworkLiveMigration", "NodeDisruptionPolicy", "OpenShiftPodSecurityAdmission", "PrivateHostedZoneAWS", "SetEIPForNLBIngressController", "VSphereControlPlaneMachineSet", "VSphereDriverConfiguration", "VSphereStaticIPs", "ValidatingAdmissionPolicy"}, Disabled:[]v1.FeatureGateName{"AWSClusterHostedDNS", "AdditionalRoutingCapabilities", "AutomatedEtcdBackup", "BootcNodeManagement", "CSIDriverSharedResource", "ClusterAPIInstall", "ClusterAPIInstallIBMCloud", "ClusterMonitoringConfig", "DNSNameResolver", "DynamicResourceAllocation", "EtcdBackendQuota", "EventedPLEG", "Example", "ExternalOIDC", "GCPClusterHostedDNS", "GatewayAPI", "ImageStreamImportMode", "IngressControllerDynamicConfigurationManager", "InsightsConfig", "InsightsConfigAPI", "InsightsOnDemandDataGather", "InsightsRuntimeExtractor", "MachineAPIMigration", "MachineAPIOperatorDisableMachineHealthCheckController", "MachineAPIProviderOpenStack", "MachineConfigNodes", "ManagedBootImagesAWS", "MaxUnavailableStatefulSet", "MetricsCollectionProfiles", "MixedCPUsAllocation", "MultiArchInstallAzure", "NetworkSegmentation", "NewOLM", "NodeSwap", "OVNObservability", "OnClusterBuild", "PersistentIPsForVirtualization", "PinnedImages", "PlatformOperators", "ProcMountType", "RouteAdvertisements", "RouteExternalCertificate", "ServiceAccountTokenNodeBinding", "SignatureStores", "SigstoreImageVerification", "TranslateStreamCloseWebsocketRequests", "UpgradeStatus", "UserNamespacesPodSecurityStandards", "UserNamespacesSupport", "VSphereMultiNetworks", "VSphereMultiVCenters", "VolumeGroupSnapshot"}}
2024-10-24T13:00:39.620668811Z I1024 13:00:39.620617       1 main.go:195] "FeatureGates initialized" logger="CCMOperator.setup" enabled=["AWSEFSDriverVolumeMetrics","AdminNetworkPolicy","AlibabaPlatform","AzureWorkloadIdentity","BareMetalLoadBalancer","BuildCSIVolumes","ChunkSizeMiB","CloudDualStackNodeIPs","DisableKubeletCloudCredentialProviders","GCPLabelsTags","HardwareSpeed","IngressControllerLBSubnetsAWS","KMSv1","ManagedBootImages","MetricsServer","MultiArchInstallAWS","MultiArchInstallGCP","NetworkDiagnosticsConfig","NetworkLiveMigration","NodeDisruptionPolicy","OpenShiftPodSecurityAdmission","PrivateHostedZoneAWS","SetEIPForNLBIngressController","VSphereControlPlaneMachineSet","VSphereDriverConfiguration","VSphereStaticIPs","ValidatingAdmissionPolicy"] disabled=["AWSClusterHostedDNS","AdditionalRoutingCapabilities","AutomatedEtcdBackup","BootcNodeManagement","CSIDriverSharedResource","ClusterAPIInstall","ClusterAPIInstallIBMCloud","ClusterMonitoringConfig","DNSNameResolver","DynamicResourceAllocation","EtcdBackendQuota","EventedPLEG","Example","ExternalOIDC","GCPClusterHostedDNS","GatewayAPI","ImageStreamImportMode","IngressControllerDynamicConfigurationManager","InsightsConfig","InsightsConfigAPI","InsightsOnDemandDataGather","InsightsRuntimeExtractor","MachineAPIMigration","MachineAPIOperatorDisableMachineHealthCheckController","MachineAPIProviderOpenStack","MachineConfigNodes","ManagedBootImagesAWS","MaxUnavailableStatefulSet","MetricsCollectionProfiles","MixedCPUsAllocation","MultiArchInstallAzure","NetworkSegmentation","NewOLM","NodeSwap","OVNObservability","OnClusterBuild","PersistentIPsForVirtualization","PinnedImages","PlatformOperators","ProcMountType","RouteAdvertisements","RouteExternalCertificate","ServiceAccountTokenNodeBinding","SignatureStores","SigstoreImageVerification","TranslateStreamCloseWebsocketRequests","UpgradeStatus","UserNamespacesPodSecurityStandards","UserNamespacesSupport","VSphereMultiNetworks","VSphereMultiVCenters","VolumeGroupSnapshot"]
2024-10-24T13:00:39.620745071Z I1024 13:00:39.620709       1 main.go:225] "starting manager" logger="CCMOperator.setup"
2024-10-24T13:00:39.621213402Z I1024 13:00:39.621185       1 server.go:208] "Starting metrics server" logger="CCMOperator.controller-runtime.metrics"
2024-10-24T13:00:39.621259252Z I1024 13:00:39.621224       1 server.go:83] "starting server" logger="CCMOperator" name="health probe" addr="127.0.0.1:9259"
2024-10-24T13:00:39.621399122Z I1024 13:00:39.621374       1 server.go:247] "Serving metrics server" logger="CCMOperator.controller-runtime.metrics" bindAddress="127.0.0.1:9257" secure=false
2024-10-24T13:00:39.621646752Z I1024 13:00:39.621624       1 leaderelection.go:250] attempting to acquire leader lease openshift-cloud-controller-manager-operator/cluster-cloud-controller-manager-leader...
2024-10-24T13:00:39.630109915Z I1024 13:00:39.630070       1 leaderelection.go:260] successfully acquired lease openshift-cloud-controller-manager-operator/cluster-cloud-controller-manager-leader
2024-10-24T13:00:39.630520936Z I1024 13:00:39.630483       1 controller.go:173] "Starting EventSource" logger="CCMOperator" controller="clusteroperator" controllerGroup="config.openshift.io" controllerKind="ClusterOperator" source="kind source: *v1.ClusterOperator"
2024-10-24T13:00:39.630520936Z I1024 13:00:39.630510       1 controller.go:173] "Starting EventSource" logger="CCMOperator" controller="clusteroperator" controllerGroup="config.openshift.io" controllerKind="ClusterOperator" source="kind source: *v1.Infrastructure"
2024-10-24T13:00:39.630553476Z I1024 13:00:39.630524       1 controller.go:173] "Starting EventSource" logger="CCMOperator" controller="clusteroperator" controllerGroup="config.openshift.io" controllerKind="ClusterOperator" source="kind source: *v1.FeatureGate"
2024-10-24T13:00:39.630553476Z I1024 13:00:39.630534       1 controller.go:173] "Starting EventSource" logger="CCMOperator" controller="clusteroperator" controllerGroup="config.openshift.io" controllerKind="ClusterOperator" source="kind source: *v1.KubeControllerManager"
2024-10-24T13:00:39.630553476Z I1024 13:00:39.630546       1 controller.go:173] "Starting EventSource" logger="CCMOperator" controller="clusteroperator" controllerGroup="config.openshift.io" controllerKind="ClusterOperator" source="kind source: *v1.ConfigMap"
2024-10-24T13:00:39.630564896Z I1024 13:00:39.630556       1 controller.go:173] "Starting EventSource" logger="CCMOperator" controller="clusteroperator" controllerGroup="config.openshift.io" controllerKind="ClusterOperator" source="kind source: *v1.Secret"
2024-10-24T13:00:39.630576365Z I1024 13:00:39.630569       1 controller.go:173] "Starting EventSource" logger="CCMOperator" controller="clusteroperator" controllerGroup="config.openshift.io" controllerKind="ClusterOperator" source="channel source: 0xc0003baa10"
2024-10-24T13:00:39.630586685Z I1024 13:00:39.630582       1 controller.go:181] "Starting Controller" logger="CCMOperator" controller="clusteroperator" controllerGroup="config.openshift.io" controllerKind="ClusterOperator"
2024-10-24T13:00:39.771961632Z I1024 13:00:39.771912       1 controller.go:215] "Starting workers" logger="CCMOperator" controller="clusteroperator" controllerGroup="config.openshift.io" controllerKind="ClusterOperator" worker count=1
2024-10-24T13:00:40.320855862Z I1024 13:00:40.320778       1 warning_handler.go:65] "spec.template.spec.nodeSelector[node-role.kubernetes.io/master]: use \"node-role.kubernetes.io/control-plane\" instead" logger="CCMOperator.KubeAPIWarningLogger"
2024-10-24T13:00:40.674486387Z E1024 13:00:40.674377       1 clusteroperator_controller.go:127] Unable to sync cluster operator status: Operation cannot be fulfilled on clusteroperators.config.openshift.io "cloud-controller-manager": the object has been modified; please apply your changes to the latest version and try again
2024-10-24T13:00:40.674486387Z E1024 13:00:40.674474       1 controller.go:324] "Reconciler error" err="Operation cannot be fulfilled on clusteroperators.config.openshift.io \"cloud-controller-manager\": the object has been modified; please apply your changes to the latest version and try again" logger="CCMOperator" controller="clusteroperator" controllerGroup="config.openshift.io" controllerKind="ClusterOperator" ClusterOperator="cloud-controller-manager" namespace="" name="cloud-controller-manager" reconcileID="5b921b49-1961-4f49-80c4-9bb87aae3e14"
2024-10-24T13:08:39.633470393Z W1024 13:08:39.633049       1 reflector.go:470] sigs.k8s.io/controller-runtime/pkg/cache/internal/informers.go:106: watch of *v1.Proxy ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
2024-10-24T13:08:39.633470393Z E1024 13:08:39.633412       1 leaderelection.go:340] Failed to update lock optimitically: Put "https://api-int.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX:6443/apis/coordination.k8s.io/v1/namespaces/openshift-cloud-controller-manager-operator/leases/cluster-cloud-controller-manager-leader": http2: client connection lost, falling back to slow path
2024-10-24T13:08:39.634258452Z W1024 13:08:39.634205       1 reflector.go:470] sigs.k8s.io/controller-runtime/pkg/cache/internal/informers.go:106: watch of *v1.FeatureGate ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
2024-10-24T13:08:39.634258452Z W1024 13:08:39.634252       1 reflector.go:470] sigs.k8s.io/controller-runtime/pkg/cache/internal/informers.go:106: watch of *v1.Secret ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
2024-10-24T13:08:39.634276792Z W1024 13:08:39.634271       1 reflector.go:470] sigs.k8s.io/controller-runtime/pkg/cache/internal/informers.go:106: watch of *v1.ClusterOperator ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
2024-10-24T13:08:39.634311612Z W1024 13:08:39.634291       1 reflector.go:470] sigs.k8s.io/controller-runtime/pkg/cache/internal/informers.go:106: watch of *v1.Deployment ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
2024-10-24T13:08:39.634324923Z W1024 13:08:39.634310       1 reflector.go:470] sigs.k8s.io/controller-runtime/pkg/cache/internal/informers.go:106: watch of *v1.ClusterRole ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
2024-10-24T13:08:39.634333663Z W1024 13:08:39.634328       1 reflector.go:470] github.com/openshift/client-go/config/informers/externalversions/factory.go:125: watch of *v1.FeatureGate ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
2024-10-24T13:08:39.634361823Z W1024 13:08:39.634342       1 reflector.go:470] github.com/openshift/client-go/config/informers/externalversions/factory.go:125: watch of *v1.ClusterVersion ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
2024-10-24T13:08:39.634369813Z W1024 13:08:39.634362       1 reflector.go:470] sigs.k8s.io/controller-runtime/pkg/cache/internal/informers.go:106: watch of *v1.KubeControllerManager ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
2024-10-24T13:08:39.634396263Z W1024 13:08:39.634378       1 reflector.go:470] sigs.k8s.io/controller-runtime/pkg/cache/internal/informers.go:106: watch of *v1.ClusterRoleBinding ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
2024-10-24T13:08:39.634505583Z W1024 13:08:39.634466       1 reflector.go:470] sigs.k8s.io/controller-runtime/pkg/cache/internal/informers.go:106: watch of *v1.Infrastructure ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
2024-10-24T13:08:39.635211903Z W1024 13:08:39.635176       1 reflector.go:470] sigs.k8s.io/controller-runtime/pkg/cache/internal/informers.go:106: watch of *v1.PodDisruptionBudget ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
2024-10-24T13:08:39.635230353Z W1024 13:08:39.635203       1 reflector.go:470] sigs.k8s.io/controller-runtime/pkg/cache/internal/informers.go:106: watch of *v1.ConfigMap ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
2024-10-24T13:10:01.672346714Z E1024 13:10:01.672257       1 leaderelection.go:340] Failed to update lock optimitically: Put "https://api-int.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX:6443/apis/coordination.k8s.io/v1/namespaces/openshift-cloud-controller-manager-operator/leases/cluster-cloud-controller-manager-leader": dial tcp 10.0.0.2:6443: i/o timeout, falling back to slow path
2024-10-24T13:13:01.159449351Z E1024 13:13:01.159366       1 leaderelection.go:340] Failed to update lock optimitically: Put "https://api-int.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX:6443/apis/coordination.k8s.io/v1/namespaces/openshift-cloud-controller-manager-operator/leases/cluster-cloud-controller-manager-leader": dial tcp 10.0.0.2:6443: i/o timeout, falling back to slow path
2024-10-24T13:14:28.742391336Z E1024 13:14:28.742208       1 leaderelection.go:340] Failed to update lock optimitically: rpc error: code = DeadlineExceeded desc = context deadline exceeded, falling back to slow path
2024-10-24T13:16:20.484241248Z E1024 13:16:20.484157       1 leaderelection.go:340] Failed to update lock optimitically: rpc error: code = DeadlineExceeded desc = context deadline exceeded, falling back to slow path
2024-10-24T13:17:20.495732105Z E1024 13:17:20.495560       1 leaderelection.go:347] error retrieving resource lock openshift-cloud-controller-manager-operator/cluster-cloud-controller-manager-leader: the server was unable to return a response in the time allotted, but may still be processing the request (get leases.coordination.k8s.io cluster-cloud-controller-manager-leader)
2024-10-24T13:17:53.504287799Z E1024 13:17:53.504227       1 leaderelection.go:340] Failed to update lock optimitically: rpc error: code = DeadlineExceeded desc = context deadline exceeded, falling back to slow path
2024-10-24T13:18:00.421595510Z E1024 13:18:00.421525       1 leaderelection.go:347] error retrieving resource lock openshift-cloud-controller-manager-operator/cluster-cloud-controller-manager-leader: Get "https://api-int.ci-op-2fcpj5j6-f6035.XXXXXXXXXXXXXXXXXXXXXX:6443/apis/coordination.k8s.io/v1/namespaces/openshift-cloud-controller-manager-operator/leases/cluster-cloud-controller-manager-leader": context deadline exceeded
2024-10-24T13:18:00.421665750Z I1024 13:18:00.421643       1 leaderelection.go:285] failed to renew lease openshift-cloud-controller-manager-operator/cluster-cloud-controller-manager-leader: timed out waiting for the condition
2024-10-24T13:18:00.422264120Z E1024 13:18:00.422207       1 main.go:227] "problem running manager" err="leader election lost" logger="CCMOperator.setup"
2024-10-24T13:18:00.422264120Z I1024 13:18:00.422220       1 internal.go:525] "Stopping and waiting for non leader election runnables" logger="CCMOperator"
