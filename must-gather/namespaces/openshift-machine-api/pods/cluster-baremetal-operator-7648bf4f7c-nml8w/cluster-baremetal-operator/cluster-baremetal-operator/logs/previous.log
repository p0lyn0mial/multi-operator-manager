2024-10-24T13:07:03.678741105Z I1024 13:07:03.678603       1 webhook.go:104] WebhookDependenciesReady: everything ready for webhooks
2024-10-24T13:07:03.710556944Z I1024 13:07:03.710486       1 clusteroperator.go:217] "new CO status" reason="WaitingForProvisioningCR" processMessage="" message="Waiting for Provisioning CR on BareMetal Platform"
2024-10-24T13:07:03.732196374Z I1024 13:07:03.732160       1 provisioning_controller.go:651] "Network stack calculation" NetworkStack=1
2024-10-24T13:07:03.750227694Z I1024 13:07:03.750181       1 recorder_logging.go:44] &Event{ObjectMeta:{dummy.18016566b8e54a68  dummy    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Pod,Namespace:dummy,Name:dummy,UID:,APIVersion:v1,ResourceVersion:,FieldPath:,},Reason:ValidatingWebhookConfigurationCreated,Message:Created ValidatingWebhookConfiguration.admissionregistration.k8s.io/cluster-baremetal-validating-webhook-configuration because it was missing,Source:EventSource{Component:,Host:,},FirstTimestamp:2024-10-24 13:07:03.750085224 +0000 UTC m=+0.137010439,LastTimestamp:2024-10-24 13:07:03.750085224 +0000 UTC m=+0.137010439,Count:1,Type:Normal,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:,ReportingInstance:,}
2024-10-24T13:07:03.750377244Z I1024 13:07:03.750340       1 webhook.go:177] "msg"="skip registering a mutating webhook, object does not implement admission.Defaulter or WithDefaulter wasn't called" "GVK"={"Group":"metal3.io","Version":"v1alpha1","Kind":"Provisioning"} "logger"="controller-runtime.builder"
2024-10-24T13:07:03.750431314Z I1024 13:07:03.750406       1 webhook.go:193] "msg"="Registering a validating webhook" "GVK"={"Group":"metal3.io","Version":"v1alpha1","Kind":"Provisioning"} "logger"="controller-runtime.builder" "path"="/validate-metal3-io-v1alpha1-provisioning"
2024-10-24T13:07:03.750535364Z I1024 13:07:03.750507       1 server.go:183] "msg"="Registering webhook" "logger"="controller-runtime.webhook" "path"="/validate-metal3-io-v1alpha1-provisioning"
2024-10-24T13:07:03.750569004Z I1024 13:07:03.750553       1 main.go:180] starting manager
2024-10-24T13:07:03.750735434Z I1024 13:07:03.750703       1 server.go:208] "msg"="Starting metrics server" "logger"="controller-runtime.metrics"
2024-10-24T13:07:03.750887574Z I1024 13:07:03.750849       1 server.go:191] "msg"="Starting webhook server" "logger"="controller-runtime.webhook"
2024-10-24T13:07:03.751376524Z I1024 13:07:03.751355       1 server.go:247] "msg"="Serving metrics server" "bindAddress"=":8080" "logger"="controller-runtime.metrics" "secure"=false
2024-10-24T13:07:03.751482024Z I1024 13:07:03.751440       1 certwatcher.go:161] "msg"="Updated current TLS certificate" "logger"="controller-runtime.certwatcher"
2024-10-24T13:07:03.751716814Z I1024 13:07:03.751694       1 certwatcher.go:115] "msg"="Starting certificate watcher" "logger"="controller-runtime.certwatcher"
2024-10-24T13:07:03.751716814Z I1024 13:07:03.751700       1 server.go:242] "msg"="Serving webhook server" "host"="" "logger"="controller-runtime.webhook" "port"=9443
2024-10-24T13:07:03.852973682Z I1024 13:07:03.852434       1 leaderelection.go:250] attempting to acquire leader lease openshift-machine-api/cluster-baremetal-operator...
2024-10-24T13:07:03.878676901Z I1024 13:07:03.878623       1 leaderelection.go:260] successfully acquired lease openshift-machine-api/cluster-baremetal-operator
2024-10-24T13:07:03.879203591Z I1024 13:07:03.879169       1 controller.go:173] "msg"="Starting EventSource" "controller"="provisioning" "controllerGroup"="metal3.io" "controllerKind"="Provisioning" "source"="kind source: *v1alpha1.Provisioning"
2024-10-24T13:07:03.879236661Z I1024 13:07:03.879210       1 controller.go:173] "msg"="Starting EventSource" "controller"="provisioning" "controllerGroup"="metal3.io" "controllerKind"="Provisioning" "source"="kind source: *v1.Secret"
2024-10-24T13:07:03.879264352Z I1024 13:07:03.879234       1 controller.go:173] "msg"="Starting EventSource" "controller"="provisioning" "controllerGroup"="metal3.io" "controllerKind"="Provisioning" "source"="kind source: *v1.Deployment"
2024-10-24T13:07:03.879264352Z I1024 13:07:03.879251       1 controller.go:173] "msg"="Starting EventSource" "controller"="provisioning" "controllerGroup"="metal3.io" "controllerKind"="Provisioning" "source"="kind source: *v1.Service"
2024-10-24T13:07:03.879341851Z I1024 13:07:03.879302       1 controller.go:173] "msg"="Starting EventSource" "controller"="provisioning" "controllerGroup"="metal3.io" "controllerKind"="Provisioning" "source"="kind source: *v1.DaemonSet"
2024-10-24T13:07:03.879411641Z I1024 13:07:03.879371       1 controller.go:173] "msg"="Starting EventSource" "controller"="provisioning" "controllerGroup"="metal3.io" "controllerKind"="Provisioning" "source"="kind source: *v1.ClusterOperator"
2024-10-24T13:07:03.879501322Z I1024 13:07:03.879440       1 controller.go:173] "msg"="Starting EventSource" "controller"="provisioning" "controllerGroup"="metal3.io" "controllerKind"="Provisioning" "source"="kind source: *v1.Proxy"
2024-10-24T13:07:03.879501322Z I1024 13:07:03.879457       1 controller.go:173] "msg"="Starting EventSource" "controller"="provisioning" "controllerGroup"="metal3.io" "controllerKind"="Provisioning" "source"="kind source: *v1beta1.Machine"
2024-10-24T13:07:03.879501322Z I1024 13:07:03.879474       1 controller.go:181] "msg"="Starting Controller" "controller"="provisioning" "controllerGroup"="metal3.io" "controllerKind"="Provisioning"
2024-10-24T13:07:04.102991347Z I1024 13:07:04.102935       1 controller.go:215] "msg"="Starting workers" "controller"="provisioning" "controllerGroup"="metal3.io" "controllerKind"="Provisioning" "worker count"=1
2024-10-24T13:09:39.935695063Z E1024 13:09:39.935609       1 leaderelection.go:340] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-machine-api/leases/cluster-baremetal-operator": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:09:39.936314392Z E1024 13:09:39.936271       1 leaderelection.go:347] error retrieving resource lock openshift-machine-api/cluster-baremetal-operator: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-machine-api/leases/cluster-baremetal-operator": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:05.938419476Z E1024 13:10:05.938338       1 leaderelection.go:340] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-machine-api/leases/cluster-baremetal-operator": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:10:05.939130306Z E1024 13:10:05.939083       1 leaderelection.go:347] error retrieving resource lock openshift-machine-api/cluster-baremetal-operator: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-machine-api/leases/cluster-baremetal-operator": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:31.937865475Z E1024 13:10:31.937807       1 leaderelection.go:340] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-machine-api/leases/cluster-baremetal-operator": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:10:31.938418664Z E1024 13:10:31.938374       1 leaderelection.go:347] error retrieving resource lock openshift-machine-api/cluster-baremetal-operator: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-machine-api/leases/cluster-baremetal-operator": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:41.978184122Z E1024 13:12:41.978109       1 leaderelection.go:340] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-machine-api/leases/cluster-baremetal-operator": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:12:41.978738372Z E1024 13:12:41.978695       1 leaderelection.go:347] error retrieving resource lock openshift-machine-api/cluster-baremetal-operator: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-machine-api/leases/cluster-baremetal-operator": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:07.980666453Z E1024 13:13:07.980601       1 leaderelection.go:340] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-machine-api/leases/cluster-baremetal-operator": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:13:07.981140653Z E1024 13:13:07.981104       1 leaderelection.go:347] error retrieving resource lock openshift-machine-api/cluster-baremetal-operator: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-machine-api/leases/cluster-baremetal-operator": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:14:33.021591132Z E1024 13:14:33.021538       1 leaderelection.go:340] Failed to update lock optimitically: rpc error: code = DeadlineExceeded desc = context deadline exceeded, falling back to slow path
2024-10-24T13:16:17.601478921Z E1024 13:16:17.601434       1 leaderelection.go:340] Failed to update lock optimitically: rpc error: code = DeadlineExceeded desc = context deadline exceeded, falling back to slow path
2024-10-24T13:17:17.605338099Z E1024 13:17:17.605296       1 leaderelection.go:347] error retrieving resource lock openshift-machine-api/cluster-baremetal-operator: the server was unable to return a response in the time allotted, but may still be processing the request (get leases.coordination.k8s.io cluster-baremetal-operator)
2024-10-24T13:17:50.614554244Z E1024 13:17:50.614495       1 leaderelection.go:340] Failed to update lock optimitically: rpc error: code = DeadlineExceeded desc = context deadline exceeded, falling back to slow path
2024-10-24T13:17:57.548115472Z E1024 13:17:57.548039       1 leaderelection.go:347] error retrieving resource lock openshift-machine-api/cluster-baremetal-operator: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-machine-api/leases/cluster-baremetal-operator": context deadline exceeded
2024-10-24T13:17:57.548255842Z I1024 13:17:57.548236       1 leaderelection.go:285] failed to renew lease openshift-machine-api/cluster-baremetal-operator: timed out waiting for the condition
2024-10-24T13:18:04.569901054Z E1024 13:18:04.569856       1 leaderelection.go:308] Failed to release lock: rpc error: code = DeadlineExceeded desc = context deadline exceeded
2024-10-24T13:18:04.570032653Z E1024 13:18:04.570016       1 main.go:182] "problem running manager" err="leader election lost"
