2024-10-24T13:18:06.239669378Z I1024 13:18:06.239513       1 cmd.go:250] Using service-serving-cert provided certificates
2024-10-24T13:18:06.239669378Z I1024 13:18:06.239631       1 leaderelection.go:121] The leader election gives 4 retries and allows for 30s of clock skew. The kube-apiserver downtime tolerance is 78s. Worst non-graceful lease acquisition is 2m43s. Worst graceful lease acquisition is {26s}.
2024-10-24T13:18:06.240175278Z I1024 13:18:06.240123       1 observer_polling.go:159] Starting file observer
2024-10-24T13:19:00.512234246Z I1024 13:19:00.512175       1 builder.go:298] kube-controller-manager-operator version v0.0.0-alpha.0-1368-ge3e3ce7-e3e3ce7ab
2024-10-24T13:19:01.157194305Z I1024 13:19:01.157147       1 secure_serving.go:57] Forcing use of http/1.1 only
2024-10-24T13:19:01.157279805Z W1024 13:19:01.157265       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256' detected.
2024-10-24T13:19:01.157314004Z W1024 13:19:01.157302       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256' detected.
2024-10-24T13:19:01.157351955Z W1024 13:19:01.157340       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_128_GCM_SHA256' detected.
2024-10-24T13:19:01.157379035Z W1024 13:19:01.157368       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_256_GCM_SHA384' detected.
2024-10-24T13:19:01.157408055Z W1024 13:19:01.157397       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_128_CBC_SHA' detected.
2024-10-24T13:19:01.157442364Z W1024 13:19:01.157431       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_256_CBC_SHA' detected.
2024-10-24T13:19:01.163233344Z I1024 13:19:01.163169       1 leaderelection.go:254] attempting to acquire leader lease openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock...
2024-10-24T13:19:01.164745425Z I1024 13:19:01.164687       1 requestheader_controller.go:172] Starting RequestHeaderAuthRequestController
2024-10-24T13:19:01.164907864Z I1024 13:19:01.164886       1 shared_informer.go:313] Waiting for caches to sync for RequestHeaderAuthRequestController
2024-10-24T13:19:01.164965644Z I1024 13:19:01.164721       1 configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2024-10-24T13:19:01.164965644Z I1024 13:19:01.164954       1 shared_informer.go:313] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-10-24T13:19:01.164989655Z I1024 13:19:01.164746       1 configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2024-10-24T13:19:01.164989655Z I1024 13:19:01.164979       1 shared_informer.go:313] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-10-24T13:19:01.165159734Z I1024 13:19:01.165113       1 dynamic_serving_content.go:135] "Starting controller" name="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key"
2024-10-24T13:19:01.165227305Z I1024 13:19:01.165192       1 secure_serving.go:213] Serving securely on [::]:8443
2024-10-24T13:19:01.165263414Z I1024 13:19:01.165240       1 tlsconfig.go:243] "Starting DynamicServingCertificateController"
2024-10-24T13:19:01.266077443Z I1024 13:19:01.266014       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-10-24T13:19:01.266077443Z I1024 13:19:01.266034       1 shared_informer.go:320] Caches are synced for RequestHeaderAuthRequestController
2024-10-24T13:19:01.266142903Z I1024 13:19:01.266111       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-10-24T13:21:57.649128543Z I1024 13:21:57.649072       1 leaderelection.go:268] successfully acquired lease openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock
2024-10-24T13:21:57.651098472Z I1024 13:21:57.651017       1 event.go:377] Event(v1.ObjectReference{Kind:"Lease", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator-lock", UID:"143a3207-feab-4e4d-8f17-72e73240d378", APIVersion:"coordination.k8s.io/v1", ResourceVersion:"23418", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' kube-controller-manager-operator-7c885b8899-z89zf_7b42a41a-ced4-472b-876b-0679545bc14f became leader
2024-10-24T13:21:57.651126152Z I1024 13:21:57.651117       1 simple_featuregate_reader.go:171] Starting feature-gate-detector
2024-10-24T13:21:57.663717243Z I1024 13:21:57.663651       1 starter.go:97] FeatureGates initialized: knownFeatureGates=[AWSEFSDriverVolumeMetrics AdminNetworkPolicy AlibabaPlatform AzureWorkloadIdentity BareMetalLoadBalancer BuildCSIVolumes ChunkSizeMiB CloudDualStackNodeIPs DisableKubeletCloudCredentialProviders GCPLabelsTags HardwareSpeed IngressControllerLBSubnetsAWS KMSv1 ManagedBootImages MetricsServer MultiArchInstallAWS MultiArchInstallGCP NetworkDiagnosticsConfig NetworkLiveMigration NodeDisruptionPolicy OpenShiftPodSecurityAdmission PrivateHostedZoneAWS SetEIPForNLBIngressController VSphereControlPlaneMachineSet VSphereDriverConfiguration VSphereStaticIPs ValidatingAdmissionPolicy AWSClusterHostedDNS AdditionalRoutingCapabilities AutomatedEtcdBackup BootcNodeManagement CSIDriverSharedResource ClusterAPIInstall ClusterAPIInstallIBMCloud ClusterMonitoringConfig DNSNameResolver DynamicResourceAllocation EtcdBackendQuota EventedPLEG Example ExternalOIDC GCPClusterHostedDNS GatewayAPI ImageStreamImportMode IngressControllerDynamicConfigurationManager InsightsConfig InsightsConfigAPI InsightsOnDemandDataGather InsightsRuntimeExtractor MachineAPIMigration MachineAPIOperatorDisableMachineHealthCheckController MachineAPIProviderOpenStack MachineConfigNodes ManagedBootImagesAWS MaxUnavailableStatefulSet MetricsCollectionProfiles MixedCPUsAllocation MultiArchInstallAzure NetworkSegmentation NewOLM NodeSwap OVNObservability OnClusterBuild PersistentIPsForVirtualization PinnedImages PlatformOperators ProcMountType RouteAdvertisements RouteExternalCertificate ServiceAccountTokenNodeBinding SignatureStores SigstoreImageVerification TranslateStreamCloseWebsocketRequests UpgradeStatus UserNamespacesPodSecurityStandards UserNamespacesSupport VSphereMultiNetworks VSphereMultiVCenters VolumeGroupSnapshot]
2024-10-24T13:21:57.663927633Z I1024 13:21:57.663888       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'FeatureGatesInitialized' FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AWSEFSDriverVolumeMetrics", "AdminNetworkPolicy", "AlibabaPlatform", "AzureWorkloadIdentity", "BareMetalLoadBalancer", "BuildCSIVolumes", "ChunkSizeMiB", "CloudDualStackNodeIPs", "DisableKubeletCloudCredentialProviders", "GCPLabelsTags", "HardwareSpeed", "IngressControllerLBSubnetsAWS", "KMSv1", "ManagedBootImages", "MetricsServer", "MultiArchInstallAWS", "MultiArchInstallGCP", "NetworkDiagnosticsConfig", "NetworkLiveMigration", "NodeDisruptionPolicy", "OpenShiftPodSecurityAdmission", "PrivateHostedZoneAWS", "SetEIPForNLBIngressController", "VSphereControlPlaneMachineSet", "VSphereDriverConfiguration", "VSphereStaticIPs", "ValidatingAdmissionPolicy"}, Disabled:[]v1.FeatureGateName{"AWSClusterHostedDNS", "AdditionalRoutingCapabilities", "AutomatedEtcdBackup", "BootcNodeManagement", "CSIDriverSharedResource", "ClusterAPIInstall", "ClusterAPIInstallIBMCloud", "ClusterMonitoringConfig", "DNSNameResolver", "DynamicResourceAllocation", "EtcdBackendQuota", "EventedPLEG", "Example", "ExternalOIDC", "GCPClusterHostedDNS", "GatewayAPI", "ImageStreamImportMode", "IngressControllerDynamicConfigurationManager", "InsightsConfig", "InsightsConfigAPI", "InsightsOnDemandDataGather", "InsightsRuntimeExtractor", "MachineAPIMigration", "MachineAPIOperatorDisableMachineHealthCheckController", "MachineAPIProviderOpenStack", "MachineConfigNodes", "ManagedBootImagesAWS", "MaxUnavailableStatefulSet", "MetricsCollectionProfiles", "MixedCPUsAllocation", "MultiArchInstallAzure", "NetworkSegmentation", "NewOLM", "NodeSwap", "OVNObservability", "OnClusterBuild", "PersistentIPsForVirtualization", "PinnedImages", "PlatformOperators", "ProcMountType", "RouteAdvertisements", "RouteExternalCertificate", "ServiceAccountTokenNodeBinding", "SignatureStores", "SigstoreImageVerification", "TranslateStreamCloseWebsocketRequests", "UpgradeStatus", "UserNamespacesPodSecurityStandards", "UserNamespacesSupport", "VSphereMultiNetworks", "VSphereMultiVCenters", "VolumeGroupSnapshot"}}
2024-10-24T13:21:57.697341145Z I1024 13:21:57.697295       1 base_controller.go:68] Waiting for caches to sync for GarbageCollectorWatcherController
2024-10-24T13:21:57.698247935Z I1024 13:21:57.698224       1 base_controller.go:68] Waiting for caches to sync for TargetConfigController
2024-10-24T13:21:57.698352045Z I1024 13:21:57.698309       1 base_controller.go:68] Waiting for caches to sync for MissingStaticPodController
2024-10-24T13:21:57.698352045Z I1024 13:21:57.698328       1 base_controller.go:68] Waiting for caches to sync for kube-controller-manager
2024-10-24T13:21:57.698371834Z I1024 13:21:57.698359       1 base_controller.go:68] Waiting for caches to sync for ConfigObserver
2024-10-24T13:21:57.698762255Z I1024 13:21:57.698708       1 base_controller.go:68] Waiting for caches to sync for SATokenSignerController
2024-10-24T13:21:57.698789764Z I1024 13:21:57.698759       1 base_controller.go:68] Waiting for caches to sync for CertRotationController
2024-10-24T13:21:57.698802244Z I1024 13:21:57.698786       1 base_controller.go:68] Waiting for caches to sync for KubeControllerManagerStaticResources-StaticResources
2024-10-24T13:21:57.698853454Z I1024 13:21:57.698834       1 base_controller.go:68] Waiting for caches to sync for GuardController
2024-10-24T13:21:57.698867874Z I1024 13:21:57.698862       1 base_controller.go:68] Waiting for caches to sync for RevisionController
2024-10-24T13:21:57.698946594Z I1024 13:21:57.698846       1 base_controller.go:68] Waiting for caches to sync for WorkerLatencyProfile
2024-10-24T13:21:57.699039754Z I1024 13:21:57.698904       1 base_controller.go:68] Waiting for caches to sync for NodeController
2024-10-24T13:21:57.699039754Z I1024 13:21:57.698918       1 base_controller.go:68] Waiting for caches to sync for kube-controller-manager-InstallerState
2024-10-24T13:21:57.699077374Z I1024 13:21:57.698928       1 base_controller.go:68] Waiting for caches to sync for StaticPodStateController
2024-10-24T13:21:57.699077374Z I1024 13:21:57.698937       1 base_controller.go:68] Waiting for caches to sync for PruneController
2024-10-24T13:21:57.699077374Z I1024 13:21:57.699050       1 base_controller.go:68] Waiting for caches to sync for InstallerController
2024-10-24T13:21:57.699077374Z I1024 13:21:57.698953       1 base_controller.go:68] Waiting for caches to sync for LoggingSyncer
2024-10-24T13:21:57.699092135Z I1024 13:21:57.698970       1 base_controller.go:68] Waiting for caches to sync for StatusSyncer_kube-controller-manager
2024-10-24T13:21:57.699092135Z I1024 13:21:57.698975       1 base_controller.go:68] Waiting for caches to sync for UnsupportedConfigOverridesController
2024-10-24T13:21:57.699129704Z I1024 13:21:57.699110       1 base_controller.go:68] Waiting for caches to sync for BackingResourceController-StaticResources
2024-10-24T13:21:57.798218028Z I1024 13:21:57.798135       1 base_controller.go:74] Caches are synced for GarbageCollectorWatcherController 
2024-10-24T13:21:57.798218028Z I1024 13:21:57.798186       1 base_controller.go:111] Starting #1 worker of GarbageCollectorWatcherController controller ...
2024-10-24T13:21:57.799320279Z I1024 13:21:57.799288       1 base_controller.go:74] Caches are synced for UnsupportedConfigOverridesController 
2024-10-24T13:21:57.799393458Z I1024 13:21:57.799361       1 base_controller.go:74] Caches are synced for LoggingSyncer 
2024-10-24T13:21:57.799393458Z I1024 13:21:57.799371       1 base_controller.go:111] Starting #1 worker of UnsupportedConfigOverridesController controller ...
2024-10-24T13:21:57.799393458Z I1024 13:21:57.799382       1 base_controller.go:111] Starting #1 worker of LoggingSyncer controller ...
2024-10-24T13:21:57.799822408Z I1024 13:21:57.799794       1 base_controller.go:74] Caches are synced for StatusSyncer_kube-controller-manager 
2024-10-24T13:21:57.799822408Z I1024 13:21:57.799812       1 base_controller.go:74] Caches are synced for PruneController 
2024-10-24T13:21:57.799861118Z I1024 13:21:57.799337       1 base_controller.go:74] Caches are synced for WorkerLatencyProfile 
2024-10-24T13:21:57.799861118Z I1024 13:21:57.799823       1 base_controller.go:111] Starting #1 worker of PruneController controller ...
2024-10-24T13:21:57.799861118Z I1024 13:21:57.799826       1 base_controller.go:111] Starting #1 worker of WorkerLatencyProfile controller ...
2024-10-24T13:21:57.799934718Z I1024 13:21:57.799813       1 base_controller.go:111] Starting #1 worker of StatusSyncer_kube-controller-manager controller ...
2024-10-24T13:21:57.801040288Z I1024 13:21:57.800992       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:21:57.802122248Z I1024 13:21:57.802092       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:21:57.818045419Z I1024 13:21:57.817974       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again" to "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9",Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 7" to "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 7" to "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9"
2024-10-24T13:21:57.890255372Z I1024 13:21:57.890194       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:57.899829992Z I1024 13:21:57.899717       1 base_controller.go:74] Caches are synced for CertRotationController 
2024-10-24T13:21:57.899901332Z I1024 13:21:57.899823       1 base_controller.go:111] Starting #1 worker of CertRotationController controller ...
2024-10-24T13:21:58.092028609Z I1024 13:21:58.091980       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:58.099321470Z I1024 13:21:58.099284       1 base_controller.go:74] Caches are synced for RevisionController 
2024-10-24T13:21:58.099391980Z I1024 13:21:58.099374       1 base_controller.go:111] Starting #1 worker of RevisionController controller ...
2024-10-24T13:21:58.101996890Z I1024 13:21:58.101918       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 10 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:21:58.290412357Z I1024 13:21:58.290352       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:58.299941817Z I1024 13:21:58.299907       1 base_controller.go:74] Caches are synced for NodeController 
2024-10-24T13:21:58.300027288Z I1024 13:21:58.300010       1 base_controller.go:111] Starting #1 worker of NodeController controller ...
2024-10-24T13:21:58.490029255Z I1024 13:21:58.489969       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:58.690573023Z I1024 13:21:58.690524       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:58.699065043Z I1024 13:21:58.699004       1 base_controller.go:74] Caches are synced for ConfigObserver 
2024-10-24T13:21:58.699065043Z I1024 13:21:58.699029       1 base_controller.go:111] Starting #1 worker of ConfigObserver controller ...
2024-10-24T13:21:58.886634500Z I1024 13:21:58.886586       1 request.go:700] Waited for 1.188283656s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets?limit=500&resourceVersion=0
2024-10-24T13:21:58.889738560Z I1024 13:21:58.889694       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:58.899236660Z I1024 13:21:58.899210       1 base_controller.go:74] Caches are synced for SATokenSignerController 
2024-10-24T13:21:58.899236660Z I1024 13:21:58.899229       1 base_controller.go:111] Starting #1 worker of SATokenSignerController controller ...
2024-10-24T13:21:59.095778348Z I1024 13:21:59.095315       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:59.098987198Z I1024 13:21:59.098955       1 base_controller.go:74] Caches are synced for kube-controller-manager 
2024-10-24T13:21:59.099046688Z I1024 13:21:59.099032       1 base_controller.go:111] Starting #1 worker of kube-controller-manager controller ...
2024-10-24T13:21:59.289632655Z I1024 13:21:59.289565       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:59.489272863Z I1024 13:21:59.489209       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:59.498977564Z I1024 13:21:59.498908       1 base_controller.go:74] Caches are synced for TargetConfigController 
2024-10-24T13:21:59.498977564Z I1024 13:21:59.498938       1 base_controller.go:111] Starting #1 worker of TargetConfigController controller ...
2024-10-24T13:21:59.499191824Z I1024 13:21:59.499137       1 base_controller.go:74] Caches are synced for BackingResourceController-StaticResources 
2024-10-24T13:21:59.499191824Z I1024 13:21:59.499159       1 base_controller.go:111] Starting #1 worker of BackingResourceController-StaticResources controller ...
2024-10-24T13:21:59.691026931Z I1024 13:21:59.690972       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:59.699415411Z I1024 13:21:59.699379       1 base_controller.go:74] Caches are synced for StaticPodStateController 
2024-10-24T13:21:59.699415411Z I1024 13:21:59.699399       1 base_controller.go:74] Caches are synced for kube-controller-manager-InstallerState 
2024-10-24T13:21:59.699415411Z I1024 13:21:59.699407       1 base_controller.go:111] Starting #1 worker of kube-controller-manager-InstallerState controller ...
2024-10-24T13:21:59.699453421Z I1024 13:21:59.699399       1 base_controller.go:111] Starting #1 worker of StaticPodStateController controller ...
2024-10-24T13:21:59.699453421Z I1024 13:21:59.699421       1 base_controller.go:74] Caches are synced for InstallerController 
2024-10-24T13:21:59.699453421Z I1024 13:21:59.699436       1 base_controller.go:111] Starting #1 worker of InstallerController controller ...
2024-10-24T13:21:59.699499401Z I1024 13:21:59.699455       1 base_controller.go:74] Caches are synced for MissingStaticPodController 
2024-10-24T13:21:59.699499401Z I1024 13:21:59.699489       1 base_controller.go:111] Starting #1 worker of MissingStaticPodController controller ...
2024-10-24T13:21:59.699571931Z I1024 13:21:59.699526       1 base_controller.go:74] Caches are synced for GuardController 
2024-10-24T13:21:59.699653971Z I1024 13:21:59.699637       1 base_controller.go:111] Starting #1 worker of GuardController controller ...
2024-10-24T13:21:59.887182939Z I1024 13:21:59.887109       1 request.go:700] Waited for 2.188270125s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts?limit=500&resourceVersion=0
2024-10-24T13:21:59.890393458Z I1024 13:21:59.890352       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:59.898959779Z I1024 13:21:59.898918       1 base_controller.go:74] Caches are synced for KubeControllerManagerStaticResources-StaticResources 
2024-10-24T13:21:59.898959779Z I1024 13:21:59.898940       1 base_controller.go:111] Starting #1 worker of KubeControllerManagerStaticResources-StaticResources controller ...
2024-10-24T13:22:00.107171707Z I1024 13:22:00.107121       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:01.086723974Z I1024 13:22:01.086672       1 request.go:700] Waited for 1.386784654s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-8-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:01.197771899Z I1024 13:22:01.197691       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:22:01.197771899Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:22:01.197771899Z  CurrentRevision: (int32) 0,
2024-10-24T13:22:01.197771899Z  TargetRevision: (int32) 9,
2024-10-24T13:22:01.197771899Z  LastFailedRevision: (int32) 4,
2024-10-24T13:22:01.197771899Z  LastFailedTime: (*v1.Time)(0xc001a0cf18)(2024-10-24 13:11:52 +0000 UTC),
2024-10-24T13:22:01.197771899Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:22:01.197771899Z  LastFailedCount: (int) 1,
2024-10-24T13:22:01.197771899Z  LastFallbackCount: (int) 0,
2024-10-24T13:22:01.197771899Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:22:01.197771899Z   (string) (len=2059) "installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:22:01.197771899Z  }
2024-10-24T13:22:01.197771899Z }
2024-10-24T13:22:01.197771899Z  because new revision pending
2024-10-24T13:22:01.263275741Z I1024 13:22:01.263211       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:01.405386807Z I1024 13:22:01.405347       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:22:01.405627686Z I1024 13:22:01.405574       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:01.456961399Z I1024 13:22:01.456866       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9" to "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:22:01.940166197Z I1024 13:22:01.940108       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:01.940239747Z I1024 13:22:01.940106       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-manager-pod-10 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:22:02.086933703Z I1024 13:22:02.086846       1 request.go:700] Waited for 1.792698629s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/default/endpoints/kubernetes
2024-10-24T13:22:02.108775784Z I1024 13:22:02.108695       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerOK' found expected kube-apiserver endpoints
2024-10-24T13:22:03.087350821Z I1024 13:22:03.087226       1 request.go:700] Waited for 1.58096948s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:22:03.337012191Z I1024 13:22:03.336955       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:03.337012191Z I1024 13:22:03.336956       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-10 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:22:04.286574817Z I1024 13:22:04.286506       1 request.go:700] Waited for 1.389978633s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods
2024-10-24T13:22:04.323023118Z I1024 13:22:04.322958       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-9-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:22:04.696597033Z I1024 13:22:04.696537       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cluster-policy-controller-config-10 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:22:04.696967603Z I1024 13:22:04.696922       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:05.287115675Z I1024 13:22:05.287077       1 request.go:700] Waited for 1.187536345s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:22:05.495901113Z I1024 13:22:05.495820       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 9, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:22:06.103666576Z I1024 13:22:06.103586       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:06.120127527Z I1024 13:22:06.120060       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/controller-manager-kubeconfig-10 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:22:06.486738091Z I1024 13:22:06.486701       1 request.go:700] Waited for 1.379424513s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps/csr-signer-ca
2024-10-24T13:22:07.496176550Z I1024 13:22:07.496054       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:07.496176550Z I1024 13:22:07.496091       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-cert-syncer-kubeconfig-10 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:22:07.687230947Z I1024 13:22:07.687161       1 request.go:700] Waited for 1.394487593s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller
2024-10-24T13:22:08.297397430Z I1024 13:22:08.297327       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 9, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:22:08.701820556Z I1024 13:22:08.701720       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-10 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:22:08.705097206Z I1024 13:22:08.702103       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:08.886483513Z I1024 13:22:08.886279       1 request.go:700] Waited for 1.185901595s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client
2024-10-24T13:22:09.790691798Z W1024 13:22:09.790621       1 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
2024-10-24T13:22:09.791012628Z I1024 13:22:09.790968       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:22:09.792328658Z W1024 13:22:09.792258       1 dynamic_operator_client.go:355] .status.conditions["GuardControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:22:09.886551301Z I1024 13:22:09.886486       1 request.go:700] Waited for 1.347960312s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-10-24T13:22:09.913387942Z I1024 13:22:09.913321       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:09.913713932Z I1024 13:22:09.913681       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:22:09.985176205Z I1024 13:22:09.985092       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded changed from True to False ("NodeControllerDegraded: All master nodes are ready")
2024-10-24T13:22:10.106454080Z I1024 13:22:10.105231       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/service-ca-10 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:22:10.106454080Z I1024 13:22:10.105459       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:10.887255090Z I1024 13:22:10.887153       1 request.go:700] Waited for 1.390054013s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-9-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:10.900980700Z I1024 13:22:10.900603       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 9, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:22:11.699058691Z I1024 13:22:11.698990       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/recycler-config-10 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:22:11.700092361Z I1024 13:22:11.700043       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:12.086897485Z I1024 13:22:12.086841       1 request.go:700] Waited for 1.57267765s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/csr-signer
2024-10-24T13:22:13.286606381Z I1024 13:22:13.286541       1 request.go:700] Waited for 1.58779903s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets
2024-10-24T13:22:13.310882163Z I1024 13:22:13.310693       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/service-account-private-key-10 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:22:14.118139283Z I1024 13:22:14.117615       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 9, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:22:14.486981578Z I1024 13:22:14.486932       1 request.go:700] Waited for 1.470984756s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:14.699483575Z I1024 13:22:14.699424       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-10 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:22:15.487093896Z I1024 13:22:15.487027       1 request.go:700] Waited for 1.367954293s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-9-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:15.694883844Z I1024 13:22:15.694840       1 core.go:220] Pod "openshift-kube-controller-manager/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2" changes: {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{"k8s.ovn.org/pod-networks":null,"k8s.v1.cni.cncf.io/network-status":null,"target.workload.openshift.io/management":"{\"effect\": \"PreferredDuringScheduling\"}"},"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null},"spec":{"containers":[{"args":["-c","# properly handle TERM and exit as soon as it is signaled\nset -euo pipefail\ntrap 'jobs -p | xargs -r kill; exit 0' TERM\nsleep infinity \u0026 wait\n"],"command":["/bin/bash"],"image":"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:39eb55fbaba0601f5bf36a2eaccc93fd172d1ab7d7d74ee36d36c9f29f7dd61b","imagePullPolicy":"IfNotPresent","name":"guard","readinessProbe":{"failureThreshold":3,"httpGet":{"host":"10.0.0.6","path":"healthz","port":10257,"scheme":"HTTPS"},"periodSeconds":5,"successThreshold":1,"timeoutSeconds":5},"resources":{"requests":{"cpu":"10m","memory":"5Mi"}},"terminationMessagePolicy":"FallbackToLogsOnError"}],"dnsPolicy":null,"enableServiceLinks":null,"imagePullSecrets":null,"preemptionPolicy":null,"priority":null,"restartPolicy":null,"schedulerName":null,"securityContext":null,"serviceAccount":null,"serviceAccountName":null,"volumes":null},"status":{"conditions":null,"containerStatuses":null,"hostIP":null,"hostIPs":null,"phase":null,"podIP":null,"podIPs":null,"qosClass":null,"startTime":null}}
2024-10-24T13:22:15.898914271Z I1024 13:22:15.898857       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-10 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:22:16.687045972Z I1024 13:22:16.686983       1 request.go:700] Waited for 1.192849466s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-9-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:16.693456242Z I1024 13:22:16.693415       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 9, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:22:16.900321490Z I1024 13:22:16.900263       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-controller-manager because it changed
2024-10-24T13:22:17.095399057Z I1024 13:22:17.095356       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:17.096557957Z I1024 13:22:17.096511       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 10 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:22:17.097077237Z W1024 13:22:17.097035       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:22:17.097077237Z W1024 13:22:17.097055       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:22:17.128178078Z W1024 13:22:17.128109       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:22:17.128178078Z W1024 13:22:17.128138       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:22:17.131410779Z I1024 13:22:17.131369       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:18.086872685Z I1024 13:22:18.086804       1 request.go:700] Waited for 1.186457875s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:22:19.086907533Z I1024 13:22:19.086841       1 request.go:700] Waited for 1.383530323s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-9-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:19.095063194Z I1024 13:22:19.095005       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 9, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:22:19.121261024Z I1024 13:22:19.121211       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:19.122952435Z I1024 13:22:19.122843       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 10","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:22:19.138382395Z I1024 13:22:19.138341       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9" to "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 10",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9" to "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 10"
2024-10-24T13:22:20.286966509Z I1024 13:22:20.286910       1 request.go:700] Waited for 1.165621375s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-10-24T13:22:21.287124178Z I1024 13:22:21.287074       1 request.go:700] Waited for 1.192157296s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-9-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:21.303040268Z I1024 13:22:21.302992       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:22:21.303040268Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:22:21.303040268Z  CurrentRevision: (int32) 0,
2024-10-24T13:22:21.303040268Z  TargetRevision: (int32) 10,
2024-10-24T13:22:21.303040268Z  LastFailedRevision: (int32) 4,
2024-10-24T13:22:21.303040268Z  LastFailedTime: (*v1.Time)(0xc000e112c0)(2024-10-24 13:11:52 +0000 UTC),
2024-10-24T13:22:21.303040268Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:22:21.303040268Z  LastFailedCount: (int) 1,
2024-10-24T13:22:21.303040268Z  LastFallbackCount: (int) 0,
2024-10-24T13:22:21.303040268Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:22:21.303040268Z   (string) (len=2059) "installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:22:21.303040268Z  }
2024-10-24T13:22:21.303040268Z }
2024-10-24T13:22:21.303040268Z  because new revision pending
2024-10-24T13:22:21.337181860Z I1024 13:22:21.337119       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:22.486886184Z I1024 13:22:22.486831       1 request.go:700] Waited for 1.150848514s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-9-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:23.486900922Z I1024 13:22:23.486835       1 request.go:700] Waited for 1.377163633s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/config
2024-10-24T13:22:23.692668310Z I1024 13:22:23.692598       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:22:23.692668310Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:22:23.692668310Z  CurrentRevision: (int32) 0,
2024-10-24T13:22:23.692668310Z  TargetRevision: (int32) 10,
2024-10-24T13:22:23.692668310Z  LastFailedRevision: (int32) 4,
2024-10-24T13:22:23.692668310Z  LastFailedTime: (*v1.Time)(0xc001834510)(2024-10-24 13:11:52 +0000 UTC),
2024-10-24T13:22:23.692668310Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:22:23.692668310Z  LastFailedCount: (int) 1,
2024-10-24T13:22:23.692668310Z  LastFallbackCount: (int) 0,
2024-10-24T13:22:23.692668310Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:22:23.692668310Z   (string) (len=2059) "installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:22:23.692668310Z  }
2024-10-24T13:22:23.692668310Z }
2024-10-24T13:22:23.692668310Z  because new revision pending
2024-10-24T13:22:25.701509526Z I1024 13:22:25.701454       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:22:26.886635842Z I1024 13:22:26.886581       1 request.go:700] Waited for 1.185153025s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:22:26.892375223Z I1024 13:22:26.892342       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 10, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:22:27.886788881Z I1024 13:22:27.886698       1 request.go:700] Waited for 1.189419715s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:22:29.086397827Z I1024 13:22:29.086336       1 request.go:700] Waited for 1.188429806s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:22:29.298228564Z I1024 13:22:29.298169       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 10, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:22:30.086677385Z I1024 13:22:30.086595       1 request.go:700] Waited for 1.194426526s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps/csr-controller-ca
2024-10-24T13:22:31.311363472Z I1024 13:22:31.311316       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 10, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:22:39.496266375Z I1024 13:22:39.496206       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 10, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:22:41.096717367Z I1024 13:22:41.096640       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 10, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:23:19.885708383Z I1024 13:23:19.885649       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 10, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:23:22.269311708Z I1024 13:23:22.269249       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 10, but has not made progress because waiting for static pod of revision 10, found 8
2024-10-24T13:23:30.177918551Z I1024 13:23:30.177864       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 10, but has not made progress because waiting for static pod of revision 10, found 8
2024-10-24T13:23:33.073233467Z I1024 13:23:33.073171       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 10, but has not made progress because static pod is pending
2024-10-24T13:23:35.273798778Z I1024 13:23:35.273729       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 10, but has not made progress because static pod is pending
2024-10-24T13:23:37.274905025Z I1024 13:23:37.274842       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 10, but has not made progress because static pod is pending
2024-10-24T13:23:42.993197868Z I1024 13:23:42.993119       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 10, but has not made progress because static pod is pending
2024-10-24T13:23:59.500920569Z E1024 13:23:59.500854       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:59.503477609Z E1024 13:23:59.503432       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:59.509326859Z E1024 13:23:59.509288       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:59.513506709Z E1024 13:23:59.513447       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:59.521436989Z E1024 13:23:59.521384       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:59.527684269Z E1024 13:23:59.527646       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:59.543566880Z E1024 13:23:59.543528       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:59.552715990Z E1024 13:23:59.552689       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:59.585563150Z E1024 13:23:59.585527       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:59.597514411Z E1024 13:23:59.597473       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:59.700581273Z E1024 13:23:59.700509       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:59.701029433Z E1024 13:23:59.700999       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:59.707401743Z E1024 13:23:59.707374       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:59.901135958Z E1024 13:23:59.901082       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:59.901135958Z E1024 13:23:59.901087       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:00.102053472Z E1024 13:24:00.101994       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:00.301185437Z E1024 13:24:00.301114       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:00.301185437Z E1024 13:24:00.301118       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:00.623603664Z E1024 13:24:00.623544       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:00.703731766Z E1024 13:24:00.703680       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:00.901980721Z E1024 13:24:00.901917       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:01.266204330Z E1024 13:24:01.266145       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:01.502010475Z E1024 13:24:01.501910       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:01.703685340Z E1024 13:24:01.703627       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:02.103521449Z E1024 13:24:02.103461       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:02.301652053Z E1024 13:24:02.301604       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:02.549865099Z E1024 13:24:02.549801       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:02.904337797Z E1024 13:24:02.904280       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:03.301949276Z E1024 13:24:03.301900       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:03.912610140Z E1024 13:24:03.912546       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:04.105634295Z E1024 13:24:04.105578       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:04.502093414Z E1024 13:24:04.502037       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:04.905257643Z E1024 13:24:04.905196       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:05.112714018Z E1024 13:24:05.112644       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:05.503384507Z E1024 13:24:05.503319       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:06.301920906Z E1024 13:24:06.301872       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:06.903288930Z E1024 13:24:06.903227       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:07.506811344Z E1024 13:24:07.506715       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:07.707885078Z E1024 13:24:07.707691       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:24:07.708617938Z E1024 13:24:07.708545       1 leaderelection.go:436] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:07.904952123Z E1024 13:24:07.904899       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:08.303280672Z E1024 13:24:08.303235       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:09.302272135Z E1024 13:24:09.302217       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:09.702587325Z E1024 13:24:09.702520       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:10.235779287Z E1024 13:24:10.235715       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:10.506872783Z E1024 13:24:10.506804       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:11.103212817Z E1024 13:24:11.103134       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:12.902650429Z E1024 13:24:12.902577       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:12.904842229Z E1024 13:24:12.904788       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:13.505976852Z E1024 13:24:13.505905       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:14.188562948Z E1024 13:24:14.188487       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:14.424719244Z E1024 13:24:14.424663       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:16.305909537Z E1024 13:24:16.305833       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:16.753465667Z E1024 13:24:16.753408       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:19.506068781Z E1024 13:24:19.506001       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:20.477673473Z E1024 13:24:20.477614       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:21.878415906Z E1024 13:24:21.878361       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:22.706113805Z E1024 13:24:22.706030       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:24.106026247Z E1024 13:24:24.105949       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:24.667804610Z E1024 13:24:24.667727       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:26.106116603Z E1024 13:24:26.106047       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:29.306403997Z E1024 13:24:29.306331       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:32.123572162Z E1024 13:24:32.123500       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:32.505615691Z E1024 13:24:32.505538       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:33.710221419Z E1024 13:24:33.710115       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:24:33.711187529Z E1024 13:24:33.711135       1 leaderelection.go:436] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:36.273296168Z E1024 13:24:36.273226       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:25:24.591196907Z I1024 13:25:24.591118       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:26.345609091Z I1024 13:25:26.345540       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:28.143094184Z I1024 13:25:28.143027       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:29.208913520Z I1024 13:25:29.208837       1 reflector.go:368] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:29.918164848Z I1024 13:25:29.918088       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:32.344202479Z I1024 13:25:32.344121       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:32.720832078Z I1024 13:25:32.720782       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubecontrollermanagers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:32.722037178Z I1024 13:25:32.721973       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:32.743385688Z I1024 13:25:32.743338       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:33.740104875Z I1024 13:25:33.740039       1 request.go:700] Waited for 1.015723647s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:25:34.323887353Z I1024 13:25:34.323816       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:34.707626871Z I1024 13:25:34.707568       1 reflector.go:368] Caches populated for *v1.Proxy from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:35.346374589Z I1024 13:25:35.346295       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:25:35.346374589Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:25:35.346374589Z  CurrentRevision: (int32) 10,
2024-10-24T13:25:35.346374589Z  TargetRevision: (int32) 0,
2024-10-24T13:25:35.346374589Z  LastFailedRevision: (int32) 4,
2024-10-24T13:25:35.346374589Z  LastFailedTime: (*v1.Time)(0xc002408078)(2024-10-24 13:11:52 +0000 UTC),
2024-10-24T13:25:35.346374589Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:25:35.346374589Z  LastFailedCount: (int) 1,
2024-10-24T13:25:35.346374589Z  LastFallbackCount: (int) 0,
2024-10-24T13:25:35.346374589Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:25:35.346374589Z   (string) (len=2059) "installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:25:35.346374589Z  }
2024-10-24T13:25:35.346374589Z }
2024-10-24T13:25:35.346374589Z  because static pod is ready
2024-10-24T13:25:35.374993889Z I1024 13:25:35.374906       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 0 to 10 because static pod is ready
2024-10-24T13:25:35.376001859Z I1024 13:25:35.375973       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:35.376924929Z I1024 13:25:35.376878       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:35.391667469Z I1024 13:25:35.391612       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 10" to "NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 10" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10"
2024-10-24T13:25:36.740264764Z I1024 13:25:36.740202       1 request.go:700] Waited for 1.012881306s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts?resourceVersion=26244
2024-10-24T13:25:36.743478814Z I1024 13:25:36.743440       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:37.127393423Z I1024 13:25:37.127329       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:38.149387860Z I1024 13:25:38.149330       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:38.158675439Z E1024 13:25:38.158629       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:38.160354289Z I1024 13:25:38.160325       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:38.169596699Z E1024 13:25:38.169566       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:38.171152169Z I1024 13:25:38.171121       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:38.178516579Z E1024 13:25:38.178477       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:38.181323229Z I1024 13:25:38.181290       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:38.189123429Z E1024 13:25:38.189083       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:38.231461989Z I1024 13:25:38.231413       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:38.238900729Z E1024 13:25:38.238851       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:38.320781739Z I1024 13:25:38.320710       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:38.330208859Z E1024 13:25:38.330181       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:38.492451618Z I1024 13:25:38.492392       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:38.499889378Z E1024 13:25:38.499839       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:38.822013817Z I1024 13:25:38.821956       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:38.829271507Z E1024 13:25:38.829193       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:38.940130537Z I1024 13:25:38.940071       1 request.go:700] Waited for 1.073976777s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra/secrets?resourceVersion=26257
2024-10-24T13:25:38.944737847Z I1024 13:25:38.944709       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:39.345449315Z I1024 13:25:39.345370       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:39.471358065Z I1024 13:25:39.471302       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:39.480350735Z E1024 13:25:39.480278       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:39.940373483Z I1024 13:25:39.940309       1 request.go:700] Waited for 1.035301686s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/kube-system/configmaps?resourceVersion=26259
2024-10-24T13:25:39.943148163Z I1024 13:25:39.943099       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:40.762507030Z I1024 13:25:40.762451       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:40.772169910Z E1024 13:25:40.772131       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:40.951504420Z I1024 13:25:40.951444       1 installer_controller.go:534] node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 3 is the oldest and needs new revision 10
2024-10-24T13:25:40.951504420Z I1024 13:25:40.951486       1 installer_controller.go:542] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:25:40.951504420Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:25:40.951504420Z  CurrentRevision: (int32) 3,
2024-10-24T13:25:40.951504420Z  TargetRevision: (int32) 10,
2024-10-24T13:25:40.951504420Z  LastFailedRevision: (int32) 0,
2024-10-24T13:25:40.951504420Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:25:40.951504420Z  LastFailedReason: (string) "",
2024-10-24T13:25:40.951504420Z  LastFailedCount: (int) 0,
2024-10-24T13:25:40.951504420Z  LastFallbackCount: (int) 0,
2024-10-24T13:25:40.951504420Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:25:40.951504420Z }
2024-10-24T13:25:40.975978529Z I1024 13:25:40.975912       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 3 to 10 because node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 3 is the oldest
2024-10-24T13:25:40.976676659Z I1024 13:25:40.976629       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:40.977532839Z I1024 13:25:40.977510       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:40.987500259Z E1024 13:25:40.987467       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:42.456999144Z I1024 13:25:42.456926       1 reflector.go:368] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:42.539035704Z I1024 13:25:42.538961       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:42.773215343Z I1024 13:25:42.773098       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:25:43.334523681Z I1024 13:25:43.334456       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:43.354552091Z E1024 13:25:43.354490       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:43.356162301Z I1024 13:25:43.356102       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:43.366817731Z E1024 13:25:43.366772       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:43.550529490Z I1024 13:25:43.550460       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 10, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:25:46.666622080Z I1024 13:25:46.666555       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:47.944701605Z I1024 13:25:47.944607       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:49.345146210Z I1024 13:25:49.345090       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:50.143801377Z I1024 13:25:50.143717       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:50.304664397Z I1024 13:25:50.304586       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:50.739166696Z I1024 13:25:50.739094       1 reflector.go:368] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:50.762579785Z I1024 13:25:50.762522       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:51.543969022Z I1024 13:25:51.543898       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:53.597167955Z I1024 13:25:53.597074       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:53.604111195Z E1024 13:25:53.604040       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:53.925252554Z I1024 13:25:53.925147       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:54.461106012Z I1024 13:25:54.461047       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:55.742714018Z I1024 13:25:55.742658       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:56.942853504Z I1024 13:25:56.942675       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:57.786119471Z I1024 13:25:57.786056       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:57.943741400Z I1024 13:25:57.943677       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:57.998906030Z I1024 13:25:57.998833       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:59.347921675Z I1024 13:25:59.347865       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:26:00.739920050Z I1024 13:26:00.739874       1 request.go:700] Waited for 1.038989826s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:26:01.545918137Z I1024 13:26:01.545868       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 10, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:26:01.740291116Z I1024 13:26:01.740241       1 request.go:700] Waited for 1.193356986s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/serving-cert
2024-10-24T13:26:02.370434854Z I1024 13:26:02.370358       1 reflector.go:368] Caches populated for *v1.Role from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:26:03.546431950Z I1024 13:26:03.546366       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 10, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:26:05.143445885Z I1024 13:26:05.143387       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:26:05.344564454Z I1024 13:26:05.344486       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:26:06.540883100Z I1024 13:26:06.540743       1 request.go:700] Waited for 1.195046376s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:07.740124446Z I1024 13:26:07.740071       1 request.go:700] Waited for 1.190302016s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:07.745972376Z I1024 13:26:07.745906       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 10, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:26:09.739873739Z I1024 13:26:09.739832       1 request.go:700] Waited for 1.050273735s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps?resourceVersion=26259
2024-10-24T13:26:09.751968058Z I1024 13:26:09.751913       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:26:09.752256089Z I1024 13:26:09.752200       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:09.752537959Z I1024 13:26:09.752518       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:09.752761979Z I1024 13:26:09.752713       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:09.753027719Z I1024 13:26:09.753010       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:09.753249609Z I1024 13:26:09.753231       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:09.753475459Z I1024 13:26:09.753429       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:09.753648098Z I1024 13:26:09.753622       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:09.753885239Z I1024 13:26:09.753863       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:09.754100459Z I1024 13:26:09.754081       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:09.946727838Z I1024 13:26:09.946636       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 10, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:26:10.740865595Z I1024 13:26:10.740794       1 request.go:700] Waited for 1.190742676s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:11.945988221Z I1024 13:26:11.945921       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 10, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:26:15.352691599Z I1024 13:26:15.352624       1 reflector.go:368] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:26:18.140207770Z I1024 13:26:18.140143       1 request.go:700] Waited for 1.180969236s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:19.340478326Z I1024 13:26:19.340403       1 request.go:700] Waited for 1.015877887s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:26:20.358388172Z I1024 13:26:20.358336       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 10, but has not made progress because waiting for static pod of revision 10, found 3
2024-10-24T13:26:23.346936702Z I1024 13:26:23.346858       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 10, but has not made progress because waiting for static pod of revision 10, found 3
2024-10-24T13:26:30.940701426Z I1024 13:26:30.940602       1 request.go:700] Waited for 1.043479407s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/config
2024-10-24T13:26:32.141903751Z I1024 13:26:32.141858       1 request.go:700] Waited for 1.194383806s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/serving-cert
2024-10-24T13:26:32.353855850Z I1024 13:26:32.353773       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 10, but has not made progress because static pod is pending
2024-10-24T13:26:34.508888513Z I1024 13:26:34.508790       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:26:35.352477470Z I1024 13:26:35.352416       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 10, but has not made progress because static pod is pending
2024-10-24T13:26:35.540202819Z I1024 13:26:35.540150       1 request.go:700] Waited for 1.031750096s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps
2024-10-24T13:26:35.548940790Z I1024 13:26:35.548893       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:35.621485729Z I1024 13:26:35.621397       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:36.551712886Z I1024 13:26:36.551643       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:36.551825216Z I1024 13:26:36.551722       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-manager-pod-11 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:26:37.551533443Z I1024 13:26:37.551482       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:37.551672083Z I1024 13:26:37.551623       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-11 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:26:38.349162360Z I1024 13:26:38.349103       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 10, but has not made progress because static pod is pending
2024-10-24T13:26:38.549933740Z I1024 13:26:38.549881       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:38.550618490Z I1024 13:26:38.550565       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cluster-policy-controller-config-11 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:26:39.551673126Z I1024 13:26:39.551598       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:39.551673126Z I1024 13:26:39.551640       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/controller-manager-kubeconfig-11 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:26:40.340554293Z I1024 13:26:40.340483       1 request.go:700] Waited for 1.101820377s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:26:40.954951861Z I1024 13:26:40.954890       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-cert-syncer-kubeconfig-11 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:26:40.955206781Z I1024 13:26:40.955160       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:41.340917920Z I1024 13:26:41.340844       1 request.go:700] Waited for 1.393867325s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa
2024-10-24T13:26:42.149181117Z I1024 13:26:42.149127       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:26:42.149181117Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:26:42.149181117Z  CurrentRevision: (int32) 10,
2024-10-24T13:26:42.149181117Z  TargetRevision: (int32) 0,
2024-10-24T13:26:42.149181117Z  LastFailedRevision: (int32) 0,
2024-10-24T13:26:42.149181117Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:26:42.149181117Z  LastFailedReason: (string) "",
2024-10-24T13:26:42.149181117Z  LastFailedCount: (int) 0,
2024-10-24T13:26:42.149181117Z  LastFallbackCount: (int) 0,
2024-10-24T13:26:42.149181117Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:26:42.149181117Z }
2024-10-24T13:26:42.149181117Z  because static pod is ready
2024-10-24T13:26:42.175269847Z I1024 13:26:42.175169       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 3 to 10 because static pod is ready
2024-10-24T13:26:42.177315807Z I1024 13:26:42.177219       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:42.180269537Z I1024 13:26:42.179947       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 4; 2 nodes are at revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 4; 2 nodes are at revision 10","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:26:42.198329517Z I1024 13:26:42.198139       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10" to "NodeInstallerProgressing: 1 node is at revision 4; 2 nodes are at revision 10",Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 4; 1 node is at revision 10" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 4; 2 nodes are at revision 10"
2024-10-24T13:26:42.350738986Z I1024 13:26:42.350685       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:42.351318226Z I1024 13:26:42.351263       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-11 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:26:42.540867116Z I1024 13:26:42.540743       1 request.go:700] Waited for 1.391595485s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:43.739910031Z I1024 13:26:43.739848       1 request.go:700] Waited for 1.388788266s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps
2024-10-24T13:26:43.749230371Z I1024 13:26:43.749178       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:43.749987561Z I1024 13:26:43.749908       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/service-ca-11 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:26:44.739913308Z I1024 13:26:44.739852       1 request.go:700] Waited for 1.393114616s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:44.949733427Z I1024 13:26:44.949631       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/recycler-config-11 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:26:44.949733427Z I1024 13:26:44.949662       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:45.740331655Z I1024 13:26:45.740279       1 request.go:700] Waited for 1.191927116s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:45.947253384Z I1024 13:26:45.947182       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:26:45.947253384Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:26:45.947253384Z  CurrentRevision: (int32) 10,
2024-10-24T13:26:45.947253384Z  TargetRevision: (int32) 0,
2024-10-24T13:26:45.947253384Z  LastFailedRevision: (int32) 0,
2024-10-24T13:26:45.947253384Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:26:45.947253384Z  LastFailedReason: (string) "",
2024-10-24T13:26:45.947253384Z  LastFailedCount: (int) 0,
2024-10-24T13:26:45.947253384Z  LastFallbackCount: (int) 0,
2024-10-24T13:26:45.947253384Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:26:45.947253384Z }
2024-10-24T13:26:45.947253384Z  because static pod is ready
2024-10-24T13:26:46.152822733Z I1024 13:26:46.152716       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/service-account-private-key-11 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:26:46.740886491Z I1024 13:26:46.740824       1 request.go:700] Waited for 1.193868626s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/config
2024-10-24T13:26:47.352335419Z I1024 13:26:47.352200       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-11 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:26:47.940594827Z I1024 13:26:47.940505       1 request.go:700] Waited for 1.191905616s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/kube-controller-manager-pod
2024-10-24T13:26:48.355675716Z I1024 13:26:48.355614       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-11 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:26:49.348975022Z I1024 13:26:49.348909       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:49.349427062Z I1024 13:26:49.349367       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 11 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:26:49.350820923Z W1024 13:26:49.350741       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:26:49.350820923Z W1024 13:26:49.350778       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:26:49.374284422Z W1024 13:26:49.374214       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:26:49.374284422Z W1024 13:26:49.374244       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:26:49.375057702Z I1024 13:26:49.375025       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:50.540549948Z I1024 13:26:50.540471       1 request.go:700] Waited for 1.162801626s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:52.348044202Z I1024 13:26:52.347988       1 installer_controller.go:534] node ci-op-2fcpj5j6-f6035-2lklf-master-1 with revision 4 is the oldest and needs new revision 10
2024-10-24T13:26:52.348044202Z I1024 13:26:52.348033       1 installer_controller.go:542] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:26:52.348044202Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:26:52.348044202Z  CurrentRevision: (int32) 4,
2024-10-24T13:26:52.348044202Z  TargetRevision: (int32) 10,
2024-10-24T13:26:52.348044202Z  LastFailedRevision: (int32) 0,
2024-10-24T13:26:52.348044202Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:26:52.348044202Z  LastFailedReason: (string) "",
2024-10-24T13:26:52.348044202Z  LastFailedCount: (int) 0,
2024-10-24T13:26:52.348044202Z  LastFallbackCount: (int) 0,
2024-10-24T13:26:52.348044202Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:26:52.348044202Z }
2024-10-24T13:26:52.370317712Z I1024 13:26:52.370222       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 4 to 10 because node ci-op-2fcpj5j6-f6035-2lklf-master-1 with revision 4 is the oldest
2024-10-24T13:26:52.371591142Z I1024 13:26:52.371540       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:52.372272452Z I1024 13:26:52.372244       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 4; 2 nodes are at revision 10; 0 nodes have achieved new revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 4; 2 nodes are at revision 10; 0 nodes have achieved new revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:26:52.390373752Z I1024 13:26:52.390070       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 4; 2 nodes are at revision 10" to "NodeInstallerProgressing: 1 node is at revision 4; 2 nodes are at revision 10; 0 nodes have achieved new revision 11",Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 4; 2 nodes are at revision 10" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 4; 2 nodes are at revision 10; 0 nodes have achieved new revision 11"
2024-10-24T13:26:53.540842638Z I1024 13:26:53.540797       1 request.go:700] Waited for 1.139865566s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-10-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:26:54.548558085Z I1024 13:26:54.548498       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:26:54.548558085Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:26:54.548558085Z  CurrentRevision: (int32) 4,
2024-10-24T13:26:54.548558085Z  TargetRevision: (int32) 11,
2024-10-24T13:26:54.548558085Z  LastFailedRevision: (int32) 0,
2024-10-24T13:26:54.548558085Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:26:54.548558085Z  LastFailedReason: (string) "",
2024-10-24T13:26:54.548558085Z  LastFailedCount: (int) 0,
2024-10-24T13:26:54.548558085Z  LastFallbackCount: (int) 0,
2024-10-24T13:26:54.548558085Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:26:54.548558085Z }
2024-10-24T13:26:54.548558085Z  because new revision pending
2024-10-24T13:26:54.578227344Z I1024 13:26:54.578179       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:55.740872561Z I1024 13:26:55.740819       1 request.go:700] Waited for 1.160303516s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-10-24T13:26:56.756397587Z I1024 13:26:56.756297       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-11-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:26:57.747153704Z I1024 13:26:57.747097       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 11, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:26:57.940076363Z I1024 13:26:57.940021       1 request.go:700] Waited for 1.183872576s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:26:59.142534698Z I1024 13:26:59.142488       1 request.go:700] Waited for 1.188849636s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:27:00.147866294Z I1024 13:27:00.147805       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:27:00.541038173Z I1024 13:27:00.540956       1 request.go:700] Waited for 1.038035567s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-10-24T13:27:01.740397439Z I1024 13:27:01.740345       1 request.go:700] Waited for 1.390107915s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:27:02.547478706Z I1024 13:27:02.547408       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:27:59.504025066Z E1024 13:27:59.503965       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:59.506170366Z E1024 13:27:59.506133       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:59.512912156Z E1024 13:27:59.512821       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:59.515825466Z E1024 13:27:59.515796       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:59.524814706Z E1024 13:27:59.524784       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:59.530187446Z E1024 13:27:59.530135       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:59.547215116Z E1024 13:27:59.547179       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:59.554918646Z E1024 13:27:59.554867       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:59.590255496Z E1024 13:27:59.590209       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:59.600230666Z E1024 13:27:59.600189       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:59.703102715Z E1024 13:27:59.703042       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:59.703884465Z E1024 13:27:59.703829       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:59.711120625Z E1024 13:27:59.711072       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:59.905207704Z E1024 13:27:59.905139       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:59.905207704Z E1024 13:27:59.905191       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:00.104361043Z E1024 13:28:00.104288       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:00.304573762Z E1024 13:28:00.304512       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:00.304573762Z E1024 13:28:00.304512       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:00.626844730Z E1024 13:28:00.626781       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:00.706829239Z E1024 13:28:00.706769       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:00.904567688Z E1024 13:28:00.904489       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:01.269386815Z E1024 13:28:01.269316       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:01.504281404Z E1024 13:28:01.504221       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:01.707982063Z E1024 13:28:01.707921       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:01.802402962Z E1024 13:28:01.802320       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:28:01.803439282Z E1024 13:28:01.803326       1 leaderelection.go:436] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:02.106191780Z E1024 13:28:02.106132       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:02.305142929Z E1024 13:28:02.305030       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:02.551902078Z E1024 13:28:02.551859       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:02.907713335Z E1024 13:28:02.907645       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:03.304065422Z E1024 13:28:03.303995       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:03.906580749Z E1024 13:28:03.906527       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:04.109320808Z E1024 13:28:04.109276       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:04.504920375Z E1024 13:28:04.504835       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:04.908826092Z E1024 13:28:04.908723       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:05.114525851Z E1024 13:28:05.114472       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:05.505743269Z E1024 13:28:05.505695       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:06.304459194Z E1024 13:28:06.304396       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:06.905888790Z E1024 13:28:06.905831       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:07.509466236Z E1024 13:28:07.509394       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:07.907506634Z E1024 13:28:07.907460       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:08.305787792Z E1024 13:28:08.305700       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:09.304548406Z E1024 13:28:09.304487       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:09.706649513Z E1024 13:28:09.706595       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:10.237945910Z E1024 13:28:10.237870       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:10.510991508Z E1024 13:28:10.510916       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:11.106277205Z E1024 13:28:11.106211       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:12.906634465Z E1024 13:28:12.906560       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:12.908268955Z E1024 13:28:12.908180       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:13.509552971Z E1024 13:28:13.509467       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:14.192054577Z E1024 13:28:14.191992       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:14.426956676Z E1024 13:28:14.426876       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:16.308818843Z E1024 13:28:16.308725       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:16.757839521Z E1024 13:28:16.757779       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:19.508898954Z E1024 13:28:19.508829       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:20.480815928Z E1024 13:28:20.480766       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:21.882445639Z E1024 13:28:21.882406       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:22.709297585Z E1024 13:28:22.709194       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:24.108828506Z E1024 13:28:24.108740       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:24.669169282Z E1024 13:28:24.669093       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:26.109512593Z E1024 13:28:26.109442       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:27.805200362Z E1024 13:28:27.805140       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:28:27.806150232Z E1024 13:28:27.806092       1 leaderelection.go:436] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:29.308367032Z E1024 13:28:29.308305       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:32.127207925Z E1024 13:28:32.127140       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:32.508694483Z E1024 13:28:32.508634       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:36.276270509Z E1024 13:28:36.276217       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:40.963842811Z E1024 13:28:40.963781       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:42.603219531Z E1024 13:28:42.603134       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:44.594240569Z E1024 13:28:44.594186       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:45.152300495Z E1024 13:28:45.152238       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:52.612695110Z E1024 13:28:52.612638       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:53.805010863Z E1024 13:28:53.804941       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:28:53.806023363Z E1024 13:28:53.805980       1 leaderelection.go:436] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:54.051025862Z E1024 13:28:54.050967       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:59.504638409Z E1024 13:28:59.504583       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:59.507051079Z E1024 13:28:59.507011       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:59.703950847Z E1024 13:28:59.703892       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:59.705836167Z E1024 13:28:59.705805       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:29:01.107915239Z E1024 13:29:01.107848       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:29:39.343481217Z I1024 13:29:39.343429       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:40.086913222Z I1024 13:29:40.086822       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:40.345511981Z I1024 13:29:40.345446       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:41.541154293Z I1024 13:29:41.541095       1 request.go:700] Waited for 1.194392761s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:29:42.740992255Z I1024 13:29:42.740917       1 request.go:700] Waited for 1.190926212s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:29:42.747742475Z I1024 13:29:42.747701       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-1" for revision 11 for the 1st time because installer pod failed: installer: i-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:42.747742475Z W1024 13:27:18.471628       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:42.747742475Z W1024 13:27:28.473946       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:42.747742475Z W1024 13:27:38.471439       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:42.747742475Z W1024 13:27:48.471152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:42.747742475Z W1024 13:27:58.471998       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:42.747742475Z W1024 13:27:58.472835       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:42.747742475Z F1024 13:27:58.472864       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:29:42.747866845Z I1024 13:29:42.747809       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer: i-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:42.747866845Z W1024 13:27:18.471628       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:42.747866845Z W1024 13:27:28.473946       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:42.747866845Z W1024 13:27:38.471439       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:42.747866845Z W1024 13:27:48.471152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:42.747866845Z W1024 13:27:58.471998       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:42.747866845Z W1024 13:27:58.472835       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:42.747866845Z F1024 13:27:58.472864       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:29:42.747933195Z I1024 13:29:42.747906       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:29:42.747933195Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:29:42.747933195Z  CurrentRevision: (int32) 4,
2024-10-24T13:29:42.747933195Z  TargetRevision: (int32) 11,
2024-10-24T13:29:42.747933195Z  LastFailedRevision: (int32) 11,
2024-10-24T13:29:42.747933195Z  LastFailedTime: (*v1.Time)(0xc00277d788)(2024-10-24 13:29:42.747687995 +0000 UTC m=+696.546771994),
2024-10-24T13:29:42.747933195Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:29:42.747933195Z  LastFailedCount: (int) 1,
2024-10-24T13:29:42.747933195Z  LastFallbackCount: (int) 0,
2024-10-24T13:29:42.747933195Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:29:42.747933195Z   (string) (len=2059) "installer: i-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:18.471628       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:28.473946       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:38.471439       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:48.471152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:58.471998       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:58.472835       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:27:58.472864       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:29:42.747933195Z  }
2024-10-24T13:29:42.747933195Z }
2024-10-24T13:29:42.747933195Z  because installer pod failed: installer: i-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:42.747933195Z W1024 13:27:18.471628       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:42.747933195Z W1024 13:27:28.473946       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:42.747933195Z W1024 13:27:38.471439       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:42.747933195Z W1024 13:27:48.471152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:42.747933195Z W1024 13:27:58.471998       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:42.747933195Z W1024 13:27:58.472835       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:42.747933195Z F1024 13:27:58.472864       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:29:43.719465119Z I1024 13:29:43.719398       1 reflector.go:368] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:44.540609744Z I1024 13:29:44.540554       1 request.go:700] Waited for 1.081096602s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets?resourceVersion=28951
2024-10-24T13:29:44.548716284Z I1024 13:29:44.548654       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:44.744042872Z I1024 13:29:44.743987       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:45.147861630Z I1024 13:29:45.147808       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-1" for revision 11 for the 1st time because installer pod failed: installer: i-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:45.147861630Z W1024 13:27:18.471628       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:45.147861630Z W1024 13:27:28.473946       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:45.147861630Z W1024 13:27:38.471439       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:45.147861630Z W1024 13:27:48.471152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:45.147861630Z W1024 13:27:58.471998       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:45.147861630Z W1024 13:27:58.472835       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:45.147861630Z F1024 13:27:58.472864       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:29:45.147919090Z I1024 13:29:45.147903       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:29:45.147919090Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:29:45.147919090Z  CurrentRevision: (int32) 4,
2024-10-24T13:29:45.147919090Z  TargetRevision: (int32) 11,
2024-10-24T13:29:45.147919090Z  LastFailedRevision: (int32) 11,
2024-10-24T13:29:45.147919090Z  LastFailedTime: (*v1.Time)(0xc0027ecae0)(2024-10-24 13:29:45.14778829 +0000 UTC m=+698.946872289),
2024-10-24T13:29:45.147919090Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:29:45.147919090Z  LastFailedCount: (int) 1,
2024-10-24T13:29:45.147919090Z  LastFallbackCount: (int) 0,
2024-10-24T13:29:45.147919090Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:29:45.147919090Z   (string) (len=2059) "installer: i-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:18.471628       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:28.473946       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:38.471439       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:48.471152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:58.471998       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:58.472835       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:27:58.472864       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:29:45.147919090Z  }
2024-10-24T13:29:45.147919090Z }
2024-10-24T13:29:45.147919090Z  because installer pod failed: installer: i-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:45.147919090Z W1024 13:27:18.471628       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:45.147919090Z W1024 13:27:28.473946       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:45.147919090Z W1024 13:27:38.471439       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:45.147919090Z W1024 13:27:48.471152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:45.147919090Z W1024 13:27:58.471998       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:45.147919090Z W1024 13:27:58.472835       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:45.147919090Z F1024 13:27:58.472864       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:29:45.148009890Z I1024 13:29:45.147925       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer: i-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:45.148009890Z W1024 13:27:18.471628       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:45.148009890Z W1024 13:27:28.473946       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:45.148009890Z W1024 13:27:38.471439       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:45.148009890Z W1024 13:27:48.471152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:45.148009890Z W1024 13:27:58.471998       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:45.148009890Z W1024 13:27:58.472835       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:45.148009890Z F1024 13:27:58.472864       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:29:45.188934449Z I1024 13:29:45.188905       1 helpers.go:260] lister was stale at resourceVersion=28884, live get showed resourceVersion=30178
2024-10-24T13:29:45.543914787Z I1024 13:29:45.543849       1 request.go:700] Waited for 1.372191771s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/config
2024-10-24T13:29:47.140471477Z I1024 13:29:47.140382       1 request.go:700] Waited for 1.059364193s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces?resourceVersion=28758
2024-10-24T13:29:47.145303257Z I1024 13:29:47.145212       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:47.148522087Z I1024 13:29:47.148474       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:47.348049265Z I1024 13:29:47.347997       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-1" for revision 11 for the 1st time because installer pod failed: installer: i-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:47.348049265Z W1024 13:27:18.471628       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:47.348049265Z W1024 13:27:28.473946       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:47.348049265Z W1024 13:27:38.471439       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:47.348049265Z W1024 13:27:48.471152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:47.348049265Z W1024 13:27:58.471998       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:47.348049265Z W1024 13:27:58.472835       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:47.348049265Z F1024 13:27:58.472864       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:29:47.348127115Z I1024 13:29:47.348077       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:29:47.348127115Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:29:47.348127115Z  CurrentRevision: (int32) 4,
2024-10-24T13:29:47.348127115Z  TargetRevision: (int32) 11,
2024-10-24T13:29:47.348127115Z  LastFailedRevision: (int32) 11,
2024-10-24T13:29:47.348127115Z  LastFailedTime: (*v1.Time)(0xc00261c210)(2024-10-24 13:29:47.347983855 +0000 UTC m=+701.147067854),
2024-10-24T13:29:47.348127115Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:29:47.348127115Z  LastFailedCount: (int) 1,
2024-10-24T13:29:47.348127115Z  LastFallbackCount: (int) 0,
2024-10-24T13:29:47.348127115Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:29:47.348127115Z   (string) (len=2059) "installer: i-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:18.471628       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:28.473946       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:38.471439       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:48.471152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:58.471998       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:58.472835       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:27:58.472864       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:29:47.348127115Z  }
2024-10-24T13:29:47.348127115Z }
2024-10-24T13:29:47.348127115Z  because installer pod failed: installer: i-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:47.348127115Z W1024 13:27:18.471628       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:47.348127115Z W1024 13:27:28.473946       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:47.348127115Z W1024 13:27:38.471439       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:47.348127115Z W1024 13:27:48.471152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:47.348127115Z W1024 13:27:58.471998       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:47.348127115Z W1024 13:27:58.472835       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:47.348127115Z F1024 13:27:58.472864       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:29:47.348258255Z I1024 13:29:47.348195       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer: i-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:47.348258255Z W1024 13:27:18.471628       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:47.348258255Z W1024 13:27:28.473946       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:47.348258255Z W1024 13:27:38.471439       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:47.348258255Z W1024 13:27:48.471152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:47.348258255Z W1024 13:27:58.471998       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:47.348258255Z W1024 13:27:58.472835       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:29:47.348258255Z F1024 13:27:58.472864       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:29:47.392839565Z I1024 13:29:47.392781       1 helpers.go:260] lister was stale at resourceVersion=28884, live get showed resourceVersion=30219
2024-10-24T13:29:47.801932482Z I1024 13:29:47.801879       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:48.122209411Z I1024 13:29:48.122125       1 reflector.go:368] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:50.143441208Z I1024 13:29:50.143346       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:50.324003696Z I1024 13:29:50.323943       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubecontrollermanagers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:50.325405706Z I1024 13:29:50.325368       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 11:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:18.471628       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:28.473946       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:38.471439       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:48.471152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:58.471998       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:58.472835       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:27:58.472864       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 4; 2 nodes are at revision 10; 0 nodes have achieved new revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 4; 2 nodes are at revision 10; 0 nodes have achieved new revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:29:50.326580477Z I1024 13:29:50.326557       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:29:50.338435246Z I1024 13:29:50.338389       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready" to "NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 11:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:18.471628       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:28.473946       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:38.471439       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:48.471152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:58.471998       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:58.472835       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:27:58.472864       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: "
2024-10-24T13:29:50.512484905Z I1024 13:29:50.512428       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:51.556570498Z I1024 13:29:51.556498       1 reflector.go:368] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:51.944073476Z I1024 13:29:51.943995       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:53.543520176Z I1024 13:29:53.543461       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:53.751178114Z I1024 13:29:53.751136       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:54.743296118Z I1024 13:29:54.743232       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:54.859212767Z I1024 13:29:54.859145       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:57.945883788Z I1024 13:29:57.945841       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:00.547410021Z I1024 13:30:00.547370       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:01.347675046Z I1024 13:30:01.347615       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:02.554589148Z I1024 13:30:02.554525       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:02.555079488Z I1024 13:30:02.555027       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:02.555402348Z I1024 13:30:02.555375       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:02.555627508Z I1024 13:30:02.555605       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:02.555868608Z I1024 13:30:02.555847       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:02.556096338Z I1024 13:30:02.556077       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:02.556297998Z I1024 13:30:02.556279       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:02.556535778Z I1024 13:30:02.556517       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:02.556745668Z I1024 13:30:02.556727       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:02.556975198Z I1024 13:30:02.556956       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:02.557193698Z I1024 13:30:02.557156       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:02.557369438Z I1024 13:30:02.557329       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.375040533Z I1024 13:30:03.374974       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:30:03.451580382Z I1024 13:30:03.451522       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:03.948589869Z I1024 13:30:03.948516       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 11, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:30:04.541143945Z I1024 13:30:04.541078       1 request.go:700] Waited for 1.165171763s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:30:05.181024621Z I1024 13:30:05.180976       1 reflector.go:368] Caches populated for *v1.Proxy from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:05.358701230Z I1024 13:30:05.358626       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:05.544462799Z I1024 13:30:05.544396       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:05.740420528Z I1024 13:30:05.740360       1 request.go:700] Waited for 1.58853639s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:30:06.740685911Z I1024 13:30:06.740638       1 request.go:700] Waited for 1.591667469s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:30:06.748476332Z I1024 13:30:06.748423       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:30:07.720895835Z I1024 13:30:07.720814       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:07.940810804Z I1024 13:30:07.940768       1 request.go:700] Waited for 1.191268112s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:30:08.947650257Z I1024 13:30:08.947573       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:30:10.344450428Z I1024 13:30:10.344398       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:12.146156677Z I1024 13:30:12.146096       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:12.206675177Z I1024 13:30:12.206632       1 reflector.go:368] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:21.527511187Z I1024 13:30:21.527449       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:24.203578121Z I1024 13:30:24.203503       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:27.439579590Z I1024 13:30:27.439497       1 reflector.go:368] Caches populated for *v1.Role from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:27.744205948Z I1024 13:30:27.744159       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:33.744455110Z I1024 13:30:33.744398       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:39.548234753Z I1024 13:30:39.548166       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 11, but has not made progress because waiting for static pod of revision 11, found 4
2024-10-24T13:30:41.952350288Z I1024 13:30:41.952296       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 11, but has not made progress because waiting for static pod of revision 11, found 4
2024-10-24T13:30:43.147182280Z I1024 13:30:43.147123       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:49.149054522Z I1024 13:30:49.148989       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 11, but has not made progress because waiting for static pod of revision 11, found 4
2024-10-24T13:30:51.549216637Z I1024 13:30:51.549152       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 11, but has not made progress because static pod is pending
2024-10-24T13:30:53.549055594Z I1024 13:30:53.548985       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 11, but has not made progress because static pod is pending
2024-10-24T13:30:54.974696215Z I1024 13:30:54.974650       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:55.351398662Z I1024 13:30:55.351331       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 11, but has not made progress because static pod is pending
2024-10-24T13:30:59.395162877Z I1024 13:30:59.395090       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 11, but has not made progress because static pod is pending
2024-10-24T13:31:00.566567079Z I1024 13:31:00.566509       1 request.go:700] Waited for 1.048912923s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/config
2024-10-24T13:31:01.766472121Z I1024 13:31:01.766420       1 request.go:700] Waited for 1.190840922s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/serving-cert
2024-10-24T13:31:02.374911507Z I1024 13:31:02.374851       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:31:02.374911507Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:31:02.374911507Z  CurrentRevision: (int32) 11,
2024-10-24T13:31:02.374911507Z  TargetRevision: (int32) 0,
2024-10-24T13:31:02.374911507Z  LastFailedRevision: (int32) 11,
2024-10-24T13:31:02.374911507Z  LastFailedTime: (*v1.Time)(0xc002445440)(2024-10-24 13:29:47 +0000 UTC),
2024-10-24T13:31:02.374911507Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:31:02.374911507Z  LastFailedCount: (int) 1,
2024-10-24T13:31:02.374911507Z  LastFallbackCount: (int) 0,
2024-10-24T13:31:02.374911507Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:31:02.374911507Z   (string) (len=2059) "installer: i-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:18.471628       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:28.473946       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:38.471439       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:48.471152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:58.471998       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:27:58.472835       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:27:58.472864       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:31:02.374911507Z  }
2024-10-24T13:31:02.374911507Z }
2024-10-24T13:31:02.374911507Z  because static pod is ready
2024-10-24T13:31:02.401870527Z I1024 13:31:02.401804       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 4 to 11 because static pod is ready
2024-10-24T13:31:02.403026297Z I1024 13:31:02.402983       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:31:02.405896557Z I1024 13:31:02.405861       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 2 nodes are at revision 10; 1 node is at revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 10; 1 node is at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:31:02.420838877Z I1024 13:31:02.419076       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 11:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:18.471628       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:28.473946       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:38.471439       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:48.471152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:58.471998       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:27:58.472835       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:27:58.472864       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: " to "NodeControllerDegraded: All master nodes are ready",Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 4; 2 nodes are at revision 10; 0 nodes have achieved new revision 11" to "NodeInstallerProgressing: 2 nodes are at revision 10; 1 node is at revision 11",Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 4; 2 nodes are at revision 10; 0 nodes have achieved new revision 11" to "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 10; 1 node is at revision 11"
2024-10-24T13:31:03.566133329Z I1024 13:31:03.566078       1 request.go:700] Waited for 1.162889792s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:31:05.384585238Z I1024 13:31:05.384531       1 gcwatcher_controller.go:250] Synced alerting rules cache
2024-10-24T13:31:05.384585238Z W1024 13:31:05.384573       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
2024-10-24T13:31:05.451385737Z I1024 13:31:05.451332       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:31:06.566654510Z I1024 13:31:06.566598       1 request.go:700] Waited for 1.115030603s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-10-24T13:31:08.774570886Z I1024 13:31:08.774518       1 installer_controller.go:534] node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 10 is the oldest and needs new revision 11
2024-10-24T13:31:08.774651856Z I1024 13:31:08.774574       1 installer_controller.go:542] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:31:08.774651856Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:31:08.774651856Z  CurrentRevision: (int32) 10,
2024-10-24T13:31:08.774651856Z  TargetRevision: (int32) 11,
2024-10-24T13:31:08.774651856Z  LastFailedRevision: (int32) 0,
2024-10-24T13:31:08.774651856Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:31:08.774651856Z  LastFailedReason: (string) "",
2024-10-24T13:31:08.774651856Z  LastFailedCount: (int) 0,
2024-10-24T13:31:08.774651856Z  LastFallbackCount: (int) 0,
2024-10-24T13:31:08.774651856Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:31:08.774651856Z }
2024-10-24T13:31:08.799850236Z I1024 13:31:08.799782       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 10 to 11 because node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 10 is the oldest
2024-10-24T13:31:08.801060666Z I1024 13:31:08.801026       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:31:09.966996018Z I1024 13:31:09.966912       1 request.go:700] Waited for 1.161737453s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-10-24T13:31:14.577171699Z I1024 13:31:14.577123       1 installer_controller.go:534] node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 10 is the oldest and needs new revision 11
2024-10-24T13:31:14.577270619Z I1024 13:31:14.577230       1 installer_controller.go:542] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:31:14.577270619Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:31:14.577270619Z  CurrentRevision: (int32) 10,
2024-10-24T13:31:14.577270619Z  TargetRevision: (int32) 11,
2024-10-24T13:31:14.577270619Z  LastFailedRevision: (int32) 0,
2024-10-24T13:31:14.577270619Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:31:14.577270619Z  LastFailedReason: (string) "",
2024-10-24T13:31:14.577270619Z  LastFailedCount: (int) 0,
2024-10-24T13:31:14.577270619Z  LastFallbackCount: (int) 0,
2024-10-24T13:31:14.577270619Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:31:14.577270619Z }
2024-10-24T13:31:16.185728209Z I1024 13:31:16.185666       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-11-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:31:16.973187373Z I1024 13:31:16.973127       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:31:17.366781681Z I1024 13:31:17.366676       1 request.go:700] Waited for 1.180841522s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:31:18.366861075Z I1024 13:31:18.366801       1 request.go:700] Waited for 1.190006853s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:31:19.375999158Z I1024 13:31:19.375932       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:31:19.566288187Z I1024 13:31:19.566228       1 request.go:700] Waited for 1.190019802s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:31:20.566627641Z I1024 13:31:20.566542       1 request.go:700] Waited for 1.189370863s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:31:21.574331294Z I1024 13:31:21.574259       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:31:57.800487471Z W1024 13:31:57.800427       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
2024-10-24T13:32:18.231330119Z I1024 13:32:18.231272       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:32:20.022058704Z I1024 13:32:20.021974       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-0" for revision 11 for the 1st time because installer pod failed: installer: i-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:20.022058704Z W1024 13:31:38.039435       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:20.022058704Z W1024 13:31:48.040152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:20.022058704Z W1024 13:31:58.039382       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:20.022058704Z W1024 13:32:08.039785       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:20.022058704Z W1024 13:32:18.039110       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:20.022058704Z W1024 13:32:18.040214       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:20.022058704Z F1024 13:32:18.040256       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:32:20.022185674Z I1024 13:32:20.022117       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:32:20.022185674Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:32:20.022185674Z  CurrentRevision: (int32) 10,
2024-10-24T13:32:20.022185674Z  TargetRevision: (int32) 11,
2024-10-24T13:32:20.022185674Z  LastFailedRevision: (int32) 11,
2024-10-24T13:32:20.022185674Z  LastFailedTime: (*v1.Time)(0xc002d229c0)(2024-10-24 13:32:20.021957284 +0000 UTC m=+853.821041273),
2024-10-24T13:32:20.022185674Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:32:20.022185674Z  LastFailedCount: (int) 1,
2024-10-24T13:32:20.022185674Z  LastFallbackCount: (int) 0,
2024-10-24T13:32:20.022185674Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:32:20.022185674Z   (string) (len=2059) "installer: i-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:31:38.039435       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:31:48.040152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:31:58.039382       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:32:08.039785       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:32:18.039110       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:32:18.040214       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:32:18.040256       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:32:20.022185674Z  }
2024-10-24T13:32:20.022185674Z }
2024-10-24T13:32:20.022185674Z  because installer pod failed: installer: i-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:20.022185674Z W1024 13:31:38.039435       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:20.022185674Z W1024 13:31:48.040152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:20.022185674Z W1024 13:31:58.039382       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:20.022185674Z W1024 13:32:08.039785       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:20.022185674Z W1024 13:32:18.039110       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:20.022185674Z W1024 13:32:18.040214       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:20.022185674Z F1024 13:32:18.040256       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:32:20.022227804Z I1024 13:32:20.022173       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer: i-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:20.022227804Z W1024 13:31:38.039435       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:20.022227804Z W1024 13:31:48.040152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:20.022227804Z W1024 13:31:58.039382       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:20.022227804Z W1024 13:32:08.039785       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:20.022227804Z W1024 13:32:18.039110       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:20.022227804Z W1024 13:32:18.040214       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:20.022227804Z F1024 13:32:18.040256       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:32:20.048937694Z I1024 13:32:20.048884       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:32:20.049869014Z I1024 13:32:20.049815       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 11:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:31:38.039435       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:31:48.040152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:31:58.039382       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:32:08.039785       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:32:18.039110       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:32:18.040214       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:32:18.040256       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 2 nodes are at revision 10; 1 node is at revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 10; 1 node is at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:32:20.066099343Z I1024 13:32:20.064933       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready" to "NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 11:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:31:38.039435       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:31:48.040152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:31:58.039382       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:32:08.039785       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:32:18.039110       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:32:18.040214       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:32:18.040256       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: "
2024-10-24T13:32:29.018809856Z E1024 13:32:29.018721       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:29.025793766Z E1024 13:32:29.025717       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:29.037736885Z E1024 13:32:29.037695       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:29.059949855Z E1024 13:32:29.059917       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:29.102209385Z E1024 13:32:29.102157       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:29.185139283Z E1024 13:32:29.185078       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:29.348784991Z E1024 13:32:29.348718       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:29.671462856Z E1024 13:32:29.671414       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:30.314143837Z E1024 13:32:30.314095       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:31.597362769Z E1024 13:32:31.597280       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:34.159463023Z E1024 13:32:34.159403       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:35.002961941Z I1024 13:32:35.002862       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 11 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:35.003711411Z E1024 13:32:35.003645       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.180166cb3ea98e7b  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 11 count 1 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:32:35.002674811 +0000 UTC m=+868.801758810,LastTimestamp:2024-10-24 13:32:35.002674811 +0000 UTC m=+868.801758810,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:32:35.004411161Z E1024 13:32:35.004369       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:35.012492091Z I1024 13:32:35.012444       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 11 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:35.013780941Z E1024 13:32:35.013705       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:35.027017911Z I1024 13:32:35.026946       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 11 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:35.028295131Z E1024 13:32:35.028240       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:35.051425980Z I1024 13:32:35.051354       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 11 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:35.052623780Z E1024 13:32:35.052580       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:35.095668410Z I1024 13:32:35.095600       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 11 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:35.096673560Z E1024 13:32:35.096629       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:35.180673439Z I1024 13:32:35.180619       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 11 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:35.181870458Z E1024 13:32:35.181835       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:35.345703116Z I1024 13:32:35.345614       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 11 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:35.346735846Z E1024 13:32:35.346695       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:35.670277151Z I1024 13:32:35.670211       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 11 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:35.671698372Z E1024 13:32:35.671631       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:36.314744832Z I1024 13:32:36.314684       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 11 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:36.315826822Z E1024 13:32:36.315800       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:37.599620244Z I1024 13:32:37.599524       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 11 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:37.600776064Z E1024 13:32:37.600696       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:39.281682850Z E1024 13:32:39.281617       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:40.165019038Z I1024 13:32:40.164923       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 11 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:40.166232448Z E1024 13:32:40.166196       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:41.940685173Z E1024 13:32:41.940623       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.180166cb3ea98e7b  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 11 count 1 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:32:35.002674811 +0000 UTC m=+868.801758810,LastTimestamp:2024-10-24 13:32:35.002674811 +0000 UTC m=+868.801758810,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:32:45.290679915Z I1024 13:32:45.290610       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 11 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:45.292158075Z E1024 13:32:45.292112       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:55.564695539Z I1024 13:32:55.564637       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:32:55.572082289Z I1024 13:32:55.572020       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:33:01.267714198Z I1024 13:33:01.267654       1 reflector.go:368] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:03.125704832Z I1024 13:33:03.125633       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:03.311108299Z I1024 13:33:03.311044       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:03.566665406Z I1024 13:33:03.566603       1 reflector.go:368] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:03.793906332Z I1024 13:33:03.793841       1 reflector.go:368] Caches populated for *v1.Proxy from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:03.812200062Z I1024 13:33:03.812146       1 reflector.go:368] Caches populated for *v1.Role from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:04.510575842Z I1024 13:33:04.510520       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:04.909485986Z I1024 13:33:04.909393       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:06.125044159Z I1024 13:33:06.124974       1 reflector.go:368] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:07.113261795Z I1024 13:33:07.113198       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:08.130744550Z I1024 13:33:08.130673       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:08.287233798Z I1024 13:33:08.287164       1 reflector.go:368] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:10.510533607Z I1024 13:33:10.510471       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:11.310118086Z I1024 13:33:11.310012       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:11.780481478Z I1024 13:33:11.780413       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:12.317892621Z I1024 13:33:12.317831       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:13.524185074Z I1024 13:33:13.524113       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:13.525036164Z W1024 13:33:13.524997       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
2024-10-24T13:33:14.911326124Z I1024 13:33:14.911275       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:15.310057708Z I1024 13:33:15.309991       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:30.130930438Z I1024 13:33:30.130875       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:32.469523015Z I1024 13:33:32.469455       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:33.092138496Z I1024 13:33:33.092086       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:34.335767438Z I1024 13:33:34.335701       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:36.334134390Z I1024 13:33:36.334086       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:33:37.326322186Z I1024 13:33:37.326241       1 request.go:700] Waited for 1.170600904s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps?resourceVersion=31699
2024-10-24T13:33:37.329114215Z I1024 13:33:37.329013       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:38.333158961Z I1024 13:33:38.332783       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:33:39.130505350Z I1024 13:33:39.129891       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:39.326774747Z I1024 13:33:39.326455       1 request.go:700] Waited for 1.042051245s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts?resourceVersion=31603
2024-10-24T13:33:39.331260847Z I1024 13:33:39.331206       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:40.129106626Z I1024 13:33:40.129064       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:40.351560643Z I1024 13:33:40.351255       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:40.726099857Z I1024 13:33:40.726048       1 request.go:700] Waited for 1.056323895s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra/secrets?resourceVersion=31482
2024-10-24T13:33:40.731819887Z I1024 13:33:40.731745       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:40.917561065Z I1024 13:33:40.917512       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:41.133885041Z I1024 13:33:41.133818       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:41.915396510Z I1024 13:33:41.915327       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:43.929414732Z I1024 13:33:43.929368       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:47.133313496Z I1024 13:33:47.133255       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:47.617822329Z I1024 13:33:47.617773       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:48.733345653Z I1024 13:33:48.733284       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:33:49.936325056Z I1024 13:33:49.936255       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:33:51.690476512Z I1024 13:33:51.690415       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:51.926224068Z I1024 13:33:51.926168       1 request.go:700] Waited for 1.066929895s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:33:53.326630058Z I1024 13:33:53.326560       1 request.go:700] Waited for 1.124057934s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:33:54.090651397Z I1024 13:33:54.090569       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubecontrollermanagers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:54.091838527Z I1024 13:33:54.091811       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:54.135054497Z I1024 13:33:54.135011       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because waiting for static pod of revision 11, found 10
2024-10-24T13:33:54.326855984Z I1024 13:33:54.326787       1 request.go:700] Waited for 1.193193113s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/recycler-config
2024-10-24T13:33:55.326854500Z I1024 13:33:55.326802       1 request.go:700] Waited for 1.190864704s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:33:56.926811777Z I1024 13:33:56.926766       1 request.go:700] Waited for 1.013531476s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps?resourceVersion=31676
2024-10-24T13:33:56.940982037Z I1024 13:33:56.940914       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:56.942224517Z I1024 13:33:56.942189       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:56.942471947Z I1024 13:33:56.942453       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:56.942721147Z I1024 13:33:56.942702       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:56.942964066Z I1024 13:33:56.942944       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:56.943180776Z I1024 13:33:56.943161       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:56.943389667Z I1024 13:33:56.943372       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:56.943676447Z I1024 13:33:56.943618       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:56.943970357Z I1024 13:33:56.943948       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:56.944225647Z I1024 13:33:56.944204       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:57.531912088Z I1024 13:33:57.531855       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because waiting for static pod of revision 11, found 10
2024-10-24T13:34:00.526158535Z I1024 13:34:00.526097       1 request.go:700] Waited for 1.018919275s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-10-24T13:34:00.736937742Z I1024 13:34:00.736883       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because waiting for static pod of revision 11, found 10
2024-10-24T13:34:01.526956111Z I1024 13:34:01.526899       1 request.go:700] Waited for 1.39441001s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:34:02.726237664Z I1024 13:34:02.726185       1 request.go:700] Waited for 1.191623553s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:34:03.737240570Z E1024 13:34:03.737183       1 guard_controller.go:300] Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:34:04.132012094Z I1024 13:34:04.131942       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because static pod is pending
2024-10-24T13:34:04.326979351Z I1024 13:34:04.326922       1 request.go:700] Waited for 1.170060033s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:34:05.526937894Z I1024 13:34:05.526877       1 request.go:700] Waited for 1.189386733s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:34:06.726926917Z I1024 13:34:06.726871       1 request.go:700] Waited for 1.190166883s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:34:07.735900923Z I1024 13:34:07.735484       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because static pod is pending
2024-10-24T13:34:07.926601620Z I1024 13:34:07.926555       1 request.go:700] Waited for 1.187604173s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:34:08.568379231Z E1024 13:34:08.568311       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0"
2024-10-24T13:34:08.569958761Z I1024 13:34:08.569910       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: 1 nodes are failing on revision 11:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:31:38.039435       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:31:48.040152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:31:58.039382       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:32:08.039785       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:32:18.039110       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:32:18.040214       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:32:18.040256       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 2 nodes are at revision 10; 1 node is at revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 10; 1 node is at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:34:08.572627721Z I1024 13:34:08.572598       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:34:08.585210151Z I1024 13:34:08.585023       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 11:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:31:38.039435       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:31:48.040152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:31:58.039382       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:32:08.039785       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:32:18.039110       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:32:18.040214       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:32:18.040256       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: " to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: 1 nodes are failing on revision 11:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:31:38.039435       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:31:48.040152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:31:58.039382       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:32:08.039785       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:32:18.039110       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:32:18.040214       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:32:18.040256       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: "
2024-10-24T13:34:08.927003926Z I1024 13:34:08.926911       1 request.go:700] Waited for 1.189908573s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:34:10.126584969Z I1024 13:34:10.126471       1 request.go:700] Waited for 1.189421593s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:34:11.134195735Z I1024 13:34:11.134083       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 11, but has not made progress because static pod is pending
2024-10-24T13:34:14.136030662Z I1024 13:34:14.135962       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:34:14.136030662Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:34:14.136030662Z  CurrentRevision: (int32) 11,
2024-10-24T13:34:14.136030662Z  TargetRevision: (int32) 0,
2024-10-24T13:34:14.136030662Z  LastFailedRevision: (int32) 11,
2024-10-24T13:34:14.136030662Z  LastFailedTime: (*v1.Time)(0xc0018bbed8)(2024-10-24 13:32:20 +0000 UTC),
2024-10-24T13:34:14.136030662Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:34:14.136030662Z  LastFailedCount: (int) 1,
2024-10-24T13:34:14.136030662Z  LastFallbackCount: (int) 0,
2024-10-24T13:34:14.136030662Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:34:14.136030662Z   (string) (len=2059) "installer: i-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:31:38.039435       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:31:48.040152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:31:58.039382       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:32:08.039785       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:32:18.039110       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:32:18.040214       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:32:18.040256       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:34:14.136030662Z  }
2024-10-24T13:34:14.136030662Z }
2024-10-24T13:34:14.136030662Z  because static pod is ready
2024-10-24T13:34:14.167225121Z I1024 13:34:14.167127       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 10 to 11 because static pod is ready
2024-10-24T13:34:14.170201021Z I1024 13:34:14.170150       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:34:14.175936891Z I1024 13:34:14.175899       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 10; 2 nodes are at revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 10; 2 nodes are at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:34:14.193166261Z I1024 13:34:14.193112       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0\nNodeInstallerDegraded: 1 nodes are failing on revision 11:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:31:38.039435       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:31:48.040152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:31:58.039382       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:32:08.039785       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:32:18.039110       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:32:18.040214       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:32:18.040256       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: " to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0",Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 10; 1 node is at revision 11" to "NodeInstallerProgressing: 1 node is at revision 10; 2 nodes are at revision 11",Available message changed from "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 10; 1 node is at revision 11" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 10; 2 nodes are at revision 11"
2024-10-24T13:34:14.326702049Z I1024 13:34:14.326636       1 request.go:700] Waited for 1.089744405s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:34:14.933461870Z W1024 13:34:14.933404       1 dynamic_operator_client.go:355] .status.conditions["GuardControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:34:14.962421780Z I1024 13:34:14.962376       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 10; 2 nodes are at revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 10; 2 nodes are at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:34:14.964114250Z I1024 13:34:14.964084       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:34:14.982110070Z I1024 13:34:14.981822       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0" to "NodeControllerDegraded: All master nodes are ready"
2024-10-24T13:34:15.326728755Z I1024 13:34:15.326674       1 request.go:700] Waited for 1.158415934s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-retry-1-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:34:16.526387078Z I1024 13:34:16.526318       1 request.go:700] Waited for 1.38966324s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:34:17.526496243Z I1024 13:34:17.526439       1 request.go:700] Waited for 1.193438824s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:34:17.935447388Z I1024 13:34:17.935378       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:34:17.935447388Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:34:17.935447388Z  CurrentRevision: (int32) 11,
2024-10-24T13:34:17.935447388Z  TargetRevision: (int32) 0,
2024-10-24T13:34:17.935447388Z  LastFailedRevision: (int32) 11,
2024-10-24T13:34:17.935447388Z  LastFailedTime: (*v1.Time)(0xc00209e2d0)(2024-10-24 13:32:20 +0000 UTC),
2024-10-24T13:34:17.935447388Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:34:17.935447388Z  LastFailedCount: (int) 1,
2024-10-24T13:34:17.935447388Z  LastFallbackCount: (int) 0,
2024-10-24T13:34:17.935447388Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:34:17.935447388Z   (string) (len=2059) "installer: i-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:31:38.039435       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:31:48.040152       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:31:58.039382       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:32:08.039785       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:32:18.039110       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:32:18.040214       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:32:18.040256       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:34:17.935447388Z  }
2024-10-24T13:34:17.935447388Z }
2024-10-24T13:34:17.935447388Z  because static pod is ready
2024-10-24T13:34:23.334201341Z I1024 13:34:23.334090       1 installer_controller.go:534] node ci-op-2fcpj5j6-f6035-2lklf-master-2 with revision 10 is the oldest and needs new revision 11
2024-10-24T13:34:23.334270761Z I1024 13:34:23.334193       1 installer_controller.go:542] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:34:23.334270761Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:34:23.334270761Z  CurrentRevision: (int32) 10,
2024-10-24T13:34:23.334270761Z  TargetRevision: (int32) 11,
2024-10-24T13:34:23.334270761Z  LastFailedRevision: (int32) 4,
2024-10-24T13:34:23.334270761Z  LastFailedTime: (*v1.Time)(0xc002529668)(2024-10-24 13:11:52 +0000 UTC),
2024-10-24T13:34:23.334270761Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:34:23.334270761Z  LastFailedCount: (int) 1,
2024-10-24T13:34:23.334270761Z  LastFallbackCount: (int) 0,
2024-10-24T13:34:23.334270761Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:34:23.334270761Z   (string) (len=2059) "installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:34:23.334270761Z  }
2024-10-24T13:34:23.334270761Z }
2024-10-24T13:34:23.360645251Z I1024 13:34:23.360545       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 10 to 11 because node ci-op-2fcpj5j6-f6035-2lklf-master-2 with revision 10 is the oldest
2024-10-24T13:34:23.369194371Z I1024 13:34:23.369135       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:34:24.526478424Z I1024 13:34:24.526415       1 request.go:700] Waited for 1.156001453s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:34:25.541384970Z I1024 13:34:25.541309       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-11-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:34:26.726788743Z I1024 13:34:26.726685       1 request.go:700] Waited for 1.185560673s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:34:26.735856103Z I1024 13:34:26.735816       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:34:27.926092915Z I1024 13:34:27.926038       1 request.go:700] Waited for 1.189190684s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:34:28.926146642Z I1024 13:34:28.926053       1 request.go:700] Waited for 1.188370534s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:34:29.132944389Z I1024 13:34:29.132885       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:34:29.927020157Z I1024 13:34:29.926962       1 request.go:700] Waited for 1.189923423s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:35:00.907712676Z I1024 13:35:00.907650       1 request.go:700] Waited for 1.002537805s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager
2024-10-24T13:35:01.907822112Z I1024 13:35:01.907763       1 request.go:700] Waited for 1.193329493s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:35:02.908381798Z I1024 13:35:02.908316       1 request.go:700] Waited for 1.193579303s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:35:03.117111515Z I1024 13:35:03.117058       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 11, but has not made progress because waiting for static pod of revision 11, found 10
2024-10-24T13:35:06.116706322Z I1024 13:35:06.116640       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 11, but has not made progress because waiting for static pod of revision 11, found 10
2024-10-24T13:35:10.163135355Z I1024 13:35:10.163065       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 11, but has not made progress because waiting for static pod of revision 11, found 10
2024-10-24T13:35:13.067709013Z I1024 13:35:13.067638       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 11, but has not made progress because static pod is pending
2024-10-24T13:35:15.269129862Z I1024 13:35:15.269076       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 11, but has not made progress because static pod is pending
2024-10-24T13:35:17.273557694Z I1024 13:35:17.273504       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 11, but has not made progress because static pod is pending
2024-10-24T13:35:22.985740432Z I1024 13:35:22.985688       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 11, but has not made progress because static pod is pending
2024-10-24T13:35:25.155077642Z I1024 13:35:25.155008       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:35:25.155077642Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:35:25.155077642Z  CurrentRevision: (int32) 11,
2024-10-24T13:35:25.155077642Z  TargetRevision: (int32) 0,
2024-10-24T13:35:25.155077642Z  LastFailedRevision: (int32) 4,
2024-10-24T13:35:25.155077642Z  LastFailedTime: (*v1.Time)(0xc00297e3f0)(2024-10-24 13:11:52 +0000 UTC),
2024-10-24T13:35:25.155077642Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:35:25.155077642Z  LastFailedCount: (int) 1,
2024-10-24T13:35:25.155077642Z  LastFallbackCount: (int) 0,
2024-10-24T13:35:25.155077642Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:35:25.155077642Z   (string) (len=2059) "installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:35:25.155077642Z  }
2024-10-24T13:35:25.155077642Z }
2024-10-24T13:35:25.155077642Z  because static pod is ready
2024-10-24T13:35:25.185728401Z I1024 13:35:25.185597       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 10 to 11 because static pod is ready
2024-10-24T13:35:25.189549871Z I1024 13:35:25.189494       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:35:25.192666861Z I1024 13:35:25.192498       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:09Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:35:25Z","message":"NodeInstallerProgressing: 3 nodes are at revision 11","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:35:25.216995861Z I1024 13:35:25.216886       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing changed from True to False ("NodeInstallerProgressing: 3 nodes are at revision 11"),Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 10; 2 nodes are at revision 11" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 11"
2024-10-24T13:35:26.347660195Z I1024 13:35:26.347601       1 request.go:700] Waited for 1.146176604s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-10-24T13:35:27.348550420Z I1024 13:35:27.348493       1 request.go:700] Waited for 1.133179774s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra
2024-10-24T13:35:28.157860429Z I1024 13:35:28.157784       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:35:28.157860429Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:35:28.157860429Z  CurrentRevision: (int32) 11,
2024-10-24T13:35:28.157860429Z  TargetRevision: (int32) 0,
2024-10-24T13:35:28.157860429Z  LastFailedRevision: (int32) 4,
2024-10-24T13:35:28.157860429Z  LastFailedTime: (*v1.Time)(0xc002c609f0)(2024-10-24 13:11:52 +0000 UTC),
2024-10-24T13:35:28.157860429Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:35:28.157860429Z  LastFailedCount: (int) 1,
2024-10-24T13:35:28.157860429Z  LastFallbackCount: (int) 0,
2024-10-24T13:35:28.157860429Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:35:28.157860429Z   (string) (len=2059) "installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:35:28.157860429Z  }
2024-10-24T13:35:28.157860429Z }
2024-10-24T13:35:28.157860429Z  because static pod is ready
2024-10-24T13:36:57.801616041Z W1024 13:36:57.801546       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
2024-10-24T13:41:57.801638075Z W1024 13:41:57.801574       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
2024-10-24T13:43:35.348032536Z I1024 13:43:35.347974       1 request.go:700] Waited for 1.009908988s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:43:36.348495284Z I1024 13:43:36.348442       1 request.go:700] Waited for 1.192329547s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:43:56.942664845Z I1024 13:43:56.942602       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:56.943004694Z I1024 13:43:56.942985       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:56.943210715Z I1024 13:43:56.943192       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:56.943416924Z I1024 13:43:56.943401       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:56.943643134Z I1024 13:43:56.943629       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:56.943914635Z I1024 13:43:56.943898       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:56.944132765Z I1024 13:43:56.944114       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:56.944335495Z I1024 13:43:56.944320       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:56.944538825Z I1024 13:43:56.944509       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:56.944732214Z I1024 13:43:56.944716       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:56.945059955Z I1024 13:43:56.944990       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:44:00.748412170Z I1024 13:44:00.748348       1 request.go:700] Waited for 1.034817168s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:46:20.155607096Z I1024 13:46:20.155551       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:46:20.156257496Z I1024 13:46:20.155616       1 core.go:352] ConfigMap "openshift-kube-controller-manager/aggregator-client-ca" changes: {"data":{"ca-bundle.crt":"-----BEGIN CERTIFICATE-----\nMIIDJDCCAgygAwIBAgIIF/RXtfGPvuMwDQYJKoZIhvcNAQELBQAwMDESMBAGA1UE\nCxMJb3BlbnNoaWZ0MRowGAYDVQQDExFhZ2dyZWdhdG9yLXNpZ25lcjAeFw0yNDEw\nMjQxMjQ5MzJaFw0yNDEwMjUxMjQ5MzJaMDAxEjAQBgNVBAsTCW9wZW5zaGlmdDEa\nMBgGA1UEAxMRYWdncmVnYXRvci1zaWduZXIwggEiMA0GCSqGSIb3DQEBAQUAA4IB\nDwAwggEKAoIBAQDD722hp3hbDTJbd/BBHJ/BcpUdsOvcwmWyQqNo/kZx3w/9jP6s\noRg9q2amHP1/cjXBXiFKkYXCjFIGhLLxi5rJYZxsdq54thnhPyhL4cXR2xu7AQKv\nQCW6e0aC5/0dEQVe98ttrpEVHw8xO+JfNZO8NHX+1hTamgrnqeUfSVyhiisbYVX6\nmoFC7uelTV8QZ6FaJnDVRasoFtHaQtLxgabpvxO6sh6s7p+8NhlI/PamyspwGjGz\nPFB6OAxki1UHtv0M5aXXZvvr5lIv1iNkudJ57TO17RyKTl8oxSL4M8SBelrYTVsP\noBzpya4rPb0iD0yhsJMCvG6wk6pQBeAQ3VbVAgMBAAGjQjBAMA4GA1UdDwEB/wQE\nAwICpDAPBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBSB3HmXaA4JHRhSMFJt3JFG\nxNDfLDANBgkqhkiG9w0BAQsFAAOCAQEAc+GK/sDrcd8OzpS0k9TZ4eraTPzSThPU\nLqqnb3jGB8DBm36ZNiigakcsuWAQJ/4xQJkJtJq6He0701HqAzw7zP6LmhMCFvXZ\nNsvLsPd6woJfmOaeWaaPBL+tI7D0v16sLf+a9Q/ONu5tVHiRoEUEMG9iih9KNltm\nUwkUKq6Xx5p1+iE37J9shYmsbD649PGTFK2eeYBSFgAZB4PBotKrIR4frTMoJLfU\nwxCuqTrm/VxyKFryZktjHX2jsLZu3tMzFAPe4UovKJl9H7vhkJ6pYSmGlrMAiXtV\nVrWGuEmpfntCC+LWyHdkrwjCUd7QclZb8TZwinu4ItpXsDAbyo6miA==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDhTCCAm2gAwIBAgIIBEEBnt4lt+cwDQYJKoZIhvcNAQELBQAwUDFOMEwGA1UE\nAwxFb3BlbnNoaWZ0LWt1YmUtYXBpc2VydmVyLW9wZXJhdG9yX2FnZ3JlZ2F0b3It\nY2xpZW50LXNpZ25lckAxNzI5Nzc3NTc5MB4XDTI0MTAyNDEzNDYxOFoXDTI0MTAy\nNTAxNDYxOVowUDFOMEwGA1UEAwxFb3BlbnNoaWZ0LWt1YmUtYXBpc2VydmVyLW9w\nZXJhdG9yX2FnZ3JlZ2F0b3ItY2xpZW50LXNpZ25lckAxNzI5Nzc3NTc5MIIBIjAN\nBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAo6Yb/O+mIGclq/AhBxIb6hP09XVu\n4lbC8pc0svu+a+XNHI1LoNHYL7HARDXBeIi6EWjUiNb3kBgCnjqeTu0r/LRx0Jlx\n1vIDmq6RJRc/oUqsxG74kz2sSVTu048NIjOKMxPwzFVY/nhBh/vZnEKe+0SDeex1\nZMV44Vtf3iVUUd362/vB0uoInsTRbpza3Jx3nJmxeyI5i4XQtgQHC0x2Q/h5Vwmh\nkvjxwlYtTEpN0AZNum0/WLZoY3xSVz4MW1btrYYrLohkD2bypx90hsB1RKBD8Ye6\nhWOf2VXIO2fXXuFsacOgucuX4RAyKbo4L2UivmnkfL4w6xYXH5OdXanSaQIDAQAB\no2MwYTAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQU\n50OJDmU5YhbiEaS58G3De3RUmBgwHwYDVR0jBBgwFoAU50OJDmU5YhbiEaS58G3D\ne3RUmBgwDQYJKoZIhvcNAQELBQADggEBADNMf830Ay4RhwyQN9aMb/XlUirZUbcg\nc/5i5ZuI0AXhz/YuLSHDoWCxk/oWSNFmK07xN2OleHj8b/OI1LEcuUuFbqPG8gI4\nRI1TWPNai4ibu37cHtC1BrkdZJuvDTy0IdDR7wKp3/Sl1YY0Lzf6e/9lWb8TuqEL\nWc9qwFeS6RA/q2fsKPg1Ix0vASgTFFcwtpstQQo3j94G6Ermtq3Rw59xcF5AAGzh\nv85qCkrkIdJR2Akewjb13mjoFz3pvMns8L3lquFgAkxnERXN8BoGST/F2UoWdGHM\nTKm+Z1iZpZTeYyrffJqO+2ftALH8iBTwpiZnpqd3l3lFWP+dYy09Lq0=\n-----END CERTIFICATE-----\n"},"metadata":{"creationTimestamp":"2024-10-24T13:03:37Z","managedFields":[{"apiVersion":"v1","fieldsType":"FieldsV1","fieldsV1":{"f:data":{".":{},"f:ca-bundle.crt":{}},"f:metadata":{"f:annotations":{".":{},"f:certificates.openshift.io/auto-regenerate-after-offline-expiry":{},"f:openshift.io/owning-component":{}},"f:labels":{".":{},"f:auth.openshift.io/managed-certificate-type":{}}}},"manager":"cluster-kube-apiserver-operator","operation":"Update","time":"2024-10-24T13:46:19Z"}],"resourceVersion":null,"uid":"b4d32c57-86bc-4670-9e1a-17c3bcb7a4cd"}}
2024-10-24T13:46:20.156596586Z I1024 13:46:20.156550       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/aggregator-client-ca -n openshift-kube-controller-manager:
2024-10-24T13:46:20.156596586Z cause by changes in data.ca-bundle.crt
2024-10-24T13:46:21.808599200Z I1024 13:46:21.801711       1 tlsconfig.go:181] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"admin-kubeconfig-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:31 +0000 UTC to 2034-10-22 12:49:31 +0000 UTC (now=2024-10-24 13:46:21.801668029 +0000 UTC))"
2024-10-24T13:46:21.812719909Z I1024 13:46:21.812666       1 tlsconfig.go:181] "Loaded client CA" index=1 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2024-10-25 12:49:34 +0000 UTC (now=2024-10-24 13:46:21.812603219 +0000 UTC))"
2024-10-24T13:46:21.812719909Z I1024 13:46:21.812705       1 tlsconfig.go:181] "Loaded client CA" index=2 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-control-plane-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2025-10-24 12:49:34 +0000 UTC (now=2024-10-24 13:46:21.812690719 +0000 UTC))"
2024-10-24T13:46:21.812838109Z I1024 13:46:21.812734       1 tlsconfig.go:181] "Loaded client CA" index=3 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-apiserver-to-kubelet-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2025-10-24 12:49:34 +0000 UTC (now=2024-10-24 13:46:21.812715659 +0000 UTC))"
2024-10-24T13:46:21.812838109Z I1024 13:46:21.812769       1 tlsconfig.go:181] "Loaded client CA" index=4 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-bootstrap-kubeconfig-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:32 +0000 UTC to 2034-10-22 12:49:32 +0000 UTC (now=2024-10-24 13:46:21.812741529 +0000 UTC))"
2024-10-24T13:46:21.812838109Z I1024 13:46:21.812791       1 tlsconfig.go:181] "Loaded client CA" index=5 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-csr-signer_@1729775012\" [] issuer=\"kubelet-signer\" (2024-10-24 13:03:31 +0000 UTC to 2024-10-25 12:49:34 +0000 UTC (now=2024-10-24 13:46:21.812777089 +0000 UTC))"
2024-10-24T13:46:21.812838109Z I1024 13:46:21.812810       1 tlsconfig.go:181] "Loaded client CA" index=6 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_node-system-admin-signer@1729775011\" [] issuer=\"<self>\" (2024-10-24 13:03:30 +0000 UTC to 2025-10-24 13:03:31 +0000 UTC (now=2024-10-24 13:46:21.812796519 +0000 UTC))"
2024-10-24T13:46:21.812857409Z I1024 13:46:21.812828       1 tlsconfig.go:181] "Loaded client CA" index=7 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"aggregator-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:32 +0000 UTC to 2024-10-25 12:49:32 +0000 UTC (now=2024-10-24 13:46:21.812816739 +0000 UTC))"
2024-10-24T13:46:21.812911179Z I1024 13:46:21.812869       1 tlsconfig.go:181] "Loaded client CA" index=8 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_aggregator-client-signer@1729777579\" [] issuer=\"<self>\" (2024-10-24 13:46:18 +0000 UTC to 2024-10-25 01:46:19 +0000 UTC (now=2024-10-24 13:46:21.812854009 +0000 UTC))"
2024-10-24T13:46:21.814696879Z I1024 13:46:21.814666       1 tlsconfig.go:203] "Loaded serving cert" certName="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key" certDetail="\"metrics.openshift-kube-controller-manager-operator.svc\" [serving] validServingFor=[metrics.openshift-kube-controller-manager-operator.svc,metrics.openshift-kube-controller-manager-operator.svc.cluster.local] issuer=\"openshift-service-serving-signer@1729775010\" (2024-10-24 13:03:41 +0000 UTC to 2026-10-24 13:03:42 +0000 UTC (now=2024-10-24 13:46:21.8146325 +0000 UTC))"
2024-10-24T13:46:21.814970339Z I1024 13:46:21.814947       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1729775941\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1729775940\" (2024-10-24 12:19:00 +0000 UTC to 2025-10-24 12:19:00 +0000 UTC (now=2024-10-24 13:46:21.814924789 +0000 UTC))"
2024-10-24T13:46:57.802477007Z W1024 13:46:57.802414       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
2024-10-24T13:50:52.136647437Z I1024 13:50:52.135138       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:50:52.338867536Z I1024 13:50:52.338711       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:50:52.511433244Z I1024 13:50:52.511364       1 reflector.go:368] Caches populated for *v1.Proxy from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:50:52.585856063Z I1024 13:50:52.585802       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:50:52.658583162Z I1024 13:50:52.658497       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubecontrollermanagers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:50:52.672223342Z I1024 13:50:52.671231       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:50:52.804736201Z I1024 13:50:52.803330       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:51:57.803578367Z W1024 13:51:57.803471       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
2024-10-24T13:53:56.943629620Z I1024 13:53:56.943556       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:56.944971860Z I1024 13:53:56.944915       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:56.945276320Z I1024 13:53:56.945256       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:56.945493060Z I1024 13:53:56.945473       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:56.945696700Z I1024 13:53:56.945676       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:56.945920560Z I1024 13:53:56.945899       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:56.946122301Z I1024 13:53:56.946106       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:56.946352280Z I1024 13:53:56.946301       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:56.946498330Z I1024 13:53:56.946457       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:54:00.748030820Z I1024 13:54:00.747962       1 request.go:700] Waited for 1.029783837s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:56:57.805098191Z W1024 13:56:57.805042       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
2024-10-24T13:57:22.479299364Z I1024 13:57:22.479239       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:57:22.750450781Z I1024 13:57:22.750390       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:57:22.962942807Z I1024 13:57:22.962859       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:57:23.065785090Z I1024 13:57:23.065700       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubecontrollermanagers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:57:23.066174570Z I1024 13:57:23.066122       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:57:23.090227280Z I1024 13:57:23.090169       1 reflector.go:368] Caches populated for *v1.Proxy from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:57:23.402942489Z I1024 13:57:23.402875       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:57:23.598234104Z I1024 13:57:23.598180       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:57:23.778726508Z I1024 13:57:23.778668       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:01:57.806129212Z W1024 14:01:57.806017       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
2024-10-24T14:03:56.944393684Z I1024 14:03:56.944309       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:56.944734624Z I1024 14:03:56.944701       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:56.945318254Z I1024 14:03:56.945278       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:56.945511654Z I1024 14:03:56.945489       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:56.945700394Z I1024 14:03:56.945659       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:56.945965224Z I1024 14:03:56.945944       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:56.946186924Z I1024 14:03:56.946166       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:56.946388304Z I1024 14:03:56.946356       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:56.946558534Z I1024 14:03:56.946506       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:56.946680314Z I1024 14:03:56.946658       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:56.946863014Z I1024 14:03:56.946837       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:56.947362584Z I1024 14:03:56.947299       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:56.947511174Z I1024 14:03:56.947484       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:04:00.747133853Z I1024 14:04:00.747060       1 request.go:700] Waited for 1.021498887s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:04:01.747469920Z I1024 14:04:01.747394       1 request.go:700] Waited for 1.193187947s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps/csr-controller-ca
2024-10-24T14:04:28.455192241Z I1024 14:04:28.455127       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubecontrollermanagers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:04:28.456115332Z I1024 14:04:28.456042       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:06:57.806733557Z W1024 14:06:57.806660       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
2024-10-24T14:07:55.317173335Z W1024 14:07:55.317116       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
2024-10-24T14:08:00.843097639Z I1024 14:08:00.843021       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:00.860511529Z I1024 14:08:00.860430       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:00.876795110Z I1024 14:08:00.876715       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:00.892606689Z I1024 14:08:00.892533       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:00.907895469Z I1024 14:08:00.907821       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:00.923921169Z I1024 14:08:00.923869       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:00.942434389Z I1024 14:08:00.942354       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:00.959762619Z I1024 14:08:00.959430       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:00.975875839Z I1024 14:08:00.975133       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:00.991476999Z I1024 14:08:00.991090       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.005154939Z I1024 14:08:01.005087       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.021930139Z I1024 14:08:01.021861       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.040112419Z I1024 14:08:01.040064       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.061466579Z I1024 14:08:01.061410       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.088503529Z I1024 14:08:01.087943       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.127633969Z I1024 14:08:01.126977       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.161441769Z I1024 14:08:01.161394       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.197596379Z I1024 14:08:01.197538       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.220029529Z I1024 14:08:01.219950       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.248830859Z I1024 14:08:01.248782       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.276376188Z I1024 14:08:01.276315       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.293341448Z I1024 14:08:01.293282       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.318357958Z I1024 14:08:01.318297       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.345557098Z I1024 14:08:01.345493       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.367940128Z I1024 14:08:01.367858       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.393493158Z I1024 14:08:01.393259       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.416287928Z I1024 14:08:01.416227       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.433495848Z I1024 14:08:01.433420       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.448417088Z I1024 14:08:01.448348       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.464298728Z I1024 14:08:01.464181       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.479732038Z I1024 14:08:01.479654       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.499498678Z I1024 14:08:01.499435       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.526019967Z I1024 14:08:01.524268       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.537853987Z I1024 14:08:01.537793       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.554780227Z I1024 14:08:01.554698       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.572731927Z I1024 14:08:01.572315       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.596491537Z I1024 14:08:01.596450       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.614169677Z I1024 14:08:01.614005       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.629058967Z I1024 14:08:01.628991       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.647223337Z I1024 14:08:01.647090       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.664665577Z I1024 14:08:01.664614       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.678568487Z I1024 14:08:01.678505       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.692100387Z I1024 14:08:01.692036       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.706913897Z I1024 14:08:01.706861       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.721124757Z I1024 14:08:01.721065       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.736012587Z I1024 14:08:01.735948       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.753455947Z I1024 14:08:01.753392       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.770377337Z I1024 14:08:01.770321       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.786674947Z I1024 14:08:01.786625       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.802205507Z I1024 14:08:01.802135       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.820512777Z I1024 14:08:01.820472       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.837465966Z I1024 14:08:01.837421       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.861971557Z I1024 14:08:01.861930       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.879684276Z I1024 14:08:01.879615       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.899269956Z I1024 14:08:01.899170       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.922657336Z I1024 14:08:01.922603       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.938494076Z I1024 14:08:01.938449       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.957834146Z I1024 14:08:01.957002       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.975014976Z I1024 14:08:01.974943       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:01.991916776Z I1024 14:08:01.991859       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.013865136Z I1024 14:08:02.013827       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.037495376Z I1024 14:08:02.037449       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.061162076Z I1024 14:08:02.061084       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.074790306Z I1024 14:08:02.074724       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.092256636Z I1024 14:08:02.092184       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.106727986Z I1024 14:08:02.106669       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.122380726Z I1024 14:08:02.122298       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.141291986Z I1024 14:08:02.141219       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.158023996Z I1024 14:08:02.157971       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.173670376Z I1024 14:08:02.173612       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.189283466Z I1024 14:08:02.189240       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.206470486Z I1024 14:08:02.206414       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.220527406Z I1024 14:08:02.220480       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.236611266Z I1024 14:08:02.236561       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.252553576Z I1024 14:08:02.252498       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.269635226Z I1024 14:08:02.269566       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.284519416Z I1024 14:08:02.284413       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.302410436Z I1024 14:08:02.302358       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.330056205Z I1024 14:08:02.330002       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.343418845Z I1024 14:08:02.343326       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.353786626Z I1024 14:08:02.353679       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.373114945Z I1024 14:08:02.373036       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.385194925Z I1024 14:08:02.385131       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.409563935Z I1024 14:08:02.409511       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.436219765Z I1024 14:08:02.436163       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.456227905Z I1024 14:08:02.456174       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.474020035Z I1024 14:08:02.473963       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.490093845Z I1024 14:08:02.490036       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.512017955Z I1024 14:08:02.511969       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.527699685Z I1024 14:08:02.527346       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.550218795Z I1024 14:08:02.550163       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.576820805Z I1024 14:08:02.576717       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.595150145Z I1024 14:08:02.595110       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.618004535Z I1024 14:08:02.617966       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.630427975Z I1024 14:08:02.630370       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.649356745Z I1024 14:08:02.649323       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.664422454Z I1024 14:08:02.664370       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.680736754Z I1024 14:08:02.680661       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.694737685Z I1024 14:08:02.694698       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.710707505Z I1024 14:08:02.710647       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.732374385Z I1024 14:08:02.732328       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.756056854Z I1024 14:08:02.755995       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.777135514Z I1024 14:08:02.777053       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.789640364Z I1024 14:08:02.789604       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.809798894Z I1024 14:08:02.809710       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.831092374Z I1024 14:08:02.831050       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.850165494Z I1024 14:08:02.850108       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.867698124Z I1024 14:08:02.867652       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.885188864Z I1024 14:08:02.885122       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.901002284Z I1024 14:08:02.900949       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.924170044Z I1024 14:08:02.924103       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:08:02.961933974Z I1024 14:08:02.961875       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:11:57.807736726Z W1024 14:11:57.807667       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
2024-10-24T14:13:26.726091651Z I1024 14:13:26.726015       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:13:27.132360099Z I1024 14:13:27.132278       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:13:27.321689099Z I1024 14:13:27.321588       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:13:27.405006969Z I1024 14:13:27.404913       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:13:27.417505328Z I1024 14:13:27.417451       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:13:27.694602287Z I1024 14:13:27.694524       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubecontrollermanagers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:13:27.695101067Z I1024 14:13:27.695021       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:27.774606647Z I1024 14:13:27.774499       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:13:56.945584054Z I1024 14:13:56.945489       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:56.945770154Z I1024 14:13:56.945713       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:56.945982895Z I1024 14:13:56.945959       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:56.946389284Z I1024 14:13:56.946339       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:56.946578975Z I1024 14:13:56.946544       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:56.946794894Z I1024 14:13:56.946716       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:56.947026135Z I1024 14:13:56.946999       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:56.947278554Z I1024 14:13:56.947245       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:56.947454344Z I1024 14:13:56.947432       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:56.947628715Z I1024 14:13:56.947611       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:56.948627255Z I1024 14:13:56.948596       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:56.948823964Z I1024 14:13:56.948800       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:14:00.896054229Z I1024 14:14:00.895983       1 request.go:700] Waited for 1.164248445s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:16:57.808414410Z W1024 14:16:57.808297       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
2024-10-24T14:19:22.301031295Z I1024 14:19:22.300977       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.434808415Z I1024 14:19:22.434742       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.529559134Z I1024 14:19:22.529462       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubecontrollermanagers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.539291524Z I1024 14:19:22.539250       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:19:22.754887014Z I1024 14:19:22.754812       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.763841013Z I1024 14:19:22.763687       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.776628024Z I1024 14:19:22.776560       1 reflector.go:368] Caches populated for *v1.Proxy from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.831419733Z I1024 14:19:22.831349       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:21:57.808813838Z W1024 14:21:57.808674       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
2024-10-24T14:23:35.523398658Z I1024 14:23:35.523311       1 request.go:700] Waited for 1.128753416s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra
2024-10-24T14:23:36.722692393Z I1024 14:23:36.722619       1 request.go:700] Waited for 1.188548735s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager
2024-10-24T14:23:56.946135914Z I1024 14:23:56.946053       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:56.946656515Z I1024 14:23:56.946632       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:56.946924895Z I1024 14:23:56.946901       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:56.947212405Z I1024 14:23:56.947189       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:56.947435995Z I1024 14:23:56.947400       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:56.947641884Z I1024 14:23:56.947608       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:56.947810794Z I1024 14:23:56.947789       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:56.947980995Z I1024 14:23:56.947960       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:56.948182915Z I1024 14:23:56.948161       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:56.948347794Z I1024 14:23:56.948327       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:56.948541384Z I1024 14:23:56.948485       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:56.948664435Z I1024 14:23:56.948649       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:56.948860254Z I1024 14:23:56.948833       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:56.949041294Z I1024 14:23:56.948999       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:56.949201504Z I1024 14:23:56.949180       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:24:00.922465269Z I1024 14:24:00.922390       1 request.go:700] Waited for 1.184427125s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T14:26:57.809908030Z W1024 14:26:57.809820       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
2024-10-24T14:31:57.810786222Z W1024 14:31:57.810696       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
2024-10-24T14:32:47.951464013Z I1024 14:32:47.951383       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:49.070188407Z I1024 14:32:49.070125       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:49.100805526Z I1024 14:32:49.100708       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:49.766581272Z I1024 14:32:49.766512       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:49.829604992Z I1024 14:32:49.828040       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:49.884321872Z I1024 14:32:49.884222       1 reflector.go:368] Caches populated for *v1.Proxy from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:32:50.191876420Z I1024 14:32:50.191645       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:33:56.947182523Z I1024 14:33:56.947018       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:56.947271633Z I1024 14:33:56.947252       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:56.947543253Z I1024 14:33:56.947514       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:56.947814593Z I1024 14:33:56.947739       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:56.948068353Z I1024 14:33:56.948032       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:56.948326093Z I1024 14:33:56.948280       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:56.948556783Z I1024 14:33:56.948530       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:56.948729013Z I1024 14:33:56.948700       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:56.949308153Z I1024 14:33:56.949261       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:56.949636163Z I1024 14:33:56.949590       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:34:00.749614641Z I1024 14:34:00.749523       1 request.go:700] Waited for 1.003355174s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T14:34:01.750079415Z I1024 14:34:01.750033       1 request.go:700] Waited for 1.191501093s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T14:36:57.811505351Z W1024 14:36:57.811419       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
2024-10-24T14:41:57.812699285Z W1024 14:41:57.812624       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
2024-10-24T14:42:19.750376675Z I1024 14:42:19.750293       1 tlsconfig.go:181] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"admin-kubeconfig-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:31 +0000 UTC to 2034-10-22 12:49:31 +0000 UTC (now=2024-10-24 14:42:19.732667465 +0000 UTC))"
2024-10-24T14:42:19.750562215Z I1024 14:42:19.750539       1 tlsconfig.go:181] "Loaded client CA" index=1 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2024-10-25 12:49:34 +0000 UTC (now=2024-10-24 14:42:19.750484265 +0000 UTC))"
2024-10-24T14:42:19.750629025Z I1024 14:42:19.750613       1 tlsconfig.go:181] "Loaded client CA" index=2 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-control-plane-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2025-10-24 12:49:34 +0000 UTC (now=2024-10-24 14:42:19.750591155 +0000 UTC))"
2024-10-24T14:42:19.750844305Z I1024 14:42:19.750824       1 tlsconfig.go:181] "Loaded client CA" index=3 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-apiserver-to-kubelet-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2025-10-24 12:49:34 +0000 UTC (now=2024-10-24 14:42:19.750801045 +0000 UTC))"
2024-10-24T14:42:19.750909304Z I1024 14:42:19.750896       1 tlsconfig.go:181] "Loaded client CA" index=4 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-bootstrap-kubeconfig-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:32 +0000 UTC to 2034-10-22 12:49:32 +0000 UTC (now=2024-10-24 14:42:19.750877235 +0000 UTC))"
2024-10-24T14:42:19.750997425Z I1024 14:42:19.750982       1 tlsconfig.go:181] "Loaded client CA" index=5 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-csr-signer_@1729775012\" [] issuer=\"kubelet-signer\" (2024-10-24 13:03:31 +0000 UTC to 2024-10-25 12:49:34 +0000 UTC (now=2024-10-24 14:42:19.750964115 +0000 UTC))"
2024-10-24T14:42:19.753788345Z I1024 14:42:19.751039       1 tlsconfig.go:181] "Loaded client CA" index=6 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_node-system-admin-signer@1729775011\" [] issuer=\"<self>\" (2024-10-24 13:03:30 +0000 UTC to 2025-10-24 13:03:31 +0000 UTC (now=2024-10-24 14:42:19.751018335 +0000 UTC))"
2024-10-24T14:42:19.753923065Z I1024 14:42:19.753896       1 tlsconfig.go:181] "Loaded client CA" index=7 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"TestUserClientCABundleRootCA_3120422217834922768\" [] issuer=\"<self>\" (2023-10-24 14:42:09 +0000 UTC to 2025-10-24 14:42:09 +0000 UTC (now=2024-10-24 14:42:19.753865265 +0000 UTC))"
2024-10-24T14:42:19.753990915Z I1024 14:42:19.753973       1 tlsconfig.go:181] "Loaded client CA" index=8 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"aggregator-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:32 +0000 UTC to 2024-10-25 12:49:32 +0000 UTC (now=2024-10-24 14:42:19.753950905 +0000 UTC))"
2024-10-24T14:42:19.754058495Z I1024 14:42:19.754041       1 tlsconfig.go:181] "Loaded client CA" index=9 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_aggregator-client-signer@1729777579\" [] issuer=\"<self>\" (2024-10-24 13:46:18 +0000 UTC to 2024-10-25 01:46:19 +0000 UTC (now=2024-10-24 14:42:19.754020975 +0000 UTC))"
2024-10-24T14:42:19.754331865Z I1024 14:42:19.754301       1 tlsconfig.go:203] "Loaded serving cert" certName="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key" certDetail="\"metrics.openshift-kube-controller-manager-operator.svc\" [serving] validServingFor=[metrics.openshift-kube-controller-manager-operator.svc,metrics.openshift-kube-controller-manager-operator.svc.cluster.local] issuer=\"openshift-service-serving-signer@1729775010\" (2024-10-24 13:03:41 +0000 UTC to 2026-10-24 13:03:42 +0000 UTC (now=2024-10-24 14:42:19.754274325 +0000 UTC))"
2024-10-24T14:42:19.754546285Z I1024 14:42:19.754525       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1729775941\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1729775940\" (2024-10-24 12:19:00 +0000 UTC to 2025-10-24 12:19:00 +0000 UTC (now=2024-10-24 14:42:19.754484305 +0000 UTC))"
2024-10-24T14:42:22.238519280Z I1024 14:42:22.237801       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:42:22.238519280Z I1024 14:42:22.237860       1 core.go:352] ConfigMap "openshift-kube-controller-manager/client-ca" changes: {"data":{"ca-bundle.crt":"-----BEGIN CERTIFICATE-----\nMIIDMDCCAhigAwIBAgIIKD8vK0yX72AwDQYJKoZIhvcNAQELBQAwNjESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSAwHgYDVQQDExdhZG1pbi1rdWJlY29uZmlnLXNpZ25lcjAe\nFw0yNDEwMjQxMjQ5MzFaFw0zNDEwMjIxMjQ5MzFaMDYxEjAQBgNVBAsTCW9wZW5z\naGlmdDEgMB4GA1UEAxMXYWRtaW4ta3ViZWNvbmZpZy1zaWduZXIwggEiMA0GCSqG\nSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDSy81Zc/XDsuCN+rMxfd1WU8gvoU7Wq+zp\n+M98eW7XxN1HuOYqdBOA4fGf3C5lwB9n1jf0B9luXHd+d8KBFs1G+8UpIzqsA15O\n9XScU0RH6pLvNLBd2D4g/q25VBXP8iWbu45D9BPoBHGXmandjxvt3r0DqVi6kyP7\nT4i2pxRocTWmQbqAHR2Cu3K9cbbstQsQc3+f+gS4TzFAaKK5UxXKpV4NI03dYidH\ndSBgEklrhV5+bW/CG4+aEgbRO3Qxq8kRufD+P/bLgvDYQenCVzIOyxWdfB/S2Gbs\nnBjqm218ju8VYxnDK3TUf2x5zUhhKo7L+bzD+DUOlc0Ao3I/6Wk/AgMBAAGjQjBA\nMA4GA1UdDwEB/wQEAwICpDAPBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBQUQoiE\nabSz6jdokVyDS8l7W3E2NDANBgkqhkiG9w0BAQsFAAOCAQEAuW15NmNUpYH2aaGM\noJSEsvxgiwOOwRwqGEmd6ZYhWR8eSjs9MaIy+Kho5Zlx5415F6hZ1GB9Uqc0heOD\nYwZqw7XXuhiL3uxgUXPUSWNhRgupReMa+D9V1ElTAb7TybWWivsqmlPE96q/RtKv\ngfmsfjI5aw1IgsKeMJ+iQuoh22su98EVqo6q3YJNl5uppt3j5uzTGAQjIJ9IWRU6\nlME8kY/tOyNwl3QiCcpln8gJZiphTfFbCG+CB4oEJip2JavOKQgRZCH3EX5zF2NL\n67VsNrTB4BgAuIJOQFvr+RWQlsHrk/U0yqMFtmcJGy21S0vFwmu6/J8q4LfzM8DG\nQw2gdQ==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDODCCAiCgAwIBAgIIYcZky+VIU0cwDQYJKoZIhvcNAQELBQAwLTESMBAGA1UE\nCxMJb3BlbnNoaWZ0MRcwFQYDVQQDEw5rdWJlbGV0LXNpZ25lcjAeFw0yNDEwMjQx\nMzAzMzFaFw0yNDEwMjUxMjQ5MzRaMCYxJDAiBgNVBAMMG2t1YmUtY3NyLXNpZ25l\ncl9AMTcyOTc3NTAxMjCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAKz8\n2CJMWXvIgMxl+F31YWHRGJyMCVmEkuNmSuwDkJu5uYsYKKiEIreKGWyZDYThU1BY\ns5inIPiFKLss/lFK6dS3TxHqAyfHrUo5xmSIuqEe9K3Rbu+Uw8QRmbJL0pAwNsPH\nx6FP4ueIKDZ8fzxUxBJtttcx5bNupd/nLT6b1zkpv1yQRJXcQcXY8+UGUZ6A5IGq\ntFa1gwQFdsWD1J+F7i9+KNx9+Od8K1IMrk/EOuQ3qJerimlN5V7+SduFMUlkoYDQ\nYvIj19yi6I4zi0I8bEri8pxtILQSADubn9NeBh7BqvUjhW1YNtJcok2uKvAzIS1j\n+/x/PN3j1JMU4vwTkskCAwEAAaNjMGEwDgYDVR0PAQH/BAQDAgKkMA8GA1UdEwEB\n/wQFMAMBAf8wHQYDVR0OBBYEFAQgUptCf64AH7y7XkwPafOhYsC5MB8GA1UdIwQY\nMBaAFE11bLLwwCVD8U4AZJ96Vk1SK9SVMA0GCSqGSIb3DQEBCwUAA4IBAQBopLGj\nVxHtwVp827laS2c63TL0CbW3+XVuIDL34Pkgz+U2GVzohnho331Q9Rid+7sgpNxv\nE2YL7ZOBybhWZICExDOIDH8ElvOFYoLl5u0/Gg1+KybFKBB5pVmcVTre3FIfQLjO\nLbRWEPey4/3NXGFvbuWOyZUmwcMBELCVY9kxr+IsqVWT8cuHd3X2f8PUFKpKsKmK\nzUyrbKFKJozIxNtFNJms7sWRuiTeySBzsUrlEYtg2gmDfvxl+vEXExvOCajMbVy8\nAG2Q+vX2xppdxnpeZsonLKu4bbHdASz/QE2XgbDPmBUavgy5E7QwDv7N/UoYhv/b\nQGJ0MIkbTu3/GM1f\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDHjCCAgagAwIBAgIIDJSZyXXaqawwDQYJKoZIhvcNAQELBQAwLTESMBAGA1UE\nCxMJb3BlbnNoaWZ0MRcwFQYDVQQDEw5rdWJlbGV0LXNpZ25lcjAeFw0yNDEwMjQx\nMjQ5MzRaFw0yNDEwMjUxMjQ5MzRaMC0xEjAQBgNVBAsTCW9wZW5zaGlmdDEXMBUG\nA1UEAxMOa3ViZWxldC1zaWduZXIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEK\nAoIBAQC8ZDuE8a9kq/gkpHinMhFa8wrcHbBPfgxsXRsO528D/qMJEDScjxTvQ6CZ\nK/jANjKk5TB9pppNSiOXwyIIPhGxPoa/vJvONdHWNglNxFajpz4JdCPD/ocxd1A+\nImVuKJ7U7ft+e1OwOZ11yrU4C9PmQPhwIP14GWgwM9liAuUX4MzdECw6RhmivGGt\n82z3gHwJh9sDHRQrRvj4qwZ3VYVqVLeNut3R7GLpXIX1Bo5RicWjJNx8v/D1s9EI\nr6eou3GWq+8r3oYZBMIQkdEzXX+Sry4AkdGy2JhLp2/bufeFE/cpX1ajyJghYCpb\nJCOTJnb5qm0xyQjW+fWERt8NDKcHAgMBAAGjQjBAMA4GA1UdDwEB/wQEAwICpDAP\nBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBRNdWyy8MAlQ/FOAGSfelZNUivUlTAN\nBgkqhkiG9w0BAQsFAAOCAQEAJyPzK6aRYpJjWaGorWKZg3w5IUdfc6YF9Eh4kUWs\nKSuVqaHyLISam2Igs3SO1Ek4G5+s51Ge0H4OYkUUX+wh/+6EwtXTqLvBqmy4gmmH\nvpDEVofcPfi8CU7wQTwIFHV8SjeOUbzQkrQ/cxeIBrVV/lf2SgdWLmId6DDhwMe2\nOLEBKIl5BzcBnAWCVDPXQ1aatrvgy8SPJNx8DZVZiOLso6pCK6A6i0yOPaPdVeub\nvfqEY3NmG3j//SFvcI7B4ET7dvI1Kafk97nNimLmNwCw6CzINXQdZcF8gHyurUeT\njzHqZjCIAEG8nK3/w67TYu8wf8KEP39PqpKYVqBqlxgIzg==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDQjCCAiqgAwIBAgIIIgBseiSWV6owDQYJKoZIhvcNAQELBQAwPzESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSkwJwYDVQQDEyBrdWJlLWFwaXNlcnZlci10by1rdWJlbGV0\nLXNpZ25lcjAeFw0yNDEwMjQxMjQ5MzRaFw0yNTEwMjQxMjQ5MzRaMD8xEjAQBgNV\nBAsTCW9wZW5zaGlmdDEpMCcGA1UEAxMga3ViZS1hcGlzZXJ2ZXItdG8ta3ViZWxl\ndC1zaWduZXIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDlVXO22DeG\nAeTZxLN/B82Kq5vVAOCGsfmxaRzvX2iR8reLVW0qBWqepmgMiYn3hWLDZ8kFSo/A\n27SX7cy+73H5l2foiv9lWDiG7HE9CUeZ0d3daRd5x7+dm9GWDHHQf9VlV0GMN4op\n4PM5cNkSf6KRcQa1Sz5cWDjVv0Bk31Dcrp4sSOhXcPQ4hhj9+K5EQ06zdaJ07mzL\nGGWJc6Xzd26kvQ0iK1YGq6RD1O8bq2C/2Ni6Oi54RZAAHKcbmnlez7yG4kPoKrjF\n3RTp1ruEyWq7av6C+kg8hWbKT0zqnJEKnoSfr/JXfWhwW2PRr7xkf3QXs3UwkQvL\nmw9xDrh28fXtAgMBAAGjQjBAMA4GA1UdDwEB/wQEAwICpDAPBgNVHRMBAf8EBTAD\nAQH/MB0GA1UdDgQWBBRlmmf8ji8J6xxD1bFp0i6684LyFDANBgkqhkiG9w0BAQsF\nAAOCAQEAs9OqLAdq7kOMJvkcOfTSWbbp3zeZ1OTGhXtHkg3zG8LQithOQAQc6XFE\n4ESxBenwnIqR94vVfVz3qtx+ieuu8VhRcNc/uHVD+Ywm9Ep4Krs285zpTRgK5hOS\nR8YpSyZaJAX6W1B0oJxaDzv3IQ1KftrR7cQnNHxLo8d6ZjGZbQZ714eLIZVSjbGO\nZvipuWsqlUfW/7MCom6fM4+iUiGRrgDFKJp6huTj2I+j013B+mAxL0J6OWxuKWCB\nPvcdPaQjvx1yZQy04RIw53i3JnBVd5NiZ19YiTZaMg9s9mmii3FoobvqZtcnugax\nU1Zmat96zSEq55TFjwnuxud41FBUzg==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDNDCCAhygAwIBAgIIX9+YZ8stdGMwDQYJKoZIhvcNAQELBQAwODESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSIwIAYDVQQDExlrdWJlLWNvbnRyb2wtcGxhbmUtc2lnbmVy\nMB4XDTI0MTAyNDEyNDkzNFoXDTI1MTAyNDEyNDkzNFowODESMBAGA1UECxMJb3Bl\nbnNoaWZ0MSIwIAYDVQQDExlrdWJlLWNvbnRyb2wtcGxhbmUtc2lnbmVyMIIBIjAN\nBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvJ4Ozu5GmdsVCYHQXe4bJ9Psetgu\nNM4u1DcVFI8isazuqTabJ+HoX5myu8Z3fH4ByUUxqiZhPR+pQzkfep/V+HWtLnPh\niSP6bouQ6uLILc6dm9Me02BWEKavsYEJtcraat5unOkFmz4S0WXb9bxC4c88TPhV\nTeRELAcNV9ppC0+/aNDucZJVyTrL23dWdj55EQR5Qbw7hrFLkX/dlsacbrum5FGI\n06md6/z3IBMQdu6jRgGNsYR4FfTu9U9shJTcJFhtcyeavYdFn3E6jln40psIrrlE\n9y5hEb6IHMhc+WEIeTYsjeFOt+6PMztm07/DlR/TdPV1ZwQYlKLeIcS9zwIDAQAB\no0IwQDAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQU\nAHHcAKEWg0AykllPyrh5YlVqTREwDQYJKoZIhvcNAQELBQADggEBAEHrMBG1K2/T\nODtEE8OKKqQhmxep1/t3l+PxAwY1q/qKmOSdqzR/XWpjxnWr4NKcQ6z5/I2OmTsT\nQR5rPa6QFdidie6o+w3vK94aigaLaJh6sfRRhLGxQPLHvzgm6mH+qyNLZ9/L01qn\noLSl65xXjZU7A0NiPS41jAAxDdLfnpJ0b5993yJl823EdCv7RR4abAXKV1CZ5uRA\n9/psJzQfY3oRgQs8X0JLJTD87aygUIjKritPUJq3+eRIt6gDZVbdFjni+IskhbwX\n2jdq96aMyepUky3WvLk/lDH+ObsVhFU8dGwNdYmVyeaK1jOZCgLTCApIdlXninmz\n49++6WDY9GY=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDOjCCAiKgAwIBAgIIK033eXNJgxAwDQYJKoZIhvcNAQELBQAwOzE5MDcGA1UE\nAwwwVGVzdFVzZXJDbGllbnRDQUJ1bmRsZVJvb3RDQV8zMTIwNDIyMjE3ODM0OTIy\nNzY4MB4XDTIzMTAyNDE0NDIwOVoXDTI1MTAyNDE0NDIwOVowOzE5MDcGA1UEAwww\nVGVzdFVzZXJDbGllbnRDQUJ1bmRsZVJvb3RDQV8zMTIwNDIyMjE3ODM0OTIyNzY4\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA5N9751pTg40lCekACzl0\nO21ldWystOPp2kYimOyvfkcKFn/j93JBqqcCdMK2Poaap/vFvj3jeiuGyVFriutK\nS5M76OwEfIBP6d6liJA24QlaeNgQ4nmNrSgfxXOEFTJmxGvXRhGWu7BnmeWBw2TM\nTqbcP2SmHZIPV4ljgKByf51sFQlSphbtMF4rOz6wFQ3ihJ1u0rWEHCK9sCfMFAVk\ngwzA87LVwvcXdrIvqlatoro6wTW0CVUAdNxQFlIK0e32Kf9kF+FbkshipVl2GvsQ\nF9mkVIIEGHKwju71EsnZqawh9SZjaolI2UbSlvJ2mlM1WIGoVj8DDiZWzUnOlPBA\nZwIDAQABo0IwQDAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/BAUwAwEB/zAdBgNV\nHQ4EFgQU1cl+IVo3ESsElayuXv6rUIjFIy4wDQYJKoZIhvcNAQELBQADggEBAKhO\n3dpFfLGJUDfSO1y0eBW5ZBzJtIjEh5Uc5EESuMn5T9K88KhRQGoiD0owvpEmC+T4\ntIGUrjaRaLJnCfHs655hB4MSSbMFvplzguGDqrerLmPUojRotwgBNGk+RCSQLj2k\nZfhZXKC0eSOwihQ2/oJUxlz2vGEjJN0PWX8xTNBvTrjLFOqCuqo2nhcr/XGI8wsh\nP3NLT2M5PBsSacfk8+WQqEW9OOvDeuxB6wYbxZRv2HhdtjOYAqsB5pMwgC7mTA7X\nJn8hVlEMc1Xhg1plutgiPSz0hmyepGP1lhtetXbzNAeqFj4f53nvv2+sOtJz/glZ\nEUHtB4m6dcF+REqkkX0=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDSDCCAjCgAwIBAgIIfLx9YwB4GnYwDQYJKoZIhvcNAQELBQAwQjESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSwwKgYDVQQDEyNrdWJlbGV0LWJvb3RzdHJhcC1rdWJlY29u\nZmlnLXNpZ25lcjAeFw0yNDEwMjQxMjQ5MzJaFw0zNDEwMjIxMjQ5MzJaMEIxEjAQ\nBgNVBAsTCW9wZW5zaGlmdDEsMCoGA1UEAxMja3ViZWxldC1ib290c3RyYXAta3Vi\nZWNvbmZpZy1zaWduZXIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDm\nY3WOK6mc00bqmADeGDIwpdqodyLvdwIRu6QVSIAGYevh9wS1xldkkyXzl+I2uSmX\n2QVATv6si2x+j8kw8bkQywB9FuGTAjYhLJeZKZvS5XVlzE2rwpdTdiLz7YPwsvjA\ne2HfEDdpRYs/KMNe2Q5jkXxZ1aE0/+rkRLbOXGEBWyc8uGCeLENLvQD4JP+0myR/\n14uG/h1E5NV3ZxbXF7DhCZoR9s1sAg6jWyZ4UfanKHNAtWc9IJs2bXc0a+Qo85nE\nnyNCzaj3px9IOzry09za41usQ1x4REG8wU2uyzq12UMpJsPQLXPyOlrBGA5vKpUh\no4PS07kCWJqSfMULkkjXAgMBAAGjQjBAMA4GA1UdDwEB/wQEAwICpDAPBgNVHRMB\nAf8EBTADAQH/MB0GA1UdDgQWBBRSmNqjIChvurEDBbBgQp4FgUip6DANBgkqhkiG\n9w0BAQsFAAOCAQEAglc4Sl2P+uGbmcosZx7EqMLkWAubCJS4GV/eYhb6cr7MsG8R\nG6xI8twLTe5M27hBVegHjvBhCkmJRykKipDcmdFQEDOnYs17vBzSx4jE8x6J9w8v\nl1aycBwSb51wsMLiLybT7ZnmffZyW48y631LEq+U9bQXSo1maGKQlReugmaIC/3H\nxZR5sQdhWKI37bI7S+6Ch2DmHAxvf4Pt4xJXcJVR3E4Vl10xTh4i7+6i5dFFBySt\n9+6wP6jBX/2nThuVU+YzczdnyQGwhjrAhhw6SBi2OYorGO0T57fWolrwins9H7VU\nG8HL94fUHZPmtCxg0zfxDp/HqTRIzdy8MzSk+g==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDhTCCAm2gAwIBAgIIbLwL36EOiOowDQYJKoZIhvcNAQELBQAwUDFOMEwGA1UE\nAwxFb3BlbnNoaWZ0LWt1YmUtYXBpc2VydmVyLW9wZXJhdG9yX25vZGUtc3lzdGVt\nLWFkbWluLXNpZ25lckAxNzI5Nzc1MDExMB4XDTI0MTAyNDEzMDMzMFoXDTI1MTAy\nNDEzMDMzMVowUDFOMEwGA1UEAwxFb3BlbnNoaWZ0LWt1YmUtYXBpc2VydmVyLW9w\nZXJhdG9yX25vZGUtc3lzdGVtLWFkbWluLXNpZ25lckAxNzI5Nzc1MDExMIIBIjAN\nBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA0rwLgZyX7Ck9N4YXVdlJMkDFf+U2\n3W2ZkDGvqzEVck9Zy+7shyke4DlSMbu0arrhMvhhnMBe4dAQsB9Yca7tE2SobJ/S\nxlfFDS3YdeZ1gEZthB6c5m3yzATpX/HSJjZVOLdDKjQAaEyAFNGClPgLBTLxzXdb\nqCIyrt5rCzLrwFvt8E1WEqDg6Xw7xHiijD/YxBfDtGBpOvFqarj1M16P0izQj2FE\niK4b37dxau7cBxpCNOoEHFX7i5MPtDfHs9+CNMdlLnCE+umP0MPhmtwJJqn/4PnP\nJemqNWJggiG7GoHD+RBvzqH5wxVwhVF+ZrE97IB7RBWMewzi/WJHCBzl7wIDAQAB\no2MwYTAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQU\nZqGk2rMImW2jow19uGgRPv72rLMwHwYDVR0jBBgwFoAUZqGk2rMImW2jow19uGgR\nPv72rLMwDQYJKoZIhvcNAQELBQADggEBAKTgEbJ8eMwbwWCadRrdpHMJjxYrHBsI\njSoORNqgsSyNefbQDCtRmi/sLmfg4+2S9Vq6TqUaK1rnrcO7vC8Olp2zoAWVbx+p\nNK6fsSruwXsDAiVuzt6PITwvc7kPHYLMUdMDlL+BS4Q9GIaudixe5l9M+RcF51DM\nXXJt18jKEijbwuBu6SDM5RlZIWdvr083pNDWF27F2oENcgsxDQw8bYeE/BDAdKgY\n/OUb2PAflN8ZMoFHkVJ5Krvvdlv+Zi90+D+ps5CKqhTNZ0Jedojp73j11UYs+HI2\nRdRpwfsWa1qrlBcR/mk9lD0YetMrG0YNWpLHEYW45AtPqYKYV/ZnBas=\n-----END CERTIFICATE-----\n"},"metadata":{"managedFields":[{"apiVersion":"v1","fieldsType":"FieldsV1","fieldsV1":{"f:data":{".":{},"f:ca-bundle.crt":{}},"f:metadata":{"f:annotations":{".":{},"f:openshift.io/owning-component":{}}}},"manager":"cluster-kube-apiserver-operator","operation":"Update","time":"2024-10-24T14:42:22Z"}],"resourceVersion":null,"uid":"ae9e507f-1c09-4a6c-8fec-faf6a5892b08"}}
2024-10-24T14:42:22.245934450Z I1024 14:42:22.244841       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/client-ca -n openshift-kube-controller-manager:
2024-10-24T14:42:22.245934450Z cause by changes in data.ca-bundle.crt
2024-10-24T14:42:33.036287456Z I1024 14:42:33.036210       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:42:33.038449466Z I1024 14:42:33.038379       1 core.go:352] ConfigMap "openshift-kube-controller-manager/client-ca" changes: {"data":{"ca-bundle.crt":"-----BEGIN CERTIFICATE-----\nMIIDMDCCAhigAwIBAgIIKD8vK0yX72AwDQYJKoZIhvcNAQELBQAwNjESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSAwHgYDVQQDExdhZG1pbi1rdWJlY29uZmlnLXNpZ25lcjAe\nFw0yNDEwMjQxMjQ5MzFaFw0zNDEwMjIxMjQ5MzFaMDYxEjAQBgNVBAsTCW9wZW5z\naGlmdDEgMB4GA1UEAxMXYWRtaW4ta3ViZWNvbmZpZy1zaWduZXIwggEiMA0GCSqG\nSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDSy81Zc/XDsuCN+rMxfd1WU8gvoU7Wq+zp\n+M98eW7XxN1HuOYqdBOA4fGf3C5lwB9n1jf0B9luXHd+d8KBFs1G+8UpIzqsA15O\n9XScU0RH6pLvNLBd2D4g/q25VBXP8iWbu45D9BPoBHGXmandjxvt3r0DqVi6kyP7\nT4i2pxRocTWmQbqAHR2Cu3K9cbbstQsQc3+f+gS4TzFAaKK5UxXKpV4NI03dYidH\ndSBgEklrhV5+bW/CG4+aEgbRO3Qxq8kRufD+P/bLgvDYQenCVzIOyxWdfB/S2Gbs\nnBjqm218ju8VYxnDK3TUf2x5zUhhKo7L+bzD+DUOlc0Ao3I/6Wk/AgMBAAGjQjBA\nMA4GA1UdDwEB/wQEAwICpDAPBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBQUQoiE\nabSz6jdokVyDS8l7W3E2NDANBgkqhkiG9w0BAQsFAAOCAQEAuW15NmNUpYH2aaGM\noJSEsvxgiwOOwRwqGEmd6ZYhWR8eSjs9MaIy+Kho5Zlx5415F6hZ1GB9Uqc0heOD\nYwZqw7XXuhiL3uxgUXPUSWNhRgupReMa+D9V1ElTAb7TybWWivsqmlPE96q/RtKv\ngfmsfjI5aw1IgsKeMJ+iQuoh22su98EVqo6q3YJNl5uppt3j5uzTGAQjIJ9IWRU6\nlME8kY/tOyNwl3QiCcpln8gJZiphTfFbCG+CB4oEJip2JavOKQgRZCH3EX5zF2NL\n67VsNrTB4BgAuIJOQFvr+RWQlsHrk/U0yqMFtmcJGy21S0vFwmu6/J8q4LfzM8DG\nQw2gdQ==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDODCCAiCgAwIBAgIIYcZky+VIU0cwDQYJKoZIhvcNAQELBQAwLTESMBAGA1UE\nCxMJb3BlbnNoaWZ0MRcwFQYDVQQDEw5rdWJlbGV0LXNpZ25lcjAeFw0yNDEwMjQx\nMzAzMzFaFw0yNDEwMjUxMjQ5MzRaMCYxJDAiBgNVBAMMG2t1YmUtY3NyLXNpZ25l\ncl9AMTcyOTc3NTAxMjCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAKz8\n2CJMWXvIgMxl+F31YWHRGJyMCVmEkuNmSuwDkJu5uYsYKKiEIreKGWyZDYThU1BY\ns5inIPiFKLss/lFK6dS3TxHqAyfHrUo5xmSIuqEe9K3Rbu+Uw8QRmbJL0pAwNsPH\nx6FP4ueIKDZ8fzxUxBJtttcx5bNupd/nLT6b1zkpv1yQRJXcQcXY8+UGUZ6A5IGq\ntFa1gwQFdsWD1J+F7i9+KNx9+Od8K1IMrk/EOuQ3qJerimlN5V7+SduFMUlkoYDQ\nYvIj19yi6I4zi0I8bEri8pxtILQSADubn9NeBh7BqvUjhW1YNtJcok2uKvAzIS1j\n+/x/PN3j1JMU4vwTkskCAwEAAaNjMGEwDgYDVR0PAQH/BAQDAgKkMA8GA1UdEwEB\n/wQFMAMBAf8wHQYDVR0OBBYEFAQgUptCf64AH7y7XkwPafOhYsC5MB8GA1UdIwQY\nMBaAFE11bLLwwCVD8U4AZJ96Vk1SK9SVMA0GCSqGSIb3DQEBCwUAA4IBAQBopLGj\nVxHtwVp827laS2c63TL0CbW3+XVuIDL34Pkgz+U2GVzohnho331Q9Rid+7sgpNxv\nE2YL7ZOBybhWZICExDOIDH8ElvOFYoLl5u0/Gg1+KybFKBB5pVmcVTre3FIfQLjO\nLbRWEPey4/3NXGFvbuWOyZUmwcMBELCVY9kxr+IsqVWT8cuHd3X2f8PUFKpKsKmK\nzUyrbKFKJozIxNtFNJms7sWRuiTeySBzsUrlEYtg2gmDfvxl+vEXExvOCajMbVy8\nAG2Q+vX2xppdxnpeZsonLKu4bbHdASz/QE2XgbDPmBUavgy5E7QwDv7N/UoYhv/b\nQGJ0MIkbTu3/GM1f\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDHjCCAgagAwIBAgIIDJSZyXXaqawwDQYJKoZIhvcNAQELBQAwLTESMBAGA1UE\nCxMJb3BlbnNoaWZ0MRcwFQYDVQQDEw5rdWJlbGV0LXNpZ25lcjAeFw0yNDEwMjQx\nMjQ5MzRaFw0yNDEwMjUxMjQ5MzRaMC0xEjAQBgNVBAsTCW9wZW5zaGlmdDEXMBUG\nA1UEAxMOa3ViZWxldC1zaWduZXIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEK\nAoIBAQC8ZDuE8a9kq/gkpHinMhFa8wrcHbBPfgxsXRsO528D/qMJEDScjxTvQ6CZ\nK/jANjKk5TB9pppNSiOXwyIIPhGxPoa/vJvONdHWNglNxFajpz4JdCPD/ocxd1A+\nImVuKJ7U7ft+e1OwOZ11yrU4C9PmQPhwIP14GWgwM9liAuUX4MzdECw6RhmivGGt\n82z3gHwJh9sDHRQrRvj4qwZ3VYVqVLeNut3R7GLpXIX1Bo5RicWjJNx8v/D1s9EI\nr6eou3GWq+8r3oYZBMIQkdEzXX+Sry4AkdGy2JhLp2/bufeFE/cpX1ajyJghYCpb\nJCOTJnb5qm0xyQjW+fWERt8NDKcHAgMBAAGjQjBAMA4GA1UdDwEB/wQEAwICpDAP\nBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBRNdWyy8MAlQ/FOAGSfelZNUivUlTAN\nBgkqhkiG9w0BAQsFAAOCAQEAJyPzK6aRYpJjWaGorWKZg3w5IUdfc6YF9Eh4kUWs\nKSuVqaHyLISam2Igs3SO1Ek4G5+s51Ge0H4OYkUUX+wh/+6EwtXTqLvBqmy4gmmH\nvpDEVofcPfi8CU7wQTwIFHV8SjeOUbzQkrQ/cxeIBrVV/lf2SgdWLmId6DDhwMe2\nOLEBKIl5BzcBnAWCVDPXQ1aatrvgy8SPJNx8DZVZiOLso6pCK6A6i0yOPaPdVeub\nvfqEY3NmG3j//SFvcI7B4ET7dvI1Kafk97nNimLmNwCw6CzINXQdZcF8gHyurUeT\njzHqZjCIAEG8nK3/w67TYu8wf8KEP39PqpKYVqBqlxgIzg==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDQjCCAiqgAwIBAgIIIgBseiSWV6owDQYJKoZIhvcNAQELBQAwPzESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSkwJwYDVQQDEyBrdWJlLWFwaXNlcnZlci10by1rdWJlbGV0\nLXNpZ25lcjAeFw0yNDEwMjQxMjQ5MzRaFw0yNTEwMjQxMjQ5MzRaMD8xEjAQBgNV\nBAsTCW9wZW5zaGlmdDEpMCcGA1UEAxMga3ViZS1hcGlzZXJ2ZXItdG8ta3ViZWxl\ndC1zaWduZXIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDlVXO22DeG\nAeTZxLN/B82Kq5vVAOCGsfmxaRzvX2iR8reLVW0qBWqepmgMiYn3hWLDZ8kFSo/A\n27SX7cy+73H5l2foiv9lWDiG7HE9CUeZ0d3daRd5x7+dm9GWDHHQf9VlV0GMN4op\n4PM5cNkSf6KRcQa1Sz5cWDjVv0Bk31Dcrp4sSOhXcPQ4hhj9+K5EQ06zdaJ07mzL\nGGWJc6Xzd26kvQ0iK1YGq6RD1O8bq2C/2Ni6Oi54RZAAHKcbmnlez7yG4kPoKrjF\n3RTp1ruEyWq7av6C+kg8hWbKT0zqnJEKnoSfr/JXfWhwW2PRr7xkf3QXs3UwkQvL\nmw9xDrh28fXtAgMBAAGjQjBAMA4GA1UdDwEB/wQEAwICpDAPBgNVHRMBAf8EBTAD\nAQH/MB0GA1UdDgQWBBRlmmf8ji8J6xxD1bFp0i6684LyFDANBgkqhkiG9w0BAQsF\nAAOCAQEAs9OqLAdq7kOMJvkcOfTSWbbp3zeZ1OTGhXtHkg3zG8LQithOQAQc6XFE\n4ESxBenwnIqR94vVfVz3qtx+ieuu8VhRcNc/uHVD+Ywm9Ep4Krs285zpTRgK5hOS\nR8YpSyZaJAX6W1B0oJxaDzv3IQ1KftrR7cQnNHxLo8d6ZjGZbQZ714eLIZVSjbGO\nZvipuWsqlUfW/7MCom6fM4+iUiGRrgDFKJp6huTj2I+j013B+mAxL0J6OWxuKWCB\nPvcdPaQjvx1yZQy04RIw53i3JnBVd5NiZ19YiTZaMg9s9mmii3FoobvqZtcnugax\nU1Zmat96zSEq55TFjwnuxud41FBUzg==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDNDCCAhygAwIBAgIIX9+YZ8stdGMwDQYJKoZIhvcNAQELBQAwODESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSIwIAYDVQQDExlrdWJlLWNvbnRyb2wtcGxhbmUtc2lnbmVy\nMB4XDTI0MTAyNDEyNDkzNFoXDTI1MTAyNDEyNDkzNFowODESMBAGA1UECxMJb3Bl\nbnNoaWZ0MSIwIAYDVQQDExlrdWJlLWNvbnRyb2wtcGxhbmUtc2lnbmVyMIIBIjAN\nBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvJ4Ozu5GmdsVCYHQXe4bJ9Psetgu\nNM4u1DcVFI8isazuqTabJ+HoX5myu8Z3fH4ByUUxqiZhPR+pQzkfep/V+HWtLnPh\niSP6bouQ6uLILc6dm9Me02BWEKavsYEJtcraat5unOkFmz4S0WXb9bxC4c88TPhV\nTeRELAcNV9ppC0+/aNDucZJVyTrL23dWdj55EQR5Qbw7hrFLkX/dlsacbrum5FGI\n06md6/z3IBMQdu6jRgGNsYR4FfTu9U9shJTcJFhtcyeavYdFn3E6jln40psIrrlE\n9y5hEb6IHMhc+WEIeTYsjeFOt+6PMztm07/DlR/TdPV1ZwQYlKLeIcS9zwIDAQAB\no0IwQDAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQU\nAHHcAKEWg0AykllPyrh5YlVqTREwDQYJKoZIhvcNAQELBQADggEBAEHrMBG1K2/T\nODtEE8OKKqQhmxep1/t3l+PxAwY1q/qKmOSdqzR/XWpjxnWr4NKcQ6z5/I2OmTsT\nQR5rPa6QFdidie6o+w3vK94aigaLaJh6sfRRhLGxQPLHvzgm6mH+qyNLZ9/L01qn\noLSl65xXjZU7A0NiPS41jAAxDdLfnpJ0b5993yJl823EdCv7RR4abAXKV1CZ5uRA\n9/psJzQfY3oRgQs8X0JLJTD87aygUIjKritPUJq3+eRIt6gDZVbdFjni+IskhbwX\n2jdq96aMyepUky3WvLk/lDH+ObsVhFU8dGwNdYmVyeaK1jOZCgLTCApIdlXninmz\n49++6WDY9GY=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDSDCCAjCgAwIBAgIIfLx9YwB4GnYwDQYJKoZIhvcNAQELBQAwQjESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSwwKgYDVQQDEyNrdWJlbGV0LWJvb3RzdHJhcC1rdWJlY29u\nZmlnLXNpZ25lcjAeFw0yNDEwMjQxMjQ5MzJaFw0zNDEwMjIxMjQ5MzJaMEIxEjAQ\nBgNVBAsTCW9wZW5zaGlmdDEsMCoGA1UEAxMja3ViZWxldC1ib290c3RyYXAta3Vi\nZWNvbmZpZy1zaWduZXIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDm\nY3WOK6mc00bqmADeGDIwpdqodyLvdwIRu6QVSIAGYevh9wS1xldkkyXzl+I2uSmX\n2QVATv6si2x+j8kw8bkQywB9FuGTAjYhLJeZKZvS5XVlzE2rwpdTdiLz7YPwsvjA\ne2HfEDdpRYs/KMNe2Q5jkXxZ1aE0/+rkRLbOXGEBWyc8uGCeLENLvQD4JP+0myR/\n14uG/h1E5NV3ZxbXF7DhCZoR9s1sAg6jWyZ4UfanKHNAtWc9IJs2bXc0a+Qo85nE\nnyNCzaj3px9IOzry09za41usQ1x4REG8wU2uyzq12UMpJsPQLXPyOlrBGA5vKpUh\no4PS07kCWJqSfMULkkjXAgMBAAGjQjBAMA4GA1UdDwEB/wQEAwICpDAPBgNVHRMB\nAf8EBTADAQH/MB0GA1UdDgQWBBRSmNqjIChvurEDBbBgQp4FgUip6DANBgkqhkiG\n9w0BAQsFAAOCAQEAglc4Sl2P+uGbmcosZx7EqMLkWAubCJS4GV/eYhb6cr7MsG8R\nG6xI8twLTe5M27hBVegHjvBhCkmJRykKipDcmdFQEDOnYs17vBzSx4jE8x6J9w8v\nl1aycBwSb51wsMLiLybT7ZnmffZyW48y631LEq+U9bQXSo1maGKQlReugmaIC/3H\nxZR5sQdhWKI37bI7S+6Ch2DmHAxvf4Pt4xJXcJVR3E4Vl10xTh4i7+6i5dFFBySt\n9+6wP6jBX/2nThuVU+YzczdnyQGwhjrAhhw6SBi2OYorGO0T57fWolrwins9H7VU\nG8HL94fUHZPmtCxg0zfxDp/HqTRIzdy8MzSk+g==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDhTCCAm2gAwIBAgIIbLwL36EOiOowDQYJKoZIhvcNAQELBQAwUDFOMEwGA1UE\nAwxFb3BlbnNoaWZ0LWt1YmUtYXBpc2VydmVyLW9wZXJhdG9yX25vZGUtc3lzdGVt\nLWFkbWluLXNpZ25lckAxNzI5Nzc1MDExMB4XDTI0MTAyNDEzMDMzMFoXDTI1MTAy\nNDEzMDMzMVowUDFOMEwGA1UEAwxFb3BlbnNoaWZ0LWt1YmUtYXBpc2VydmVyLW9w\nZXJhdG9yX25vZGUtc3lzdGVtLWFkbWluLXNpZ25lckAxNzI5Nzc1MDExMIIBIjAN\nBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA0rwLgZyX7Ck9N4YXVdlJMkDFf+U2\n3W2ZkDGvqzEVck9Zy+7shyke4DlSMbu0arrhMvhhnMBe4dAQsB9Yca7tE2SobJ/S\nxlfFDS3YdeZ1gEZthB6c5m3yzATpX/HSJjZVOLdDKjQAaEyAFNGClPgLBTLxzXdb\nqCIyrt5rCzLrwFvt8E1WEqDg6Xw7xHiijD/YxBfDtGBpOvFqarj1M16P0izQj2FE\niK4b37dxau7cBxpCNOoEHFX7i5MPtDfHs9+CNMdlLnCE+umP0MPhmtwJJqn/4PnP\nJemqNWJggiG7GoHD+RBvzqH5wxVwhVF+ZrE97IB7RBWMewzi/WJHCBzl7wIDAQAB\no2MwYTAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQU\nZqGk2rMImW2jow19uGgRPv72rLMwHwYDVR0jBBgwFoAUZqGk2rMImW2jow19uGgR\nPv72rLMwDQYJKoZIhvcNAQELBQADggEBAKTgEbJ8eMwbwWCadRrdpHMJjxYrHBsI\njSoORNqgsSyNefbQDCtRmi/sLmfg4+2S9Vq6TqUaK1rnrcO7vC8Olp2zoAWVbx+p\nNK6fsSruwXsDAiVuzt6PITwvc7kPHYLMUdMDlL+BS4Q9GIaudixe5l9M+RcF51DM\nXXJt18jKEijbwuBu6SDM5RlZIWdvr083pNDWF27F2oENcgsxDQw8bYeE/BDAdKgY\n/OUb2PAflN8ZMoFHkVJ5Krvvdlv+Zi90+D+ps5CKqhTNZ0Jedojp73j11UYs+HI2\nRdRpwfsWa1qrlBcR/mk9lD0YetMrG0YNWpLHEYW45AtPqYKYV/ZnBas=\n-----END CERTIFICATE-----\n"},"metadata":{"managedFields":[{"apiVersion":"v1","fieldsType":"FieldsV1","fieldsV1":{"f:data":{".":{},"f:ca-bundle.crt":{}},"f:metadata":{"f:annotations":{".":{},"f:openshift.io/owning-component":{}}}},"manager":"cluster-kube-apiserver-operator","operation":"Update","time":"2024-10-24T14:42:32Z"}],"resourceVersion":null,"uid":"ae9e507f-1c09-4a6c-8fec-faf6a5892b08"}}
2024-10-24T14:42:33.038701216Z I1024 14:42:33.038644       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/client-ca -n openshift-kube-controller-manager:
2024-10-24T14:42:33.038701216Z cause by changes in data.ca-bundle.crt
2024-10-24T14:43:56.946989337Z I1024 14:43:56.946932       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:43:56.948337667Z I1024 14:43:56.948268       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:43:56.948623176Z I1024 14:43:56.948596       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:43:56.949052096Z I1024 14:43:56.948885       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:43:56.949359836Z I1024 14:43:56.949324       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:43:56.949523136Z I1024 14:43:56.949498       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:43:56.949700436Z I1024 14:43:56.949652       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:44:00.880296833Z I1024 14:44:00.880215       1 request.go:700] Waited for 1.129604493s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T14:44:01.880408187Z I1024 14:44:01.880329       1 request.go:700] Waited for 1.187587293s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client
