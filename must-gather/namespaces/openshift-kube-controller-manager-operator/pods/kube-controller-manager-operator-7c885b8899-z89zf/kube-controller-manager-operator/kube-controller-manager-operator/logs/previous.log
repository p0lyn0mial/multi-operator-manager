2024-10-24T13:04:59.727275754Z I1024 13:04:59.727144       1 cmd.go:250] Using service-serving-cert provided certificates
2024-10-24T13:04:59.727443594Z I1024 13:04:59.727400       1 leaderelection.go:121] The leader election gives 4 retries and allows for 30s of clock skew. The kube-apiserver downtime tolerance is 78s. Worst non-graceful lease acquisition is 2m43s. Worst graceful lease acquisition is {26s}.
2024-10-24T13:04:59.727883584Z I1024 13:04:59.727858       1 observer_polling.go:159] Starting file observer
2024-10-24T13:04:59.749850184Z I1024 13:04:59.749810       1 builder.go:298] kube-controller-manager-operator version v0.0.0-alpha.0-1368-ge3e3ce7-e3e3ce7ab
2024-10-24T13:05:00.268093405Z I1024 13:05:00.268050       1 secure_serving.go:57] Forcing use of http/1.1 only
2024-10-24T13:05:00.268093405Z W1024 13:05:00.268078       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256' detected.
2024-10-24T13:05:00.268093405Z W1024 13:05:00.268083       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256' detected.
2024-10-24T13:05:00.268093405Z W1024 13:05:00.268088       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_128_GCM_SHA256' detected.
2024-10-24T13:05:00.268152855Z W1024 13:05:00.268092       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_256_GCM_SHA384' detected.
2024-10-24T13:05:00.268152855Z W1024 13:05:00.268095       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_128_CBC_SHA' detected.
2024-10-24T13:05:00.268152855Z W1024 13:05:00.268098       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_256_CBC_SHA' detected.
2024-10-24T13:05:00.279836635Z I1024 13:05:00.279781       1 requestheader_controller.go:172] Starting RequestHeaderAuthRequestController
2024-10-24T13:05:00.279956445Z I1024 13:05:00.279845       1 configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2024-10-24T13:05:00.280090305Z I1024 13:05:00.280002       1 shared_informer.go:313] Waiting for caches to sync for RequestHeaderAuthRequestController
2024-10-24T13:05:00.280090305Z I1024 13:05:00.279854       1 configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2024-10-24T13:05:00.280122045Z I1024 13:05:00.280005       1 shared_informer.go:313] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-10-24T13:05:00.280122045Z I1024 13:05:00.280091       1 shared_informer.go:313] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-10-24T13:05:00.280234335Z I1024 13:05:00.280172       1 dynamic_serving_content.go:135] "Starting controller" name="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key"
2024-10-24T13:05:00.280336475Z I1024 13:05:00.280304       1 secure_serving.go:213] Serving securely on [::]:8443
2024-10-24T13:05:00.280415015Z I1024 13:05:00.280399       1 tlsconfig.go:243] "Starting DynamicServingCertificateController"
2024-10-24T13:05:00.281637565Z I1024 13:05:00.281611       1 leaderelection.go:254] attempting to acquire leader lease openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock...
2024-10-24T13:05:00.303014185Z I1024 13:05:00.302990       1 leaderelection.go:268] successfully acquired lease openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock
2024-10-24T13:05:00.304267135Z I1024 13:05:00.304179       1 event.go:377] Event(v1.ObjectReference{Kind:"Lease", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator-lock", UID:"143a3207-feab-4e4d-8f17-72e73240d378", APIVersion:"coordination.k8s.io/v1", ResourceVersion:"10754", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' kube-controller-manager-operator-7c885b8899-z89zf_2e83f909-2da2-4f7c-a7b8-fe75ed59caee became leader
2024-10-24T13:05:00.304577425Z I1024 13:05:00.304355       1 simple_featuregate_reader.go:171] Starting feature-gate-detector
2024-10-24T13:05:00.307793535Z I1024 13:05:00.307761       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'FeatureGatesInitialized' FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AWSEFSDriverVolumeMetrics", "AdminNetworkPolicy", "AlibabaPlatform", "AzureWorkloadIdentity", "BareMetalLoadBalancer", "BuildCSIVolumes", "ChunkSizeMiB", "CloudDualStackNodeIPs", "DisableKubeletCloudCredentialProviders", "GCPLabelsTags", "HardwareSpeed", "IngressControllerLBSubnetsAWS", "KMSv1", "ManagedBootImages", "MetricsServer", "MultiArchInstallAWS", "MultiArchInstallGCP", "NetworkDiagnosticsConfig", "NetworkLiveMigration", "NodeDisruptionPolicy", "OpenShiftPodSecurityAdmission", "PrivateHostedZoneAWS", "SetEIPForNLBIngressController", "VSphereControlPlaneMachineSet", "VSphereDriverConfiguration", "VSphereStaticIPs", "ValidatingAdmissionPolicy"}, Disabled:[]v1.FeatureGateName{"AWSClusterHostedDNS", "AdditionalRoutingCapabilities", "AutomatedEtcdBackup", "BootcNodeManagement", "CSIDriverSharedResource", "ClusterAPIInstall", "ClusterAPIInstallIBMCloud", "ClusterMonitoringConfig", "DNSNameResolver", "DynamicResourceAllocation", "EtcdBackendQuota", "EventedPLEG", "Example", "ExternalOIDC", "GCPClusterHostedDNS", "GatewayAPI", "ImageStreamImportMode", "IngressControllerDynamicConfigurationManager", "InsightsConfig", "InsightsConfigAPI", "InsightsOnDemandDataGather", "InsightsRuntimeExtractor", "MachineAPIMigration", "MachineAPIOperatorDisableMachineHealthCheckController", "MachineAPIProviderOpenStack", "MachineConfigNodes", "ManagedBootImagesAWS", "MaxUnavailableStatefulSet", "MetricsCollectionProfiles", "MixedCPUsAllocation", "MultiArchInstallAzure", "NetworkSegmentation", "NewOLM", "NodeSwap", "OVNObservability", "OnClusterBuild", "PersistentIPsForVirtualization", "PinnedImages", "PlatformOperators", "ProcMountType", "RouteAdvertisements", "RouteExternalCertificate", "ServiceAccountTokenNodeBinding", "SignatureStores", "SigstoreImageVerification", "TranslateStreamCloseWebsocketRequests", "UpgradeStatus", "UserNamespacesPodSecurityStandards", "UserNamespacesSupport", "VSphereMultiNetworks", "VSphereMultiVCenters", "VolumeGroupSnapshot"}}
2024-10-24T13:05:00.307907245Z I1024 13:05:00.307785       1 starter.go:97] FeatureGates initialized: knownFeatureGates=[AWSEFSDriverVolumeMetrics AdminNetworkPolicy AlibabaPlatform AzureWorkloadIdentity BareMetalLoadBalancer BuildCSIVolumes ChunkSizeMiB CloudDualStackNodeIPs DisableKubeletCloudCredentialProviders GCPLabelsTags HardwareSpeed IngressControllerLBSubnetsAWS KMSv1 ManagedBootImages MetricsServer MultiArchInstallAWS MultiArchInstallGCP NetworkDiagnosticsConfig NetworkLiveMigration NodeDisruptionPolicy OpenShiftPodSecurityAdmission PrivateHostedZoneAWS SetEIPForNLBIngressController VSphereControlPlaneMachineSet VSphereDriverConfiguration VSphereStaticIPs ValidatingAdmissionPolicy AWSClusterHostedDNS AdditionalRoutingCapabilities AutomatedEtcdBackup BootcNodeManagement CSIDriverSharedResource ClusterAPIInstall ClusterAPIInstallIBMCloud ClusterMonitoringConfig DNSNameResolver DynamicResourceAllocation EtcdBackendQuota EventedPLEG Example ExternalOIDC GCPClusterHostedDNS GatewayAPI ImageStreamImportMode IngressControllerDynamicConfigurationManager InsightsConfig InsightsConfigAPI InsightsOnDemandDataGather InsightsRuntimeExtractor MachineAPIMigration MachineAPIOperatorDisableMachineHealthCheckController MachineAPIProviderOpenStack MachineConfigNodes ManagedBootImagesAWS MaxUnavailableStatefulSet MetricsCollectionProfiles MixedCPUsAllocation MultiArchInstallAzure NetworkSegmentation NewOLM NodeSwap OVNObservability OnClusterBuild PersistentIPsForVirtualization PinnedImages PlatformOperators ProcMountType RouteAdvertisements RouteExternalCertificate ServiceAccountTokenNodeBinding SignatureStores SigstoreImageVerification TranslateStreamCloseWebsocketRequests UpgradeStatus UserNamespacesPodSecurityStandards UserNamespacesSupport VSphereMultiNetworks VSphereMultiVCenters VolumeGroupSnapshot]
2024-10-24T13:05:00.343413025Z I1024 13:05:00.343374       1 base_controller.go:68] Waiting for caches to sync for GarbageCollectorWatcherController
2024-10-24T13:05:00.343880045Z I1024 13:05:00.343831       1 base_controller.go:68] Waiting for caches to sync for SATokenSignerController
2024-10-24T13:05:00.343967495Z I1024 13:05:00.343921       1 base_controller.go:68] Waiting for caches to sync for WorkerLatencyProfile
2024-10-24T13:05:00.344049625Z I1024 13:05:00.343852       1 base_controller.go:68] Waiting for caches to sync for CertRotationController
2024-10-24T13:05:00.344124875Z I1024 13:05:00.343963       1 base_controller.go:68] Waiting for caches to sync for TargetConfigController
2024-10-24T13:05:00.344177025Z I1024 13:05:00.344036       1 base_controller.go:68] Waiting for caches to sync for MissingStaticPodController
2024-10-24T13:05:00.344214345Z I1024 13:05:00.344126       1 base_controller.go:68] Waiting for caches to sync for ConfigObserver
2024-10-24T13:05:00.344541155Z I1024 13:05:00.344511       1 base_controller.go:68] Waiting for caches to sync for StatusSyncer_kube-controller-manager
2024-10-24T13:05:00.344836915Z I1024 13:05:00.344805       1 base_controller.go:68] Waiting for caches to sync for KubeControllerManagerStaticResources-StaticResources
2024-10-24T13:05:00.345044545Z I1024 13:05:00.345015       1 base_controller.go:68] Waiting for caches to sync for GuardController
2024-10-24T13:05:00.345062275Z I1024 13:05:00.345045       1 base_controller.go:68] Waiting for caches to sync for RevisionController
2024-10-24T13:05:00.345107695Z I1024 13:05:00.345078       1 base_controller.go:68] Waiting for caches to sync for NodeController
2024-10-24T13:05:00.345211055Z I1024 13:05:00.345179       1 base_controller.go:68] Waiting for caches to sync for kube-controller-manager-InstallerState
2024-10-24T13:05:00.345226855Z I1024 13:05:00.345208       1 base_controller.go:68] Waiting for caches to sync for StaticPodStateController
2024-10-24T13:05:00.345226855Z I1024 13:05:00.345223       1 base_controller.go:68] Waiting for caches to sync for PruneController
2024-10-24T13:05:00.345237595Z I1024 13:05:00.345184       1 base_controller.go:68] Waiting for caches to sync for InstallerController
2024-10-24T13:05:00.345297285Z I1024 13:05:00.345273       1 base_controller.go:68] Waiting for caches to sync for BackingResourceController-StaticResources
2024-10-24T13:05:00.345318905Z I1024 13:05:00.345303       1 base_controller.go:68] Waiting for caches to sync for UnsupportedConfigOverridesController
2024-10-24T13:05:00.345329655Z I1024 13:05:00.345319       1 base_controller.go:68] Waiting for caches to sync for LoggingSyncer
2024-10-24T13:05:00.346035535Z I1024 13:05:00.345990       1 base_controller.go:68] Waiting for caches to sync for kube-controller-manager
2024-10-24T13:05:00.381108455Z I1024 13:05:00.381034       1 shared_informer.go:320] Caches are synced for RequestHeaderAuthRequestController
2024-10-24T13:05:00.381108455Z I1024 13:05:00.381076       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-10-24T13:05:00.381164905Z I1024 13:05:00.381114       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-10-24T13:05:00.444403225Z I1024 13:05:00.444360       1 base_controller.go:74] Caches are synced for MissingStaticPodController 
2024-10-24T13:05:00.444403225Z I1024 13:05:00.444377       1 base_controller.go:111] Starting #1 worker of MissingStaticPodController controller ...
2024-10-24T13:05:00.444439625Z I1024 13:05:00.444391       1 base_controller.go:74] Caches are synced for WorkerLatencyProfile 
2024-10-24T13:05:00.444439625Z I1024 13:05:00.444411       1 base_controller.go:111] Starting #1 worker of WorkerLatencyProfile controller ...
2024-10-24T13:05:00.444783295Z I1024 13:05:00.444717       1 base_controller.go:74] Caches are synced for StatusSyncer_kube-controller-manager 
2024-10-24T13:05:00.444783295Z I1024 13:05:00.444733       1 base_controller.go:111] Starting #1 worker of StatusSyncer_kube-controller-manager controller ...
2024-10-24T13:05:00.445204625Z I1024 13:05:00.445149       1 base_controller.go:74] Caches are synced for RevisionController 
2024-10-24T13:05:00.445204625Z I1024 13:05:00.445163       1 base_controller.go:74] Caches are synced for GuardController 
2024-10-24T13:05:00.445204625Z I1024 13:05:00.445177       1 base_controller.go:111] Starting #1 worker of GuardController controller ...
2024-10-24T13:05:00.445204625Z I1024 13:05:00.445179       1 base_controller.go:74] Caches are synced for NodeController 
2024-10-24T13:05:00.445204625Z I1024 13:05:00.445188       1 base_controller.go:111] Starting #1 worker of NodeController controller ...
2024-10-24T13:05:00.445204625Z I1024 13:05:00.445167       1 base_controller.go:111] Starting #1 worker of RevisionController controller ...
2024-10-24T13:05:00.445504695Z I1024 13:05:00.445415       1 base_controller.go:74] Caches are synced for InstallerController 
2024-10-24T13:05:00.445504695Z I1024 13:05:00.445431       1 base_controller.go:111] Starting #1 worker of InstallerController controller ...
2024-10-24T13:05:00.445678865Z I1024 13:05:00.445618       1 base_controller.go:74] Caches are synced for kube-controller-manager-InstallerState 
2024-10-24T13:05:00.445732855Z I1024 13:05:00.445683       1 base_controller.go:111] Starting #1 worker of kube-controller-manager-InstallerState controller ...
2024-10-24T13:05:00.445732855Z I1024 13:05:00.445627       1 base_controller.go:74] Caches are synced for PruneController 
2024-10-24T13:05:00.445732855Z I1024 13:05:00.445719       1 base_controller.go:111] Starting #1 worker of PruneController controller ...
2024-10-24T13:05:00.445851965Z I1024 13:05:00.445636       1 base_controller.go:74] Caches are synced for StaticPodStateController 
2024-10-24T13:05:00.445907415Z I1024 13:05:00.445893       1 base_controller.go:111] Starting #1 worker of StaticPodStateController controller ...
2024-10-24T13:05:00.445946495Z E1024 13:05:00.445636       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:00.445994535Z E1024 13:05:00.445981       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:00.446036095Z E1024 13:05:00.446024       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:00.446420365Z I1024 13:05:00.445843       1 base_controller.go:74] Caches are synced for LoggingSyncer 
2024-10-24T13:05:00.446485735Z I1024 13:05:00.446471       1 base_controller.go:111] Starting #1 worker of LoggingSyncer controller ...
2024-10-24T13:05:00.446588985Z I1024 13:05:00.445853       1 base_controller.go:74] Caches are synced for BackingResourceController-StaticResources 
2024-10-24T13:05:00.447064605Z I1024 13:05:00.447018       1 base_controller.go:111] Starting #1 worker of BackingResourceController-StaticResources controller ...
2024-10-24T13:05:00.447064605Z I1024 13:05:00.445861       1 base_controller.go:74] Caches are synced for UnsupportedConfigOverridesController 
2024-10-24T13:05:00.447064605Z I1024 13:05:00.447056       1 base_controller.go:111] Starting #1 worker of UnsupportedConfigOverridesController controller ...
2024-10-24T13:05:00.447544995Z I1024 13:05:00.445946       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:00.471906855Z E1024 13:05:00.471874       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:00.478369945Z E1024 13:05:00.478326       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:00.478369945Z E1024 13:05:00.478341       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:00.478369945Z E1024 13:05:00.478345       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:00.479268775Z E1024 13:05:00.479235       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:00.490678945Z E1024 13:05:00.490640       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:00.490678945Z E1024 13:05:00.490660       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:00.490678945Z E1024 13:05:00.490665       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:00.491572105Z E1024 13:05:00.491538       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:00.513225145Z E1024 13:05:00.512964       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:00.513225145Z E1024 13:05:00.512987       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:00.513225145Z E1024 13:05:00.512995       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:00.514607045Z E1024 13:05:00.514260       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:00.539673865Z I1024 13:05:00.539370       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:05:00.556811095Z E1024 13:05:00.556728       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:00.556811095Z E1024 13:05:00.556767       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:00.556811095Z E1024 13:05:00.556774       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:00.558463735Z E1024 13:05:00.558416       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:00.640053115Z E1024 13:05:00.639991       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:00.640053115Z E1024 13:05:00.640013       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:00.640053115Z E1024 13:05:00.640023       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:00.641255065Z E1024 13:05:00.641206       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:00.739684425Z I1024 13:05:00.739399       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:05:00.803038785Z E1024 13:05:00.802985       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:00.803038785Z E1024 13:05:00.803006       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:00.803038785Z E1024 13:05:00.803011       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:00.804071515Z E1024 13:05:00.804012       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:00.939896516Z I1024 13:05:00.939843       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:05:01.127388976Z E1024 13:05:01.127322       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:01.127388976Z E1024 13:05:01.127351       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:01.127388976Z E1024 13:05:01.127360       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:01.128439156Z E1024 13:05:01.128380       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:01.139209626Z I1024 13:05:01.139175       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:05:01.339701946Z I1024 13:05:01.339650       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:05:01.537123556Z I1024 13:05:01.537065       1 request.go:700] Waited for 1.191841831s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces?limit=500&resourceVersion=0
2024-10-24T13:05:01.540579396Z I1024 13:05:01.540540       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:05:01.739232867Z I1024 13:05:01.739183       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:05:01.745732496Z I1024 13:05:01.745657       1 base_controller.go:74] Caches are synced for KubeControllerManagerStaticResources-StaticResources 
2024-10-24T13:05:01.745732496Z I1024 13:05:01.745692       1 base_controller.go:111] Starting #1 worker of KubeControllerManagerStaticResources-StaticResources controller ...
2024-10-24T13:05:01.770510746Z E1024 13:05:01.770470       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:01.770510746Z E1024 13:05:01.770493       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:01.770510746Z E1024 13:05:01.770497       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:01.771657027Z E1024 13:05:01.771622       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:01.939200697Z I1024 13:05:01.939150       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:05:02.138473047Z I1024 13:05:02.138391       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:05:02.354024767Z I1024 13:05:02.353964       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:05:02.444069687Z I1024 13:05:02.443999       1 base_controller.go:74] Caches are synced for SATokenSignerController 
2024-10-24T13:05:02.444069687Z I1024 13:05:02.444000       1 base_controller.go:74] Caches are synced for GarbageCollectorWatcherController 
2024-10-24T13:05:02.444117547Z I1024 13:05:02.444084       1 base_controller.go:111] Starting #1 worker of GarbageCollectorWatcherController controller ...
2024-10-24T13:05:02.444117547Z I1024 13:05:02.444080       1 base_controller.go:111] Starting #1 worker of SATokenSignerController controller ...
2024-10-24T13:05:02.538703328Z I1024 13:05:02.538663       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:05:02.544829008Z I1024 13:05:02.544780       1 base_controller.go:74] Caches are synced for TargetConfigController 
2024-10-24T13:05:02.544880758Z I1024 13:05:02.544829       1 base_controller.go:111] Starting #1 worker of TargetConfigController controller ...
2024-10-24T13:05:02.544880758Z I1024 13:05:02.544832       1 base_controller.go:74] Caches are synced for ConfigObserver 
2024-10-24T13:05:02.544880758Z I1024 13:05:02.544802       1 base_controller.go:74] Caches are synced for CertRotationController 
2024-10-24T13:05:02.544880758Z I1024 13:05:02.544857       1 base_controller.go:111] Starting #1 worker of CertRotationController controller ...
2024-10-24T13:05:02.544896778Z I1024 13:05:02.544849       1 base_controller.go:111] Starting #1 worker of ConfigObserver controller ...
2024-10-24T13:05:02.546645308Z I1024 13:05:02.546602       1 base_controller.go:74] Caches are synced for kube-controller-manager 
2024-10-24T13:05:02.546645308Z I1024 13:05:02.546620       1 base_controller.go:111] Starting #1 worker of kube-controller-manager controller ...
2024-10-24T13:05:02.737217928Z I1024 13:05:02.737162       1 request.go:700] Waited for 2.291245933s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:05:03.058134658Z E1024 13:05:03.056042       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:03.058134658Z E1024 13:05:03.056071       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:03.058134658Z E1024 13:05:03.056080       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:03.058134658Z E1024 13:05:03.057597       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:03.737315529Z I1024 13:05:03.737262       1 request.go:700] Waited for 1.292925001s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:05:04.341872890Z I1024 13:05:04.341811       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 2, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:05:04.666202111Z E1024 13:05:04.666137       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:04.666297371Z E1024 13:05:04.666281       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:04.666340710Z E1024 13:05:04.666326       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:04.667887801Z E1024 13:05:04.667860       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:04.669583810Z E1024 13:05:04.669537       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:04.670212650Z E1024 13:05:04.670184       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:04.670272381Z E1024 13:05:04.670257       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:04.672549531Z E1024 13:05:04.671734       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:04.744901361Z I1024 13:05:04.744821       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:05:04.745120480Z E1024 13:05:04.745026       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:05:04.751041391Z E1024 13:05:04.751016       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:04.751145700Z E1024 13:05:04.751130       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:04.751217411Z E1024 13:05:04.751184       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:04.761103701Z E1024 13:05:04.761057       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:05.620045332Z E1024 13:05:05.619987       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:05.620045332Z E1024 13:05:05.620010       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:05.620045332Z E1024 13:05:05.620015       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:05.620927152Z E1024 13:05:05.620894       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:06.141874983Z I1024 13:05:06.141516       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:05:06.141874983Z E1024 13:05:06.141642       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:05:07.341127954Z I1024 13:05:07.341002       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:05:07.341127954Z E1024 13:05:07.341073       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:05:08.341085365Z I1024 13:05:08.341017       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:05:08.341232185Z E1024 13:05:08.341203       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:05:09.141688966Z I1024 13:05:09.141634       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:05:09.141765486Z E1024 13:05:09.141697       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:05:09.271281836Z E1024 13:05:09.271242       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:09.271925636Z E1024 13:05:09.271904       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:09.272006946Z E1024 13:05:09.271991       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:09.273362806Z E1024 13:05:09.273339       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:09.345498876Z I1024 13:05:09.345463       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:09.345900536Z I1024 13:05:09.345842       1 core.go:352] ConfigMap "openshift-kube-controller-manager/serviceaccount-ca" changes: {"data":{"ca-bundle.crt":"-----BEGIN CERTIFICATE-----\nMIIDMjCCAhqgAwIBAgIIOlelAZRIRJQwDQYJKoZIhvcNAQELBQAwNzESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSEwHwYDVQQDExhrdWJlLWFwaXNlcnZlci1sYi1zaWduZXIw\nHhcNMjQxMDI0MTI0OTMyWhcNMzQxMDIyMTI0OTMyWjA3MRIwEAYDVQQLEwlvcGVu\nc2hpZnQxITAfBgNVBAMTGGt1YmUtYXBpc2VydmVyLWxiLXNpZ25lcjCCASIwDQYJ\nKoZIhvcNAQEBBQADggEPADCCAQoCggEBAOcnMnNp8mbJzP0YRtfP2eQLUaxDRCWh\nwLjXPeI+RJNc5XRTf8K7cnFvZM+VxeDvt3vvHmK+v6eeT2vM4sTe1Fi4y3+N+52E\nAZfAsx5jZkOLMqXmYCEtcM0iE5hCDlqj+iqz3+N9/h9r/wlkGcuLjFatvfYPe2aD\norY3S/xWccWpBmPNNb6g+JgNbFkZtwSgP2rA0DgJQNm+SElSVXsOD4z6NJeQYUGS\n3S+3muL/R0tqHU6oqJUUS5i+SI0zUtGXSPF71/SZwp0ZzlqJOnF1+oKwvLwVYenJ\n1chzH2ooswTzIl2GbrriQiiFXcNatw5HPYAUj/u5mxc2UFdq0BS/kS8CAwEAAaNC\nMEAwDgYDVR0PAQH/BAQDAgKkMA8GA1UdEwEB/wQFMAMBAf8wHQYDVR0OBBYEFHl2\n38/JZPz+0k/JseyNGSSnxIWbMA0GCSqGSIb3DQEBCwUAA4IBAQCt/f91wvEf5yXB\nM6iVHyYS5quVkgKOyW/VlOiWBrC3nzumzbyKBKCCDVFV0ObFBUJ94uhYGCM32OLe\nkOF3g/sNMtjj+z8OWauQqQ8goczpC+NJb/ANaAtdFN+el5gLy13sXPsu8/gidAOb\njapZ7wk8Px33n/sQbsvM7eSuW3mWsEWCznXMAiXzkt4R2jLxYslFcqzAyjqYXOeI\n8hYcgmLVk5R2ZTKtgN6K0H1BRIPNPZ76GKjK0KpguzyRHJN8y6iD/Oe4779z0t1k\nsLOsY8mzi1bRHEV31Og7s6nFy42ECM5WZb/btqdJn2K/AQF3WCtdX6U9+rSuScOB\n5fOatgOb\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDQDCCAiigAwIBAgIIaxpuJ4b9n/wwDQYJKoZIhvcNAQELBQAwPjESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSgwJgYDVQQDEx9rdWJlLWFwaXNlcnZlci1sb2NhbGhvc3Qt\nc2lnbmVyMB4XDTI0MTAyNDEyNDkzMVoXDTM0MTAyMjEyNDkzMVowPjESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSgwJgYDVQQDEx9rdWJlLWFwaXNlcnZlci1sb2NhbGhvc3Qt\nc2lnbmVyMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvCLC4H8c9qPx\niqEgtyn9mblELDIJA//g3A6vuhVprmVxFKdR+SLdN7iuPXWJyNJoMujRpLh4O8Tx\nynHOHASH3NZu20NBxPNwM7cM2YN35rYKMwgGMg6H/mFCyMnXo2wTbpG0kVbk1I+D\npQDuCCd5Nwa8MyFMRmxC7FWSD/NXyJN96+TywP62d9UBwp8F2TV0IwEYJPp7QMBK\nTDef+8mWKaMjYpaTbDTh/ce6B6faSfliGhBqsKSWfUPBss/4nlWsDKOLagoDHQTt\nuFYyqXveH3lieKd0eu/mCUioLzq1GQ9oIdNHbqYf+zWB3hiJPwbxfRq01+NB+1Ga\nHtT4qKkLiQIDAQABo0IwQDAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/BAUwAwEB\n/zAdBgNVHQ4EFgQUAoX0QNb/ygmPyFVnWrPc/3lKS+4wDQYJKoZIhvcNAQELBQAD\nggEBAFnjav9JNB6NSH2HgOlj2mvqXSYOKmLD1c6WluJXOSh2YOE9iGDZJEpNGfx3\nsXdk3PKp9vheMdfBIWDme2H7ocJiPUl7HlzP0PvSl5f/9Jad3KEl5koJMxaobHMg\n86BT5Lg3TQ3H369Bw9yedYuw6Wakl8zGgYsHRdDiBsQFYheObHYcbWsZmsMM38uq\n8oXuysYM7Lvm1YceS5083X0W22yqnzIGsbclB6MaNO3GGOaUSM/jS+1ngse1nuFD\nX7ao+N0irLEUdy8/yoJe4/aV9tJlLqPJ+6tNTvLBU7I6pIo8lRqe79cMUXkfcdSB\n/jkfSdUQBBv/qdvCnP3Dz2dNsT4=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDTDCCAjSgAwIBAgIINVjIWQIi1JIwDQYJKoZIhvcNAQELBQAwRDESMBAGA1UE\nCxMJb3BlbnNoaWZ0MS4wLAYDVQQDEyVrdWJlLWFwaXNlcnZlci1zZXJ2aWNlLW5l\ndHdvcmstc2lnbmVyMB4XDTI0MTAyNDEyNDkzMVoXDTM0MTAyMjEyNDkzMVowRDES\nMBAGA1UECxMJb3BlbnNoaWZ0MS4wLAYDVQQDEyVrdWJlLWFwaXNlcnZlci1zZXJ2\naWNlLW5ldHdvcmstc2lnbmVyMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKC\nAQEAuZZryAJp0pIRsH8v0/cE4aX+NTYYQ/quEDW2uF9UuD18KBNm17UGUadohlFB\n8MZFqxyEUE3doAzNNNn+mlb1tdffMyrPCKuue/+uL283ESHexPCUipD2NZCJMLxP\n4cFBNY24XxsyCgP4GW0CLK6jzNDRUpmqAvuAtPaGpwoMmdHYEbiYfD+kQpeSEpe7\n65W04BdcW93RWcU8Pcq8mj5ryRy37PXOSKv6cD20zs3o3swhJQjXJ7S7HPNiIPJu\nWAIDXMTbmlE5oT7fawQUVEzZAMTxHwz386X+PnqivblZW10wCaew9ixkzgnBtyzR\njInePtAOofQ+OAZRjfjK7tbwYQIDAQABo0IwQDAOBgNVHQ8BAf8EBAMCAqQwDwYD\nVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQUV9YpeGN1ZV9lrUjasKNrI8densowDQYJ\nKoZIhvcNAQELBQADggEBABWprtX9/Bmt/SDZMR++58OVDOHeN5IM5XmJTg1L9Y71\nwZ52OrAJTiHykyf0ZgdA1WFs4XCKRygK58Q0zh5TaN1Fbmt/ziKs6TfHpHr1EI9M\n8q5UN2en8KBnnkM5baV4pbs41Pj7LIzmuBdullsTzjWKz/+LiBYiUtEIViyLrAzS\nqmritaAg3r4ZguaL+KCWTRLpBJkmupaokwdo9rCJtY5qH70FaoNbdIofWE5Hi5Rx\nWZFOqIheZBTRD/bbhLUBCIgqacvwaIS0LDdHgPrpc5I0LUFZ/l4Te9TsY4sjYQQf\nOK4o1aud8IMYecdfB1khOkhpEQzsBcjTOyKTP0+zrq0=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDlzCCAn+gAwIBAgIIFwQ1KsBW4yQwDQYJKoZIhvcNAQELBQAwWTFXMFUGA1UE\nAwxOb3BlbnNoaWZ0LWt1YmUtYXBpc2VydmVyLW9wZXJhdG9yX2xvY2FsaG9zdC1y\nZWNvdmVyeS1zZXJ2aW5nLXNpZ25lckAxNzI5Nzc1MDExMB4XDTI0MTAyNDEzMDMz\nMFoXDTM0MTAyMjEzMDMzMVowWTFXMFUGA1UEAwxOb3BlbnNoaWZ0LWt1YmUtYXBp\nc2VydmVyLW9wZXJhdG9yX2xvY2FsaG9zdC1yZWNvdmVyeS1zZXJ2aW5nLXNpZ25l\nckAxNzI5Nzc1MDExMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAzml1\nSjsUKDZX7It4x6PImlu6eePhmNdUxp+1TGyUvU3BKiv/JsbyjYBOg3dip58nPBq9\nreTr4t3ZNnVMAbnaWmpwPR8sbkdjkoHETi0ipIPqEIQ47Yn2MHsY54AsXMcDS/3Z\nkVSbJhRPJaZq4+ZBZC0AGgDgAQd8bKyX1O2ybBp+/np/MoZB+3MTfKa77/2dqUDL\ny8mOG6V9/W7Z96Yvt+GJXSkTKaSD8ADbXIZ7MM7DFlMi3+s2paooWgpZIroZB08S\nrl8L6r22ncV/3CjlDm3KkoKHl1to1WdxKot8b8bSGC/tyc/zYBTc8lKek2BvdrK+\nmeiC+ghVASGtHowSXQIDAQABo2MwYTAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/\nBAUwAwEB/zAdBgNVHQ4EFgQUmszbl4eL8cP9ms1ey+CdkVsPpeowHwYDVR0jBBgw\nFoAUmszbl4eL8cP9ms1ey+CdkVsPpeowDQYJKoZIhvcNAQELBQADggEBAJ2S6HTb\n3PyIvKsTvhCx3YPsRyZgL76ffg3oiYvyc+UnOkm8Qy0wwS2I0byXy+KOITmabJZQ\n6OdkkJB+h9CqWxuWPhmTmzVlP6/kJxRKUJutc7Qxxbv9mQ4MOGh1QmsYPaFwyajn\nfGz6OeVrYCGunB97m65sKBEcqAV7ECBM51aY8EYUQLb0w67g//YJPhWmPukm0gVa\n5KQ97kxl7dxuwrVr7VOeZMawHSQPUcN6kGhablM7MNRblC+dddiw+8uJX6q3xbYH\nmRgoGDhXTB4wj2bz5Zk7sFGt82QoUY+Tg2x8CBpZkNgJAGijwxrXy3dkRAoNJ1rg\nU1KCNil9uJyZHR8=\n-----END CERTIFICATE-----\n"},"metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:05:09.346315736Z I1024 13:05:09.346278       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/serviceaccount-ca -n openshift-kube-controller-manager:
2024-10-24T13:05:09.346315736Z cause by changes in data.ca-bundle.crt
2024-10-24T13:05:09.348356806Z I1024 13:05:09.348251       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 3 triggered by "required configmap/serviceaccount-ca has changed"
2024-10-24T13:05:09.443849907Z E1024 13:05:09.443799       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:09.444580626Z E1024 13:05:09.444562       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:09.444622737Z E1024 13:05:09.444610       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:09.446215237Z E1024 13:05:09.446192       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:10.344786678Z I1024 13:05:10.344707       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:10.541675408Z I1024 13:05:10.541243       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:05:10.541675408Z E1024 13:05:10.541332       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:05:11.141983179Z I1024 13:05:11.141911       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 2, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:05:11.346247829Z I1024 13:05:11.346178       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-manager-pod-3 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:05:11.346247829Z I1024 13:05:11.346224       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:12.347281150Z I1024 13:05:12.347230       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:12.348276360Z I1024 13:05:12.348225       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-3 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:05:12.541771810Z I1024 13:05:12.541651       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:05:12.541836500Z E1024 13:05:12.541780       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:05:12.925675880Z E1024 13:05:12.925604       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:12.925675880Z E1024 13:05:12.925630       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:12.925675880Z E1024 13:05:12.925638       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:12.927198070Z E1024 13:05:12.927150       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:13.143574391Z I1024 13:05:13.143521       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 2, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:05:13.345845131Z I1024 13:05:13.345772       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:13.345911001Z I1024 13:05:13.345857       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cluster-policy-controller-config-3 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:05:14.343931543Z I1024 13:05:14.343863       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:14.344320433Z I1024 13:05:14.344262       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/controller-manager-kubeconfig-3 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:05:14.741799043Z I1024 13:05:14.741658       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:05:14.741799043Z E1024 13:05:14.741715       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:05:15.142341453Z I1024 13:05:15.142283       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 2, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:05:15.345895834Z I1024 13:05:15.345823       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:15.346065493Z I1024 13:05:15.345984       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-cert-syncer-kubeconfig-3 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:05:16.147532845Z I1024 13:05:16.147484       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:16.147699924Z I1024 13:05:16.147540       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-3 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:05:16.942293515Z I1024 13:05:16.941904       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 2, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:05:17.145703746Z I1024 13:05:17.145647       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:17.145864465Z I1024 13:05:17.145664       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/service-ca-3 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:05:17.342020576Z I1024 13:05:17.341940       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:05:17.342147676Z E1024 13:05:17.342118       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:05:18.145043637Z I1024 13:05:18.144983       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:18.145383407Z I1024 13:05:18.145319       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/recycler-config-3 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:05:18.741508288Z I1024 13:05:18.741447       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 2, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:05:18.945560769Z I1024 13:05:18.945461       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/service-account-private-key-3 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:05:19.832767840Z E1024 13:05:19.830572       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:19.832767840Z E1024 13:05:19.830612       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:19.832767840Z E1024 13:05:19.830650       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:19.832767840Z E1024 13:05:19.832219       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:19.946588770Z I1024 13:05:19.946518       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-3 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:05:20.541563760Z I1024 13:05:20.541500       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:05:20.541733690Z E1024 13:05:20.541696       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:05:20.740646981Z I1024 13:05:20.740585       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 2, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:05:20.947133791Z I1024 13:05:20.946847       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-3 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:05:21.944554732Z I1024 13:05:21.944337       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:21.946804662Z I1024 13:05:21.946771       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 3 triggered by "required configmap/serviceaccount-ca has changed"
2024-10-24T13:05:21.948243332Z W1024 13:05:21.948216       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:05:21.948243332Z W1024 13:05:21.948233       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:05:21.987545832Z I1024 13:05:21.986468       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:22.560713252Z E1024 13:05:22.560671       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:05:22.561154643Z I1024 13:05:22.561123       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:05:22.741523603Z I1024 13:05:22.741486       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 2, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:05:22.780467183Z I1024 13:05:22.780426       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:32Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:05:22.788283913Z I1024 13:05:22.784532       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:22.802078773Z I1024 13:05:22.801998       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3"
2024-10-24T13:05:23.136593093Z I1024 13:05:23.136541       1 request.go:700] Waited for 1.136430212s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-10-24T13:05:24.336651415Z I1024 13:05:24.336190       1 request.go:700] Waited for 1.187929431s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-10-24T13:05:24.944928186Z I1024 13:05:24.944445       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:05:24.945181656Z E1024 13:05:24.945142       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:05:25.159331516Z I1024 13:05:25.159277       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:05:25.159331516Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:05:25.159331516Z  CurrentRevision: (int32) 0,
2024-10-24T13:05:25.159331516Z  TargetRevision: (int32) 3,
2024-10-24T13:05:25.159331516Z  LastFailedRevision: (int32) 0,
2024-10-24T13:05:25.159331516Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:05:25.159331516Z  LastFailedReason: (string) "",
2024-10-24T13:05:25.159331516Z  LastFailedCount: (int) 0,
2024-10-24T13:05:25.159331516Z  LastFallbackCount: (int) 0,
2024-10-24T13:05:25.159331516Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:05:25.159331516Z }
2024-10-24T13:05:25.159331516Z  because new revision pending
2024-10-24T13:05:25.160283566Z E1024 13:05:25.159632       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:25.160283566Z E1024 13:05:25.159651       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:25.160283566Z E1024 13:05:25.159656       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:25.161183296Z E1024 13:05:25.161094       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:25.185665306Z I1024 13:05:25.185624       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:25.337133066Z I1024 13:05:25.337097       1 request.go:700] Waited for 1.194916221s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:26.537232327Z I1024 13:05:26.537193       1 request.go:700] Waited for 1.351687961s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-3-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:27.542487558Z E1024 13:05:27.542444       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:05:27.542938698Z I1024 13:05:27.542603       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:05:27.737150789Z I1024 13:05:27.737097       1 request.go:700] Waited for 1.195228912s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods
2024-10-24T13:05:27.756972759Z I1024 13:05:27.756915       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-3-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:05:27.757599039Z E1024 13:05:27.757552       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:27.757599039Z E1024 13:05:27.757573       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:27.757599039Z E1024 13:05:27.757581       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:27.759793969Z E1024 13:05:27.759723       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:27.770394759Z E1024 13:05:27.770325       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:27.770394759Z E1024 13:05:27.770357       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:27.770394759Z E1024 13:05:27.770363       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:27.771836309Z E1024 13:05:27.771809       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:27.784215579Z E1024 13:05:27.784166       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:27.784215579Z E1024 13:05:27.784199       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:27.784215579Z E1024 13:05:27.784208       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:27.785598349Z E1024 13:05:27.785567       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:28.247388339Z E1024 13:05:28.246832       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:28.247388339Z E1024 13:05:28.247381       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:28.247439659Z E1024 13:05:28.247392       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:28.248966400Z E1024 13:05:28.248939       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:28.742040320Z I1024 13:05:28.741985       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:05:28.937109680Z I1024 13:05:28.937038       1 request.go:700] Waited for 1.179959681s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:05:29.377461481Z E1024 13:05:29.377202       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:29.377461481Z E1024 13:05:29.377433       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:29.377461481Z E1024 13:05:29.377439       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:29.378612111Z E1024 13:05:29.378569       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:29.622728451Z E1024 13:05:29.622188       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:29.622728451Z E1024 13:05:29.622504       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:29.622728451Z E1024 13:05:29.622517       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:29.627108631Z E1024 13:05:29.625092       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:29.741224821Z I1024 13:05:29.741152       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:05:29.741545651Z E1024 13:05:29.741442       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:05:30.136783592Z I1024 13:05:30.136707       1 request.go:700] Waited for 1.192708752s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:05:30.184673272Z E1024 13:05:30.184611       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:30.184673272Z E1024 13:05:30.184639       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:30.184673272Z E1024 13:05:30.184647       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:30.186254801Z E1024 13:05:30.186213       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:30.411720412Z E1024 13:05:30.411672       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:30.411720412Z E1024 13:05:30.411701       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:30.411720412Z E1024 13:05:30.411709       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:30.413272582Z E1024 13:05:30.413218       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:30.420584802Z E1024 13:05:30.420546       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:30.420668942Z E1024 13:05:30.420653       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:30.420706392Z E1024 13:05:30.420694       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:30.421940432Z E1024 13:05:30.421900       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:30.646014352Z E1024 13:05:30.645945       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:30.646014352Z E1024 13:05:30.645972       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:30.646014352Z E1024 13:05:30.645979       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:30.647487512Z E1024 13:05:30.647433       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:30.942093602Z I1024 13:05:30.942029       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:05:32.949632335Z I1024 13:05:32.949566       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:05:35.687809728Z E1024 13:05:35.684318       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:35.687809728Z E1024 13:05:35.684822       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:35.687809728Z E1024 13:05:35.684830       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:35.687809728Z E1024 13:05:35.686280       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:35.899800739Z I1024 13:05:35.899715       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:32Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:05:35.913389459Z I1024 13:05:35.913340       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded changed from False to True ("GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]")
2024-10-24T13:05:36.141823959Z I1024 13:05:36.141731       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:05:36.141971499Z E1024 13:05:36.141948       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:05:39.759544369Z E1024 13:05:39.759026       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:39.759544369Z E1024 13:05:39.759521       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:39.759544369Z E1024 13:05:39.759528       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:39.761652359Z E1024 13:05:39.761501       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:40.517182505Z E1024 13:05:40.517136       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:40.517802155Z E1024 13:05:40.517775       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:40.517858415Z E1024 13:05:40.517845       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:40.519293215Z E1024 13:05:40.519265       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:40.679093176Z E1024 13:05:40.674595       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:40.679093176Z E1024 13:05:40.674623       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:40.679093176Z E1024 13:05:40.674630       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:40.679093176Z E1024 13:05:40.676126       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:43.721359939Z E1024 13:05:43.720871       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:43.722230069Z E1024 13:05:43.722207       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:43.722280979Z E1024 13:05:43.722267       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:43.723805278Z E1024 13:05:43.723687       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:46.583882352Z E1024 13:05:46.583397       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:46.583882352Z E1024 13:05:46.583870       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:46.583882352Z E1024 13:05:46.583878       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:46.585472432Z E1024 13:05:46.585437       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:05:50.731881200Z E1024 13:05:50.731632       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:50.731961820Z E1024 13:05:50.731947       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:50.731995740Z E1024 13:05:50.731984       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:50.735032430Z E1024 13:05:50.734711       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:02.454066167Z I1024 13:06:02.453540       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:06:02.454066167Z E1024 13:06:02.453602       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:06:10.497091378Z E1024 13:06:10.496627       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:10.497167458Z E1024 13:06:10.497154       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:10.497200869Z E1024 13:06:10.497190       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:10.498714648Z E1024 13:06:10.498678       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:11.025294048Z E1024 13:06:11.025227       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:11.025391267Z E1024 13:06:11.025376       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:11.025428898Z E1024 13:06:11.025416       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:11.026857408Z E1024 13:06:11.026832       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:11.180720618Z E1024 13:06:11.180643       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:11.180720618Z E1024 13:06:11.180680       1 guard_controller.go:300] Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:11.180720618Z E1024 13:06:11.180699       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:11.192824348Z I1024 13:06:11.192775       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:06:11.199845098Z I1024 13:06:11.199786       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorVersionChanged' clusteroperator/kube-controller-manager version "kube-controller-manager" changed from "" to "1.31.1"
2024-10-24T13:06:11.199845098Z I1024 13:06:11.199815       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorVersionChanged' clusteroperator/kube-controller-manager version "operator" changed from "" to "4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest"
2024-10-24T13:06:11.200022037Z I1024 13:06:11.199975       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"versions":[{"name":"raw-internal","version":"4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest"},{"name":"kube-controller-manager","version":"1.31.1"},{"name":"operator","version":"4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest"}]}}
2024-10-24T13:06:11.203634297Z E1024 13:06:11.203574       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:11.204550517Z I1024 13:06:11.204503       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:11.213598206Z I1024 13:06:11.213556       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:32Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}],"versions":[{"name":"raw-internal","version":"4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest"},{"name":"kube-controller-manager","version":"1.31.1"},{"name":"operator","version":"4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest"}]}}
2024-10-24T13:06:11.213954346Z I1024 13:06:11.213919       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: status.versions changed from [{"raw-internal" "4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest"}] to [{"raw-internal" "4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest"} {"kube-controller-manager" "1.31.1"} {"operator" "4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest"}]
2024-10-24T13:06:11.214013437Z I1024 13:06:11.213992       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorVersionChanged' clusteroperator/kube-controller-manager version "kube-controller-manager" changed from "" to "1.31.1"
2024-10-24T13:06:11.214054646Z I1024 13:06:11.214035       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorVersionChanged' clusteroperator/kube-controller-manager version "operator" changed from "" to "4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest"
2024-10-24T13:06:11.223215746Z E1024 13:06:11.223154       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:06:11.225408766Z I1024 13:06:11.225369       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:32Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:06:11.238102875Z I1024 13:06:11.237329       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]" to "GuardControllerDegraded: [Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:11.585535555Z I1024 13:06:11.585457       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:06:11.585680435Z E1024 13:06:11.585612       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:06:11.687958149Z E1024 13:06:11.687861       1 guard_controller.go:300] Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:11.687958149Z E1024 13:06:11.687899       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:11.687958149Z E1024 13:06:11.687910       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:11.689005909Z E1024 13:06:11.688952       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:11.988174141Z I1024 13:06:11.988096       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:06:12.381162938Z I1024 13:06:12.380838       1 request.go:700] Waited for 1.118635764s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra
2024-10-24T13:06:13.381434670Z I1024 13:06:13.381361       1 request.go:700] Waited for 1.19472711s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/serving-cert
2024-10-24T13:06:14.580976110Z I1024 13:06:14.580915       1 request.go:700] Waited for 1.193819381s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/cluster-policy-controller-config
2024-10-24T13:06:15.191265024Z W1024 13:06:15.191202       1 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
2024-10-24T13:06:15.191388194Z E1024 13:06:15.191347       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:15.191388194Z E1024 13:06:15.191367       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:15.191499094Z I1024 13:06:15.191464       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:06:15.219522073Z E1024 13:06:15.219434       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:15.221968952Z I1024 13:06:15.221936       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:32Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:06:15.223294782Z I1024 13:06:15.223251       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:15.237566501Z I1024 13:06:15.237487       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]" to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:15.581192601Z I1024 13:06:15.581123       1 request.go:700] Waited for 1.19528269s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:15.587149101Z I1024 13:06:15.587095       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:06:16.581266913Z I1024 13:06:16.581201       1 request.go:700] Waited for 1.360104131s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:17.008188778Z I1024 13:06:17.008141       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:17.009198708Z I1024 13:06:17.009138       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: ","reason":"GuardController_SyncError::StaticPods_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:32Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:06:17.023236727Z I1024 13:06:17.023176       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]" to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: "
2024-10-24T13:06:17.780733913Z I1024 13:06:17.780672       1 request.go:700] Waited for 1.592364057s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:06:17.986047081Z I1024 13:06:17.985970       1 core.go:220] Pod "openshift-kube-controller-manager/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0" changes: {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{"k8s.ovn.org/pod-networks":null,"k8s.v1.cni.cncf.io/network-status":null,"target.workload.openshift.io/management":"{\"effect\": \"PreferredDuringScheduling\"}"},"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null},"spec":{"containers":[{"args":["-c","# properly handle TERM and exit as soon as it is signaled\nset -euo pipefail\ntrap 'jobs -p | xargs -r kill; exit 0' TERM\nsleep infinity \u0026 wait\n"],"command":["/bin/bash"],"image":"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:39eb55fbaba0601f5bf36a2eaccc93fd172d1ab7d7d74ee36d36c9f29f7dd61b","imagePullPolicy":"IfNotPresent","name":"guard","readinessProbe":{"failureThreshold":3,"httpGet":{"host":"10.0.0.3","path":"healthz","port":10257,"scheme":"HTTPS"},"periodSeconds":5,"successThreshold":1,"timeoutSeconds":5},"resources":{"requests":{"cpu":"10m","memory":"5Mi"}},"terminationMessagePolicy":"FallbackToLogsOnError"}],"dnsPolicy":null,"enableServiceLinks":null,"preemptionPolicy":null,"priority":null,"restartPolicy":null,"schedulerName":null,"securityContext":null,"serviceAccount":null,"serviceAccountName":null,"volumes":null},"status":{"conditions":null,"containerStatuses":null,"hostIP":null,"hostIPs":null,"phase":null,"podIP":null,"podIPs":null,"qosClass":null,"startTime":null}}
2024-10-24T13:06:18.185546629Z I1024 13:06:18.185496       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:06:18.185595459Z E1024 13:06:18.185576       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:06:18.781530054Z I1024 13:06:18.781457       1 request.go:700] Waited for 1.594910497s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-3-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:19.683110841Z E1024 13:06:19.682541       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:19.683110841Z E1024 13:06:19.683098       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:19.683321481Z I1024 13:06:19.682876       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-kube-controller-manager because it changed
2024-10-24T13:06:19.684483341Z E1024 13:06:19.684439       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:19.685890351Z E1024 13:06:19.685841       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:19.685890351Z E1024 13:06:19.685865       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:19.980974244Z I1024 13:06:19.980919       1 request.go:700] Waited for 1.595059857s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:20.187082212Z I1024 13:06:20.186996       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:06:20.981513806Z I1024 13:06:20.981468       1 request.go:700] Waited for 1.295298005s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:21.186157464Z I1024 13:06:21.186063       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:06:21.186157464Z E1024 13:06:21.186135       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:06:21.408684721Z I1024 13:06:21.408625       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:21.409303521Z I1024 13:06:21.409268       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:32Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:06:21.436595419Z I1024 13:06:21.436526       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: " to "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:22.181467656Z I1024 13:06:22.181381       1 request.go:700] Waited for 1.194406611s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:22.188288525Z E1024 13:06:22.188243       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:22.189593375Z E1024 13:06:22.189555       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:23.380525526Z I1024 13:06:23.380458       1 request.go:700] Waited for 1.594797467s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/serviceaccount-ca
2024-10-24T13:06:24.185558920Z I1024 13:06:24.185475       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:06:24.185647340Z E1024 13:06:24.185602       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:06:24.380666858Z I1024 13:06:24.380617       1 request.go:700] Waited for 1.392125349s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:06:24.585686766Z I1024 13:06:24.585621       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:06:25.191365931Z E1024 13:06:25.190875       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:25.192799491Z E1024 13:06:25.192743       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:25.381012890Z I1024 13:06:25.380956       1 request.go:700] Waited for 1.395680449s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:26.381314392Z I1024 13:06:26.381255       1 request.go:700] Waited for 1.088564727s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-10-24T13:06:27.185045435Z I1024 13:06:27.184972       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:06:27.185136974Z E1024 13:06:27.185114       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:06:27.581311601Z I1024 13:06:27.581249       1 request.go:700] Waited for 1.19146312s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-10-24T13:06:27.985971818Z I1024 13:06:27.985905       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:06:29.185602188Z I1024 13:06:29.185512       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:06:29.185661308Z E1024 13:06:29.185628       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:06:31.505942263Z E1024 13:06:31.505400       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:32.580659130Z I1024 13:06:32.580591       1 request.go:700] Waited for 1.074162517s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:33.385356983Z E1024 13:06:33.385274       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:33.386408283Z E1024 13:06:33.386358       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:33.985937398Z I1024 13:06:33.985826       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:06:33.985937398Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:06:33.985937398Z  CurrentRevision: (int32) 3,
2024-10-24T13:06:33.985937398Z  TargetRevision: (int32) 0,
2024-10-24T13:06:33.985937398Z  LastFailedRevision: (int32) 0,
2024-10-24T13:06:33.985937398Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:06:33.985937398Z  LastFailedReason: (string) "",
2024-10-24T13:06:33.985937398Z  LastFailedCount: (int) 0,
2024-10-24T13:06:33.985937398Z  LastFallbackCount: (int) 0,
2024-10-24T13:06:33.985937398Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:06:33.985937398Z }
2024-10-24T13:06:33.985937398Z  because static pod is ready
2024-10-24T13:06:34.008344147Z I1024 13:06:34.008283       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 0 to 3 because static pod is ready
2024-10-24T13:06:34.010358476Z I1024 13:06:34.010311       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:34.011977776Z I1024 13:06:34.011937       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 3","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:06:34.024211495Z I1024 13:06:34.023474       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3" to "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 3",Available changed from False to True ("StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 3")
2024-10-24T13:06:35.181252668Z I1024 13:06:35.181187       1 request.go:700] Waited for 1.169023172s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager
2024-10-24T13:06:35.585552995Z I1024 13:06:35.585481       1 installer_controller.go:534] node ci-op-2fcpj5j6-f6035-2lklf-master-1 static pod not found and needs new revision 3
2024-10-24T13:06:35.585552995Z I1024 13:06:35.585539       1 installer_controller.go:542] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:06:35.585552995Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:06:35.585552995Z  CurrentRevision: (int32) 0,
2024-10-24T13:06:35.585552995Z  TargetRevision: (int32) 3,
2024-10-24T13:06:35.585552995Z  LastFailedRevision: (int32) 0,
2024-10-24T13:06:35.585552995Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:06:35.585552995Z  LastFailedReason: (string) "",
2024-10-24T13:06:35.585552995Z  LastFailedCount: (int) 0,
2024-10-24T13:06:35.585552995Z  LastFallbackCount: (int) 0,
2024-10-24T13:06:35.585552995Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:06:35.585552995Z }
2024-10-24T13:06:35.607395043Z I1024 13:06:35.607332       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 0 to 3 because node ci-op-2fcpj5j6-f6035-2lklf-master-1 static pod not found
2024-10-24T13:06:35.608782853Z I1024 13:06:35.608719       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:35.986542801Z I1024 13:06:35.986451       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:06:35.986690321Z E1024 13:06:35.986642       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:06:36.781205004Z I1024 13:06:36.781148       1 request.go:700] Waited for 1.171451121s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-3-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:37.590679798Z I1024 13:06:37.590181       1 core.go:352] ConfigMap "openshift-kube-controller-manager/serviceaccount-ca" changes: {"data":{"ca-bundle.crt":"-----BEGIN CERTIFICATE-----\nMIIDMjCCAhqgAwIBAgIIOlelAZRIRJQwDQYJKoZIhvcNAQELBQAwNzESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSEwHwYDVQQDExhrdWJlLWFwaXNlcnZlci1sYi1zaWduZXIw\nHhcNMjQxMDI0MTI0OTMyWhcNMzQxMDIyMTI0OTMyWjA3MRIwEAYDVQQLEwlvcGVu\nc2hpZnQxITAfBgNVBAMTGGt1YmUtYXBpc2VydmVyLWxiLXNpZ25lcjCCASIwDQYJ\nKoZIhvcNAQEBBQADggEPADCCAQoCggEBAOcnMnNp8mbJzP0YRtfP2eQLUaxDRCWh\nwLjXPeI+RJNc5XRTf8K7cnFvZM+VxeDvt3vvHmK+v6eeT2vM4sTe1Fi4y3+N+52E\nAZfAsx5jZkOLMqXmYCEtcM0iE5hCDlqj+iqz3+N9/h9r/wlkGcuLjFatvfYPe2aD\norY3S/xWccWpBmPNNb6g+JgNbFkZtwSgP2rA0DgJQNm+SElSVXsOD4z6NJeQYUGS\n3S+3muL/R0tqHU6oqJUUS5i+SI0zUtGXSPF71/SZwp0ZzlqJOnF1+oKwvLwVYenJ\n1chzH2ooswTzIl2GbrriQiiFXcNatw5HPYAUj/u5mxc2UFdq0BS/kS8CAwEAAaNC\nMEAwDgYDVR0PAQH/BAQDAgKkMA8GA1UdEwEB/wQFMAMBAf8wHQYDVR0OBBYEFHl2\n38/JZPz+0k/JseyNGSSnxIWbMA0GCSqGSIb3DQEBCwUAA4IBAQCt/f91wvEf5yXB\nM6iVHyYS5quVkgKOyW/VlOiWBrC3nzumzbyKBKCCDVFV0ObFBUJ94uhYGCM32OLe\nkOF3g/sNMtjj+z8OWauQqQ8goczpC+NJb/ANaAtdFN+el5gLy13sXPsu8/gidAOb\njapZ7wk8Px33n/sQbsvM7eSuW3mWsEWCznXMAiXzkt4R2jLxYslFcqzAyjqYXOeI\n8hYcgmLVk5R2ZTKtgN6K0H1BRIPNPZ76GKjK0KpguzyRHJN8y6iD/Oe4779z0t1k\nsLOsY8mzi1bRHEV31Og7s6nFy42ECM5WZb/btqdJn2K/AQF3WCtdX6U9+rSuScOB\n5fOatgOb\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDQDCCAiigAwIBAgIIaxpuJ4b9n/wwDQYJKoZIhvcNAQELBQAwPjESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSgwJgYDVQQDEx9rdWJlLWFwaXNlcnZlci1sb2NhbGhvc3Qt\nc2lnbmVyMB4XDTI0MTAyNDEyNDkzMVoXDTM0MTAyMjEyNDkzMVowPjESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSgwJgYDVQQDEx9rdWJlLWFwaXNlcnZlci1sb2NhbGhvc3Qt\nc2lnbmVyMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvCLC4H8c9qPx\niqEgtyn9mblELDIJA//g3A6vuhVprmVxFKdR+SLdN7iuPXWJyNJoMujRpLh4O8Tx\nynHOHASH3NZu20NBxPNwM7cM2YN35rYKMwgGMg6H/mFCyMnXo2wTbpG0kVbk1I+D\npQDuCCd5Nwa8MyFMRmxC7FWSD/NXyJN96+TywP62d9UBwp8F2TV0IwEYJPp7QMBK\nTDef+8mWKaMjYpaTbDTh/ce6B6faSfliGhBqsKSWfUPBss/4nlWsDKOLagoDHQTt\nuFYyqXveH3lieKd0eu/mCUioLzq1GQ9oIdNHbqYf+zWB3hiJPwbxfRq01+NB+1Ga\nHtT4qKkLiQIDAQABo0IwQDAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/BAUwAwEB\n/zAdBgNVHQ4EFgQUAoX0QNb/ygmPyFVnWrPc/3lKS+4wDQYJKoZIhvcNAQELBQAD\nggEBAFnjav9JNB6NSH2HgOlj2mvqXSYOKmLD1c6WluJXOSh2YOE9iGDZJEpNGfx3\nsXdk3PKp9vheMdfBIWDme2H7ocJiPUl7HlzP0PvSl5f/9Jad3KEl5koJMxaobHMg\n86BT5Lg3TQ3H369Bw9yedYuw6Wakl8zGgYsHRdDiBsQFYheObHYcbWsZmsMM38uq\n8oXuysYM7Lvm1YceS5083X0W22yqnzIGsbclB6MaNO3GGOaUSM/jS+1ngse1nuFD\nX7ao+N0irLEUdy8/yoJe4/aV9tJlLqPJ+6tNTvLBU7I6pIo8lRqe79cMUXkfcdSB\n/jkfSdUQBBv/qdvCnP3Dz2dNsT4=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDTDCCAjSgAwIBAgIINVjIWQIi1JIwDQYJKoZIhvcNAQELBQAwRDESMBAGA1UE\nCxMJb3BlbnNoaWZ0MS4wLAYDVQQDEyVrdWJlLWFwaXNlcnZlci1zZXJ2aWNlLW5l\ndHdvcmstc2lnbmVyMB4XDTI0MTAyNDEyNDkzMVoXDTM0MTAyMjEyNDkzMVowRDES\nMBAGA1UECxMJb3BlbnNoaWZ0MS4wLAYDVQQDEyVrdWJlLWFwaXNlcnZlci1zZXJ2\naWNlLW5ldHdvcmstc2lnbmVyMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKC\nAQEAuZZryAJp0pIRsH8v0/cE4aX+NTYYQ/quEDW2uF9UuD18KBNm17UGUadohlFB\n8MZFqxyEUE3doAzNNNn+mlb1tdffMyrPCKuue/+uL283ESHexPCUipD2NZCJMLxP\n4cFBNY24XxsyCgP4GW0CLK6jzNDRUpmqAvuAtPaGpwoMmdHYEbiYfD+kQpeSEpe7\n65W04BdcW93RWcU8Pcq8mj5ryRy37PXOSKv6cD20zs3o3swhJQjXJ7S7HPNiIPJu\nWAIDXMTbmlE5oT7fawQUVEzZAMTxHwz386X+PnqivblZW10wCaew9ixkzgnBtyzR\njInePtAOofQ+OAZRjfjK7tbwYQIDAQABo0IwQDAOBgNVHQ8BAf8EBAMCAqQwDwYD\nVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQUV9YpeGN1ZV9lrUjasKNrI8densowDQYJ\nKoZIhvcNAQELBQADggEBABWprtX9/Bmt/SDZMR++58OVDOHeN5IM5XmJTg1L9Y71\nwZ52OrAJTiHykyf0ZgdA1WFs4XCKRygK58Q0zh5TaN1Fbmt/ziKs6TfHpHr1EI9M\n8q5UN2en8KBnnkM5baV4pbs41Pj7LIzmuBdullsTzjWKz/+LiBYiUtEIViyLrAzS\nqmritaAg3r4ZguaL+KCWTRLpBJkmupaokwdo9rCJtY5qH70FaoNbdIofWE5Hi5Rx\nWZFOqIheZBTRD/bbhLUBCIgqacvwaIS0LDdHgPrpc5I0LUFZ/l4Te9TsY4sjYQQf\nOK4o1aud8IMYecdfB1khOkhpEQzsBcjTOyKTP0+zrq0=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDlzCCAn+gAwIBAgIIFwQ1KsBW4yQwDQYJKoZIhvcNAQELBQAwWTFXMFUGA1UE\nAwxOb3BlbnNoaWZ0LWt1YmUtYXBpc2VydmVyLW9wZXJhdG9yX2xvY2FsaG9zdC1y\nZWNvdmVyeS1zZXJ2aW5nLXNpZ25lckAxNzI5Nzc1MDExMB4XDTI0MTAyNDEzMDMz\nMFoXDTM0MTAyMjEzMDMzMVowWTFXMFUGA1UEAwxOb3BlbnNoaWZ0LWt1YmUtYXBp\nc2VydmVyLW9wZXJhdG9yX2xvY2FsaG9zdC1yZWNvdmVyeS1zZXJ2aW5nLXNpZ25l\nckAxNzI5Nzc1MDExMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAzml1\nSjsUKDZX7It4x6PImlu6eePhmNdUxp+1TGyUvU3BKiv/JsbyjYBOg3dip58nPBq9\nreTr4t3ZNnVMAbnaWmpwPR8sbkdjkoHETi0ipIPqEIQ47Yn2MHsY54AsXMcDS/3Z\nkVSbJhRPJaZq4+ZBZC0AGgDgAQd8bKyX1O2ybBp+/np/MoZB+3MTfKa77/2dqUDL\ny8mOG6V9/W7Z96Yvt+GJXSkTKaSD8ADbXIZ7MM7DFlMi3+s2paooWgpZIroZB08S\nrl8L6r22ncV/3CjlDm3KkoKHl1to1WdxKot8b8bSGC/tyc/zYBTc8lKek2BvdrK+\nmeiC+ghVASGtHowSXQIDAQABo2MwYTAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/\nBAUwAwEB/zAdBgNVHQ4EFgQUmszbl4eL8cP9ms1ey+CdkVsPpeowHwYDVR0jBBgw\nFoAUmszbl4eL8cP9ms1ey+CdkVsPpeowDQYJKoZIhvcNAQELBQADggEBAJ2S6HTb\n3PyIvKsTvhCx3YPsRyZgL76ffg3oiYvyc+UnOkm8Qy0wwS2I0byXy+KOITmabJZQ\n6OdkkJB+h9CqWxuWPhmTmzVlP6/kJxRKUJutc7Qxxbv9mQ4MOGh1QmsYPaFwyajn\nfGz6OeVrYCGunB97m65sKBEcqAV7ECBM51aY8EYUQLb0w67g//YJPhWmPukm0gVa\n5KQ97kxl7dxuwrVr7VOeZMawHSQPUcN6kGhablM7MNRblC+dddiw+8uJX6q3xbYH\nmRgoGDhXTB4wj2bz5Zk7sFGt82QoUY+Tg2x8CBpZkNgJAGijwxrXy3dkRAoNJ1rg\nU1KCNil9uJyZHR8=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDmzCCAoOgAwIBAgIIGVifAwvO2bwwDQYJKoZIhvcNAQELBQAwJjEkMCIGA1UE\nAwwbaW5ncmVzcy1vcGVyYXRvckAxNzI5Nzc1MTg0MB4XDTI0MTAyNDEzMDYyNVoX\nDTI2MTAyNDEzMDYyNlowPTE7MDkGA1UEAwwyKi5hcHBzLmNpLW9wLTJmY3BqNWo2\nLWY2MDM1LmdjcC0zLmNpLm9wZW5zaGlmdC5vcmcwggEiMA0GCSqGSIb3DQEBAQUA\nA4IBDwAwggEKAoIBAQC5lBc/sd7Gm0FTBzfdSyoBN8jwz3jgKfmoRokTrzKWv//t\nbnHmepkOL3q/ibK2FnCTvkcEqYTRdPtYzW7VMSo2V8kvKkPdgW5z7LrKP8bFq0qC\nR7YOSCcUJflYFfCvhEqgIiLN05U1hJMYw1meMH3Y3VBLAf83Nu+o9ktpjzTqTwBX\naQjP7XDZs4Zw3mBYlknT4VgSmEY0BlwQtX2PNuoup3jC28SS6HfkC5Uws6o0EzoU\nxCb9EogTtzByEpTY25RorJhPr83v2gkY4GSRItNNU2WUz+IVFWQsZKy+3zcWZBVx\nkbwR3ymiAvd+sVkEl0rwcyEwhEgYbxnW0o25rUjjAgMBAAGjgbUwgbIwDgYDVR0P\nAQH/BAQDAgWgMBMGA1UdJQQMMAoGCCsGAQUFBwMBMAwGA1UdEwEB/wQCMAAwHQYD\nVR0OBBYEFB+MJoBnDQ7h918tfRvplOuBHN0qMB8GA1UdIwQYMBaAFNDcJhKdybkO\nCinYNyXbwuDtUgWTMD0GA1UdEQQ2MDSCMiouYXBwcy5jaS1vcC0yZmNwajVqNi1m\nNjAzNS5nY3AtMy5jaS5vcGVuc2hpZnQub3JnMA0GCSqGSIb3DQEBCwUAA4IBAQC9\n0ODyOuqGU56uqhdFQilwfnfAJsaKGgcE4LMILjSOLYU5afb2aje3K7UrAI8KGUoy\nBn0O+9KVu/knkjtoWq7XLXPb8MpGSo1TPKSJFm9tjgdkgBnRIgBS8JXsPGF322fF\nO5mK5z7SEPfxvCTIG8yj3d3m4F/aIzg0/+VUXHMDof8pkC1yEYNiP7ij1ItPCbNQ\nfGw6Uq/7tvU+Sc/bVVbogPoD/WHJlywt1TEhI/K6Wil2RQZFC7WGQpqgIr6PSdHR\nRMjvQikEVrSzDNbCsb6FvJdabM/kKiI0HakvMqWqOfkeHUvpZ35xxgYi+6flQ4ln\n4XnZO6EssN3W8l8Hnf98\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDDDCCAfSgAwIBAgIBATANBgkqhkiG9w0BAQsFADAmMSQwIgYDVQQDDBtpbmdy\nZXNzLW9wZXJhdG9yQDE3Mjk3NzUxODQwHhcNMjQxMDI0MTMwNjIzWhcNMjYxMDI0\nMTMwNjI0WjAmMSQwIgYDVQQDDBtpbmdyZXNzLW9wZXJhdG9yQDE3Mjk3NzUxODQw\nggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDdActzMlPVmjtASy3hCJDs\nBWYHKHTYimlFhLYN9AkyiN/3VwqRk+hVzGFBCpkDigPAeF0yv5CKh9O5pB8lBOOD\nAa7GwwuIztdTq8fQuHhzfvlo3+i8Nw78yJm1ar3uwxJKmaLFPi8TTaQCWRKpfS1j\nk9mMMj1uQVH0nJGeHGTPFbux9ZekXS3oEC8DD17rZKPM9TH7Q4mTy+Va4knoPlls\nFiNxPDnGLWGCdWFEFqoiEkzy868lleA0FyjXZHksjG+ih/l+89UBQh/Lx9Czsd2u\nkapMb/DhU9qMsfSner3JrxNEQopQisyNN4U3MVsCZSq3ZuhSCfVJeX82Lrx84IuH\nAgMBAAGjRTBDMA4GA1UdDwEB/wQEAwICpDASBgNVHRMBAf8ECDAGAQH/AgEAMB0G\nA1UdDgQWBBTQ3CYSncm5Dgop2Dcl28Lg7VIFkzANBgkqhkiG9w0BAQsFAAOCAQEA\nIujqg0CbwLyhfAHo/FFqfv2mSlhkzZ7hqYNTlkzor2/Lvujh3CKb8rX1CgcA3mhX\nM1SofVaZap5cfP2wOlEOrhd7BtYzEcJR1AkhdQoSZBf66aSbFK6R3VJgdbh8upWz\nMjyf1UaBmWmNQsnVG9P+0oQXUgMvMyPZO7nrMv7chDCF0NYLRqVeZg8eCHZ/D0BZ\nJso6ceiATZzYr+Khqtc+to6O/x14q9o7hzL7WGAb6UeviigEBPRA+C/L7Wndu0EZ\nCDNWzot4v1sVEjJ12zEjtg7+DwubY4pmaVlOC/FpcNReGKbgnUczUS8ahZ20ziQd\nQua4z9iRfzKlLRT0nSYXgQ==\n-----END CERTIFICATE-----\n"},"metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:06:37.590808578Z I1024 13:06:37.590641       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:37.591042228Z I1024 13:06:37.591015       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/serviceaccount-ca -n openshift-kube-controller-manager:
2024-10-24T13:06:37.591042228Z cause by changes in data.ca-bundle.crt
2024-10-24T13:06:37.592774587Z I1024 13:06:37.592725       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 4 triggered by "required configmap/serviceaccount-ca has changed"
2024-10-24T13:06:37.792355466Z I1024 13:06:37.792281       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-3-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:06:38.186148983Z I1024 13:06:38.186085       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:06:38.186710133Z E1024 13:06:38.186667       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:06:38.781451808Z I1024 13:06:38.781398       1 request.go:700] Waited for 1.18865018s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps
2024-10-24T13:06:38.792070458Z I1024 13:06:38.792042       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:38.985066936Z I1024 13:06:38.985009       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 3, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:06:39.980772288Z I1024 13:06:39.980456       1 request.go:700] Waited for 1.394492828s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/localhost-recovery-client-token
2024-10-24T13:06:40.191335496Z I1024 13:06:40.191259       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-manager-pod-4 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:06:40.191483926Z I1024 13:06:40.191312       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:40.786151261Z E1024 13:06:40.786092       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:40.786151261Z E1024 13:06:40.786115       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:40.787153001Z E1024 13:06:40.787112       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:40.982473799Z I1024 13:06:40.981290       1 request.go:700] Waited for 1.395961929s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:41.593732124Z I1024 13:06:41.593658       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-4 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:06:41.593939104Z I1024 13:06:41.593881       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:41.786269163Z I1024 13:06:41.786206       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:06:42.180727480Z I1024 13:06:42.180653       1 request.go:700] Waited for 1.19490853s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:42.793340416Z I1024 13:06:42.793267       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cluster-policy-controller-config-4 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:06:42.793526666Z I1024 13:06:42.793496       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:43.186056018Z E1024 13:06:43.185995       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:43.186056018Z E1024 13:06:43.186018       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:43.187463988Z E1024 13:06:43.187414       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:43.381707904Z I1024 13:06:43.381371       1 request.go:700] Waited for 1.195646484s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:43.988930353Z I1024 13:06:43.988881       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:43.989502192Z I1024 13:06:43.989448       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/controller-manager-kubeconfig-4 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:06:44.190828579Z I1024 13:06:44.190743       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:06:44.581341811Z I1024 13:06:44.581283       1 request.go:700] Waited for 1.195298157s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:45.188565580Z I1024 13:06:45.188518       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:45.188654509Z I1024 13:06:45.188517       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-cert-syncer-kubeconfig-4 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:06:45.581468422Z I1024 13:06:45.581410       1 request.go:700] Waited for 1.195273257s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:45.586194342Z E1024 13:06:45.586129       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:45.586194342Z E1024 13:06:45.586161       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:45.587536062Z E1024 13:06:45.587489       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:46.189914470Z I1024 13:06:46.189855       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-4 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:06:46.190329310Z I1024 13:06:46.190299       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:46.386664446Z I1024 13:06:46.386607       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:06:47.187714201Z I1024 13:06:47.187438       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:47.187714201Z I1024 13:06:47.187551       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/service-ca-4 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:06:47.585656383Z E1024 13:06:47.585443       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:47.585656383Z E1024 13:06:47.585618       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:47.586699043Z E1024 13:06:47.586658       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:47.588055003Z E1024 13:06:47.588005       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:48.189713231Z I1024 13:06:48.189637       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/recycler-config-4 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:06:48.192035792Z I1024 13:06:48.192003       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:48.385780638Z I1024 13:06:48.385706       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:06:49.187609712Z I1024 13:06:49.187557       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/service-account-private-key-4 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:06:49.585497415Z E1024 13:06:49.585426       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:49.586838854Z E1024 13:06:49.586813       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:50.189565983Z I1024 13:06:50.189153       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-4 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:06:50.381356279Z I1024 13:06:50.381264       1 request.go:700] Waited for 1.193524337s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:06:50.586633785Z I1024 13:06:50.586561       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:06:51.196905644Z I1024 13:06:51.196810       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-4 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:06:51.384501050Z I1024 13:06:51.384437       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:06:51.384705190Z E1024 13:06:51.384663       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:06:51.840695491Z I1024 13:06:51.840618       1 tlsconfig.go:181] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"admin-kubeconfig-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:31 +0000 UTC to 2034-10-22 12:49:31 +0000 UTC (now=2024-10-24 13:06:51.840571241 +0000 UTC))"
2024-10-24T13:06:51.858444291Z I1024 13:06:51.858411       1 tlsconfig.go:181] "Loaded client CA" index=1 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2024-10-25 12:49:34 +0000 UTC (now=2024-10-24 13:06:51.858364211 +0000 UTC))"
2024-10-24T13:06:51.858562251Z I1024 13:06:51.858529       1 tlsconfig.go:181] "Loaded client CA" index=2 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-control-plane-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2025-10-24 12:49:34 +0000 UTC (now=2024-10-24 13:06:51.858502801 +0000 UTC))"
2024-10-24T13:06:51.858623131Z I1024 13:06:51.858607       1 tlsconfig.go:181] "Loaded client CA" index=3 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-apiserver-to-kubelet-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2025-10-24 12:49:34 +0000 UTC (now=2024-10-24 13:06:51.858588151 +0000 UTC))"
2024-10-24T13:06:51.858689891Z I1024 13:06:51.858671       1 tlsconfig.go:181] "Loaded client CA" index=4 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-bootstrap-kubeconfig-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:32 +0000 UTC to 2034-10-22 12:49:32 +0000 UTC (now=2024-10-24 13:06:51.858648451 +0000 UTC))"
2024-10-24T13:06:51.861408521Z I1024 13:06:51.858894       1 tlsconfig.go:181] "Loaded client CA" index=5 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-csr-signer_@1729775012\" [] issuer=\"kubelet-signer\" (2024-10-24 13:03:31 +0000 UTC to 2024-10-25 12:49:34 +0000 UTC (now=2024-10-24 13:06:51.858714811 +0000 UTC))"
2024-10-24T13:06:51.861506621Z I1024 13:06:51.861480       1 tlsconfig.go:181] "Loaded client CA" index=6 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_node-system-admin-signer@1729775011\" [] issuer=\"<self>\" (2024-10-24 13:03:30 +0000 UTC to 2025-10-24 13:03:31 +0000 UTC (now=2024-10-24 13:06:51.861451361 +0000 UTC))"
2024-10-24T13:06:51.861533791Z I1024 13:06:51.861512       1 tlsconfig.go:181] "Loaded client CA" index=7 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"aggregator-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:32 +0000 UTC to 2024-10-25 12:49:32 +0000 UTC (now=2024-10-24 13:06:51.861496321 +0000 UTC))"
2024-10-24T13:06:51.864794411Z I1024 13:06:51.861762       1 tlsconfig.go:203] "Loaded serving cert" certName="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key" certDetail="\"metrics.openshift-kube-controller-manager-operator.svc\" [serving] validServingFor=[metrics.openshift-kube-controller-manager-operator.svc,metrics.openshift-kube-controller-manager-operator.svc.cluster.local] issuer=\"openshift-service-serving-signer@1729775010\" (2024-10-24 13:03:41 +0000 UTC to 2026-10-24 13:03:42 +0000 UTC (now=2024-10-24 13:06:51.861726191 +0000 UTC))"
2024-10-24T13:06:51.864794411Z I1024 13:06:51.861965       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1729775100\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1729775100\" (2024-10-24 12:04:59 +0000 UTC to 2025-10-24 12:04:59 +0000 UTC (now=2024-10-24 13:06:51.861947151 +0000 UTC))"
2024-10-24T13:06:52.187933004Z I1024 13:06:52.187869       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:52.188059655Z I1024 13:06:52.188019       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 4 triggered by "required configmap/serviceaccount-ca has changed"
2024-10-24T13:06:52.189076395Z W1024 13:06:52.189049       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:06:52.189076395Z W1024 13:06:52.189064       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:06:52.208627104Z W1024 13:06:52.208577       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:06:52.208688314Z W1024 13:06:52.208629       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:06:52.209079794Z I1024 13:06:52.209036       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:52.591726667Z I1024 13:06:52.591666       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:06:52.631357006Z I1024 13:06:52.631289       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:52.633053276Z I1024 13:06:52.632988       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 3; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 3; 0 nodes have achieved new revision 4","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:06:52.647879116Z I1024 13:06:52.645209       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 3" to "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 3; 0 nodes have achieved new revision 4",Available message changed from "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 3" to "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 3; 0 nodes have achieved new revision 4"
2024-10-24T13:06:52.781426463Z I1024 13:06:52.781333       1 request.go:700] Waited for 1.121591779s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:53.785038264Z I1024 13:06:53.784735       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:06:53.785038264Z E1024 13:06:53.784915       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:06:53.981026460Z I1024 13:06:53.980985       1 request.go:700] Waited for 1.353177435s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-3-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:54.190197276Z E1024 13:06:54.187794       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:54.190197276Z E1024 13:06:54.188032       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:54.192777536Z E1024 13:06:54.190316       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:54.981481732Z I1024 13:06:54.981389       1 request.go:700] Waited for 1.396346314s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:55.391136764Z I1024 13:06:55.391076       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:06:55.391136764Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:06:55.391136764Z  CurrentRevision: (int32) 0,
2024-10-24T13:06:55.391136764Z  TargetRevision: (int32) 4,
2024-10-24T13:06:55.391136764Z  LastFailedRevision: (int32) 0,
2024-10-24T13:06:55.391136764Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:06:55.391136764Z  LastFailedReason: (string) "",
2024-10-24T13:06:55.391136764Z  LastFailedCount: (int) 0,
2024-10-24T13:06:55.391136764Z  LastFallbackCount: (int) 0,
2024-10-24T13:06:55.391136764Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:06:55.391136764Z }
2024-10-24T13:06:55.391136764Z  because new revision pending
2024-10-24T13:06:55.413374453Z I1024 13:06:55.413326       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:56.185407509Z I1024 13:06:56.185317       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:06:56.185503958Z E1024 13:06:56.185451       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:06:56.580617551Z I1024 13:06:56.580522       1 request.go:700] Waited for 1.188221037s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:57.580684482Z I1024 13:06:57.580613       1 request.go:700] Waited for 1.59607603s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:57.985819684Z E1024 13:06:57.985692       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:57.985819684Z E1024 13:06:57.985719       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:57.986898214Z E1024 13:06:57.986874       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:06:58.185536821Z I1024 13:06:58.185479       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:06:58.185536821Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:06:58.185536821Z  CurrentRevision: (int32) 0,
2024-10-24T13:06:58.185536821Z  TargetRevision: (int32) 4,
2024-10-24T13:06:58.185536821Z  LastFailedRevision: (int32) 0,
2024-10-24T13:06:58.185536821Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:06:58.185536821Z  LastFailedReason: (string) "",
2024-10-24T13:06:58.185536821Z  LastFailedCount: (int) 0,
2024-10-24T13:06:58.185536821Z  LastFallbackCount: (int) 0,
2024-10-24T13:06:58.185536821Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:06:58.185536821Z }
2024-10-24T13:06:58.185536821Z  because new revision pending
2024-10-24T13:06:58.580833113Z I1024 13:06:58.580768       1 request.go:700] Waited for 1.196317197s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/localhost-recovery-client-token
2024-10-24T13:06:58.984541835Z I1024 13:06:58.984470       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:06:58.984674385Z E1024 13:06:58.984646       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:06:59.580953034Z I1024 13:06:59.580894       1 request.go:700] Waited for 1.176217868s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager
2024-10-24T13:07:00.387005408Z E1024 13:07:00.386795       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:00.387005408Z E1024 13:07:00.386984       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:00.388004038Z E1024 13:07:00.387966       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:00.593180174Z I1024 13:07:00.593114       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:07:00.781044431Z I1024 13:07:00.780793       1 request.go:700] Waited for 1.157771638s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra
2024-10-24T13:07:01.185436673Z I1024 13:07:01.185358       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:07:01.185590343Z E1024 13:07:01.185541       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:07:01.781109452Z I1024 13:07:01.781041       1 request.go:700] Waited for 1.332923795s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-10-24T13:07:01.984370128Z I1024 13:07:01.984307       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 4, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:07:02.781289642Z I1024 13:07:02.781049       1 request.go:700] Waited for 1.393663133s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:07:03.386427991Z E1024 13:07:03.386390       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:03.386497601Z E1024 13:07:03.386484       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:03.388056061Z E1024 13:07:03.388028       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:03.781238633Z I1024 13:07:03.781191       1 request.go:700] Waited for 1.336632234s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:07:04.586312688Z I1024 13:07:04.586245       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:07:04.781718884Z I1024 13:07:04.781326       1 request.go:700] Waited for 1.391059943s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:07:05.188414847Z I1024 13:07:05.188343       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:07:05.188414847Z E1024 13:07:05.188393       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:07:05.980502982Z I1024 13:07:05.980426       1 request.go:700] Waited for 1.191466247s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:07:05.985251681Z E1024 13:07:05.985176       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:05.985251681Z E1024 13:07:05.985198       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:05.986347051Z E1024 13:07:05.986302       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:06.786201666Z I1024 13:07:06.786140       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:07:10.381193607Z I1024 13:07:10.380856       1 request.go:700] Waited for 1.062443179s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:11.186066942Z E1024 13:07:11.186001       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:11.186066942Z E1024 13:07:11.186024       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:11.186998002Z E1024 13:07:11.186956       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:11.380953438Z I1024 13:07:11.380886       1 request.go:700] Waited for 1.116526619s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:07:11.630519543Z I1024 13:07:11.630444       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:07:13.186022203Z E1024 13:07:13.185975       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:13.186110953Z E1024 13:07:13.186098       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:13.187592843Z E1024 13:07:13.187528       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:13.386730349Z I1024 13:07:13.386670       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:07:16.136959787Z E1024 13:07:16.134942       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:16.136959787Z E1024 13:07:16.135383       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:16.136959787Z E1024 13:07:16.136771       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:26.519913458Z E1024 13:07:26.519369       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:26.519913458Z E1024 13:07:26.519885       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:26.521538499Z E1024 13:07:26.521495       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:31.983856483Z E1024 13:07:31.983481       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:31.983856483Z E1024 13:07:31.983828       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:31.985094912Z E1024 13:07:31.985050       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:32.441681124Z E1024 13:07:32.441610       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:32.441681124Z E1024 13:07:32.441640       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:32.443603394Z E1024 13:07:32.443551       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:36.746368832Z E1024 13:07:36.746311       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:36.746513182Z E1024 13:07:36.746493       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:36.748584191Z E1024 13:07:36.748531       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:41.084219218Z E1024 13:07:41.084172       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:07:41.084449658Z I1024 13:07:41.084404       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:07:42.847327934Z E1024 13:07:42.847262       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:42.847327934Z E1024 13:07:42.847285       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:42.848691244Z E1024 13:07:42.848624       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:44.843458356Z I1024 13:07:44.843383       1 request.go:700] Waited for 1.141083649s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:45.649916650Z E1024 13:07:45.649854       1 guard_controller.go:300] Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:45.649916650Z E1024 13:07:45.649889       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:45.670106480Z E1024 13:07:45.670058       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:45.675880040Z I1024 13:07:45.671901       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:07:45.676151130Z I1024 13:07:45.676119       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 3; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 3; 0 nodes have achieved new revision 4","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:07:45.691815299Z I1024 13:07:45.691767       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]" to "GuardControllerDegraded: [Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:07:46.282370018Z I1024 13:07:46.281415       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:07:46.282370018Z I1024 13:07:46.282193       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: ","reason":"GuardController_SyncError::StaticPods_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 3; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 3; 0 nodes have achieved new revision 4","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:07:46.297351058Z I1024 13:07:46.297289       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]" to "GuardControllerDegraded: [Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: "
2024-10-24T13:07:46.843557157Z I1024 13:07:46.843506       1 request.go:700] Waited for 1.166961007s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:07:47.447540596Z I1024 13:07:47.447481       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 4, but has not made progress because static pod is pending
2024-10-24T13:07:48.043303892Z I1024 13:07:48.043235       1 request.go:700] Waited for 1.593461217s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:07:48.249046872Z I1024 13:07:48.248952       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:07:48.249148002Z E1024 13:07:48.249109       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:07:49.243888805Z I1024 13:07:49.243819       1 request.go:700] Waited for 1.573665268s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager
2024-10-24T13:07:50.443108847Z I1024 13:07:50.443053       1 request.go:700] Waited for 1.149813257s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra
2024-10-24T13:07:50.847196085Z I1024 13:07:50.847016       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-10-24T13:07:50.847238166Z E1024 13:07:50.847221       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5"
2024-10-24T13:07:51.443425811Z I1024 13:07:51.443140       1 request.go:700] Waited for 1.195813022s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:51.454994902Z I1024 13:07:51.454945       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 4, but has not made progress because static pod is pending
2024-10-24T13:07:52.051503408Z W1024 13:07:52.050895       1 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
2024-10-24T13:07:52.051503408Z E1024 13:07:52.051045       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:52.052059008Z I1024 13:07:52.052021       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:07:52.080744601Z E1024 13:07:52.080674       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:07:52.080955841Z I1024 13:07:52.080923       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:07:52.088827772Z I1024 13:07:52.088731       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: ","reason":"GuardController_SyncError::StaticPods_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 3; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 3; 0 nodes have achieved new revision 4","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:07:52.102500053Z I1024 13:07:52.101916       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: " to "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: "
2024-10-24T13:07:53.243169410Z I1024 13:07:53.243107       1 request.go:700] Waited for 1.162024799s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-10-24T13:07:54.243871304Z I1024 13:07:54.243793       1 request.go:700] Waited for 1.59528031s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:54.855962871Z I1024 13:07:54.855905       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerOK' found expected kube-apiserver endpoints
2024-10-24T13:07:55.443182656Z I1024 13:07:55.443102       1 request.go:700] Waited for 1.39115125s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client
2024-10-24T13:07:56.048391963Z I1024 13:07:56.048313       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 4, but has not made progress because static pod is pending
2024-10-24T13:07:56.443266650Z I1024 13:07:56.443208       1 request.go:700] Waited for 1.196389092s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/csr-signer
2024-10-24T13:07:57.262630897Z I1024 13:07:57.262576       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/next-service-account-private-key -n openshift-kube-controller-manager-operator because it was missing
2024-10-24T13:07:57.443833694Z I1024 13:07:57.443788       1 request.go:700] Waited for 1.195719772s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:57.450180654Z I1024 13:07:57.450145       1 core.go:220] Pod "openshift-kube-controller-manager/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1" changes: {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{"k8s.ovn.org/pod-networks":null,"k8s.v1.cni.cncf.io/network-status":null,"target.workload.openshift.io/management":"{\"effect\": \"PreferredDuringScheduling\"}"},"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null},"spec":{"containers":[{"args":["-c","# properly handle TERM and exit as soon as it is signaled\nset -euo pipefail\ntrap 'jobs -p | xargs -r kill; exit 0' TERM\nsleep infinity \u0026 wait\n"],"command":["/bin/bash"],"image":"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:39eb55fbaba0601f5bf36a2eaccc93fd172d1ab7d7d74ee36d36c9f29f7dd61b","imagePullPolicy":"IfNotPresent","name":"guard","readinessProbe":{"failureThreshold":3,"httpGet":{"host":"10.0.0.4","path":"healthz","port":10257,"scheme":"HTTPS"},"periodSeconds":5,"successThreshold":1,"timeoutSeconds":5},"resources":{"requests":{"cpu":"10m","memory":"5Mi"}},"terminationMessagePolicy":"FallbackToLogsOnError"}],"dnsPolicy":null,"enableServiceLinks":null,"preemptionPolicy":null,"priority":null,"restartPolicy":null,"schedulerName":null,"securityContext":null,"serviceAccount":null,"serviceAccountName":null,"volumes":null},"status":{"conditions":null,"containerStatuses":null,"hostIP":null,"hostIPs":null,"phase":null,"podIP":null,"podIPs":null,"qosClass":null,"startTime":null}}
2024-10-24T13:07:58.444047647Z I1024 13:07:58.443861       1 request.go:700] Waited for 1.181461081s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/configmaps/sa-token-signing-certs
2024-10-24T13:07:58.460296339Z I1024 13:07:58.460246       1 core.go:352] ConfigMap "openshift-config-managed/sa-token-signing-certs" changes: {"data":{"service-account-002.pub":"-----BEGIN RSA PUBLIC KEY-----\nMIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEApYEdlJOUNNdab1Iuqld4\nPN4sKBBIKCJeIMx34fi7pTN1WcE3YVbptMF9LAyw2QaB/kKXQxUGPcF2k/kBr1wz\nnNVBuMujJqETmQaBj088S6UB6NL+SgYp8Y/zqx6wrAI2gTK/1fYN8o4Ii3iRSlGm\nLafhh2bVHY6+jSfdHhKflT5f9mO+dtRyvaht5dsgXskifFSTsk+sKe4Zf+wBRBAb\nqXEMS35lU6A761MY7GP0Ufz1NkEz2oEODZFzy6Jr+XxInu7MdyDhzfI/bwSrJm7q\nmydVj+8i1KrZWq/WqKtKdZL+TV3eAQ42Ub/J/GWZe2eEIvDq8zo5z+Hox3JD8TDj\nOXhvXGv5YcxOS83DsYEKO6Iz1Po4mtfUIY32pZDELtVGPtmiG2BuWb9dRJPnBnYy\nye3pMxYqIh5vRR8ZKlG8V/C/ER7f4SC2XyIyf+8JVMeaMiITdJ1ZrLYvmrAKGopu\nYeQ8gTGPcMrya9jsiY79UpEIKP6gqtxIy6ss0xeLkn8b7pLD3aGd1HCuhBeaY5pv\ntu57H6W2v8lS57N9H/WRaJ3zEDl1DKIGPstZE77Pr8rMfQnKkQl7Dy8wi3uUZQAQ\nwnrbilgM/OVxzFpfCje2wMzffPgUi5sBzdpb5WkWfOmwiOKOwxCgKmQGaHMFqVVX\nSSxY/EMcbd14U8cLxCFbV7MCAwEAAQ==\n-----END RSA PUBLIC KEY-----\n"}}
2024-10-24T13:07:58.461629979Z I1024 13:07:58.461574       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/sa-token-signing-certs -n openshift-config-managed:
2024-10-24T13:07:58.461629979Z cause by changes in data.service-account-002.pub
2024-10-24T13:07:58.657161008Z E1024 13:07:58.656953       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:58.659068498Z E1024 13:07:58.659021       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:07:58.659331528Z I1024 13:07:58.659291       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-kube-controller-manager because it changed
2024-10-24T13:07:59.248556943Z I1024 13:07:59.248500       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 4, but has not made progress because static pod is pending
2024-10-24T13:07:59.843416209Z I1024 13:07:59.843346       1 request.go:700] Waited for 1.183553071s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:08:00.843504233Z I1024 13:08:00.843447       1 request.go:700] Waited for 1.382105839s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-10-24T13:08:02.043318605Z I1024 13:08:02.043259       1 request.go:700] Waited for 1.393734721s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:08:03.243949818Z I1024 13:08:03.243873       1 request.go:700] Waited for 1.195539473s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:08:03.250299608Z I1024 13:08:03.250248       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 4, but has not made progress because static pod is pending
2024-10-24T13:08:03.648092776Z E1024 13:08:03.648009       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:03.649640036Z E1024 13:08:03.649594       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:08:06.250155800Z I1024 13:08:06.250109       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 4, but has not made progress because static pod is pending
2024-10-24T13:08:07.050478835Z E1024 13:08:07.050436       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:07.052003705Z E1024 13:08:07.051979       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:08:10.048402826Z E1024 13:08:10.048337       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:10.049721057Z E1024 13:08:10.049671       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:08:18.610110789Z E1024 13:08:18.610053       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:18.611518060Z E1024 13:08:18.611482       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:08:30.222212430Z E1024 13:08:30.222148       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:30.223878830Z E1024 13:08:30.223843       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:08:40.088051995Z E1024 13:08:40.086970       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:40.115358118Z E1024 13:08:40.115220       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:08:40.513873695Z I1024 13:08:40.513806       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 3; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 3; 0 nodes have achieved new revision 4","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:08:40.517016655Z I1024 13:08:40.516976       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:08:40.524236496Z I1024 13:08:40.524184       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: " to "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:08:40.893652921Z I1024 13:08:40.893535       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:08:40.893652921Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:08:40.893652921Z  CurrentRevision: (int32) 4,
2024-10-24T13:08:40.893652921Z  TargetRevision: (int32) 0,
2024-10-24T13:08:40.893652921Z  LastFailedRevision: (int32) 0,
2024-10-24T13:08:40.893652921Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:08:40.893652921Z  LastFailedReason: (string) "",
2024-10-24T13:08:40.893652921Z  LastFailedCount: (int) 0,
2024-10-24T13:08:40.893652921Z  LastFallbackCount: (int) 0,
2024-10-24T13:08:40.893652921Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:08:40.893652921Z }
2024-10-24T13:08:40.893652921Z  because static pod is ready
2024-10-24T13:08:40.940309305Z I1024 13:08:40.937520       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 0 to 4 because static pod is ready
2024-10-24T13:08:40.942567505Z I1024 13:08:40.942535       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:08:40.945009735Z I1024 13:08:40.944955       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:08:40.968564978Z I1024 13:08:40.968464       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 3; 0 nodes have achieved new revision 4" to "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4",Available message changed from "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 3; 0 nodes have achieved new revision 4" to "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4"
2024-10-24T13:08:41.688040745Z I1024 13:08:41.687984       1 request.go:700] Waited for 1.159247589s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/config
2024-10-24T13:08:41.892831745Z E1024 13:08:41.892783       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:41.894475765Z E1024 13:08:41.894419       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:08:42.688470659Z I1024 13:08:42.688422       1 request.go:700] Waited for 1.150531148s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra
2024-10-24T13:08:44.298446650Z I1024 13:08:44.293910       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:08:44.298446650Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:08:44.298446650Z  CurrentRevision: (int32) 4,
2024-10-24T13:08:44.298446650Z  TargetRevision: (int32) 0,
2024-10-24T13:08:44.298446650Z  LastFailedRevision: (int32) 0,
2024-10-24T13:08:44.298446650Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:08:44.298446650Z  LastFailedReason: (string) "",
2024-10-24T13:08:44.298446650Z  LastFailedCount: (int) 0,
2024-10-24T13:08:44.298446650Z  LastFallbackCount: (int) 0,
2024-10-24T13:08:44.298446650Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:08:44.298446650Z }
2024-10-24T13:08:44.298446650Z  because static pod is ready
2024-10-24T13:08:46.093726909Z E1024 13:08:46.093677       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:46.095142179Z E1024 13:08:46.095088       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:08:47.091856962Z I1024 13:08:47.091793       1 installer_controller.go:534] node ci-op-2fcpj5j6-f6035-2lklf-master-2 static pod not found and needs new revision 4
2024-10-24T13:08:47.091856962Z I1024 13:08:47.091835       1 installer_controller.go:542] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:08:47.091856962Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:08:47.091856962Z  CurrentRevision: (int32) 0,
2024-10-24T13:08:47.091856962Z  TargetRevision: (int32) 4,
2024-10-24T13:08:47.091856962Z  LastFailedRevision: (int32) 0,
2024-10-24T13:08:47.091856962Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:08:47.091856962Z  LastFailedReason: (string) "",
2024-10-24T13:08:47.091856962Z  LastFailedCount: (int) 0,
2024-10-24T13:08:47.091856962Z  LastFallbackCount: (int) 0,
2024-10-24T13:08:47.091856962Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:08:47.091856962Z }
2024-10-24T13:08:47.110769234Z I1024 13:08:47.110676       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 0 to 4 because node ci-op-2fcpj5j6-f6035-2lklf-master-2 static pod not found
2024-10-24T13:08:47.113215894Z I1024 13:08:47.113188       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:08:48.905499412Z I1024 13:08:48.905429       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:08:49.694117597Z I1024 13:08:49.694045       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 4, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:08:50.088013383Z I1024 13:08:50.087942       1 request.go:700] Waited for 1.18200336s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:08:51.088602587Z I1024 13:08:51.088533       1 request.go:700] Waited for 1.194771412s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:08:52.093367371Z I1024 13:08:52.093284       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 4, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:08:53.098479961Z E1024 13:08:53.098127       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:53.103313551Z E1024 13:08:53.101485       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:08:53.103760920Z I1024 13:08:53.103703       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:08:54.102093745Z I1024 13:08:54.102033       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:08:54.134857866Z I1024 13:08:54.134805       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:08:54.288271012Z I1024 13:08:54.288211       1 request.go:700] Waited for 1.18447031s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:08:55.093014229Z I1024 13:08:55.092944       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:08:55.296094767Z I1024 13:08:55.296047       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:08:55.296493786Z I1024 13:08:55.296458       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-manager-pod-5 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:08:55.488557013Z I1024 13:08:55.488503       1 request.go:700] Waited for 1.195235191s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:08:56.687973765Z I1024 13:08:56.687918       1 request.go:700] Waited for 1.391669958s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps
2024-10-24T13:08:56.696926865Z I1024 13:08:56.696857       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-5 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:08:56.697503505Z I1024 13:08:56.697460       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:08:57.688443590Z I1024 13:08:57.688383       1 request.go:700] Waited for 1.195608741s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:57.692933930Z I1024 13:08:57.692878       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:08:57.896029287Z I1024 13:08:57.895970       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:08:57.896828137Z I1024 13:08:57.896728       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cluster-policy-controller-config-5 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:08:58.093144594Z E1024 13:08:58.093051       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:58.094194354Z E1024 13:08:58.094142       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:08:58.887891941Z I1024 13:08:58.887842       1 request.go:700] Waited for 1.193762511s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:08:59.095600159Z I1024 13:08:59.095522       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:08:59.095858538Z I1024 13:08:59.095818       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/controller-manager-kubeconfig-5 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:08:59.887958936Z I1024 13:08:59.887901       1 request.go:700] Waited for 1.195489452s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:09:00.092602583Z I1024 13:09:00.092517       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:09:00.294438830Z I1024 13:09:00.294387       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:09:00.294662850Z I1024 13:09:00.294625       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-cert-syncer-kubeconfig-5 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:09:01.296230235Z I1024 13:09:01.296153       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-5 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:09:01.296313005Z I1024 13:09:01.296170       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:09:01.488457372Z I1024 13:09:01.488394       1 request.go:700] Waited for 1.041030765s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:09:02.488900286Z I1024 13:09:02.488855       1 request.go:700] Waited for 1.593941025s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/cluster-policy-controller-config
2024-10-24T13:09:02.696259393Z I1024 13:09:02.696194       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:09:02.895433680Z I1024 13:09:02.895359       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:09:02.895503180Z I1024 13:09:02.895476       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/service-ca-5 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:09:03.293214144Z E1024 13:09:03.293134       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:09:03.294578994Z E1024 13:09:03.294543       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:09:03.688304448Z I1024 13:09:03.688238       1 request.go:700] Waited for 1.193371351s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/recycler-config
2024-10-24T13:09:04.095153852Z I1024 13:09:04.095051       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:09:04.095153852Z I1024 13:09:04.095129       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/recycler-config-5 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:09:04.888114179Z I1024 13:09:04.888051       1 request.go:700] Waited for 1.194791581s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps/csr-signer-ca
2024-10-24T13:09:05.090239306Z E1024 13:09:05.090186       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:05.288490783Z I1024 13:09:05.288400       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretCreateFailed' Failed to create Secret/service-account-private-key-5 -n openshift-kube-controller-manager: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:05.289216413Z E1024 13:09:05.289168       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.1801658305227113  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:SecretCreateFailed,Message:Failed to create Secret/service-account-private-key-5 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:09:05.288245523 +0000 UTC m=+245.609552850,LastTimestamp:2024-10-24 13:09:05.288245523 +0000 UTC m=+245.609552850,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:09:05.290436413Z E1024 13:09:05.290389       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:05.290436413Z I1024 13:09:05.290412       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 5: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:05.292655523Z I1024 13:09:05.292609       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:09:05.489017739Z E1024 13:09:05.488940       1 guard_controller.go:366] Unable to apply pod kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0 changes: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:05.888937083Z I1024 13:09:05.888874       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 4 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:05.889772773Z E1024 13:09:05.889711       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.1801658328ed319b  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 4 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:05.888735643 +0000 UTC m=+246.210042960,LastTimestamp:2024-10-24 13:09:05.888735643 +0000 UTC m=+246.210042960,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:09:05.890075893Z E1024 13:09:05.890049       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:06.090101350Z E1024 13:09:06.090049       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:06.090169750Z I1024 13:09:06.090089       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 5: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:06.092934900Z I1024 13:09:06.092877       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:09:06.288571897Z E1024 13:09:06.288523       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:09:06.290871377Z W1024 13:09:06.290818       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:06.290921037Z E1024 13:09:06.290873       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2, Unable to apply pod kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0 changes: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:06.689040831Z I1024 13:09:06.688986       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 4 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:06.690126381Z E1024 13:09:06.690073       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:06.890606788Z E1024 13:09:06.890545       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:06.890606788Z I1024 13:09:06.890582       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 5: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:06.892939218Z I1024 13:09:06.892904       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:09:07.288946832Z I1024 13:09:07.288858       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 4 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:07.290024822Z E1024 13:09:07.289987       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:07.490490699Z E1024 13:09:07.490432       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:07.490490699Z I1024 13:09:07.490468       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 5: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:07.492812899Z I1024 13:09:07.492738       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:09:07.889177503Z I1024 13:09:07.889122       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 4 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:07.890147103Z E1024 13:09:07.890102       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:08.090742530Z E1024 13:09:08.090687       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:08.090742530Z I1024 13:09:08.090722       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 5: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:08.093051200Z I1024 13:09:08.093001       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:09:08.488675124Z I1024 13:09:08.488602       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 4 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:08.489957114Z E1024 13:09:08.489804       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:08.689817611Z E1024 13:09:08.689729       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:08.689817611Z I1024 13:09:08.689786       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 5: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:08.692288671Z I1024 13:09:08.692236       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:09:09.088873045Z I1024 13:09:09.088788       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 4 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:09.089969955Z E1024 13:09:09.089896       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:09.290698862Z E1024 13:09:09.290641       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:09.290698862Z I1024 13:09:09.290677       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 5: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:09.293111292Z I1024 13:09:09.293065       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:09:09.689165066Z I1024 13:09:09.689039       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 4 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:09.690222756Z E1024 13:09:09.690166       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:09.890984333Z E1024 13:09:09.890931       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:09.890984333Z I1024 13:09:09.890966       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 5: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:09.893385443Z I1024 13:09:09.893341       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:09:10.089962519Z E1024 13:09:10.089908       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:10.091858789Z E1024 13:09:10.091824       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:10.097983669Z E1024 13:09:10.097911       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:10.120436010Z E1024 13:09:10.120292       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:10.162888242Z E1024 13:09:10.162839       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:10.245430125Z E1024 13:09:10.245380       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:10.408540750Z E1024 13:09:10.408476       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:10.491536634Z I1024 13:09:10.491437       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 4 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:10.492562243Z E1024 13:09:10.492526       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:10.690867840Z E1024 13:09:10.690816       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:10.690867840Z I1024 13:09:10.690852       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 5: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:10.697848401Z I1024 13:09:10.697792       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:09:10.730687762Z E1024 13:09:10.730639       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:11.288487711Z I1024 13:09:11.288398       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 4 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:11.290050431Z E1024 13:09:11.290000       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:11.374506074Z E1024 13:09:11.374445       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:11.490950008Z E1024 13:09:11.490888       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:11.490950008Z I1024 13:09:11.490926       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 5: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:11.888888902Z E1024 13:09:11.888827       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:09:11.891259572Z W1024 13:09:11.891215       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:11.891286832Z E1024 13:09:11.891272       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:09:11.974559355Z I1024 13:09:11.974496       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:09:12.047933767Z E1024 13:09:12.047874       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.1801658305227113  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:SecretCreateFailed,Message:Failed to create Secret/service-account-private-key-5 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:09:05.288245523 +0000 UTC m=+245.609552850,LastTimestamp:2024-10-24 13:09:05.288245523 +0000 UTC m=+245.609552850,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:09:12.289176045Z I1024 13:09:12.289110       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 4 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:12.290184335Z E1024 13:09:12.290072       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:12.656986198Z E1024 13:09:12.656930       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:12.690939759Z E1024 13:09:12.690877       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:12.690973339Z I1024 13:09:12.690924       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 5: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:13.088958272Z E1024 13:09:13.088896       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:09:13.091109772Z W1024 13:09:13.091063       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:13.091151482Z E1024 13:09:13.091113       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2]"
2024-10-24T13:09:13.493500856Z E1024 13:09:13.493428       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:15.220175886Z E1024 13:09:15.220104       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:15.227457176Z E1024 13:09:15.227393       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.1801658328ed319b  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 4 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:05.888735643 +0000 UTC m=+246.210042960,LastTimestamp:2024-10-24 13:09:05.888735643 +0000 UTC m=+246.210042960,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:09:15.695345522Z E1024 13:09:15.695284       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:17.413347492Z I1024 13:09:17.413268       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 4 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:17.414586522Z E1024 13:09:17.414539       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:17.813862066Z I1024 13:09:17.813775       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:09:17.816264826Z E1024 13:09:17.816222       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:17.816291886Z I1024 13:09:17.816255       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 5: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:18.895936843Z E1024 13:09:18.895878       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:20.342556414Z E1024 13:09:20.342490       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:20.416741507Z E1024 13:09:20.416673       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:09:20.417480947Z E1024 13:09:20.417429       1 leaderelection.go:436] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:22.049389363Z E1024 13:09:22.049331       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.1801658305227113  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:SecretCreateFailed,Message:Failed to create Secret/service-account-private-key-5 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:09:05.288245523 +0000 UTC m=+245.609552850,LastTimestamp:2024-10-24 13:09:05.288245523 +0000 UTC m=+245.609552850,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:09:22.095146105Z E1024 13:09:22.095075       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:25.229390814Z E1024 13:09:25.229331       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.1801658328ed319b  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 4 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:05.888735643 +0000 UTC m=+246.210042960,LastTimestamp:2024-10-24 13:09:05.888735643 +0000 UTC m=+246.210042960,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:09:25.295893686Z E1024 13:09:25.295815       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:27.658630328Z I1024 13:09:27.658551       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 4 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:27.659866228Z E1024 13:09:27.659835       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:28.059084262Z I1024 13:09:28.059023       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:09:28.061498822Z E1024 13:09:28.061472       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:28.061553753Z I1024 13:09:28.061499       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 5: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:28.495527397Z E1024 13:09:28.495467       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:30.585035089Z E1024 13:09:30.584980       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:31.695850568Z E1024 13:09:31.695737       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:32.050684150Z E1024 13:09:32.050632       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.1801658305227113  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:SecretCreateFailed,Message:Failed to create Secret/service-account-private-key-5 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:09:05.288245523 +0000 UTC m=+245.609552850,LastTimestamp:2024-10-24 13:09:05.288245523 +0000 UTC m=+245.609552850,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:09:34.895394018Z E1024 13:09:34.895318       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:35.231058530Z E1024 13:09:35.231003       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.1801658328ed319b  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 4 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:05.888735643 +0000 UTC m=+246.210042960,LastTimestamp:2024-10-24 13:09:05.888735643 +0000 UTC m=+246.210042960,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:09:38.095447319Z E1024 13:09:38.095377       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:41.295333699Z E1024 13:09:41.295257       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:42.052691475Z E1024 13:09:42.052636       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.1801658305227113  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:SecretCreateFailed,Message:Failed to create Secret/service-account-private-key-5 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:09:05.288245523 +0000 UTC m=+245.609552850,LastTimestamp:2024-10-24 13:09:05.288245523 +0000 UTC m=+245.609552850,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:09:44.495449387Z E1024 13:09:44.495386       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:45.232513552Z E1024 13:09:45.232457       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.1801658328ed319b  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 4 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:05.888735643 +0000 UTC m=+246.210042960,LastTimestamp:2024-10-24 13:09:05.888735643 +0000 UTC m=+246.210042960,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:09:46.418554012Z E1024 13:09:46.418474       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:09:46.419158272Z E1024 13:09:46.419115       1 leaderelection.go:436] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:47.694461276Z E1024 13:09:47.694395       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:48.143006071Z I1024 13:09:48.142932       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 4 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:48.144317762Z E1024 13:09:48.144208       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:48.544601775Z I1024 13:09:48.544531       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:09:48.547327286Z E1024 13:09:48.547286       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:48.547355316Z I1024 13:09:48.547319       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 5: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:50.895094306Z E1024 13:09:50.895032       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:51.067239352Z E1024 13:09:51.067180       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:52.054218506Z E1024 13:09:52.054157       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.1801658305227113  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:SecretCreateFailed,Message:Failed to create Secret/service-account-private-key-5 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:09:05.288245523 +0000 UTC m=+245.609552850,LastTimestamp:2024-10-24 13:09:05.288245523 +0000 UTC m=+245.609552850,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:09:55.234145975Z E1024 13:09:55.234079       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.1801658328ed319b  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 4 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:05.888735643 +0000 UTC m=+246.210042960,LastTimestamp:2024-10-24 13:09:05.888735643 +0000 UTC m=+246.210042960,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:10:00.449709746Z E1024 13:10:00.449660       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:00.449951816Z I1024 13:10:00.449920       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:10:00.452029296Z E1024 13:10:00.451999       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:00.452058366Z E1024 13:10:00.452023       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:00.452474816Z E1024 13:10:00.452439       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:00.452474816Z I1024 13:10:00.452458       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 5: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:00.457531627Z E1024 13:10:00.457495       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:00.462799677Z E1024 13:10:00.462745       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:00.651080801Z E1024 13:10:00.651021       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:00.850009626Z E1024 13:10:00.849948       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:01.052701580Z E1024 13:10:01.052638       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:01.449630379Z E1024 13:10:01.449568       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:01.652795643Z E1024 13:10:01.652712       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:02.050152694Z E1024 13:10:02.050101       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:02.055670423Z E1024 13:10:02.055611       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.1801658305227113  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:SecretCreateFailed,Message:Failed to create Secret/service-account-private-key-5 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:09:05.288245523 +0000 UTC m=+245.609552850,LastTimestamp:2024-10-24 13:09:05.288245523 +0000 UTC m=+245.609552850,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:10:02.252723348Z E1024 13:10:02.252652       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:02.554396157Z E1024 13:10:02.554344       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:02.651290409Z E1024 13:10:02.651230       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:02.850226613Z E1024 13:10:02.850162       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:03.052427408Z E1024 13:10:03.052365       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:03.650764561Z E1024 13:10:03.650673       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:03.851972446Z E1024 13:10:03.851909       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:04.450383681Z E1024 13:10:04.450316       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:04.853017850Z E1024 13:10:04.852963       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:05.051325125Z E1024 13:10:05.051258       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:05.236378819Z E1024 13:10:05.236295       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.1801658328ed319b  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 4 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:05.888735643 +0000 UTC m=+246.210042960,LastTimestamp:2024-10-24 13:09:05.888735643 +0000 UTC m=+246.210042960,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:10:05.450372675Z E1024 13:10:05.450316       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:06.052988899Z E1024 13:10:06.052934       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:06.456371607Z E1024 13:10:06.456219       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:06.651613092Z E1024 13:10:06.651554       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:06.849673797Z E1024 13:10:06.849604       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:07.452385792Z E1024 13:10:07.452338       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:07.652930817Z E1024 13:10:07.652865       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:08.252091291Z E1024 13:10:08.252023       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:08.851311495Z E1024 13:10:08.851248       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:09.412256588Z E1024 13:10:09.412194       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:09.651350954Z E1024 13:10:09.651292       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:10.218710157Z E1024 13:10:10.218667       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:10.936596055Z E1024 13:10:10.936546       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:12.057503121Z E1024 13:10:12.057450       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.1801658305227113  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:SecretCreateFailed,Message:Failed to create Secret/service-account-private-key-5 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:09:05.288245523 +0000 UTC m=+245.609552850,LastTimestamp:2024-10-24 13:09:05.288245523 +0000 UTC m=+245.609552850,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:10:12.419332649Z E1024 13:10:12.419272       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:10:12.420022590Z E1024 13:10:12.419986       1 leaderelection.go:436] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:12.581734263Z E1024 13:10:12.581665       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:13.501422555Z E1024 13:10:13.501358       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:14.535264610Z E1024 13:10:14.535201       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:15.237888887Z E1024 13:10:15.237833       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.1801658328ed319b  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 4 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:05.888735643 +0000 UTC m=+246.210042960,LastTimestamp:2024-10-24 13:09:05.888735643 +0000 UTC m=+246.210042960,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:10:15.344923269Z E1024 13:10:15.344859       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:18.631388188Z E1024 13:10:18.631321       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:22.058940990Z E1024 13:10:22.058890       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.1801658305227113  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:SecretCreateFailed,Message:Failed to create Secret/service-account-private-key-5 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:09:05.288245523 +0000 UTC m=+245.609552850,LastTimestamp:2024-10-24 13:09:05.288245523 +0000 UTC m=+245.609552850,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:10:24.778524255Z E1024 13:10:24.778374       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:25.239917116Z E1024 13:10:25.239855       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.1801658328ed319b  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 4 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:05.888735643 +0000 UTC m=+246.210042960,LastTimestamp:2024-10-24 13:09:05.888735643 +0000 UTC m=+246.210042960,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:10:25.591444094Z E1024 13:10:25.591387       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:28.876575862Z E1024 13:10:28.876523       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:29.108096628Z I1024 13:10:29.108022       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 4 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:29.109271997Z E1024 13:10:29.109236       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:29.511122957Z I1024 13:10:29.511038       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:10:29.513712727Z E1024 13:10:29.513663       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:29.513742657Z I1024 13:10:29.513708       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 5: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:32.030618327Z E1024 13:10:32.030545       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:32.061065357Z E1024 13:10:32.060990       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.1801658305227113  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:SecretCreateFailed,Message:Failed to create Secret/service-account-private-key-5 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:09:05.288245523 +0000 UTC m=+245.609552850,LastTimestamp:2024-10-24 13:09:05.288245523 +0000 UTC m=+245.609552850,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:10:35.241401004Z E1024 13:10:35.241344       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.1801658328ed319b  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 4 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:05.888735643 +0000 UTC m=+246.210042960,LastTimestamp:2024-10-24 13:09:05.888735643 +0000 UTC m=+246.210042960,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:11:00.450642533Z I1024 13:11:00.450572       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:11:00.480798394Z I1024 13:11:00.480448       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/service-account-private-key-5 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:11:00.492147714Z I1024 13:11:00.492055       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-5 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:11:00.503369124Z I1024 13:11:00.503295       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-5 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:11:00.513294945Z I1024 13:11:00.513228       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 5 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:11:00.514512425Z W1024 13:11:00.514485       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:00.514512425Z W1024 13:11:00.514501       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:10.030609257Z I1024 13:11:10.030530       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:10.211642118Z I1024 13:11:10.211564       1 reflector.go:368] Caches populated for *v1.Proxy from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:17.796124309Z I1024 13:11:17.796066       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:19.145128683Z I1024 13:11:19.145072       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:24.572709871Z I1024 13:11:24.572645       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:24.573485601Z I1024 13:11:24.573440       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:24.574357481Z I1024 13:11:24.574315       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:24.574920151Z I1024 13:11:24.574878       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:24.574941871Z I1024 13:11:24.574912       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:11:24.575201991Z I1024 13:11:24.575169       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:24.575467781Z I1024 13:11:24.575447       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:24.575673991Z I1024 13:11:24.575654       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:24.575891891Z I1024 13:11:24.575855       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:24.586480611Z I1024 13:11:24.586405       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-2" for revision 4 for the 1st time because installer pod failed: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:24.586480611Z W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:24.586480611Z W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:24.586480611Z W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:24.586480611Z W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:24.586480611Z W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:24.586480611Z W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:24.586480611Z F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:24.586536311Z I1024 13:11:24.586498       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:11:24.586536311Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:11:24.586536311Z  CurrentRevision: (int32) 0,
2024-10-24T13:11:24.586536311Z  TargetRevision: (int32) 4,
2024-10-24T13:11:24.586536311Z  LastFailedRevision: (int32) 4,
2024-10-24T13:11:24.586536311Z  LastFailedTime: (*v1.Time)(0xc000b82540)(2024-10-24 13:11:24.586390591 +0000 UTC m=+384.907697918),
2024-10-24T13:11:24.586536311Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:11:24.586536311Z  LastFailedCount: (int) 1,
2024-10-24T13:11:24.586536311Z  LastFallbackCount: (int) 0,
2024-10-24T13:11:24.586536311Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:11:24.586536311Z   (string) (len=2059) "installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:11:24.586536311Z  }
2024-10-24T13:11:24.586536311Z }
2024-10-24T13:11:24.586536311Z  because installer pod failed: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:24.586536311Z W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:24.586536311Z W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:24.586536311Z W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:24.586536311Z W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:24.586536311Z W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:24.586536311Z W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:24.586536311Z F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:24.586560161Z I1024 13:11:24.586539       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:24.586560161Z W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:24.586560161Z W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:24.586560161Z W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:24.586560161Z W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:24.586560161Z W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:24.586560161Z W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:24.586560161Z F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:24.587045551Z I1024 13:11:24.587002       1 revision_controller.go:274] down the branch indicating that our cache was out of date and we're trying to recreate a revision.
2024-10-24T13:11:24.589421411Z W1024 13:11:24.589379       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:24.589421411Z W1024 13:11:24.589397       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:24.613459791Z W1024 13:11:24.613405       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:24.613459791Z W1024 13:11:24.613423       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:24.640020511Z I1024 13:11:24.639973       1 helpers.go:260] lister was stale at resourceVersion=16221, live get showed resourceVersion=17220
2024-10-24T13:11:24.669312152Z W1024 13:11:24.669262       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:24.669312152Z W1024 13:11:24.669283       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:24.742812233Z W1024 13:11:24.742761       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:24.742812233Z W1024 13:11:24.742781       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:24.817115813Z W1024 13:11:24.817080       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:24.817115813Z W1024 13:11:24.817096       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:24.920179874Z W1024 13:11:24.920121       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:24.920179874Z W1024 13:11:24.920143       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:25.103599406Z W1024 13:11:25.103528       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:25.103599406Z W1024 13:11:25.103563       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:25.445255330Z W1024 13:11:25.445194       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:25.445369200Z W1024 13:11:25.445353       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:25.799437543Z I1024 13:11:25.799347       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-2" for revision 4 for the 1st time because installer pod failed: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:25.799437543Z W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:25.799437543Z W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:25.799437543Z W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:25.799437543Z W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:25.799437543Z W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:25.799437543Z W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:25.799437543Z F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:25.799533083Z I1024 13:11:25.799490       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:25.799533083Z W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:25.799533083Z W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:25.799533083Z W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:25.799533083Z W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:25.799533083Z W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:25.799533083Z W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:25.799533083Z F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:25.799558363Z I1024 13:11:25.799478       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:11:25.799558363Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:11:25.799558363Z  CurrentRevision: (int32) 0,
2024-10-24T13:11:25.799558363Z  TargetRevision: (int32) 4,
2024-10-24T13:11:25.799558363Z  LastFailedRevision: (int32) 4,
2024-10-24T13:11:25.799558363Z  LastFailedTime: (*v1.Time)(0xc002a281b0)(2024-10-24 13:11:25.799326853 +0000 UTC m=+386.120634181),
2024-10-24T13:11:25.799558363Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:11:25.799558363Z  LastFailedCount: (int) 1,
2024-10-24T13:11:25.799558363Z  LastFallbackCount: (int) 0,
2024-10-24T13:11:25.799558363Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:11:25.799558363Z   (string) (len=2059) "installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:11:25.799558363Z  }
2024-10-24T13:11:25.799558363Z }
2024-10-24T13:11:25.799558363Z  because installer pod failed: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:25.799558363Z W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:25.799558363Z W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:25.799558363Z W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:25.799558363Z W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:25.799558363Z W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:25.799558363Z W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:25.799558363Z F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:25.837603654Z I1024 13:11:25.837556       1 helpers.go:260] lister was stale at resourceVersion=16221, live get showed resourceVersion=17407
2024-10-24T13:11:26.110665787Z W1024 13:11:26.109637       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:26.110665787Z W1024 13:11:26.109665       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:27.418100751Z W1024 13:11:27.418032       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:27.418100751Z W1024 13:11:27.418061       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:27.473689191Z I1024 13:11:27.473643       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:27.475211001Z W1024 13:11:27.475150       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:27.475211001Z W1024 13:11:27.475175       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:28.402069421Z I1024 13:11:28.402001       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-2" for revision 4 for the 1st time because installer pod failed: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:28.402069421Z W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:28.402069421Z W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:28.402069421Z W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:28.402069421Z W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:28.402069421Z W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:28.402069421Z W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:28.402069421Z F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:28.402154471Z I1024 13:11:28.402102       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:11:28.402154471Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:11:28.402154471Z  CurrentRevision: (int32) 0,
2024-10-24T13:11:28.402154471Z  TargetRevision: (int32) 4,
2024-10-24T13:11:28.402154471Z  LastFailedRevision: (int32) 4,
2024-10-24T13:11:28.402154471Z  LastFailedTime: (*v1.Time)(0xc0025f2a80)(2024-10-24 13:11:28.401980481 +0000 UTC m=+388.723287808),
2024-10-24T13:11:28.402154471Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:11:28.402154471Z  LastFailedCount: (int) 1,
2024-10-24T13:11:28.402154471Z  LastFallbackCount: (int) 0,
2024-10-24T13:11:28.402154471Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:11:28.402154471Z   (string) (len=2059) "installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:11:28.402154471Z  }
2024-10-24T13:11:28.402154471Z }
2024-10-24T13:11:28.402154471Z  because installer pod failed: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:28.402154471Z W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:28.402154471Z W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:28.402154471Z W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:28.402154471Z W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:28.402154471Z W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:28.402154471Z W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:28.402154471Z F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:28.402630381Z I1024 13:11:28.402455       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:28.402630381Z W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:28.402630381Z W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:28.402630381Z W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:28.402630381Z W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:28.402630381Z W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:28.402630381Z W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:28.402630381Z F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:28.450961912Z I1024 13:11:28.450906       1 helpers.go:260] lister was stale at resourceVersion=16221, live get showed resourceVersion=17413
2024-10-24T13:11:29.427606692Z I1024 13:11:29.427533       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:30.001356128Z W1024 13:11:30.001300       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:30.001356128Z W1024 13:11:30.001321       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:32.997318080Z I1024 13:11:32.997246       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:35.995976621Z I1024 13:11:35.995913       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:38.025372653Z I1024 13:11:38.025323       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:40.011715234Z I1024 13:11:40.011642       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:40.266544867Z W1024 13:11:40.266477       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:40.266544867Z W1024 13:11:40.266510       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:41.416029229Z I1024 13:11:41.415972       1 reflector.go:368] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:43.796479473Z I1024 13:11:43.796404       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:43.996061476Z I1024 13:11:43.995990       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:44.477263881Z I1024 13:11:44.477218       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:44.583297412Z I1024 13:11:44.583231       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:45.802497595Z I1024 13:11:45.802426       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-2" for revision 4 for the 1st time because installer pod failed: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:45.802497595Z W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:45.802497595Z W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:45.802497595Z W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:45.802497595Z W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:45.802497595Z W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:45.802497595Z W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:45.802497595Z F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:45.802598865Z I1024 13:11:45.802536       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:11:45.802598865Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:11:45.802598865Z  CurrentRevision: (int32) 0,
2024-10-24T13:11:45.802598865Z  TargetRevision: (int32) 4,
2024-10-24T13:11:45.802598865Z  LastFailedRevision: (int32) 4,
2024-10-24T13:11:45.802598865Z  LastFailedTime: (*v1.Time)(0xc001c34048)(2024-10-24 13:11:45.802407295 +0000 UTC m=+406.123714622),
2024-10-24T13:11:45.802598865Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:11:45.802598865Z  LastFailedCount: (int) 1,
2024-10-24T13:11:45.802598865Z  LastFallbackCount: (int) 0,
2024-10-24T13:11:45.802598865Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:11:45.802598865Z   (string) (len=2059) "installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:11:45.802598865Z  }
2024-10-24T13:11:45.802598865Z }
2024-10-24T13:11:45.802598865Z  because installer pod failed: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:45.802598865Z W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:45.802598865Z W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:45.802598865Z W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:45.802598865Z W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:45.802598865Z W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:45.802598865Z W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:45.802598865Z F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:45.802624845Z I1024 13:11:45.802586       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:45.802624845Z W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:45.802624845Z W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:45.802624845Z W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:45.802624845Z W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:45.802624845Z W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:45.802624845Z W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:45.802624845Z F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:45.844978455Z I1024 13:11:45.844914       1 helpers.go:260] lister was stale at resourceVersion=16221, live get showed resourceVersion=17599
2024-10-24T13:11:45.944285486Z I1024 13:11:45.944229       1 reflector.go:368] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:47.398366282Z E1024 13:11:47.397639       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:11:47.399100752Z E1024 13:11:47.399056       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:11:47.453339042Z I1024 13:11:47.453285       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:47.598726144Z I1024 13:11:47.598657       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-2" for revision 4 for the 1st time because installer pod failed: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:47.598726144Z W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:47.598726144Z W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:47.598726144Z W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:47.598726144Z W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:47.598726144Z W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:47.598726144Z W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:47.598726144Z F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:47.598807224Z I1024 13:11:47.598772       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:11:47.598807224Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:11:47.598807224Z  CurrentRevision: (int32) 0,
2024-10-24T13:11:47.598807224Z  TargetRevision: (int32) 4,
2024-10-24T13:11:47.598807224Z  LastFailedRevision: (int32) 4,
2024-10-24T13:11:47.598807224Z  LastFailedTime: (*v1.Time)(0xc000b82df8)(2024-10-24 13:11:47.598642254 +0000 UTC m=+407.919949571),
2024-10-24T13:11:47.598807224Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:11:47.598807224Z  LastFailedCount: (int) 1,
2024-10-24T13:11:47.598807224Z  LastFallbackCount: (int) 0,
2024-10-24T13:11:47.598807224Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:11:47.598807224Z   (string) (len=2059) "installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:11:47.598807224Z  }
2024-10-24T13:11:47.598807224Z }
2024-10-24T13:11:47.598807224Z  because installer pod failed: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:47.598807224Z W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:47.598807224Z W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:47.598807224Z W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:47.598807224Z W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:47.598807224Z W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:47.598807224Z W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:47.598807224Z F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:47.598892184Z I1024 13:11:47.598827       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:47.598892184Z W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:47.598892184Z W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:47.598892184Z W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:47.598892184Z W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:47.598892184Z W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:47.598892184Z W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:47.598892184Z F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:47.637721384Z I1024 13:11:47.637627       1 helpers.go:260] lister was stale at resourceVersion=16221, live get showed resourceVersion=17924
2024-10-24T13:11:48.392797232Z I1024 13:11:48.392716       1 request.go:700] Waited for 1.018070481s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/nodes?resourceVersion=16603
2024-10-24T13:11:48.396386782Z I1024 13:11:48.396344       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:48.795745257Z I1024 13:11:48.795684       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:48.808957577Z I1024 13:11:48.808917       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:49.396200533Z I1024 13:11:49.396151       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:50.401803884Z E1024 13:11:50.401667       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:11:50.405557324Z E1024 13:11:50.405516       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:11:50.996216520Z I1024 13:11:50.996151       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:52.598121717Z I1024 13:11:52.598052       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-2" for revision 4 for the 1st time because installer pod failed: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:52.598121717Z W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:52.598121717Z W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:52.598121717Z W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:52.598121717Z W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:52.598121717Z W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:52.598121717Z W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:52.598121717Z F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:52.598196117Z I1024 13:11:52.598114       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:52.598196117Z W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:52.598196117Z W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:52.598196117Z W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:52.598196117Z W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:52.598196117Z W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:52.598196117Z W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:52.598196117Z F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:52.598196117Z I1024 13:11:52.598153       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:11:52.598196117Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:11:52.598196117Z  CurrentRevision: (int32) 0,
2024-10-24T13:11:52.598196117Z  TargetRevision: (int32) 4,
2024-10-24T13:11:52.598196117Z  LastFailedRevision: (int32) 4,
2024-10-24T13:11:52.598196117Z  LastFailedTime: (*v1.Time)(0xc000685278)(2024-10-24 13:11:52.598033647 +0000 UTC m=+412.919340974),
2024-10-24T13:11:52.598196117Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:11:52.598196117Z  LastFailedCount: (int) 1,
2024-10-24T13:11:52.598196117Z  LastFallbackCount: (int) 0,
2024-10-24T13:11:52.598196117Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:11:52.598196117Z   (string) (len=2059) "installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:11:52.598196117Z  }
2024-10-24T13:11:52.598196117Z }
2024-10-24T13:11:52.598196117Z  because installer pod failed: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:52.598196117Z W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:52.598196117Z W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:52.598196117Z W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:52.598196117Z W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:52.598196117Z W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:52.598196117Z W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:52.598196117Z F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:52.634592227Z I1024 13:11:52.634548       1 helpers.go:260] lister was stale at resourceVersion=16221, live get showed resourceVersion=17948
2024-10-24T13:11:52.798999279Z E1024 13:11:52.798951       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:11:52.800350919Z E1024 13:11:52.800287       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:11:55.195665924Z I1024 13:11:55.195593       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:55.250228705Z I1024 13:11:55.250168       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:56.076482134Z I1024 13:11:56.076390       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:57.794710282Z I1024 13:11:57.794632       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:59.364233349Z I1024 13:11:59.364166       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubecontrollermanagers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:59.365844099Z I1024 13:11:59.365790       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-5,service-account-private-key-5
2024-10-24T13:11:59.366099059Z I1024 13:11:59.366077       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:59.366277139Z I1024 13:11:59.366245       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nNodeInstallerDegraded: 1 nodes are failing on revision 4:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 5","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:59.366647109Z I1024 13:11:59.366589       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 6 triggered by "secret \"service-account-private-key-5\" not found"
2024-10-24T13:11:59.385395349Z I1024 13:11:59.384365       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2" to "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nNodeInstallerDegraded: 1 nodes are failing on revision 4:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ",Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4" to "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 5",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4" to "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 5"
2024-10-24T13:11:59.391248599Z E1024 13:11:59.391217       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5"
2024-10-24T13:11:59.396326899Z E1024 13:11:59.396303       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5"
2024-10-24T13:11:59.397406259Z I1024 13:11:59.397334       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-5,service-account-private-key-5
2024-10-24T13:11:59.397456099Z I1024 13:11:59.397413       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:59.398372419Z I1024 13:11:59.398335       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5\nNodeInstallerDegraded: 1 nodes are failing on revision 4:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::InstallerController_Error::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 5","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:59.400011569Z I1024 13:11:59.399961       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-5,service-account-private-key-5
2024-10-24T13:11:59.400136239Z E1024 13:11:59.400101       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5"
2024-10-24T13:11:59.419286690Z I1024 13:11:59.419174       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nNodeInstallerDegraded: 1 nodes are failing on revision 4:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: " to "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5\nNodeInstallerDegraded: 1 nodes are failing on revision 4:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: "
2024-10-24T13:11:59.422290520Z I1024 13:11:59.422230       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-5,service-account-private-key-5
2024-10-24T13:11:59.422327829Z E1024 13:11:59.422300       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5"
2024-10-24T13:11:59.464496020Z I1024 13:11:59.464407       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-5,service-account-private-key-5
2024-10-24T13:11:59.464634650Z E1024 13:11:59.464587       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5"
2024-10-24T13:11:59.546909771Z E1024 13:11:59.546574       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5"
2024-10-24T13:11:59.546979301Z I1024 13:11:59.546944       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-5,service-account-private-key-5
2024-10-24T13:11:59.709268003Z I1024 13:11:59.709145       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-5,service-account-private-key-5
2024-10-24T13:11:59.709316223Z E1024 13:11:59.709252       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5"
2024-10-24T13:12:00.032100526Z I1024 13:12:00.032030       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-5,service-account-private-key-5
2024-10-24T13:12:00.032146446Z E1024 13:12:00.032094       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5"
2024-10-24T13:12:00.208570808Z I1024 13:12:00.208522       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:00.209076378Z I1024 13:12:00.209016       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-5,service-account-private-key-5
2024-10-24T13:12:00.209210888Z E1024 13:12:00.209171       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5"
2024-10-24T13:12:00.392953470Z I1024 13:12:00.392895       1 request.go:700] Waited for 1.002984091s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/secrets?resourceVersion=16503
2024-10-24T13:12:00.396260890Z I1024 13:12:00.396216       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:00.517989201Z I1024 13:12:00.517927       1 reflector.go:368] Caches populated for *v1.Role from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:00.674306963Z I1024 13:12:00.674214       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-5,service-account-private-key-5
2024-10-24T13:12:00.674382273Z E1024 13:12:00.674295       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5"
2024-10-24T13:12:01.403274280Z I1024 13:12:01.403229       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:01.403385501Z I1024 13:12:01.403358       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-manager-pod-6 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:01.404740951Z E1024 13:12:01.404713       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5"
2024-10-24T13:12:01.404841751Z I1024 13:12:01.404819       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-5,service-account-private-key-5
2024-10-24T13:12:01.592447912Z I1024 13:12:01.592383       1 request.go:700] Waited for 1.143316882s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-10-24T13:12:02.593106093Z I1024 13:12:02.593019       1 request.go:700] Waited for 1.189893322s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps
2024-10-24T13:12:02.603947693Z I1024 13:12:02.603866       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:02.604547153Z I1024 13:12:02.604491       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-5,service-account-private-key-5
2024-10-24T13:12:02.604691303Z E1024 13:12:02.604666       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5"
2024-10-24T13:12:02.605266183Z I1024 13:12:02.605231       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-6 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:03.195820890Z I1024 13:12:03.195737       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:03.236869000Z I1024 13:12:03.236775       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-5,service-account-private-key-5
2024-10-24T13:12:03.236869000Z E1024 13:12:03.236841       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5"
2024-10-24T13:12:03.602550404Z I1024 13:12:03.602465       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:03.603224424Z I1024 13:12:03.602579       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cluster-policy-controller-config-6 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:03.603340574Z E1024 13:12:03.603300       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5"
2024-10-24T13:12:03.603355314Z I1024 13:12:03.603299       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-5,service-account-private-key-5
2024-10-24T13:12:03.719467185Z I1024 13:12:03.719401       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:04.402828122Z I1024 13:12:04.402768       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:04.403801062Z E1024 13:12:04.403702       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5"
2024-10-24T13:12:04.404193412Z I1024 13:12:04.404116       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-5,service-account-private-key-5
2024-10-24T13:12:04.404193412Z I1024 13:12:04.404148       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/controller-manager-kubeconfig-6 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:04.995520088Z I1024 13:12:04.995451       1 reflector.go:368] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:05.199850660Z I1024 13:12:05.199801       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-cert-syncer-kubeconfig-6 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:05.200095941Z I1024 13:12:05.200073       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:05.200285481Z E1024 13:12:05.200244       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5"
2024-10-24T13:12:05.200336741Z I1024 13:12:05.200315       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-5,service-account-private-key-5
2024-10-24T13:12:05.801438257Z I1024 13:12:05.801375       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-6 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:05.801860477Z I1024 13:12:05.801817       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:05.801912957Z E1024 13:12:05.801887       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5"
2024-10-24T13:12:05.802086977Z I1024 13:12:05.802032       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-5,service-account-private-key-5
2024-10-24T13:12:06.401131213Z I1024 13:12:06.401075       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/service-ca-6 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:06.401261813Z E1024 13:12:06.401223       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5"
2024-10-24T13:12:06.401453923Z I1024 13:12:06.401416       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-5,service-account-private-key-5
2024-10-24T13:12:06.401517363Z I1024 13:12:06.401495       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:07.001240006Z I1024 13:12:07.001177       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:07.001320086Z I1024 13:12:07.001283       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/recycler-config-6 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:07.001574016Z I1024 13:12:07.001549       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-5,service-account-private-key-5
2024-10-24T13:12:07.001767806Z E1024 13:12:07.001699       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5"
2024-10-24T13:12:07.602381479Z I1024 13:12:07.602295       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/service-account-private-key-6 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:08.196552332Z I1024 13:12:08.196472       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:08.403296399Z I1024 13:12:08.403209       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-6 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:09.006122502Z I1024 13:12:09.006044       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-6 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:09.600996165Z I1024 13:12:09.600925       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:09.601579505Z E1024 13:12:09.601530       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5"
2024-10-24T13:12:09.601782746Z W1024 13:12:09.601707       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:12:09.601782746Z W1024 13:12:09.601726       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:12:09.602004585Z I1024 13:12:09.601944       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-5,service-account-private-key-5
2024-10-24T13:12:09.602128876Z I1024 13:12:09.602056       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 6 triggered by "secret \"service-account-private-key-5\" not found"
2024-10-24T13:12:09.626568055Z W1024 13:12:09.626518       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:12:09.626568055Z W1024 13:12:09.626538       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:12:09.629925205Z I1024 13:12:09.629891       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:09.630522345Z I1024 13:12:09.630474       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-6,service-account-private-key-6
2024-10-24T13:12:09.648904225Z I1024 13:12:09.648841       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 7 triggered by "secret \"service-account-private-key-6\" not found"
2024-10-24T13:12:09.659405885Z E1024 13:12:09.659353       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-6,service-account-private-key-6"
2024-10-24T13:12:09.662799845Z E1024 13:12:09.662738       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-6,service-account-private-key-6"
2024-10-24T13:12:09.663187905Z I1024 13:12:09.663147       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-6,service-account-private-key-6
2024-10-24T13:12:09.663445465Z I1024 13:12:09.663420       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:09.664505375Z I1024 13:12:09.664399       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: secrets: localhost-recovery-client-token-6,service-account-private-key-6\nNodeInstallerDegraded: 1 nodes are failing on revision 4:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::InstallerController_Error::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:12:09.679718314Z I1024 13:12:09.679647       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: secrets: localhost-recovery-client-token-5,service-account-private-key-5\nNodeInstallerDegraded: 1 nodes are failing on revision 4:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: " to "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: secrets: localhost-recovery-client-token-6,service-account-private-key-6\nNodeInstallerDegraded: 1 nodes are failing on revision 4:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ",Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 5" to "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 6",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 5" to "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 6"
2024-10-24T13:12:10.603543774Z I1024 13:12:10.603493       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:10.604093284Z E1024 13:12:10.604036       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-6,service-account-private-key-6"
2024-10-24T13:12:10.604429114Z I1024 13:12:10.604392       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-6,service-account-private-key-6
2024-10-24T13:12:11.603348622Z I1024 13:12:11.603297       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:11.604026982Z I1024 13:12:11.603965       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-6,service-account-private-key-6
2024-10-24T13:12:11.604131272Z E1024 13:12:11.604017       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-6,service-account-private-key-6"
2024-10-24T13:12:11.604639802Z I1024 13:12:11.604611       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-manager-pod-7 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:12.401786303Z I1024 13:12:12.401698       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-7 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:12.401946663Z I1024 13:12:12.401902       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:12.402419053Z I1024 13:12:12.402390       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-6,service-account-private-key-6
2024-10-24T13:12:12.402503393Z E1024 13:12:12.402468       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-6,service-account-private-key-6"
2024-10-24T13:12:13.204475314Z I1024 13:12:13.204407       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cluster-policy-controller-config-7 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:13.208041624Z I1024 13:12:13.207990       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:13.213275294Z E1024 13:12:13.213223       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-6,service-account-private-key-6"
2024-10-24T13:12:13.216186744Z I1024 13:12:13.213553       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-6,service-account-private-key-6
2024-10-24T13:12:14.200903922Z I1024 13:12:14.200836       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:14.201297732Z E1024 13:12:14.201243       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-6,service-account-private-key-6"
2024-10-24T13:12:14.201297732Z I1024 13:12:14.201240       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-6,service-account-private-key-6
2024-10-24T13:12:14.202263162Z I1024 13:12:14.202087       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/controller-manager-kubeconfig-7 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:14.999086793Z E1024 13:12:14.999018       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:12:15.201477090Z I1024 13:12:15.201434       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:15.201569450Z I1024 13:12:15.201541       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-cert-syncer-kubeconfig-7 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:15.201891820Z I1024 13:12:15.201821       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-6,service-account-private-key-6
2024-10-24T13:12:15.202019621Z E1024 13:12:15.201994       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-6,service-account-private-key-6"
2024-10-24T13:12:16.003824611Z I1024 13:12:16.003716       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-7 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:16.004442171Z I1024 13:12:16.004416       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:16.004833111Z I1024 13:12:16.004804       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-6,service-account-private-key-6
2024-10-24T13:12:16.005168811Z E1024 13:12:16.005037       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-6,service-account-private-key-6"
2024-10-24T13:12:16.600190915Z E1024 13:12:16.600120       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:12:16.801303142Z I1024 13:12:16.801251       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:16.801539322Z I1024 13:12:16.801498       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/service-ca-7 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:16.801735012Z E1024 13:12:16.801706       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-6,service-account-private-key-6"
2024-10-24T13:12:16.801846262Z I1024 13:12:16.801822       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-6,service-account-private-key-6
2024-10-24T13:12:16.978961340Z I1024 13:12:16.978904       1 reflector.go:368] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:17.602486963Z I1024 13:12:17.602437       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:17.602959133Z I1024 13:12:17.602906       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-6,service-account-private-key-6
2024-10-24T13:12:17.602991043Z E1024 13:12:17.602953       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-6,service-account-private-key-6"
2024-10-24T13:12:17.604401793Z I1024 13:12:17.604319       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/recycler-config-7 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:18.201225946Z E1024 13:12:18.201153       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:12:18.401450084Z I1024 13:12:18.401369       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/service-account-private-key-7 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:19.209527555Z I1024 13:12:19.209465       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:19.405018762Z I1024 13:12:19.404941       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-7 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:20.004799645Z E1024 13:12:20.002742       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:12:20.206454983Z I1024 13:12:20.206403       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-7 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:20.600711869Z I1024 13:12:20.600662       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:21.002023154Z I1024 13:12:21.001966       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:21.002684954Z I1024 13:12:21.002653       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-6,service-account-private-key-6
2024-10-24T13:12:21.003334014Z E1024 13:12:21.003309       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-6,service-account-private-key-6"
2024-10-24T13:12:21.004140714Z I1024 13:12:21.004035       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 7 triggered by "secret \"service-account-private-key-6\" not found"
2024-10-24T13:12:21.004888424Z W1024 13:12:21.004843       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:12:21.004888424Z W1024 13:12:21.004862       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:12:21.027115054Z W1024 13:12:21.027076       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:12:21.027115054Z W1024 13:12:21.027093       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:12:21.032795214Z I1024 13:12:21.032766       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:21.033622744Z I1024 13:12:21.033581       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-7,service-account-private-key-7
2024-10-24T13:12:21.053839993Z I1024 13:12:21.053787       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 8 triggered by "secret \"service-account-private-key-7\" not found"
2024-10-24T13:12:21.065952123Z E1024 13:12:21.065912       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-7,service-account-private-key-7"
2024-10-24T13:12:21.068534793Z I1024 13:12:21.068498       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:21.068900383Z E1024 13:12:21.068876       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-7,service-account-private-key-7"
2024-10-24T13:12:21.069909343Z I1024 13:12:21.069879       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-7,service-account-private-key-7
2024-10-24T13:12:21.070139993Z I1024 13:12:21.070058       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: secrets: localhost-recovery-client-token-7,service-account-private-key-7\nNodeInstallerDegraded: 1 nodes are failing on revision 4:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::InstallerController_Error::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:12:21.090004623Z I1024 13:12:21.089951       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: secrets: localhost-recovery-client-token-6,service-account-private-key-6\nNodeInstallerDegraded: 1 nodes are failing on revision 4:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: " to "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: secrets: localhost-recovery-client-token-7,service-account-private-key-7\nNodeInstallerDegraded: 1 nodes are failing on revision 4:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ",Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 6" to "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 7",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 6" to "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 7"
2024-10-24T13:12:21.196886692Z I1024 13:12:21.196844       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:21.197496192Z I1024 13:12:21.197466       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: service-account-private-key-7
2024-10-24T13:12:21.217231242Z E1024 13:12:21.217189       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: service-account-private-key-7"
2024-10-24T13:12:21.220741661Z I1024 13:12:21.220701       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: secrets: service-account-private-key-7\nNodeInstallerDegraded: 1 nodes are failing on revision 4:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::InstallerController_Error::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:12:21.220902442Z I1024 13:12:21.220871       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:21.238535381Z I1024 13:12:21.238466       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: secrets: localhost-recovery-client-token-7,service-account-private-key-7\nNodeInstallerDegraded: 1 nodes are failing on revision 4:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: " to "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: secrets: service-account-private-key-7\nNodeInstallerDegraded: 1 nodes are failing on revision 4:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: "
2024-10-24T13:12:22.192779120Z I1024 13:12:22.192685       1 request.go:700] Waited for 1.138926167s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps
2024-10-24T13:12:22.200285650Z I1024 13:12:22.200212       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:23.193025938Z I1024 13:12:23.192960       1 request.go:700] Waited for 1.184848195s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-10-24T13:12:23.395505966Z I1024 13:12:23.395359       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:23.604765914Z I1024 13:12:23.604690       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:23.605866054Z I1024 13:12:23.605823       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-manager-pod-8 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:23.797551971Z I1024 13:12:23.797477       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:12:23.797551971Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:12:23.797551971Z  CurrentRevision: (int32) 0,
2024-10-24T13:12:23.797551971Z  TargetRevision: (int32) 7,
2024-10-24T13:12:23.797551971Z  LastFailedRevision: (int32) 4,
2024-10-24T13:12:23.797551971Z  LastFailedTime: (*v1.Time)(0xc001e43c98)(2024-10-24 13:11:52 +0000 UTC),
2024-10-24T13:12:23.797551971Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:12:23.797551971Z  LastFailedCount: (int) 1,
2024-10-24T13:12:23.797551971Z  LastFallbackCount: (int) 0,
2024-10-24T13:12:23.797551971Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:12:23.797551971Z   (string) (len=2059) "installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:12:23.797551971Z  }
2024-10-24T13:12:23.797551971Z }
2024-10-24T13:12:23.797551971Z  because new revision pending
2024-10-24T13:12:23.819934321Z I1024 13:12:23.819885       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:23.820975851Z I1024 13:12:23.820921       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: secrets: service-account-private-key-7","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:12:23.835263011Z I1024 13:12:23.835218       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: secrets: service-account-private-key-7\nNodeInstallerDegraded: 1 nodes are failing on revision 4:\nNodeInstallerDegraded: installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: " to "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: secrets: service-account-private-key-7"
2024-10-24T13:12:23.872902581Z I1024 13:12:23.872834       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:23.874953910Z I1024 13:12:23.874900       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:12:23.889623860Z I1024 13:12:23.889524       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: secrets: service-account-private-key-7" to "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:12:24.392344425Z I1024 13:12:24.392266       1 request.go:700] Waited for 1.390218894s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:12:24.601931602Z I1024 13:12:24.601807       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:24.602535103Z I1024 13:12:24.602447       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-8 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:12:25.392780163Z I1024 13:12:25.392710       1 request.go:700] Waited for 1.200735507s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:12:25.993119337Z I1024 13:12:25.993050       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMapCreateFailed' Failed to create ConfigMap/cluster-policy-controller-config-8 -n openshift-kube-controller-manager: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:25.993873847Z E1024 13:12:25.993820       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.180165b1c010bba8  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/cluster-policy-controller-config-8 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:12:25.992919976 +0000 UTC m=+446.314227304,LastTimestamp:2024-10-24 13:12:25.992919976 +0000 UTC m=+446.314227304,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:12:25.995303666Z E1024 13:12:25.995278       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:25.995336077Z I1024 13:12:25.995303       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 8: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:26.000596576Z I1024 13:12:26.000555       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 8 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:12:26.198500464Z E1024 13:12:26.198449       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:26.392939462Z I1024 13:12:26.392864       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'PodCreateFailed' Failed to create Pod/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-controller-manager: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:26.392939462Z I1024 13:12:26.392906       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:26.393508492Z E1024 13:12:26.393477       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.180165b1d7e452b8  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:PodCreateFailed,Message:Failed to create Pod/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:12:26.392662712 +0000 UTC m=+446.713970039,LastTimestamp:2024-10-24 13:12:26.392662712 +0000 UTC m=+446.713970039,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:12:26.393947962Z E1024 13:12:26.393911       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:26.592979050Z I1024 13:12:26.592918       1 request.go:700] Waited for 1.393796095s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa
2024-10-24T13:12:26.793521018Z E1024 13:12:26.793440       1 guard_controller.go:366] Unable to apply pod kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0 changes: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:27.395156331Z E1024 13:12:27.395103       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:27.395156331Z I1024 13:12:27.395137       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 8: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:27.397732630Z I1024 13:12:27.397690       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 8 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:12:27.593060668Z I1024 13:12:27.592962       1 request.go:700] Waited for 1.387774724s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-10-24T13:12:27.597090338Z E1024 13:12:27.597043       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:27.796898356Z I1024 13:12:27.796475       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:27.798685066Z E1024 13:12:27.798657       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:28.192986422Z E1024 13:12:28.192921       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:12:28.195209651Z W1024 13:12:28.195145       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:28.195265742Z E1024 13:12:28.195211       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2, Unable to apply pod kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0 changes: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:28.216583411Z E1024 13:12:28.216527       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.180165b1c010bba8  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/cluster-policy-controller-config-8 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:12:25.992919976 +0000 UTC m=+446.314227304,LastTimestamp:2024-10-24 13:12:25.992919976 +0000 UTC m=+446.314227304,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:12:28.394888179Z E1024 13:12:28.394828       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:28.396544529Z E1024 13:12:28.396516       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:28.402491209Z E1024 13:12:28.402439       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:28.424675109Z E1024 13:12:28.424634       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:28.466826019Z E1024 13:12:28.466782       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:28.548789957Z E1024 13:12:28.548735       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:28.594397237Z E1024 13:12:28.594365       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:28.710995096Z E1024 13:12:28.710928       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:28.793051735Z I1024 13:12:28.792989       1 request.go:700] Waited for 1.395271424s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps
2024-10-24T13:12:28.795596874Z E1024 13:12:28.795553       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:28.795633674Z I1024 13:12:28.795592       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 8: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:28.798309654Z I1024 13:12:28.798275       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 8 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:12:28.996426532Z E1024 13:12:28.996327       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:29.033539092Z E1024 13:12:29.033494       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:29.193786160Z I1024 13:12:29.193695       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:29.194931910Z E1024 13:12:29.194874       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:29.676590935Z E1024 13:12:29.676523       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:29.795540603Z E1024 13:12:29.795467       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:29.795540603Z I1024 13:12:29.795502       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 8: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:29.797927163Z I1024 13:12:29.797878       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 8 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:12:29.996522601Z E1024 13:12:29.996470       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:30.193253128Z I1024 13:12:30.193186       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:30.194306999Z E1024 13:12:30.194254       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:30.397272376Z E1024 13:12:30.397232       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.180165b1d7e452b8  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:PodCreateFailed,Message:Failed to create Pod/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:12:26.392662712 +0000 UTC m=+446.713970039,LastTimestamp:2024-10-24 13:12:26.392662712 +0000 UTC m=+446.713970039,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:12:30.399011516Z E1024 13:12:30.398973       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:30.795127032Z E1024 13:12:30.795085       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:30.795177892Z I1024 13:12:30.795122       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 8: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:30.797797842Z I1024 13:12:30.797730       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 8 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:12:30.959137170Z E1024 13:12:30.959080       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:30.995546389Z E1024 13:12:30.995472       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:31.192857777Z I1024 13:12:31.192791       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:31.194301407Z E1024 13:12:31.194265       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:31.594022773Z E1024 13:12:31.593969       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:31.794929240Z E1024 13:12:31.794865       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:31.794929240Z I1024 13:12:31.794907       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 8: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:31.797215240Z I1024 13:12:31.797179       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 8 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:12:31.995682648Z E1024 13:12:31.995633       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:32.193391436Z I1024 13:12:32.193312       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:32.194484245Z E1024 13:12:32.194445       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:32.794682288Z E1024 13:12:32.794625       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:32.794682288Z I1024 13:12:32.794655       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 8: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:32.797062888Z I1024 13:12:32.797023       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 8 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:12:32.996374006Z E1024 13:12:32.996331       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:33.194061844Z I1024 13:12:33.193979       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:33.195282004Z E1024 13:12:33.195217       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:33.521951540Z E1024 13:12:33.521901       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:33.795013127Z E1024 13:12:33.794949       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:33.795013127Z I1024 13:12:33.794991       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 8: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:33.797586487Z I1024 13:12:33.797541       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 8 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:12:33.993011024Z I1024 13:12:33.992922       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:33.994317754Z E1024 13:12:33.994261       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:34.196210052Z E1024 13:12:34.196153       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:34.594990507Z E1024 13:12:34.594911       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:34.795548275Z E1024 13:12:34.795485       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:34.795548275Z I1024 13:12:34.795526       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 8: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:34.993610663Z I1024 13:12:34.993546       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:34.994884433Z E1024 13:12:34.994818       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:35.077974762Z I1024 13:12:35.077906       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 8 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:12:35.599364146Z E1024 13:12:35.599291       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:35.793288343Z I1024 13:12:35.793218       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:35.794610693Z E1024 13:12:35.794544       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:35.994660781Z E1024 13:12:35.994596       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:35.994660781Z I1024 13:12:35.994629       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 8: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:36.392772226Z I1024 13:12:36.392697       1 request.go:700] Waited for 1.000060628s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:12:36.598207634Z E1024 13:12:36.598130       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:36.793508942Z I1024 13:12:36.793438       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:36.794513322Z E1024 13:12:36.794477       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:36.994822709Z E1024 13:12:36.994768       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:37.395929365Z E1024 13:12:37.395879       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:38.217726235Z E1024 13:12:38.217666       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.180165b1c010bba8  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/cluster-policy-controller-config-8 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:12:25.992919976 +0000 UTC m=+446.314227304,LastTimestamp:2024-10-24 13:12:25.992919976 +0000 UTC m=+446.314227304,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:12:38.398010563Z E1024 13:12:38.397948       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:38.645282810Z E1024 13:12:38.645217       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:39.594468929Z E1024 13:12:39.594409       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:39.798529387Z E1024 13:12:39.798435       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:40.403859210Z E1024 13:12:40.403801       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.180165b1d7e452b8  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:PodCreateFailed,Message:Failed to create Pod/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:12:26.392662712 +0000 UTC m=+446.713970039,LastTimestamp:2024-10-24 13:12:26.392662712 +0000 UTC m=+446.713970039,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:12:40.595569838Z E1024 13:12:40.595502       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:40.795075255Z E1024 13:12:40.795011       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:41.117580541Z I1024 13:12:41.117494       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 8 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:12:41.595063786Z E1024 13:12:41.595000       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:41.595063786Z I1024 13:12:41.595039       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 8: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:42.393492557Z I1024 13:12:42.393433       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:42.394938157Z E1024 13:12:42.394887       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:42.594787705Z E1024 13:12:42.594708       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:42.998953110Z E1024 13:12:42.998901       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:43.795181651Z E1024 13:12:43.795121       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:45.396582192Z E1024 13:12:45.396496       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:45.594836220Z E1024 13:12:45.594780       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:46.396763211Z E1024 13:12:46.396686       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:48.159653670Z E1024 13:12:48.159599       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:48.218976649Z E1024 13:12:48.218909       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.180165b1c010bba8  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/cluster-policy-controller-config-8 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:12:25.992919976 +0000 UTC m=+446.314227304,LastTimestamp:2024-10-24 13:12:25.992919976 +0000 UTC m=+446.314227304,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:12:48.479581917Z E1024 13:12:48.479511       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:12:48.480106197Z E1024 13:12:48.480063       1 leaderelection.go:436] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:48.796608073Z E1024 13:12:48.796541       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:48.888281912Z E1024 13:12:48.888208       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:50.404767915Z E1024 13:12:50.404689       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.180165b1d7e452b8  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:PodCreateFailed,Message:Failed to create Pod/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:12:26.392662712 +0000 UTC m=+446.713970039,LastTimestamp:2024-10-24 13:12:26.392662712 +0000 UTC m=+446.713970039,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:12:51.838362978Z I1024 13:12:51.838295       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 8 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:12:51.840931548Z E1024 13:12:51.840875       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:51.840931548Z I1024 13:12:51.840914       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 8: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:51.996482306Z E1024 13:12:51.996411       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:52.638327799Z I1024 13:12:52.638260       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:52.639463609Z E1024 13:12:52.639423       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:53.285889581Z E1024 13:12:53.285830       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:55.196612440Z E1024 13:12:55.196551       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:56.997545999Z E1024 13:12:56.997491       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:58.221206575Z E1024 13:12:58.221142       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.180165b1c010bba8  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/cluster-policy-controller-config-8 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:12:25.992919976 +0000 UTC m=+446.314227304,LastTimestamp:2024-10-24 13:12:25.992919976 +0000 UTC m=+446.314227304,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:12:58.596330020Z E1024 13:12:58.596265       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:00.406540110Z E1024 13:13:00.406490       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.180165b1d7e452b8  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:PodCreateFailed,Message:Failed to create Pod/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:12:26.392662712 +0000 UTC m=+446.713970039,LastTimestamp:2024-10-24 13:12:26.392662712 +0000 UTC m=+446.713970039,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:13:00.450984499Z E1024 13:13:00.450945       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:00.451670449Z I1024 13:13:00.451637       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 8 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:13:00.456216179Z E1024 13:13:00.456176       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:00.456989499Z E1024 13:13:00.456968       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:00.457059399Z I1024 13:13:00.457036       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 8: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:00.594773007Z E1024 13:13:00.594712       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:00.796499155Z E1024 13:13:00.796444       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:00.994745053Z E1024 13:13:00.994693       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:01.195143581Z E1024 13:13:01.195073       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:01.594901686Z E1024 13:13:01.594837       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:01.794832234Z E1024 13:13:01.794782       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:01.995153932Z E1024 13:13:01.995097       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:01.996459192Z E1024 13:13:01.996395       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:02.395395637Z E1024 13:13:02.395342       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:02.555136375Z E1024 13:13:02.555095       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:02.595125305Z I1024 13:13:02.595052       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:02.595965945Z E1024 13:13:02.595903       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.180165ba45b693b9  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:SecretUpdateFailed,Message:Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-satokensignercontroller,Host:,},FirstTimestamp:2024-10-24 13:13:02.594896825 +0000 UTC m=+482.916204152,LastTimestamp:2024-10-24 13:13:02.594896825 +0000 UTC m=+482.916204152,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-satokensignercontroller,ReportingInstance:,}"
2024-10-24T13:13:02.596302375Z E1024 13:13:02.596260       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:02.794955363Z I1024 13:13:02.794890       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:02.796014203Z E1024 13:13:02.795980       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:02.995408070Z I1024 13:13:02.995354       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:02.996471830Z E1024 13:13:02.996431       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:03.195464498Z I1024 13:13:03.195390       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:03.196785388Z E1024 13:13:03.196703       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:03.395074016Z E1024 13:13:03.395027       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:03.595140693Z I1024 13:13:03.595083       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:03.596233363Z E1024 13:13:03.596164       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:03.995640359Z I1024 13:13:03.995556       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:03.996952999Z E1024 13:13:03.996871       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:04.595617652Z I1024 13:13:04.595553       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:04.596572862Z E1024 13:13:04.596534       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:04.996723727Z E1024 13:13:04.996668       1 base_controller.go:271] "Unhandled Error" err="StaticPodStateController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:05.195799454Z E1024 13:13:05.195736       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:05.595683140Z I1024 13:13:05.595625       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:05.596978600Z E1024 13:13:05.596937       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:06.200511373Z E1024 13:13:06.200442       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:06.595883679Z I1024 13:13:06.595807       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:06.597379869Z E1024 13:13:06.597308       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:07.995726833Z E1024 13:13:07.995679       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:08.195925280Z I1024 13:13:08.195818       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:08.197135290Z E1024 13:13:08.197053       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:08.222734920Z E1024 13:13:08.222670       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.180165b1c010bba8  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/cluster-policy-controller-config-8 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:12:25.992919976 +0000 UTC m=+446.314227304,LastTimestamp:2024-10-24 13:12:25.992919976 +0000 UTC m=+446.314227304,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:13:08.399427168Z E1024 13:13:08.399363       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:09.370628077Z E1024 13:13:09.370533       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Get \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:10.408622435Z E1024 13:13:10.408557       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.180165b1d7e452b8  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:PodCreateFailed,Message:Failed to create Pod/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:12:26.392662712 +0000 UTC m=+446.713970039,LastTimestamp:2024-10-24 13:12:26.392662712 +0000 UTC m=+446.713970039,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:13:10.760638421Z I1024 13:13:10.760575       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:10.761805941Z E1024 13:13:10.761742       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:10.941867279Z E1024 13:13:10.941819       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.180165ba45b693b9  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:SecretUpdateFailed,Message:Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-satokensignercontroller,Host:,},FirstTimestamp:2024-10-24 13:13:02.594896825 +0000 UTC m=+482.916204152,LastTimestamp:2024-10-24 13:13:02.594896825 +0000 UTC m=+482.916204152,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-satokensignercontroller,ReportingInstance:,}"
2024-10-24T13:13:12.325030141Z I1024 13:13:12.324957       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 8 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:13:12.328034811Z E1024 13:13:12.327985       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=kube-controller-manager-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:12.328069091Z I1024 13:13:12.328029       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 8: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:12.530059255Z E1024 13:13:12.530005       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: [\"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/namespace-openshift-infra.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/recycler-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-client-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/localhost-recovery-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrole.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml\" (string): Delete \"https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-role.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, \"assets/kube-controller-manager/gce/cloud-provider-binding.yaml\" (string): Delete \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"KubeControllerManagerStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=KubeControllerManagerStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:13.118620939Z E1024 13:13:13.118552       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:13.122587948Z I1024 13:13:13.122515       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:13.123954409Z E1024 13:13:13.123916       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:14.481194602Z E1024 13:13:14.481103       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:13:14.482015112Z E1024 13:13:14.481958       1 leaderelection.go:436] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:15.885057702Z I1024 13:13:15.884994       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:15.886294702Z E1024 13:13:15.886264       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:17.483223697Z E1024 13:13:17.483175       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:18.224266169Z E1024 13:13:18.224202       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.180165b1c010bba8  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/cluster-policy-controller-config-8 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:12:25.992919976 +0000 UTC m=+446.314227304,LastTimestamp:2024-10-24 13:12:25.992919976 +0000 UTC m=+446.314227304,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:13:20.409805367Z E1024 13:13:20.409656       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.180165b1d7e452b8  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:PodCreateFailed,Message:Failed to create Pod/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-controller-manager: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:12:26.392662712 +0000 UTC m=+446.713970039,LastTimestamp:2024-10-24 13:12:26.392662712 +0000 UTC m=+446.713970039,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:13:20.943094866Z E1024 13:13:20.943039       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.180165ba45b693b9  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:SecretUpdateFailed,Message:Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-satokensignercontroller,Host:,},FirstTimestamp:2024-10-24 13:13:02.594896825 +0000 UTC m=+482.916204152,LastTimestamp:2024-10-24 13:13:02.594896825 +0000 UTC m=+482.916204152,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-satokensignercontroller,ReportingInstance:,}"
2024-10-24T13:13:26.142158199Z I1024 13:13:26.142083       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretUpdated' Updated Secret/service-account-private-key -n openshift-kube-controller-manager because it changed
2024-10-24T13:13:54.112621367Z I1024 13:13:54.112557       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:13:54.120313887Z I1024 13:13:54.120271       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:13:56.674788536Z I1024 13:13:56.674713       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:00.453089150Z I1024 13:14:00.453031       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 8 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:14:00.471460419Z I1024 13:14:00.471396       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cluster-policy-controller-config-8 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:14:00.479478888Z I1024 13:14:00.479419       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/controller-manager-kubeconfig-8 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:14:00.489134557Z I1024 13:14:00.489029       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-cert-syncer-kubeconfig-8 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:14:00.500883446Z I1024 13:14:00.500799       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-8 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:14:00.660335684Z I1024 13:14:00.660257       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/service-ca-8 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:14:00.860723368Z I1024 13:14:00.860649       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/recycler-config-8 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:14:01.060862962Z I1024 13:14:01.060788       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/service-account-private-key-8 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:14:01.261953716Z I1024 13:14:01.261647       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-8 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:14:01.462045861Z I1024 13:14:01.461954       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-8 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:14:01.661337395Z I1024 13:14:01.661261       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 8 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:14:01.662575205Z W1024 13:14:01.662524       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:14:01.662575205Z W1024 13:14:01.662552       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:14:02.054550544Z I1024 13:14:02.054277       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:02.858337751Z I1024 13:14:02.858252       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-10-24T13:14:02.888921669Z I1024 13:14:02.888859       1 helpers.go:184] lister was stale at resourceVersion=18493, live get showed resourceVersion=18901
2024-10-24T13:14:02.908922408Z E1024 13:14:02.908864       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:14:03.457905854Z I1024 13:14:03.457823       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-10-24T13:14:03.494944771Z I1024 13:14:03.494891       1 helpers.go:184] lister was stale at resourceVersion=18493, live get showed resourceVersion=18908
2024-10-24T13:14:03.495024801Z E1024 13:14:03.495002       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:14:04.057834977Z I1024 13:14:04.057709       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-10-24T13:14:04.093696394Z I1024 13:14:04.093651       1 helpers.go:184] lister was stale at resourceVersion=18493, live get showed resourceVersion=18908
2024-10-24T13:14:04.093804805Z E1024 13:14:04.093783       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:14:04.658089940Z I1024 13:14:04.658003       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-10-24T13:14:04.694011848Z I1024 13:14:04.693927       1 helpers.go:184] lister was stale at resourceVersion=18493, live get showed resourceVersion=18908
2024-10-24T13:14:04.694074288Z E1024 13:14:04.694044       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:14:05.261687433Z I1024 13:14:05.261612       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-10-24T13:14:05.294729850Z I1024 13:14:05.294686       1 helpers.go:184] lister was stale at resourceVersion=18493, live get showed resourceVersion=18908
2024-10-24T13:14:05.294818320Z E1024 13:14:05.294782       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:14:05.657335632Z I1024 13:14:05.657241       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-10-24T13:14:05.695826639Z I1024 13:14:05.695772       1 helpers.go:184] lister was stale at resourceVersion=18493, live get showed resourceVersion=18908
2024-10-24T13:14:05.695929499Z E1024 13:14:05.695899       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:14:06.067717180Z I1024 13:14:06.067247       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-10-24T13:14:06.123916335Z I1024 13:14:06.123874       1 helpers.go:184] lister was stale at resourceVersion=18493, live get showed resourceVersion=18908
2024-10-24T13:14:06.124134605Z E1024 13:14:06.124104       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:14:06.659080804Z I1024 13:14:06.659008       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-10-24T13:14:06.697100180Z I1024 13:14:06.697054       1 helpers.go:184] lister was stale at resourceVersion=18493, live get showed resourceVersion=18908
2024-10-24T13:14:06.697212770Z E1024 13:14:06.697189       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:14:07.657840025Z I1024 13:14:07.657779       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-10-24T13:14:07.692730472Z I1024 13:14:07.692679       1 helpers.go:184] lister was stale at resourceVersion=18493, live get showed resourceVersion=18908
2024-10-24T13:14:07.692875392Z E1024 13:14:07.692853       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:14:08.455553663Z I1024 13:14:08.455497       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:11.146643571Z I1024 13:14:11.146582       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:14.528821776Z I1024 13:14:14.528772       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:14.529151556Z I1024 13:14:14.529086       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:14:14.529470196Z I1024 13:14:14.529395       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:14:14.529909196Z I1024 13:14:14.529887       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:14:14.530110186Z I1024 13:14:14.530095       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:14:14.530307496Z I1024 13:14:14.530290       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:14:14.530531896Z I1024 13:14:14.530500       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:14:14.530691496Z I1024 13:14:14.530666       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:14:14.530893926Z I1024 13:14:14.530840       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:14:14.531037436Z I1024 13:14:14.530998       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:14:14.531190926Z I1024 13:14:14.531132       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 8 triggered by "required secret/localhost-recovery-client-token has changed"
2024-10-24T13:14:15.655511008Z I1024 13:14:15.655452       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:17.121928931Z I1024 13:14:17.121868       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:18.942492831Z I1024 13:14:18.942432       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:20.546193144Z I1024 13:14:20.546118       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:21.112118923Z I1024 13:14:21.112053       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: rpc error: code = Unknown desc = malformed header: missing HTTP content-type
2024-10-24T13:14:23.836768744Z I1024 13:14:23.836684       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:26.211677654Z I1024 13:14:26.211612       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:26.490597109Z I1024 13:14:26.490544       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:28.381725705Z I1024 13:14:28.381663       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:30.646963292Z I1024 13:14:30.646911       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:30.848377371Z I1024 13:14:30.848266       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:32.902650798Z I1024 13:14:32.902571       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:34.799501665Z I1024 13:14:34.799444       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:35.257109450Z I1024 13:14:35.257046       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:36.145910841Z I1024 13:14:36.145858       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:38.553807150Z I1024 13:14:38.553763       1 reflector.go:368] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:39.331824687Z I1024 13:14:39.331783       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:39.518963177Z E1024 13:14:39.518890       1 leaderelection.go:429] Failed to update lock optimitically: rpc error: code = DeadlineExceeded desc = context deadline exceeded, falling back to slow path
2024-10-24T13:14:39.563491604Z I1024 13:14:39.563435       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:39.671625968Z I1024 13:14:39.671555       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:42.199231640Z E1024 13:14:42.199186       1 event.go:359] "Server rejected event (will not retry!)" err="rpc error: code = DeadlineExceeded desc = context deadline exceeded" event="&Event{ObjectMeta:{kube-controller-manager-operator.180165cc8db0e007  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:SecretUpdateFailed,Message:Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: rpc error: code = Unknown desc = malformed header: missing HTTP content-type,Source:EventSource{Component:kube-controller-manager-operator-satokensignercontroller,Host:,},FirstTimestamp:2024-10-24 13:14:21.111894023 +0000 UTC m=+561.433201340,LastTimestamp:2024-10-24 13:14:21.111894023 +0000 UTC m=+561.433201340,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-satokensignercontroller,ReportingInstance:,}"
2024-10-24T13:14:48.540135814Z E1024 13:14:48.540077       1 event.go:359] "Server rejected event (will not retry!)" err="Timeout: request did not complete within requested timeout - context deadline exceeded" event="&Event{ObjectMeta:{kube-controller-manager-operator.180165b1c083d430  openshift-kube-controller-manager-operator   18877 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:StartingNewRevision,Message:new revision 8 triggered by \"required secret/localhost-recovery-client-token has changed\",Source:EventSource{Component:kube-controller-manager-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:12:26 +0000 UTC,LastTimestamp:2024-10-24 13:14:14.530857706 +0000 UTC m=+554.852165043,Count:15,Type:Normal,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:14:51.963327697Z I1024 13:14:51.963281       1 reflector.go:368] Caches populated for *v1.Proxy from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:52.005787764Z I1024 13:14:52.005691       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:55.122188714Z E1024 13:14:55.122095       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Timeout: request did not complete within requested timeout - context deadline exceeded"
2024-10-24T13:14:55.570389289Z E1024 13:14:55.570313       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Timeout: request did not complete within requested timeout - context deadline exceeded"
2024-10-24T13:14:55.570432529Z I1024 13:14:55.570408       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 8: rpc error: code = DeadlineExceeded desc = context deadline exceeded
2024-10-24T13:14:55.573278199Z W1024 13:14:55.573223       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:14:55.573278199Z W1024 13:14:55.573247       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:15:06.845916093Z I1024 13:15:06.845860       1 reflector.go:368] Caches populated for *v1.Role from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:11.150898078Z E1024 13:15:11.150816       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: the server was unable to return a response in the time allotted, but may still be processing the request (get pods)"
2024-10-24T13:15:11.154331188Z I1024 13:15:11.154150       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": the server was unable to return a response in the time allotted, but may still be processing the request (get pods installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2)
2024-10-24T13:15:18.163695605Z I1024 13:15:18.163617       1 trace.go:236] Trace[1287459697]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:14:56.685) (total time: 21473ms):
2024-10-24T13:15:18.163695605Z Trace[1287459697]: ---"Objects listed" error:<nil> 21473ms (13:15:18.159)
2024-10-24T13:15:18.163695605Z Trace[1287459697]: [21.473688846s] [21.473688846s] END
2024-10-24T13:15:18.163695605Z I1024 13:15:18.163667       1 reflector.go:368] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:18.265791189Z I1024 13:15:18.265733       1 trace.go:236] Trace[281342060]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:14:42.648) (total time: 35616ms):
2024-10-24T13:15:18.265791189Z Trace[281342060]: ---"Objects listed" error:<nil> 35616ms (13:15:18.265)
2024-10-24T13:15:18.265791189Z Trace[281342060]: [35.616862083s] [35.616862083s] END
2024-10-24T13:15:18.266488249Z I1024 13:15:18.265895       1 reflector.go:368] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:18.267278899Z I1024 13:15:18.266724       1 trace.go:236] Trace[779384007]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:14:49.262) (total time: 29004ms):
2024-10-24T13:15:18.267278899Z Trace[779384007]: ---"Objects listed" error:<nil> 29004ms (13:15:18.266)
2024-10-24T13:15:18.267278899Z Trace[779384007]: [29.004295524s] [29.004295524s] END
2024-10-24T13:15:18.267278899Z I1024 13:15:18.266742       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=kubecontrollermanagers from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:18.267860259Z I1024 13:15:18.267828       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:18.271890109Z I1024 13:15:18.268393       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again","reason":"GuardController_SyncError::SATokenSigner_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:18.357823564Z I1024 13:15:18.357672       1 trace.go:236] Trace[756195782]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:14:46.271) (total time: 32085ms):
2024-10-24T13:15:18.357823564Z Trace[756195782]: ---"Objects listed" error:<nil> 32085ms (13:15:18.357)
2024-10-24T13:15:18.357823564Z Trace[756195782]: [32.085977586s] [32.085977586s] END
2024-10-24T13:15:18.357823564Z I1024 13:15:18.357697       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:18.406568192Z I1024 13:15:18.406468       1 trace.go:236] Trace[2045399222]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:14:49.900) (total time: 28506ms):
2024-10-24T13:15:18.406568192Z Trace[2045399222]: ---"Objects listed" error:<nil> 28506ms (13:15:18.406)
2024-10-24T13:15:18.406568192Z Trace[2045399222]: [28.506248533s] [28.506248533s] END
2024-10-24T13:15:18.406568192Z I1024 13:15:18.406493       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:18.433022130Z I1024 13:15:18.431182       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2" to "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:18.521378615Z I1024 13:15:18.520918       1 trace.go:236] Trace[1977458093]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:14:55.940) (total time: 22580ms):
2024-10-24T13:15:18.521378615Z Trace[1977458093]: ---"Objects listed" error:<nil> 22578ms (13:15:18.519)
2024-10-24T13:15:18.521378615Z Trace[1977458093]: [22.580241436s] [22.580241436s] END
2024-10-24T13:15:18.521475215Z I1024 13:15:18.521454       1 reflector.go:368] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:18.538409364Z I1024 13:15:18.538369       1 trace.go:236] Trace[630021468]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:14:54.377) (total time: 24160ms):
2024-10-24T13:15:18.538409364Z Trace[630021468]: ---"Objects listed" error:<nil> 24160ms (13:15:18.538)
2024-10-24T13:15:18.538409364Z Trace[630021468]: [24.160408069s] [24.160408069s] END
2024-10-24T13:15:18.539256104Z I1024 13:15:18.539234       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:18.841801228Z E1024 13:15:18.840889       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:18.841801228Z I1024 13:15:18.841433       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-10-24T13:15:18.898808084Z E1024 13:15:18.898279       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:18.957401161Z I1024 13:15:18.956962       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: the server was unable to return a response in the time allotted, but may still be processing the request (get pods installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2)\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again","reason":"GuardController_SyncError::InstallerController_Error::SATokenSigner_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:18.964485211Z I1024 13:15:18.961955       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:18.967562161Z E1024 13:15:18.967513       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: the server was unable to return a response in the time allotted, but may still be processing the request (get pods installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2)"
2024-10-24T13:15:18.974057910Z E1024 13:15:18.973950       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:18.974334000Z I1024 13:15:18.974220       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-10-24T13:15:18.974334000Z I1024 13:15:18.974249       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-8,service-account-private-key-8
2024-10-24T13:15:19.042995027Z E1024 13:15:19.041470       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:19.043566337Z I1024 13:15:19.043536       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: the server was unable to return a response in the time allotted, but may still be processing the request (get pods installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2)\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again","reason":"GuardController_SyncError::InstallerController_Error::SATokenSigner_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:19.049638166Z I1024 13:15:19.046800       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 9 triggered by "secret \"service-account-private-key-8\" not found"
2024-10-24T13:15:19.079299385Z I1024 13:15:19.070382       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:19.090841224Z E1024 13:15:19.084520       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-8,service-account-private-key-8"
2024-10-24T13:15:19.099082374Z E1024 13:15:19.097975       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:19.099082374Z I1024 13:15:19.098007       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-10-24T13:15:19.099600814Z E1024 13:15:19.099265       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-8,service-account-private-key-8"
2024-10-24T13:15:19.099969954Z I1024 13:15:19.099943       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-8,service-account-private-key-8
2024-10-24T13:15:19.109731243Z E1024 13:15:19.106905       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:19.109731243Z E1024 13:15:19.107659       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-8,service-account-private-key-8"
2024-10-24T13:15:19.109731243Z I1024 13:15:19.107683       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-8,service-account-private-key-8
2024-10-24T13:15:19.111161573Z I1024 13:15:19.111078       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: secrets: localhost-recovery-client-token-8,service-account-private-key-8\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again","reason":"GuardController_SyncError::InstallerController_Error::SATokenSigner_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:19.126011352Z E1024 13:15:19.120833       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2, the server was unable to return a response in the time allotted, but may still be processing the request (get pods kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0)]"
2024-10-24T13:15:19.158696391Z E1024 13:15:19.156955       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-8,service-account-private-key-8"
2024-10-24T13:15:19.158696391Z I1024 13:15:19.156987       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-8,service-account-private-key-8
2024-10-24T13:15:19.158696391Z I1024 13:15:19.157186       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:19.161104710Z E1024 13:15:19.160356       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-8,service-account-private-key-8"
2024-10-24T13:15:19.161104710Z I1024 13:15:19.160389       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-8,service-account-private-key-8
2024-10-24T13:15:19.161737940Z E1024 13:15:19.161716       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:19.162143510Z E1024 13:15:19.162121       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:19.162243590Z I1024 13:15:19.162208       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-10-24T13:15:19.163722710Z I1024 13:15:19.163691       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2, the server was unable to return a response in the time allotted, but may still be processing the request (get pods kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0)]\nInstallerControllerDegraded: missing required resources: secrets: localhost-recovery-client-token-8,service-account-private-key-8\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again","reason":"GuardController_SyncError::InstallerController_Error::SATokenSigner_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:19.211083437Z E1024 13:15:19.211017       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:19.213568377Z I1024 13:15:19.213535       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2, the server was unable to return a response in the time allotted, but may still be processing the request (get pods kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0)]\nInstallerControllerDegraded: missing required resources: secrets: localhost-recovery-client-token-8,service-account-private-key-8\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again","reason":"GuardController_SyncError::InstallerController_Error::SATokenSigner_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:19.222903847Z E1024 13:15:19.222863       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:19.222983297Z I1024 13:15:19.222958       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-10-24T13:15:19.224616937Z I1024 13:15:19.224588       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:19.280463564Z E1024 13:15:19.225370       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-8,service-account-private-key-8"
2024-10-24T13:15:19.280687354Z I1024 13:15:19.225385       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-8,service-account-private-key-8
2024-10-24T13:15:19.282372384Z E1024 13:15:19.282345       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-8,service-account-private-key-8"
2024-10-24T13:15:19.282448813Z I1024 13:15:19.282422       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-8,service-account-private-key-8
2024-10-24T13:15:19.317792452Z E1024 13:15:19.317725       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:19.405310397Z I1024 13:15:19.405190       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2, the server was unable to return a response in the time allotted, but may still be processing the request (get pods kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0)]\nInstallerControllerDegraded: missing required resources: secrets: localhost-recovery-client-token-8,service-account-private-key-8\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again\nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::InstallerController_Error::SATokenSigner_Error::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:19.410033487Z I1024 13:15:19.409979       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-manager-pod-9 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:15:19.486079833Z E1024 13:15:19.486029       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:19.486311732Z I1024 13:15:19.486285       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:19.487027313Z E1024 13:15:19.487006       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-8,service-account-private-key-8"
2024-10-24T13:15:19.493122602Z I1024 13:15:19.488785       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-8,service-account-private-key-8
2024-10-24T13:15:19.493187322Z I1024 13:15:19.490561       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2, the server was unable to return a response in the time allotted, but may still be processing the request (get pods kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0)]\nInstallerControllerDegraded: missing required resources: secrets: localhost-recovery-client-token-8,service-account-private-key-8\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again\nStaticPodsDegraded: the server was unable to return a response in the time allotted, but may still be processing the request (get pods kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0)\nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::InstallerController_Error::SATokenSigner_Error::StaticPods_Error::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:19.500675512Z I1024 13:15:19.500369       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-10-24T13:15:19.500675512Z E1024 13:15:19.500453       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:19.602382596Z I1024 13:15:19.602326       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-8,service-account-private-key-8
2024-10-24T13:15:19.602532706Z E1024 13:15:19.602505       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-8,service-account-private-key-8"
2024-10-24T13:15:19.614835845Z E1024 13:15:19.614677       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:19.650926064Z I1024 13:15:19.650859       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2, the server was unable to return a response in the time allotted, but may still be processing the request (get pods kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0)]\nInstallerControllerDegraded: missing required resources: secrets: localhost-recovery-client-token-8,service-account-private-key-8\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again\nStaticPodsDegraded: the server was unable to return a response in the time allotted, but may still be processing the request (get pods kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0)\nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::InstallerController_Error::SATokenSigner_Error::StaticPods_Error::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:19.687952862Z E1024 13:15:19.687894       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:19.749154798Z I1024 13:15:19.749112       1 trace.go:236] Trace[1991330202]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:15:07.155) (total time: 12593ms):
2024-10-24T13:15:19.749154798Z Trace[1991330202]: ---"Objects listed" error:<nil> 12593ms (13:15:19.748)
2024-10-24T13:15:19.749154798Z Trace[1991330202]: [12.593080682s] [12.593080682s] END
2024-10-24T13:15:19.749240938Z I1024 13:15:19.749222       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:19.768247457Z E1024 13:15:19.768143       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:19.773644727Z I1024 13:15:19.773595       1 trace.go:236] Trace[1461056767]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:14:51.839) (total time: 27934ms):
2024-10-24T13:15:19.773644727Z Trace[1461056767]: ---"Objects listed" error:<nil> 27934ms (13:15:19.773)
2024-10-24T13:15:19.773644727Z Trace[1461056767]: [27.934073244s] [27.934073244s] END
2024-10-24T13:15:19.773644727Z I1024 13:15:19.773618       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:19.865958532Z I1024 13:15:19.865908       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:19.866348752Z E1024 13:15:19.866313       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: localhost-recovery-client-token-8,service-account-private-key-8"
2024-10-24T13:15:19.866373022Z I1024 13:15:19.866355       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: localhost-recovery-client-token-8,service-account-private-key-8
2024-10-24T13:15:19.868096171Z I1024 13:15:19.868059       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: secrets: localhost-recovery-client-token-8,service-account-private-key-8\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again\nStaticPodsDegraded: the server was unable to return a response in the time allotted, but may still be processing the request (get pods kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0)\nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::InstallerController_Error::SATokenSigner_Error::StaticPods_Error::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:19.914924949Z I1024 13:15:19.914872       1 trace.go:236] Trace[1714473772]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:14:47.946) (total time: 31968ms):
2024-10-24T13:15:19.914924949Z Trace[1714473772]: ---"Objects listed" error:<nil> 31967ms (13:15:19.914)
2024-10-24T13:15:19.914924949Z Trace[1714473772]: [31.968076653s] [31.968076653s] END
2024-10-24T13:15:19.914924949Z I1024 13:15:19.914893       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:19.944466468Z E1024 13:15:19.944420       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2"
2024-10-24T13:15:20.003185554Z E1024 13:15:20.003132       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:20.011115264Z I1024 13:15:20.011045       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-9 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:15:20.228209822Z E1024 13:15:20.228155       1 base_controller.go:271] "Unhandled Error" err="SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:20.228313842Z I1024 13:15:20.228186       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-10-24T13:15:20.307659188Z I1024 13:15:20.307448       1 trace.go:236] Trace[1665170784]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:15:03.657) (total time: 16650ms):
2024-10-24T13:15:20.307659188Z Trace[1665170784]: ---"Objects listed" error:<nil> 16650ms (13:15:20.307)
2024-10-24T13:15:20.307659188Z Trace[1665170784]: [16.65026711s] [16.65026711s] END
2024-10-24T13:15:20.307659188Z I1024 13:15:20.307467       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:20.334102256Z I1024 13:15:20.334040       1 trace.go:236] Trace[2144926178]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:14:54.797) (total time: 25536ms):
2024-10-24T13:15:20.334102256Z Trace[2144926178]: ---"Objects listed" error:<nil> 25536ms (13:15:20.333)
2024-10-24T13:15:20.334102256Z Trace[2144926178]: [25.536874254s] [25.536874254s] END
2024-10-24T13:15:20.334102256Z I1024 13:15:20.334064       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:20.411800022Z I1024 13:15:20.411430       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: secrets: localhost-recovery-client-token-8,service-account-private-key-8\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again\nStaticPodsDegraded: the server was unable to return a response in the time allotted, but may still be processing the request (get pods kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0)\nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::InstallerController_Error::SATokenSigner_Error::StaticPods_Error::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:20.456313820Z I1024 13:15:20.446553       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.488824388Z E1024 13:15:20.488776       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:20.490716298Z I1024 13:15:20.490687       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: secrets: localhost-recovery-client-token-8,service-account-private-key-8\nStaticPodsDegraded: the server was unable to return a response in the time allotted, but may still be processing the request (get pods kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0)\nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::InstallerController_Error::StaticPods_Error::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:20.590473462Z E1024 13:15:20.590418       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:20.968631562Z I1024 13:15:20.965830       1 request.go:700] Waited for 1.050328163s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:21.222709319Z I1024 13:15:21.222645       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cluster-policy-controller-config-9 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:15:21.965921347Z I1024 13:15:21.965845       1 request.go:700] Waited for 1.09201005s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager
2024-10-24T13:15:22.278806634Z I1024 13:15:22.278155       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:15:22.278806634Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:15:22.278806634Z  CurrentRevision: (int32) 0,
2024-10-24T13:15:22.278806634Z  TargetRevision: (int32) 8,
2024-10-24T13:15:22.278806634Z  LastFailedRevision: (int32) 4,
2024-10-24T13:15:22.278806634Z  LastFailedTime: (*v1.Time)(0xc0009360c0)(2024-10-24 13:11:52 +0000 UTC),
2024-10-24T13:15:22.278806634Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:15:22.278806634Z  LastFailedCount: (int) 1,
2024-10-24T13:15:22.278806634Z  LastFallbackCount: (int) 0,
2024-10-24T13:15:22.278806634Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:15:22.278806634Z   (string) (len=2059) "installer: i-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:14.627959       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:24.627766       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:34.627494       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:44.628050       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.627778       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:54.629332       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:09:54.629375       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:15:22.278806634Z  }
2024-10-24T13:15:22.278806634Z }
2024-10-24T13:15:22.278806634Z  because new revision pending
2024-10-24T13:15:22.358342000Z I1024 13:15:22.358285       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: secrets: localhost-recovery-client-token-8,service-account-private-key-8\nStaticPodsDegraded: the server was unable to return a response in the time allotted, but may still be processing the request (get pods kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0)\nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::InstallerController_Error::StaticPods_Error::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:22.359369330Z I1024 13:15:22.359343       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:22.419688308Z I1024 13:15:22.419316       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/controller-manager-kubeconfig-9 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:15:22.453506456Z I1024 13:15:22.453455       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:22.473875715Z E1024 13:15:22.473811       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:22.475626375Z I1024 13:15:22.475583       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nStaticPodsDegraded: the server was unable to return a response in the time allotted, but may still be processing the request (get pods kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0)\nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::StaticPods_Error::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:22.499957704Z E1024 13:15:22.499920       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:22.829305070Z I1024 13:15:22.829233       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nStaticPodsDegraded: the server was unable to return a response in the time allotted, but may still be processing the request (get pods kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0)\nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::StaticPods_Error::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:22.860951169Z E1024 13:15:22.859435       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:22.877793228Z I1024 13:15:22.877335       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nStaticPodsDegraded: the server was unable to return a response in the time allotted, but may still be processing the request (get pods kube-controller-manager-ci-op-2fcpj5j6-f6035-2lklf-master-0)\nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::StaticPods_Error::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:22.881275178Z I1024 13:15:22.880897       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:22.906636377Z E1024 13:15:22.906547       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:22.908807757Z I1024 13:15:22.908744       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:22.923650446Z E1024 13:15:22.923577       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:23.051670651Z I1024 13:15:23.051620       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:23.094851519Z E1024 13:15:23.094724       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:23.383380666Z I1024 13:15:23.383324       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-cert-syncer-kubeconfig-9 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:15:23.566538839Z I1024 13:15:23.566464       1 request.go:700] Waited for 1.104547642s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-8-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:24.589656395Z I1024 13:15:24.589573       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-9 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:15:24.766354057Z I1024 13:15:24.766300       1 request.go:700] Waited for 1.152930831s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods
2024-10-24T13:15:24.804938385Z I1024 13:15:24.804888       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-8-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:15:25.576894842Z I1024 13:15:25.576830       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/service-ca-9 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:15:25.772593544Z I1024 13:15:25.772489       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 8, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:15:26.175909876Z I1024 13:15:26.175847       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:26.184503416Z E1024 13:15:26.184442       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:26.186276826Z I1024 13:15:26.186244       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:26.195048596Z E1024 13:15:26.194990       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:26.428956566Z E1024 13:15:26.428895       1 base_controller.go:271] "Unhandled Error" err="KubeControllerManagerStaticResources-StaticResources reconciliation failed: \"assets/kube-controller-manager/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-controller-manager)"
2024-10-24T13:15:26.430221796Z I1024 13:15:26.430177       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:26.431924465Z I1024 13:15:26.431891       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-controller-manager/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-controller-manager)\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::KubeControllerManagerStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:26.459180124Z E1024 13:15:26.459115       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:26.577468169Z I1024 13:15:26.577409       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/recycler-config-9 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:15:27.566877237Z I1024 13:15:27.566800       1 request.go:700] Waited for 1.136221911s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-10-24T13:15:27.777231998Z I1024 13:15:27.777124       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/service-account-private-key-9 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:15:27.975693770Z I1024 13:15:27.975632       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 8, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:15:28.803447224Z I1024 13:15:28.803370       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-9 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:15:29.373717509Z I1024 13:15:29.373655       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-controller-manager/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-controller-manager)\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::KubeControllerManagerStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:29.382775639Z E1024 13:15:29.382691       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:29.384632999Z I1024 13:15:29.384605       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-controller-manager/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-controller-manager)\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::KubeControllerManagerStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:29.396271508Z E1024 13:15:29.396217       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:29.778310882Z I1024 13:15:29.778248       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-9 -n openshift-kube-controller-manager because it was missing
2024-10-24T13:15:29.977935734Z I1024 13:15:29.977863       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 8, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:15:30.776388509Z I1024 13:15:30.776301       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 9 triggered by "secret \"service-account-private-key-8\" not found"
2024-10-24T13:15:30.777498229Z W1024 13:15:30.777463       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:15:30.777498229Z W1024 13:15:30.777480       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:15:30.800952308Z I1024 13:15:30.800905       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:30.801732998Z I1024 13:15:30.801706       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-controller-manager/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-controller-manager)\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::KubeControllerManagerStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:30.802329828Z I1024 13:15:30.802161       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 9 triggered by "required secret/service-account-private-key has changed,required secret/localhost-recovery-client-token has changed"
2024-10-24T13:15:30.811394537Z E1024 13:15:30.811365       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:31.965894988Z I1024 13:15:31.965825       1 request.go:700] Waited for 1.16381192s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps
2024-10-24T13:15:31.994923797Z E1024 13:15:31.994853       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": KubeControllerManager.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:15:31.995045137Z I1024 13:15:31.994961       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 9: configmap "revision-status-9" not found
2024-10-24T13:15:31.997426477Z W1024 13:15:31.997385       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:15:31.997426477Z W1024 13:15:31.997406       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:15:32.015160046Z E1024 13:15:32.015097       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": KubeControllerManager.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:15:32.017534776Z W1024 13:15:32.017479       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:15:32.017534776Z W1024 13:15:32.017498       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:15:32.033978186Z E1024 13:15:32.033936       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": KubeControllerManager.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:15:32.036699315Z W1024 13:15:32.036668       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:15:32.036699315Z W1024 13:15:32.036687       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:15:32.051161864Z E1024 13:15:32.051135       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": KubeControllerManager.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:15:32.056562395Z W1024 13:15:32.056516       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:15:32.056562395Z W1024 13:15:32.056542       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:15:32.075788623Z E1024 13:15:32.075708       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": KubeControllerManager.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:15:32.158348990Z W1024 13:15:32.158291       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:15:32.158348990Z W1024 13:15:32.158311       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:15:32.171696899Z E1024 13:15:32.171632       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": KubeControllerManager.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:15:32.173520669Z I1024 13:15:32.173487       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 8, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:15:32.196883818Z I1024 13:15:32.196841       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9
2024-10-24T13:15:32.198544978Z I1024 13:15:32.198520       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-controller-manager/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-controller-manager)\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::KubeControllerManagerStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:32.198849638Z I1024 13:15:32.198560       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:32.200017138Z W1024 13:15:32.199883       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:15:32.200109798Z W1024 13:15:32.200079       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:15:32.208782458Z E1024 13:15:32.208703       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:32.216783677Z E1024 13:15:32.216732       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": KubeControllerManager.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:15:32.245335366Z E1024 13:15:32.245287       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9"
2024-10-24T13:15:32.248191336Z I1024 13:15:32.247717       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9
2024-10-24T13:15:32.252931136Z I1024 13:15:32.250441       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:32.253332616Z I1024 13:15:32.250587       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-controller-manager/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-controller-manager)\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::InstallerController_Error::KubeControllerManagerStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:32.256278066Z W1024 13:15:32.256082       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:15:32.256278066Z W1024 13:15:32.256121       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:15:32.265772095Z E1024 13:15:32.265717       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:32.278566435Z E1024 13:15:32.278531       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9"
2024-10-24T13:15:32.280151625Z I1024 13:15:32.280108       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9
2024-10-24T13:15:32.280219615Z E1024 13:15:32.280183       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9"
2024-10-24T13:15:32.291157574Z I1024 13:15:32.291059       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9
2024-10-24T13:15:32.291273774Z E1024 13:15:32.291243       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9"
2024-10-24T13:15:32.334159392Z I1024 13:15:32.334060       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9
2024-10-24T13:15:32.334245172Z E1024 13:15:32.334213       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9"
2024-10-24T13:15:32.399242789Z E1024 13:15:32.399189       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": KubeControllerManager.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:15:32.402232259Z W1024 13:15:32.402148       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:15:32.402232259Z W1024 13:15:32.402183       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:15:32.416029779Z I1024 13:15:32.415978       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9
2024-10-24T13:15:32.416086879Z E1024 13:15:32.416073       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9"
2024-10-24T13:15:32.574443852Z I1024 13:15:32.574380       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-controller-manager/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-controller-manager)\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::InstallerController_Error::KubeControllerManagerStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:32.578504092Z I1024 13:15:32.578449       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9
2024-10-24T13:15:32.578693252Z E1024 13:15:32.578629       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9"
2024-10-24T13:15:32.582702242Z E1024 13:15:32.582645       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:32.584650072Z I1024 13:15:32.584610       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9\nKubeControllerManagerStaticResourcesDegraded: \"assets/kube-controller-manager/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-kube-controller-manager)\nKubeControllerManagerStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::InstallerController_Error::KubeControllerManagerStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:32.594532381Z E1024 13:15:32.594487       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:32.601106501Z E1024 13:15:32.601040       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": KubeControllerManager.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:15:32.901444408Z I1024 13:15:32.901357       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9
2024-10-24T13:15:32.901528268Z E1024 13:15:32.901470       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9"
2024-10-24T13:15:33.043106932Z W1024 13:15:33.043039       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:15:33.043106932Z W1024 13:15:33.043065       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:15:33.062618181Z E1024 13:15:33.062536       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": KubeControllerManager.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:15:33.544053271Z I1024 13:15:33.543976       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9
2024-10-24T13:15:33.544231741Z E1024 13:15:33.544181       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9"
2024-10-24T13:15:33.620177447Z W1024 13:15:33.620114       1 dynamic_operator_client.go:355] .status.conditions["KubeControllerManagerStaticResourcesDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:15:33.648910916Z E1024 13:15:33.647062       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9"
2024-10-24T13:15:33.649037016Z W1024 13:15:33.649006       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:15:33.649037016Z W1024 13:15:33.649024       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:15:33.649798056Z I1024 13:15:33.649774       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9\nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::InstallerController_Error::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:33.649990886Z I1024 13:15:33.649943       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9
2024-10-24T13:15:33.652397776Z I1024 13:15:33.652359       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:33.658081905Z E1024 13:15:33.658019       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:33.671536435Z E1024 13:15:33.671492       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": KubeControllerManager.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:15:34.826453425Z I1024 13:15:34.826372       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9
2024-10-24T13:15:34.826587415Z E1024 13:15:34.826538       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9"
2024-10-24T13:15:34.974481809Z I1024 13:15:34.974429       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9\nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::InstallerController_Error::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:34.982594619Z E1024 13:15:34.982552       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:34.984189389Z I1024 13:15:34.984150       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9\nTargetConfigControllerDegraded: \"configmap/trusted-ca-bundle\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps trusted-ca-bundle)","reason":"GuardController_SyncError::InstallerController_Error::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:34.993023698Z E1024 13:15:34.992989       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:35.625578781Z W1024 13:15:35.625506       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:15:35.625578781Z W1024 13:15:35.625541       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:15:35.642860220Z E1024 13:15:35.642830       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": KubeControllerManager.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:15:36.009545435Z I1024 13:15:36.009475       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:36.009987415Z E1024 13:15:36.009482       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9"
2024-10-24T13:15:36.009987415Z I1024 13:15:36.009607       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9
2024-10-24T13:15:36.010179865Z I1024 13:15:36.010130       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:36.011515805Z W1024 13:15:36.011487       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:15:36.011630184Z W1024 13:15:36.011557       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:15:36.020076744Z E1024 13:15:36.020004       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:36.028826114Z E1024 13:15:36.028735       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": KubeControllerManager.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:15:36.973201474Z I1024 13:15:36.973133       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:36.981832663Z E1024 13:15:36.981744       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:36.983535083Z I1024 13:15:36.983484       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:36.991484523Z E1024 13:15:36.991428       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:38.775055596Z I1024 13:15:38.774982       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:38.783521876Z E1024 13:15:38.783483       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:38.785319656Z I1024 13:15:38.785275       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:38.793904815Z E1024 13:15:38.793864       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"kube-controller-manager\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:39.948789226Z I1024 13:15:39.948663       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9
2024-10-24T13:15:39.948789226Z E1024 13:15:39.948738       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9"
2024-10-24T13:15:45.886498021Z W1024 13:15:45.886434       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:15:45.886498021Z W1024 13:15:45.886462       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:15:45.903632911Z E1024 13:15:45.903560       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": KubeControllerManager.operator.openshift.io \"cluster\" is invalid: status.latestAvailableRevision: Invalid value: \"integer\": must only increase"
2024-10-24T13:15:48.909965062Z I1024 13:15:48.909899       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:50.298481672Z I1024 13:15:50.298425       1 reflector.go:368] Caches populated for *v1.Role from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:51.299802919Z I1024 13:15:51.299710       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:51.758739910Z I1024 13:15:51.758674       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:51.759593999Z E1024 13:15:51.759500       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9"
2024-10-24T13:15:51.759689130Z I1024 13:15:51.759523       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9
2024-10-24T13:15:51.762130460Z I1024 13:15:51.762086       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9
2024-10-24T13:15:51.762250419Z E1024 13:15:51.762214       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9"
2024-10-24T13:15:53.569318202Z I1024 13:15:53.569263       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:56.311278104Z I1024 13:15:56.311212       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:56.523083425Z I1024 13:15:56.523034       1 reflector.go:368] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:56.881623270Z I1024 13:15:56.880785       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:58.873494204Z I1024 13:15:58.873451       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:59.120581574Z I1024 13:15:59.120514       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:59.389987772Z I1024 13:15:59.389934       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:59.619827093Z I1024 13:15:59.618021       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:59.891437871Z I1024 13:15:59.891376       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:00.431044088Z E1024 13:16:00.431002       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9"
2024-10-24T13:16:00.431206018Z I1024 13:16:00.431118       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9
2024-10-24T13:16:00.456177377Z W1024 13:16:00.456137       1 dynamic_operator_client.go:352] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:16:00.456279446Z W1024 13:16:00.456217       1 dynamic_operator_client.go:355] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:16:00.457475777Z I1024 13:16:00.457448       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:16:01.015792333Z I1024 13:16:01.015703       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:01.016982893Z E1024 13:16:01.016950       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9"
2024-10-24T13:16:01.017287143Z I1024 13:16:01.017256       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9
2024-10-24T13:16:01.017988023Z I1024 13:16:01.017963       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:16:01.024543652Z I1024 13:16:01.024497       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:16:01.026945262Z E1024 13:16:01.026891       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9"
2024-10-24T13:16:01.027102912Z I1024 13:16:01.027031       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:16:01.027342232Z I1024 13:16:01.027045       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9
2024-10-24T13:16:01.027406642Z I1024 13:16:01.027352       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:16:01.027718182Z I1024 13:16:01.027689       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:16:01.028111942Z I1024 13:16:01.028088       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:16:01.028466252Z I1024 13:16:01.028445       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:16:01.029097032Z I1024 13:16:01.029058       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:16:01.029380962Z I1024 13:16:01.029353       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:16:01.029598482Z I1024 13:16:01.029572       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:16:01.030121672Z I1024 13:16:01.029858       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:16:01.030208002Z I1024 13:16:01.030177       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:16:01.030299462Z I1024 13:16:01.030270       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: service-ca-9,serviceaccount-ca-9
2024-10-24T13:16:01.916495024Z I1024 13:16:01.916431       1 reflector.go:368] Caches populated for *v1.Proxy from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:05.911668903Z I1024 13:16:05.911592       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:07.717146345Z I1024 13:16:07.717101       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:07.749884464Z I1024 13:16:07.749842       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:08.110803338Z E1024 13:16:08.110726       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: configmaps: service-ca-9,serviceaccount-ca-9"
2024-10-24T13:16:08.914214634Z I1024 13:16:08.914170       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:09.164303853Z I1024 13:16:09.164250       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:09.239580760Z I1024 13:16:09.239505       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:13.278538067Z I1024 13:16:13.278490       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:14.772450043Z I1024 13:16:14.772365       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:15.164423286Z I1024 13:16:15.164364       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:16.110087755Z I1024 13:16:16.110030       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:18.687646665Z E1024 13:16:18.687595       1 leaderelection.go:429] Failed to update lock optimitically: rpc error: code = DeadlineExceeded desc = context deadline exceeded, falling back to slow path
2024-10-24T13:16:19.304088558Z I1024 13:16:19.304026       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:25.772803631Z E1024 13:16:25.772726       1 event.go:359] "Server rejected event (will not retry!)" err="Timeout: request did not complete within requested timeout - context deadline exceeded" event="&Event{ObjectMeta:{kube-controller-manager-operator.180165dd1aacab52  openshift-kube-controller-manager-operator   20290 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:RequiredInstallerResourcesMissing,Message:configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:15:32 +0000 UTC,LastTimestamp:2024-10-24 13:15:51.75920788 +0000 UTC m=+652.080515207,Count:14,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:16:34.461777284Z E1024 13:16:34.461712       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"kube-controller-manager-RevisionController\": Timeout: request did not complete within requested timeout - context deadline exceeded"
2024-10-24T13:16:34.471313503Z E1024 13:16:34.471275       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: Timeout: request did not complete within requested timeout - context deadline exceeded"
2024-10-24T13:16:34.472925303Z I1024 13:16:34.472888       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:16:41.482290345Z E1024 13:16:41.482218       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:16:51.762280402Z E1024 13:16:51.762210       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: the server was unable to return a response in the time allotted, but may still be processing the request (get pods)"
2024-10-24T13:16:53.572232926Z E1024 13:16:53.572182       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: the server was unable to return a response in the time allotted, but may still be processing the request"
2024-10-24T13:16:59.783572723Z E1024 13:16:59.783495       1 event.go:359] "Server rejected event (will not retry!)" err="Timeout: request did not complete within requested timeout - context deadline exceeded" event="&Event{ObjectMeta:{kube-controller-manager-operator.180165dd1aacab52  openshift-kube-controller-manager-operator   20290 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:RequiredInstallerResourcesMissing,Message:configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:15:32 +0000 UTC,LastTimestamp:2024-10-24 13:15:51.76195734 +0000 UTC m=+652.083264686,Count:15,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:17:00.455705918Z I1024 13:17:00.455655       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:17:07.464256521Z E1024 13:17:07.464171       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_kube-controller-manager reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:17:15.136410859Z E1024 13:17:15.136290       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: the server was unable to return a response in the time allotted, but may still be processing the request (get pods installer-8-ci-op-2fcpj5j6-f6035-2lklf-master-2)"
2024-10-24T13:17:18.706501830Z E1024 13:17:18.706426       1 leaderelection.go:436] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: the server was unable to return a response in the time allotted, but may still be processing the request (get leases.coordination.k8s.io kube-controller-manager-operator-lock)
2024-10-24T13:17:33.787005429Z E1024 13:17:33.786900       1 event.go:359] "Server rejected event (will not retry!)" err="Timeout: request did not complete within requested timeout - context deadline exceeded" event="&Event{ObjectMeta:{kube-controller-manager-operator.180165dd1aacab52  openshift-kube-controller-manager-operator   20290 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:c2dbbf9d-d89a-4f92-888e-f8d34b1f90f8,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:RequiredInstallerResourcesMissing,Message:configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:15:32 +0000 UTC,LastTimestamp:2024-10-24 13:16:00.430643698 +0000 UTC m=+660.751951035,Count:16,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:17:51.714599445Z E1024 13:17:51.714535       1 leaderelection.go:429] Failed to update lock optimitically: rpc error: code = DeadlineExceeded desc = context deadline exceeded, falling back to slow path
2024-10-24T13:17:51.764922781Z E1024 13:17:51.764856       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:17:51.765491951Z E1024 13:17:51.765454       1 base_controller.go:271] "Unhandled Error" err="kube-controller-manager-InstallerState reconciliation failed: the server was unable to return a response in the time allotted, but may still be processing the request (get pods)"
2024-10-24T13:17:53.575607674Z E1024 13:17:53.575554       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: the server was unable to return a response in the time allotted, but may still be processing the request"
2024-10-24T13:17:58.642062094Z E1024 13:17:58.641992       1 leaderelection.go:436] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": context deadline exceeded
2024-10-24T13:17:58.642062094Z I1024 13:17:58.642032       1 leaderelection.go:297] failed to renew lease openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: timed out waiting for the condition
2024-10-24T13:17:58.780024083Z W1024 13:17:58.779964       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": rpc error: code = DeadlineExceeded desc = context deadline exceeded
2024-10-24T13:17:58.780072283Z E1024 13:17:58.780023       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2, the server was unable to return a response in the time allotted, but may still be processing the request (get pods kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0), the server was unable to return a response in the time allotted, but may still be processing the request (get pods kube-controller-manager-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1)]"
2024-10-24T13:18:00.455989337Z I1024 13:18:00.455922       1 status_controller.go:225] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:05:35Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-2\nInstallerControllerDegraded: missing required resources: configmaps: cluster-policy-controller-config-9,config-9,controller-manager-kubeconfig-9,kube-controller-cert-syncer-kubeconfig-9,kube-controller-manager-pod-9,recycler-config-9,service-ca-9,serviceaccount-ca-9","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:04:12Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:06:34Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 3; 1 node is at revision 4; 0 nodes have achieved new revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:30Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:30Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:18:03.544508587Z E1024 13:18:03.544443       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get serviceaccounts installer-sa), \"manifests/installer-cluster-rolebinding.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get clusterrolebindings.rbac.authorization.k8s.io system:openshift:operator:openshift-kube-controller-manager-installer), unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": rpc error: code = DeadlineExceeded desc = context deadline exceeded]"
2024-10-24T13:18:05.648892026Z E1024 13:18:05.648841       1 leaderelection.go:322] Failed to release lock: rpc error: code = DeadlineExceeded desc = context deadline exceeded
2024-10-24T13:18:05.648936446Z W1024 13:18:05.648903       1 leaderelection.go:84] leader election lost
