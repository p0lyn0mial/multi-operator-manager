2024-10-24T13:04:43.514606105Z I1024 13:04:43.514409       1 profiler.go:21] Starting profiling endpoint at http://127.0.0.1:6060/debug/pprof/
2024-10-24T13:04:43.514780794Z I1024 13:04:43.514703       1 observer_polling.go:159] Starting file observer
2024-10-24T13:04:43.515079854Z I1024 13:04:43.515017       1 cmd.go:250] Using service-serving-cert provided certificates
2024-10-24T13:04:43.515101254Z I1024 13:04:43.515076       1 leaderelection.go:121] The leader election gives 4 retries and allows for 30s of clock skew. The kube-apiserver downtime tolerance is 78s. Worst non-graceful lease acquisition is 2m43s. Worst graceful lease acquisition is {26s}.
2024-10-24T13:04:43.515462424Z I1024 13:04:43.515424       1 observer_polling.go:159] Starting file observer
2024-10-24T13:04:43.534402034Z I1024 13:04:43.534160       1 builder.go:298] openshift-cluster-etcd-operator version v0.0.0-alpha.0-1564-g26e5aee-26e5aee9
2024-10-24T13:04:43.965986155Z I1024 13:04:43.965905       1 secure_serving.go:57] Forcing use of http/1.1 only
2024-10-24T13:04:43.965986155Z W1024 13:04:43.965936       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256' detected.
2024-10-24T13:04:43.965986155Z W1024 13:04:43.965944       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256' detected.
2024-10-24T13:04:43.965986155Z W1024 13:04:43.965950       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_128_GCM_SHA256' detected.
2024-10-24T13:04:43.965986155Z W1024 13:04:43.965956       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_256_GCM_SHA384' detected.
2024-10-24T13:04:43.965986155Z W1024 13:04:43.965961       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_128_CBC_SHA' detected.
2024-10-24T13:04:43.965986155Z W1024 13:04:43.965965       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_256_CBC_SHA' detected.
2024-10-24T13:04:43.970055195Z I1024 13:04:43.969979       1 requestheader_controller.go:172] Starting RequestHeaderAuthRequestController
2024-10-24T13:04:43.970055195Z I1024 13:04:43.970007       1 configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2024-10-24T13:04:43.970055195Z I1024 13:04:43.970025       1 shared_informer.go:313] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-10-24T13:04:43.970055195Z I1024 13:04:43.970027       1 shared_informer.go:313] Waiting for caches to sync for RequestHeaderAuthRequestController
2024-10-24T13:04:43.970121275Z I1024 13:04:43.970052       1 configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2024-10-24T13:04:43.970121275Z I1024 13:04:43.970067       1 shared_informer.go:313] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-10-24T13:04:43.970370265Z I1024 13:04:43.970323       1 dynamic_serving_content.go:135] "Starting controller" name="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key"
2024-10-24T13:04:43.970615405Z I1024 13:04:43.970556       1 secure_serving.go:213] Serving securely on [::]:8443
2024-10-24T13:04:43.970615405Z I1024 13:04:43.970591       1 tlsconfig.go:243] "Starting DynamicServingCertificateController"
2024-10-24T13:04:43.971069535Z I1024 13:04:43.971028       1 leaderelection.go:254] attempting to acquire leader lease openshift-etcd-operator/openshift-cluster-etcd-operator-lock...
2024-10-24T13:04:43.979565055Z I1024 13:04:43.979527       1 leaderelection.go:268] successfully acquired lease openshift-etcd-operator/openshift-cluster-etcd-operator-lock
2024-10-24T13:04:43.979663425Z I1024 13:04:43.979629       1 event.go:377] Event(v1.ObjectReference{Kind:"Lease", Namespace:"openshift-etcd-operator", Name:"openshift-cluster-etcd-operator-lock", UID:"c84f0bae-a1b8-4371-af39-b17979ae2fc2", APIVersion:"coordination.k8s.io/v1", ResourceVersion:"10130", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' etcd-operator-7bbcf99d5c-9746p_bab5ae12-dba6-4399-b182-d464571b7536 became leader
2024-10-24T13:04:43.984531605Z I1024 13:04:43.984478       1 starter.go:169] recorded cluster versions: map[etcd:4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest operator:4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest raw-internal:4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest]
2024-10-24T13:04:43.991568345Z I1024 13:04:43.991533       1 simple_featuregate_reader.go:171] Starting feature-gate-detector
2024-10-24T13:04:43.995653255Z I1024 13:04:43.995595       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'FeatureGatesInitialized' FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AWSEFSDriverVolumeMetrics", "AdminNetworkPolicy", "AlibabaPlatform", "AzureWorkloadIdentity", "BareMetalLoadBalancer", "BuildCSIVolumes", "ChunkSizeMiB", "CloudDualStackNodeIPs", "DisableKubeletCloudCredentialProviders", "GCPLabelsTags", "HardwareSpeed", "IngressControllerLBSubnetsAWS", "KMSv1", "ManagedBootImages", "MetricsServer", "MultiArchInstallAWS", "MultiArchInstallGCP", "NetworkDiagnosticsConfig", "NetworkLiveMigration", "NodeDisruptionPolicy", "OpenShiftPodSecurityAdmission", "PrivateHostedZoneAWS", "SetEIPForNLBIngressController", "VSphereControlPlaneMachineSet", "VSphereDriverConfiguration", "VSphereStaticIPs", "ValidatingAdmissionPolicy"}, Disabled:[]v1.FeatureGateName{"AWSClusterHostedDNS", "AdditionalRoutingCapabilities", "AutomatedEtcdBackup", "BootcNodeManagement", "CSIDriverSharedResource", "ClusterAPIInstall", "ClusterAPIInstallIBMCloud", "ClusterMonitoringConfig", "DNSNameResolver", "DynamicResourceAllocation", "EtcdBackendQuota", "EventedPLEG", "Example", "ExternalOIDC", "GCPClusterHostedDNS", "GatewayAPI", "ImageStreamImportMode", "IngressControllerDynamicConfigurationManager", "InsightsConfig", "InsightsConfigAPI", "InsightsOnDemandDataGather", "InsightsRuntimeExtractor", "MachineAPIMigration", "MachineAPIOperatorDisableMachineHealthCheckController", "MachineAPIProviderOpenStack", "MachineConfigNodes", "ManagedBootImagesAWS", "MaxUnavailableStatefulSet", "MetricsCollectionProfiles", "MixedCPUsAllocation", "MultiArchInstallAzure", "NetworkSegmentation", "NewOLM", "NodeSwap", "OVNObservability", "OnClusterBuild", "PersistentIPsForVirtualization", "PinnedImages", "PlatformOperators", "ProcMountType", "RouteAdvertisements", "RouteExternalCertificate", "ServiceAccountTokenNodeBinding", "SignatureStores", "SigstoreImageVerification", "TranslateStreamCloseWebsocketRequests", "UpgradeStatus", "UserNamespacesPodSecurityStandards", "UserNamespacesSupport", "VSphereMultiNetworks", "VSphereMultiVCenters", "VolumeGroupSnapshot"}}
2024-10-24T13:04:43.995762855Z I1024 13:04:43.995623       1 starter.go:451] FeatureGates initializedenabled[AWSEFSDriverVolumeMetrics AdminNetworkPolicy AlibabaPlatform AzureWorkloadIdentity BareMetalLoadBalancer BuildCSIVolumes ChunkSizeMiB CloudDualStackNodeIPs DisableKubeletCloudCredentialProviders GCPLabelsTags HardwareSpeed IngressControllerLBSubnetsAWS KMSv1 ManagedBootImages MetricsServer MultiArchInstallAWS MultiArchInstallGCP NetworkDiagnosticsConfig NetworkLiveMigration NodeDisruptionPolicy OpenShiftPodSecurityAdmission PrivateHostedZoneAWS SetEIPForNLBIngressController VSphereControlPlaneMachineSet VSphereDriverConfiguration VSphereStaticIPs ValidatingAdmissionPolicy]disabled[AWSClusterHostedDNS AdditionalRoutingCapabilities AutomatedEtcdBackup BootcNodeManagement CSIDriverSharedResource ClusterAPIInstall ClusterAPIInstallIBMCloud ClusterMonitoringConfig DNSNameResolver DynamicResourceAllocation EtcdBackendQuota EventedPLEG Example ExternalOIDC GCPClusterHostedDNS GatewayAPI ImageStreamImportMode IngressControllerDynamicConfigurationManager InsightsConfig InsightsConfigAPI InsightsOnDemandDataGather InsightsRuntimeExtractor MachineAPIMigration MachineAPIOperatorDisableMachineHealthCheckController MachineAPIProviderOpenStack MachineConfigNodes ManagedBootImagesAWS MaxUnavailableStatefulSet MetricsCollectionProfiles MixedCPUsAllocation MultiArchInstallAzure NetworkSegmentation NewOLM NodeSwap OVNObservability OnClusterBuild PersistentIPsForVirtualization PinnedImages PlatformOperators ProcMountType RouteAdvertisements RouteExternalCertificate ServiceAccountTokenNodeBinding SignatureStores SigstoreImageVerification TranslateStreamCloseWebsocketRequests UpgradeStatus UserNamespacesPodSecurityStandards UserNamespacesSupport VSphereMultiNetworks VSphereMultiVCenters VolumeGroupSnapshot]
2024-10-24T13:04:43.995793665Z I1024 13:04:43.995780       1 starter.go:506] waiting for cluster version informer sync...
2024-10-24T13:04:44.070211955Z I1024 13:04:44.070151       1 shared_informer.go:320] Caches are synced for RequestHeaderAuthRequestController
2024-10-24T13:04:44.070211955Z I1024 13:04:44.070188       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-10-24T13:04:44.070211955Z I1024 13:04:44.070132       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-10-24T13:04:44.101405065Z I1024 13:04:44.101347       1 starter.go:529] Detected available machine API, starting vertical scaling related controllers and informers...
2024-10-24T13:04:44.102313195Z I1024 13:04:44.102249       1 base_controller.go:68] Waiting for caches to sync for ClusterMemberRemovalController
2024-10-24T13:04:44.102313195Z I1024 13:04:44.102271       1 base_controller.go:68] Waiting for caches to sync for MachineDeletionHooksController
2024-10-24T13:04:44.103145135Z I1024 13:04:44.103114       1 base_controller.go:68] Waiting for caches to sync for MissingStaticPodController
2024-10-24T13:04:44.103479515Z I1024 13:04:44.103236       1 base_controller.go:68] Waiting for caches to sync for ConfigObserver
2024-10-24T13:04:44.103678115Z I1024 13:04:44.103349       1 base_controller.go:68] Waiting for caches to sync for etcd
2024-10-24T13:04:44.103846565Z I1024 13:04:44.103357       1 base_controller.go:68] Waiting for caches to sync for TargetConfigController
2024-10-24T13:04:44.103846565Z I1024 13:04:44.103364       1 base_controller.go:68] Waiting for caches to sync for EtcdCertSignerController
2024-10-24T13:04:44.103910375Z I1024 13:04:44.103372       1 base_controller.go:68] Waiting for caches to sync for EtcdCertCleanerController
2024-10-24T13:04:44.103910375Z I1024 13:04:44.103893       1 base_controller.go:68] Waiting for caches to sync for ClusterMemberController
2024-10-24T13:04:44.103910375Z I1024 13:04:44.103900       1 base_controller.go:74] Caches are synced for EtcdCertCleanerController 
2024-10-24T13:04:44.103925935Z I1024 13:04:44.103908       1 base_controller.go:111] Starting #1 worker of EtcdCertCleanerController controller ...
2024-10-24T13:04:44.103970625Z I1024 13:04:44.103952       1 base_controller.go:68] Waiting for caches to sync for EtcdMembersController
2024-10-24T13:04:44.104072375Z I1024 13:04:44.104043       1 base_controller.go:74] Caches are synced for EtcdMembersController 
2024-10-24T13:04:44.104110445Z I1024 13:04:44.104096       1 base_controller.go:111] Starting #1 worker of EtcdMembersController controller ...
2024-10-24T13:04:44.104188025Z I1024 13:04:44.104164       1 base_controller.go:68] Waiting for caches to sync for BootstrapTeardownController
2024-10-24T13:04:44.104236755Z I1024 13:04:44.104222       1 base_controller.go:68] Waiting for caches to sync for UnsupportedConfigOverridesController
2024-10-24T13:04:44.104379195Z I1024 13:04:44.104347       1 base_controller.go:68] Waiting for caches to sync for NodeController
2024-10-24T13:04:44.104460265Z I1024 13:04:44.104436       1 base_controller.go:68] Waiting for caches to sync for ScriptController
2024-10-24T13:04:44.104537665Z I1024 13:04:44.104496       1 base_controller.go:68] Waiting for caches to sync for RevisionController
2024-10-24T13:04:44.104597225Z I1024 13:04:44.103377       1 base_controller.go:68] Waiting for caches to sync for EtcdEndpointsController
2024-10-24T13:04:44.104659245Z I1024 13:04:44.104350       1 base_controller.go:68] Waiting for caches to sync for GuardController
2024-10-24T13:04:44.104659245Z I1024 13:04:44.104223       1 base_controller.go:68] Waiting for caches to sync for FSyncController
2024-10-24T13:04:44.104676645Z E1024 13:04:44.104650       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: getting cache client could not retrieve endpoints: node lister not synced"
2024-10-24T13:04:44.104676645Z I1024 13:04:44.104446       1 base_controller.go:68] Waiting for caches to sync for etcd-InstallerState
2024-10-24T13:04:44.104687135Z I1024 13:04:44.104655       1 base_controller.go:74] Caches are synced for FSyncController 
2024-10-24T13:04:44.104696795Z I1024 13:04:44.104688       1 base_controller.go:111] Starting #1 worker of FSyncController controller ...
2024-10-24T13:04:44.104708205Z I1024 13:04:44.104690       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' etcds.operator.openshift.io "cluster" not found
2024-10-24T13:04:44.104742875Z I1024 13:04:44.103981       1 base_controller.go:68] Waiting for caches to sync for StatusSyncer_etcd
2024-10-24T13:04:44.104742875Z I1024 13:04:44.104457       1 base_controller.go:68] Waiting for caches to sync for etcd-StaticPodState
2024-10-24T13:04:44.104774715Z I1024 13:04:44.104475       1 base_controller.go:68] Waiting for caches to sync for PruneController
2024-10-24T13:04:44.104790425Z I1024 13:04:44.104484       1 base_controller.go:68] Waiting for caches to sync for UnsupportedConfigOverridesController
2024-10-24T13:04:44.104834815Z I1024 13:04:44.104518       1 base_controller.go:68] Waiting for caches to sync for EtcdStaticResources-StaticResources
2024-10-24T13:04:44.104834815Z I1024 13:04:44.104519       1 base_controller.go:68] Waiting for caches to sync for LoggingSyncer
2024-10-24T13:04:44.104834815Z I1024 13:04:44.104539       1 base_controller.go:68] Waiting for caches to sync for InstallerController
2024-10-24T13:04:44.104847665Z I1024 13:04:44.104543       1 base_controller.go:68] Waiting for caches to sync for DefragController
2024-10-24T13:04:44.104890745Z I1024 13:04:44.104548       1 envvarcontroller.go:236] Starting EnvVarController
2024-10-24T13:04:44.105523185Z I1024 13:04:44.105494       1 base_controller.go:68] Waiting for caches to sync for BackingResourceController-StaticResources
2024-10-24T13:04:44.113374265Z E1024 13:04:44.113333       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: getting cache client could not retrieve endpoints: node lister not synced"
2024-10-24T13:04:44.113531735Z I1024 13:04:44.113436       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' etcds.operator.openshift.io "cluster" not found
2024-10-24T13:04:44.128385195Z I1024 13:04:44.128347       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:04:44.154814275Z I1024 13:04:44.154742       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:04:44.154989275Z I1024 13:04:44.154793       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:04:44.202948145Z I1024 13:04:44.202888       1 base_controller.go:74] Caches are synced for MachineDeletionHooksController 
2024-10-24T13:04:44.202948145Z I1024 13:04:44.202908       1 base_controller.go:111] Starting #1 worker of MachineDeletionHooksController controller ...
2024-10-24T13:04:44.202948145Z I1024 13:04:44.202921       1 base_controller.go:74] Caches are synced for ClusterMemberRemovalController 
2024-10-24T13:04:44.202948145Z I1024 13:04:44.202943       1 base_controller.go:111] Starting #1 worker of ClusterMemberRemovalController controller ...
2024-10-24T13:04:44.204333775Z I1024 13:04:44.204300       1 base_controller.go:74] Caches are synced for UnsupportedConfigOverridesController 
2024-10-24T13:04:44.204400905Z I1024 13:04:44.204386       1 base_controller.go:111] Starting #1 worker of UnsupportedConfigOverridesController controller ...
2024-10-24T13:04:44.204519655Z I1024 13:04:44.204333       1 base_controller.go:74] Caches are synced for BootstrapTeardownController 
2024-10-24T13:04:44.204582585Z I1024 13:04:44.204558       1 base_controller.go:111] Starting #1 worker of BootstrapTeardownController controller ...
2024-10-24T13:04:44.204635875Z I1024 13:04:44.204500       1 base_controller.go:74] Caches are synced for NodeController 
2024-10-24T13:04:44.204670825Z I1024 13:04:44.204656       1 base_controller.go:111] Starting #1 worker of NodeController controller ...
2024-10-24T13:04:44.204843715Z I1024 13:04:44.204523       1 base_controller.go:74] Caches are synced for ScriptController 
2024-10-24T13:04:44.204897295Z I1024 13:04:44.204868       1 base_controller.go:111] Starting #1 worker of ScriptController controller ...
2024-10-24T13:04:44.204897295Z I1024 13:04:44.204885       1 base_controller.go:74] Caches are synced for StatusSyncer_etcd 
2024-10-24T13:04:44.204909955Z I1024 13:04:44.204895       1 base_controller.go:111] Starting #1 worker of StatusSyncer_etcd controller ...
2024-10-24T13:04:44.204951785Z I1024 13:04:44.204928       1 base_controller.go:74] Caches are synced for PruneController 
2024-10-24T13:04:44.204999555Z I1024 13:04:44.204975       1 base_controller.go:74] Caches are synced for UnsupportedConfigOverridesController 
2024-10-24T13:04:44.205199775Z I1024 13:04:44.205182       1 base_controller.go:111] Starting #1 worker of UnsupportedConfigOverridesController controller ...
2024-10-24T13:04:44.205253655Z I1024 13:04:44.204980       1 base_controller.go:111] Starting #1 worker of PruneController controller ...
2024-10-24T13:04:44.205316815Z E1024 13:04:44.204943       1 base_controller.go:271] "Unhandled Error" err="BootstrapTeardownController reconciliation failed: failed to get bootstrap scaling strategy: failed to get openshift-etcd namespace: namespace \"openshift-etcd\" not found"
2024-10-24T13:04:44.205316815Z I1024 13:04:44.205067       1 base_controller.go:74] Caches are synced for EtcdEndpointsController 
2024-10-24T13:04:44.205331785Z I1024 13:04:44.205320       1 base_controller.go:111] Starting #1 worker of EtcdEndpointsController controller ...
2024-10-24T13:04:44.205350825Z I1024 13:04:44.205114       1 base_controller.go:74] Caches are synced for LoggingSyncer 
2024-10-24T13:04:44.205350825Z I1024 13:04:44.205339       1 base_controller.go:111] Starting #1 worker of LoggingSyncer controller ...
2024-10-24T13:04:44.205437745Z I1024 13:04:44.205409       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:44.205514555Z I1024 13:04:44.205149       1 base_controller.go:74] Caches are synced for DefragController 
2024-10-24T13:04:44.205514555Z I1024 13:04:44.205509       1 base_controller.go:111] Starting #1 worker of DefragController controller ...
2024-10-24T13:04:44.206249225Z I1024 13:04:44.206228       1 base_controller.go:74] Caches are synced for BackingResourceController-StaticResources 
2024-10-24T13:04:44.208813255Z I1024 13:04:44.208792       1 base_controller.go:111] Starting #1 worker of BackingResourceController-StaticResources controller ...
2024-10-24T13:04:44.212224575Z E1024 13:04:44.211813       1 base_controller.go:271] "Unhandled Error" err="BootstrapTeardownController reconciliation failed: failed to get bootstrap scaling strategy: failed to get openshift-etcd namespace: namespace \"openshift-etcd\" not found"
2024-10-24T13:04:44.212428515Z E1024 13:04:44.212406       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: no etcd members are present"
2024-10-24T13:04:44.224250305Z E1024 13:04:44.224203       1 base_controller.go:271] "Unhandled Error" err="BootstrapTeardownController reconciliation failed: failed to get bootstrap scaling strategy: failed to get openshift-etcd namespace: namespace \"openshift-etcd\" not found"
2024-10-24T13:04:44.235153295Z E1024 13:04:44.235121       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": missing env var values"
2024-10-24T13:04:44.235740445Z E1024 13:04:44.235706       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: no etcd members are present"
2024-10-24T13:04:44.236230655Z I1024 13:04:44.236186       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:44.236348295Z E1024 13:04:44.236233       1 base_controller.go:271] "Unhandled Error" err="BootstrapTeardownController reconciliation failed: failed to get bootstrap scaling strategy: failed to get openshift-etcd namespace: namespace \"openshift-etcd\" not found"
2024-10-24T13:04:44.236731695Z E1024 13:04:44.236703       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": missing env var values"
2024-10-24T13:04:44.236992165Z I1024 13:04:44.236959       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"EtcdMembersControllerDegraded: giving up getting a cached client after 3 tries\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]\nStaticPodsDegraded: pod/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2 container \"etcd\" is terminated: Error: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:32.165129Z\",\"caller\":\"flags/flag.go:93\",\"msg\":\"unrecognized environment variable\",\"environment-variable\":\"ETCDCTL_ENDPOINTS=\"}\nStaticPodsDegraded: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:37.166032Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc000498000/127.0.0.1:2379\",\"attempt\":0,\"error\":\"rpc error: code = DeadlineExceeded desc = latest balancer error: last connection error: connection error: desc = \\\"transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused\\\"\"}\nStaticPodsDegraded: Error: context deadline exceeded\nStaticPodsDegraded: could not parse revision.json, falling back to WAL parsing. Err=open /var/lib/etcd/revision.json: no such file or directorycould not find local cluster id: couldn't find cluster id in WAL or revision: open /var/lib/etcd/member/wal: no such file or directory\nStaticPodsDegraded: open /var/lib/etcd/revision.json: no such file or directory\nScriptControllerDegraded: \"configmap/etcd-pod\": missing env var values\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:31Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:04:44.240771125Z E1024 13:04:44.240723       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: no etcd members are present"
2024-10-24T13:04:44.242054225Z E1024 13:04:44.242008       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": missing env var values"
2024-10-24T13:04:44.250800235Z I1024 13:04:44.250452       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "EtcdMembersControllerDegraded: giving up getting a cached client after 3 tries\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]\nStaticPodsDegraded: pod/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2 container \"etcd\" is terminated: Error: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:32.165129Z\",\"caller\":\"flags/flag.go:93\",\"msg\":\"unrecognized environment variable\",\"environment-variable\":\"ETCDCTL_ENDPOINTS=\"}\nStaticPodsDegraded: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:37.166032Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc000498000/127.0.0.1:2379\",\"attempt\":0,\"error\":\"rpc error: code = DeadlineExceeded desc = latest balancer error: last connection error: connection error: desc = \\\"transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused\\\"\"}\nStaticPodsDegraded: Error: context deadline exceeded\nStaticPodsDegraded: could not parse revision.json, falling back to WAL parsing. Err=open /var/lib/etcd/revision.json: no such file or directorycould not find local cluster id: couldn't find cluster id in WAL or revision: open /var/lib/etcd/member/wal: no such file or directory\nStaticPodsDegraded: open /var/lib/etcd/revision.json: no such file or directory\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found" to "EtcdMembersControllerDegraded: giving up getting a cached client after 3 tries\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]\nStaticPodsDegraded: pod/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2 container \"etcd\" is terminated: Error: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:32.165129Z\",\"caller\":\"flags/flag.go:93\",\"msg\":\"unrecognized environment variable\",\"environment-variable\":\"ETCDCTL_ENDPOINTS=\"}\nStaticPodsDegraded: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:37.166032Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc000498000/127.0.0.1:2379\",\"attempt\":0,\"error\":\"rpc error: code = DeadlineExceeded desc = latest balancer error: last connection error: connection error: desc = \\\"transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused\\\"\"}\nStaticPodsDegraded: Error: context deadline exceeded\nStaticPodsDegraded: could not parse revision.json, falling back to WAL parsing. Err=open /var/lib/etcd/revision.json: no such file or directorycould not find local cluster id: couldn't find cluster id in WAL or revision: open /var/lib/etcd/member/wal: no such file or directory\nStaticPodsDegraded: open /var/lib/etcd/revision.json: no such file or directory\nScriptControllerDegraded: \"configmap/etcd-pod\": missing env var values\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found"
2024-10-24T13:04:44.253889315Z E1024 13:04:44.253864       1 base_controller.go:271] "Unhandled Error" err="BootstrapTeardownController reconciliation failed: failed to get bootstrap scaling strategy: failed to get openshift-etcd namespace: namespace \"openshift-etcd\" not found"
2024-10-24T13:04:44.260206045Z E1024 13:04:44.260171       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: no etcd members are present"
2024-10-24T13:04:44.264166195Z E1024 13:04:44.264123       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": missing env var values"
2024-10-24T13:04:44.306207855Z E1024 13:04:44.306155       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": missing env var values"
2024-10-24T13:04:44.306894065Z E1024 13:04:44.306850       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: no etcd members are present"
2024-10-24T13:04:44.309812375Z I1024 13:04:44.309767       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:04:44.336097125Z E1024 13:04:44.336042       1 base_controller.go:271] "Unhandled Error" err="BootstrapTeardownController reconciliation failed: failed to get bootstrap scaling strategy: failed to get openshift-etcd namespace: namespace \"openshift-etcd\" not found"
2024-10-24T13:04:44.388110185Z E1024 13:04:44.388045       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": missing env var values"
2024-10-24T13:04:44.392109405Z E1024 13:04:44.392080       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: no etcd members are present"
2024-10-24T13:04:44.404677735Z I1024 13:04:44.404636       1 base_controller.go:74] Caches are synced for TargetConfigController 
2024-10-24T13:04:44.404677735Z I1024 13:04:44.404653       1 base_controller.go:74] Caches are synced for RevisionController 
2024-10-24T13:04:44.404734955Z I1024 13:04:44.404672       1 base_controller.go:111] Starting #1 worker of RevisionController controller ...
2024-10-24T13:04:44.404734955Z I1024 13:04:44.404659       1 base_controller.go:111] Starting #1 worker of TargetConfigController controller ...
2024-10-24T13:04:44.404858945Z E1024 13:04:44.404815       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: TargetConfigController missing env var values"
2024-10-24T13:04:44.404930095Z I1024 13:04:44.404912       1 envvarcontroller.go:242] caches synced
2024-10-24T13:04:44.497938665Z E1024 13:04:44.497876       1 base_controller.go:271] "Unhandled Error" err="BootstrapTeardownController reconciliation failed: failed to get bootstrap scaling strategy: failed to get openshift-etcd namespace: namespace \"openshift-etcd\" not found"
2024-10-24T13:04:44.506451715Z I1024 13:04:44.506397       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:04:44.557367025Z E1024 13:04:44.557333       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: no etcd members are present"
2024-10-24T13:04:44.603969586Z I1024 13:04:44.603934       1 base_controller.go:74] Caches are synced for EtcdCertSignerController 
2024-10-24T13:04:44.604039736Z I1024 13:04:44.604026       1 base_controller.go:111] Starting #1 worker of EtcdCertSignerController controller ...
2024-10-24T13:04:44.651160275Z I1024 13:04:44.651121       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 58167296
2024-10-24T13:04:44.653134585Z E1024 13:04:44.652801       1 base_controller.go:271] "Unhandled Error" err="BootstrapTeardownController reconciliation failed: failed to get bootstrap scaling strategy: failed to get openshift-etcd namespace: namespace \"openshift-etcd\" not found"
2024-10-24T13:04:44.653134585Z I1024 13:04:44.653000       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:44.658934775Z E1024 13:04:44.658883       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: no etcd members are present"
2024-10-24T13:04:44.683265586Z E1024 13:04:44.683233       1 base_controller.go:271] "Unhandled Error" err="BootstrapTeardownController reconciliation failed: failed to get bootstrap scaling strategy: failed to get openshift-etcd namespace: namespace \"openshift-etcd\" not found"
2024-10-24T13:04:44.683846306Z I1024 13:04:44.683827       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:44.684925256Z I1024 13:04:44.684895       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]\nStaticPodsDegraded: pod/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2 container \"etcd\" is terminated: Error: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:32.165129Z\",\"caller\":\"flags/flag.go:93\",\"msg\":\"unrecognized environment variable\",\"environment-variable\":\"ETCDCTL_ENDPOINTS=\"}\nStaticPodsDegraded: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:37.166032Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc000498000/127.0.0.1:2379\",\"attempt\":0,\"error\":\"rpc error: code = DeadlineExceeded desc = latest balancer error: last connection error: connection error: desc = \\\"transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused\\\"\"}\nStaticPodsDegraded: Error: context deadline exceeded\nStaticPodsDegraded: could not parse revision.json, falling back to WAL parsing. Err=open /var/lib/etcd/revision.json: no such file or directorycould not find local cluster id: couldn't find cluster id in WAL or revision: open /var/lib/etcd/member/wal: no such file or directory\nStaticPodsDegraded: open /var/lib/etcd/revision.json: no such file or directory\nScriptControllerDegraded: \"configmap/etcd-pod\": missing env var values\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:31Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:04:44.697121976Z E1024 13:04:44.697080       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: no etcd members are present"
2024-10-24T13:04:44.698545346Z I1024 13:04:44.698513       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "EtcdMembersControllerDegraded: giving up getting a cached client after 3 tries\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]\nStaticPodsDegraded: pod/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2 container \"etcd\" is terminated: Error: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:32.165129Z\",\"caller\":\"flags/flag.go:93\",\"msg\":\"unrecognized environment variable\",\"environment-variable\":\"ETCDCTL_ENDPOINTS=\"}\nStaticPodsDegraded: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:37.166032Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc000498000/127.0.0.1:2379\",\"attempt\":0,\"error\":\"rpc error: code = DeadlineExceeded desc = latest balancer error: last connection error: connection error: desc = \\\"transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused\\\"\"}\nStaticPodsDegraded: Error: context deadline exceeded\nStaticPodsDegraded: could not parse revision.json, falling back to WAL parsing. Err=open /var/lib/etcd/revision.json: no such file or directorycould not find local cluster id: couldn't find cluster id in WAL or revision: open /var/lib/etcd/member/wal: no such file or directory\nStaticPodsDegraded: open /var/lib/etcd/revision.json: no such file or directory\nScriptControllerDegraded: \"configmap/etcd-pod\": missing env var values\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]\nStaticPodsDegraded: pod/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2 container \"etcd\" is terminated: Error: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:32.165129Z\",\"caller\":\"flags/flag.go:93\",\"msg\":\"unrecognized environment variable\",\"environment-variable\":\"ETCDCTL_ENDPOINTS=\"}\nStaticPodsDegraded: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:37.166032Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc000498000/127.0.0.1:2379\",\"attempt\":0,\"error\":\"rpc error: code = DeadlineExceeded desc = latest balancer error: last connection error: connection error: desc = \\\"transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused\\\"\"}\nStaticPodsDegraded: Error: context deadline exceeded\nStaticPodsDegraded: could not parse revision.json, falling back to WAL parsing. Err=open /var/lib/etcd/revision.json: no such file or directorycould not find local cluster id: couldn't find cluster id in WAL or revision: open /var/lib/etcd/member/wal: no such file or directory\nStaticPodsDegraded: open /var/lib/etcd/revision.json: no such file or directory\nScriptControllerDegraded: \"configmap/etcd-pod\": missing env var values\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found"
2024-10-24T13:04:44.706137916Z I1024 13:04:44.706116       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:04:44.763578726Z I1024 13:04:44.763544       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:44.763928986Z E1024 13:04:44.763907       1 base_controller.go:271] "Unhandled Error" err="BootstrapTeardownController reconciliation failed: failed to get bootstrap scaling strategy: failed to get openshift-etcd namespace: namespace \"openshift-etcd\" not found"
2024-10-24T13:04:44.770699286Z E1024 13:04:44.770651       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: no etcd members are present"
2024-10-24T13:04:44.774516426Z I1024 13:04:44.774486       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.02 %, dbSize: 58200064
2024-10-24T13:04:44.787165266Z I1024 13:04:44.787112       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.02 %, dbSize: 58200064
2024-10-24T13:04:44.819800356Z E1024 13:04:44.819691       1 base_controller.go:271] "Unhandled Error" err="BootstrapTeardownController reconciliation failed: failed to get bootstrap scaling strategy: failed to get openshift-etcd namespace: namespace \"openshift-etcd\" not found"
2024-10-24T13:04:44.884374006Z E1024 13:04:44.884314       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: no etcd members are present"
2024-10-24T13:04:44.906665296Z I1024 13:04:44.906617       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:04:45.004424976Z I1024 13:04:45.004320       1 base_controller.go:74] Caches are synced for ClusterMemberController 
2024-10-24T13:04:45.004568136Z I1024 13:04:45.004549       1 base_controller.go:111] Starting #1 worker of ClusterMemberController controller ...
2024-10-24T13:04:45.004634616Z I1024 13:04:45.004511       1 base_controller.go:74] Caches are synced for MissingStaticPodController 
2024-10-24T13:04:45.004676956Z I1024 13:04:45.004663       1 base_controller.go:111] Starting #1 worker of MissingStaticPodController controller ...
2024-10-24T13:04:45.005028856Z I1024 13:04:45.004957       1 base_controller.go:74] Caches are synced for InstallerController 
2024-10-24T13:04:45.005101776Z I1024 13:04:45.005086       1 base_controller.go:111] Starting #1 worker of InstallerController controller ...
2024-10-24T13:04:45.005791136Z I1024 13:04:45.005729       1 base_controller.go:74] Caches are synced for etcd-InstallerState 
2024-10-24T13:04:45.005818636Z I1024 13:04:45.005794       1 base_controller.go:111] Starting #1 worker of etcd-InstallerState controller ...
2024-10-24T13:04:45.006007076Z I1024 13:04:45.005955       1 base_controller.go:74] Caches are synced for etcd-StaticPodState 
2024-10-24T13:04:45.006107356Z I1024 13:04:45.006091       1 base_controller.go:111] Starting #1 worker of etcd-StaticPodState controller ...
2024-10-24T13:04:45.006504086Z I1024 13:04:45.006481       1 base_controller.go:74] Caches are synced for GuardController 
2024-10-24T13:04:45.006561666Z I1024 13:04:45.006548       1 base_controller.go:111] Starting #1 worker of GuardController controller ...
2024-10-24T13:04:45.007130266Z E1024 13:04:45.007109       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:04:45.007193866Z E1024 13:04:45.007180       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:04:45.053521106Z I1024 13:04:45.053463       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MemberPromote' successfully promoted learner member https://10.0.0.6:2380
2024-10-24T13:04:45.106852476Z I1024 13:04:45.106788       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:04:45.205554136Z I1024 13:04:45.205503       1 base_controller.go:74] Caches are synced for EtcdStaticResources-StaticResources 
2024-10-24T13:04:45.205554136Z I1024 13:04:45.205529       1 base_controller.go:111] Starting #1 worker of EtcdStaticResources-StaticResources controller ...
2024-10-24T13:04:45.302718897Z I1024 13:04:45.302667       1 request.go:700] Waited for 1.198341001s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/configmaps?limit=500&resourceVersion=0
2024-10-24T13:04:45.319507786Z I1024 13:04:45.319450       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:04:45.403717536Z I1024 13:04:45.403650       1 base_controller.go:74] Caches are synced for ConfigObserver 
2024-10-24T13:04:45.403717536Z I1024 13:04:45.403694       1 base_controller.go:111] Starting #1 worker of ConfigObserver controller ...
2024-10-24T13:04:45.506832516Z I1024 13:04:45.506745       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:04:45.707076007Z I1024 13:04:45.707015       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:04:45.805145937Z I1024 13:04:45.805087       1 base_controller.go:74] Caches are synced for etcd 
2024-10-24T13:04:45.805253097Z I1024 13:04:45.805235       1 base_controller.go:111] Starting #1 worker of etcd controller ...
2024-10-24T13:04:46.129471697Z I1024 13:04:46.129423       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]\nStaticPodsDegraded: pod/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2 container \"etcd\" is terminated: Error: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:32.165129Z\",\"caller\":\"flags/flag.go:93\",\"msg\":\"unrecognized environment variable\",\"environment-variable\":\"ETCDCTL_ENDPOINTS=\"}\nStaticPodsDegraded: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:37.166032Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc000498000/127.0.0.1:2379\",\"attempt\":0,\"error\":\"rpc error: code = DeadlineExceeded desc = latest balancer error: last connection error: connection error: desc = \\\"transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused\\\"\"}\nStaticPodsDegraded: Error: context deadline exceeded\nStaticPodsDegraded: could not parse revision.json, falling back to WAL parsing. Err=open /var/lib/etcd/revision.json: no such file or directorycould not find local cluster id: couldn't find cluster id in WAL or revision: open /var/lib/etcd/member/wal: no such file or directory\nStaticPodsDegraded: open /var/lib/etcd/revision.json: no such file or directory\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:31Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:04:46.130283497Z I1024 13:04:46.130254       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:46.130500517Z I1024 13:04:46.130482       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:04:46.143823068Z I1024 13:04:46.143771       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]\nStaticPodsDegraded: pod/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2 container \"etcd\" is terminated: Error: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:32.165129Z\",\"caller\":\"flags/flag.go:93\",\"msg\":\"unrecognized environment variable\",\"environment-variable\":\"ETCDCTL_ENDPOINTS=\"}\nStaticPodsDegraded: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:37.166032Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc000498000/127.0.0.1:2379\",\"attempt\":0,\"error\":\"rpc error: code = DeadlineExceeded desc = latest balancer error: last connection error: connection error: desc = \\\"transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused\\\"\"}\nStaticPodsDegraded: Error: context deadline exceeded\nStaticPodsDegraded: could not parse revision.json, falling back to WAL parsing. Err=open /var/lib/etcd/revision.json: no such file or directorycould not find local cluster id: couldn't find cluster id in WAL or revision: open /var/lib/etcd/member/wal: no such file or directory\nStaticPodsDegraded: open /var/lib/etcd/revision.json: no such file or directory\nScriptControllerDegraded: \"configmap/etcd-pod\": missing env var values\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]\nStaticPodsDegraded: pod/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2 container \"etcd\" is terminated: Error: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:32.165129Z\",\"caller\":\"flags/flag.go:93\",\"msg\":\"unrecognized environment variable\",\"environment-variable\":\"ETCDCTL_ENDPOINTS=\"}\nStaticPodsDegraded: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:37.166032Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc000498000/127.0.0.1:2379\",\"attempt\":0,\"error\":\"rpc error: code = DeadlineExceeded desc = latest balancer error: last connection error: connection error: desc = \\\"transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused\\\"\"}\nStaticPodsDegraded: Error: context deadline exceeded\nStaticPodsDegraded: could not parse revision.json, falling back to WAL parsing. Err=open /var/lib/etcd/revision.json: no such file or directorycould not find local cluster id: couldn't find cluster id in WAL or revision: open /var/lib/etcd/member/wal: no such file or directory\nStaticPodsDegraded: open /var/lib/etcd/revision.json: no such file or directory\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found"
2024-10-24T13:04:46.153932087Z I1024 13:04:46.153858       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 58380288
2024-10-24T13:04:46.159794757Z I1024 13:04:46.159768       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:46.173202037Z I1024 13:04:46.173157       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 58380288
2024-10-24T13:04:46.200574608Z I1024 13:04:46.200535       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:04:46.204313897Z I1024 13:04:46.200847       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:46.230203567Z I1024 13:04:46.230150       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 58380288
2024-10-24T13:04:46.302886558Z I1024 13:04:46.302845       1 request.go:700] Waited for 1.896017763s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-10-24T13:04:46.815194108Z I1024 13:04:46.814885       1 core.go:352] ConfigMap "openshift-etcd/etcd-endpoints" changes: {"data":{"529ebe931a1baebd":"10.0.0.6"},"metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:04:46.816726188Z I1024 13:04:46.816362       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-endpoints -n openshift-etcd:
2024-10-24T13:04:46.816726188Z cause by changes in data.529ebe931a1baebd
2024-10-24T13:04:46.817857648Z W1024 13:04:46.817822       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379]] vs. [[https://10.0.0.5:2379 https://10.0.0.6:2379]]
2024-10-24T13:04:46.818598188Z I1024 13:04:46.818558       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:46.824316818Z I1024 13:04:46.824266       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 2 triggered by "required configmap/etcd-endpoints has been created"
2024-10-24T13:04:46.828434408Z W1024 13:04:46.828402       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379]] vs. [[https://10.0.0.5:2379 https://10.0.0.6:2379]]
2024-10-24T13:04:46.828717988Z W1024 13:04:46.828682       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379]] vs. [[https://10.0.0.5:2379 https://10.0.0.6:2379]]
2024-10-24T13:04:46.849047298Z W1024 13:04:46.848998       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379]] vs. [[https://10.0.0.5:2379 https://10.0.0.6:2379]]
2024-10-24T13:04:46.852376428Z W1024 13:04:46.852346       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379]] vs. [[https://10.0.0.5:2379 https://10.0.0.6:2379]]
2024-10-24T13:04:46.854933528Z I1024 13:04:46.854895       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]\nStaticPodsDegraded: pod/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2 container \"etcd\" is terminated: Error: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:32.165129Z\",\"caller\":\"flags/flag.go:93\",\"msg\":\"unrecognized environment variable\",\"environment-variable\":\"ETCDCTL_ENDPOINTS=\"}\nStaticPodsDegraded: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:37.166032Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc000498000/127.0.0.1:2379\",\"attempt\":0,\"error\":\"rpc error: code = DeadlineExceeded desc = latest balancer error: last connection error: connection error: desc = \\\"transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused\\\"\"}\nStaticPodsDegraded: Error: context deadline exceeded\nStaticPodsDegraded: could not parse revision.json, falling back to WAL parsing. Err=open /var/lib/etcd/revision.json: no such file or directorycould not find local cluster id: couldn't find cluster id in WAL or revision: open /var/lib/etcd/member/wal: no such file or directory\nStaticPodsDegraded: open /var/lib/etcd/revision.json: no such file or directory\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:31Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:04:46.857576278Z I1024 13:04:46.855723       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:46.871200278Z I1024 13:04:46.871114       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 58531840
2024-10-24T13:04:46.876439348Z I1024 13:04:46.875061       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]\nStaticPodsDegraded: pod/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2 container \"etcd\" is terminated: Error: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:32.165129Z\",\"caller\":\"flags/flag.go:93\",\"msg\":\"unrecognized environment variable\",\"environment-variable\":\"ETCDCTL_ENDPOINTS=\"}\nStaticPodsDegraded: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:37.166032Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc000498000/127.0.0.1:2379\",\"attempt\":0,\"error\":\"rpc error: code = DeadlineExceeded desc = latest balancer error: last connection error: connection error: desc = \\\"transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused\\\"\"}\nStaticPodsDegraded: Error: context deadline exceeded\nStaticPodsDegraded: could not parse revision.json, falling back to WAL parsing. Err=open /var/lib/etcd/revision.json: no such file or directorycould not find local cluster id: couldn't find cluster id in WAL or revision: open /var/lib/etcd/member/wal: no such file or directory\nStaticPodsDegraded: open /var/lib/etcd/revision.json: no such file or directory\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]\nStaticPodsDegraded: pod/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2 container \"etcd\" is terminated: Error: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:32.165129Z\",\"caller\":\"flags/flag.go:93\",\"msg\":\"unrecognized environment variable\",\"environment-variable\":\"ETCDCTL_ENDPOINTS=\"}\nStaticPodsDegraded: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:37.166032Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc000498000/127.0.0.1:2379\",\"attempt\":0,\"error\":\"rpc error: code = DeadlineExceeded desc = latest balancer error: last connection error: connection error: desc = \\\"transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused\\\"\"}\nStaticPodsDegraded: Error: context deadline exceeded\nStaticPodsDegraded: could not parse revision.json, falling back to WAL parsing. Err=open /var/lib/etcd/revision.json: no such file or directorycould not find local cluster id: couldn't find cluster id in WAL or revision: open /var/lib/etcd/member/wal: no such file or directory\nStaticPodsDegraded: open /var/lib/etcd/revision.json: no such file or directory\nEtcdMembersDegraded: No unhealthy members found"
2024-10-24T13:04:47.303348439Z I1024 13:04:47.303287       1 request.go:700] Waited for 2.097236313s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd
2024-10-24T13:04:48.303643860Z I1024 13:04:48.303581       1 request.go:700] Waited for 1.479290132s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps
2024-10-24T13:04:48.314318630Z I1024 13:04:48.314279       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:48.709211591Z E1024 13:04:48.709145       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:04:48.715790971Z E1024 13:04:48.715719       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:04:48.715790971Z E1024 13:04:48.715738       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:04:49.503270701Z I1024 13:04:49.503220       1 request.go:700] Waited for 1.593774022s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-10-24T13:04:49.710047942Z I1024 13:04:49.709988       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 1, but has not made progress because static pod is pending
2024-10-24T13:04:49.918288022Z I1024 13:04:49.918225       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:49.921480602Z I1024 13:04:49.921421       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-pod-2 -n openshift-etcd because it was missing
2024-10-24T13:04:50.109423432Z W1024 13:04:50.109353       1 dynamic_operator_client.go:343] .status.conditions["StaticPodsDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:04:50.109423432Z W1024 13:04:50.109380       1 dynamic_operator_client.go:346] .status.conditions["StaticPodsDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:04:50.133597832Z I1024 13:04:50.133540       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:50.133815102Z I1024 13:04:50.133768       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:03:31Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:04:50.146455872Z I1024 13:04:50.146255       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]\nStaticPodsDegraded: pod/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2 container \"etcd\" is terminated: Error: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:32.165129Z\",\"caller\":\"flags/flag.go:93\",\"msg\":\"unrecognized environment variable\",\"environment-variable\":\"ETCDCTL_ENDPOINTS=\"}\nStaticPodsDegraded: {\"level\":\"warn\",\"ts\":\"2024-10-24T13:04:37.166032Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc000498000/127.0.0.1:2379\",\"attempt\":0,\"error\":\"rpc error: code = DeadlineExceeded desc = latest balancer error: last connection error: connection error: desc = \\\"transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused\\\"\"}\nStaticPodsDegraded: Error: context deadline exceeded\nStaticPodsDegraded: could not parse revision.json, falling back to WAL parsing. Err=open /var/lib/etcd/revision.json: no such file or directorycould not find local cluster id: couldn't find cluster id in WAL or revision: open /var/lib/etcd/member/wal: no such file or directory\nStaticPodsDegraded: open /var/lib/etcd/revision.json: no such file or directory\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]\nEtcdMembersDegraded: No unhealthy members found"
2024-10-24T13:04:50.704087603Z I1024 13:04:50.703679       1 request.go:700] Waited for 1.394008642s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:04:50.717106433Z I1024 13:04:50.716782       1 core.go:352] ConfigMap "openshift-etcd/etcd-scripts" changes: {"apiVersion":"v1","data":{"etcd.env":"export ALL_ETCD_ENDPOINTS=\"https://10.0.0.5:2379,https://10.0.0.6:2379\"\nexport ETCDCTL_API=\"3\"\nexport ETCDCTL_CACERT=\"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\nexport ETCDCTL_CERT=\"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\nexport ETCDCTL_ENDPOINTS=\"https://10.0.0.6:2379\"\nexport ETCDCTL_KEY=\"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\nexport ETCD_CIPHER_SUITES=\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\nexport ETCD_DATA_DIR=\"/var/lib/etcd\"\nexport ETCD_ELECTION_TIMEOUT=\"1000\"\nexport ETCD_ENABLE_PPROF=\"true\"\nexport ETCD_EXPERIMENTAL_MAX_LEARNERS=\"3\"\nexport ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION=\"200ms\"\nexport ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL=\"5s\"\nexport ETCD_HEARTBEAT_INTERVAL=\"100\"\nexport ETCD_IMAGE=\"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\nexport ETCD_INITIAL_CLUSTER_STATE=\"existing\"\nexport ETCD_QUOTA_BACKEND_BYTES=\"8589934592\"\nexport ETCD_SOCKET_REUSE_ADDRESS=\"true\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME=\"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST=\"10.0.0.3\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP=\"10.0.0.3\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME=\"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST=\"10.0.0.4\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP=\"10.0.0.4\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME=\"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST=\"10.0.0.6\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP=\"10.0.0.6\"\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:04:50.720779343Z I1024 13:04:50.717720       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-scripts -n openshift-etcd:
2024-10-24T13:04:50.720779343Z cause by changes in data.etcd.env
2024-10-24T13:04:50.720779343Z I1024 13:04:50.718174       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:50.921316653Z I1024 13:04:50.920816       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:50.922640693Z I1024 13:04:50.922601       1 core.go:352] ConfigMap "openshift-etcd/etcd-pod" changes: {"apiVersion":"v1","data":{"pod.yaml":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: etcd\n  namespace: openshift-etcd\n  annotations:\n    kubectl.kubernetes.io/default-container: etcd\n    target.workload.openshift.io/management: '{\"effect\": \"PreferredDuringScheduling\"}'\n  labels:\n    app: etcd\n    k8s-app: etcd\n    etcd: \"true\"\n    revision: \"REVISION\"\nspec:\n  initContainers:\n    - name: setup\n      image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          echo -n \"Fixing etcd log permissions.\"\n          mkdir -p /var/log/etcd  \u0026\u0026 chmod 0600 /var/log/etcd\n          echo -n \"Fixing etcd auto backup permissions.\"\n          mkdir -p /var/lib/etcd-auto-backup  \u0026\u0026 chmod 0600 /var/lib/etcd-auto-backup\n      securityContext:\n        privileged: true\n      resources:\n        requests:\n          memory: 50Mi\n          cpu: 5m\n      volumeMounts:\n        - mountPath: /var/log/etcd\n          name: log-dir\n    - name: etcd-ensure-env-vars\n      image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          set -euo pipefail\n\n          : \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST?not set}\"\n          : \"${NODE_NODE_ENVVAR_NAME_ETCD_NAME?not set}\"\n          : \"${NODE_NODE_ENVVAR_NAME_IP?not set}\"\n\n          # check for ipv4 addresses as well as ipv6 addresses with extra square brackets\n          if [[ \"${NODE_NODE_ENVVAR_NAME_IP}\" != \"${NODE_IP}\" \u0026\u0026 \"${NODE_NODE_ENVVAR_NAME_IP}\" != \"[${NODE_IP}]\" ]]; then\n            # echo the error message to stderr\n            echo \"Expected node IP to be ${NODE_IP} got ${NODE_NODE_ENVVAR_NAME_IP}\" \u003e\u00262\n            exit 1\n          fi\n\n          # check for ipv4 addresses as well as ipv6 addresses with extra square brackets\n          if [[ \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" != \"${NODE_IP}\" \u0026\u0026 \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" != \"[${NODE_IP}]\" ]]; then\n            # echo the error message to stderr\n            echo \"Expected etcd url host to be ${NODE_IP} got ${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" \u003e\u00262\n            exit 1\n          fi\n\n      resources:\n        requests:\n          memory: 60Mi\n          cpu: 10m\n      securityContext:\n        privileged: true\n      env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.5:2379,https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"1000\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"100\"\n      - name: \"ETCD_IMAGE\"\n        value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n        value: \"10.0.0.6\"\n      - name: NODE_IP\n        valueFrom:\n          fieldRef:\n            fieldPath: status.podIP\n    - name: etcd-resources-copy\n      image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          set -euo pipefail\n\n          rm -f $(grep -l '^### Created by cluster-etcd-operator' /usr/local/bin/*)\n          cp -p /etc/kubernetes/static-pod-certs/configmaps/etcd-scripts/*.sh /usr/local/bin\n\n      resources:\n        requests:\n          memory: 60Mi\n          cpu: 10m\n      securityContext:\n        privileged: true\n      volumeMounts:\n        - mountPath: /etc/kubernetes/static-pod-resources\n          name: resource-dir\n        - mountPath: /etc/kubernetes/static-pod-certs\n          name: cert-dir\n        - mountPath: /usr/local/bin\n          name: usr-local-bin\n  containers:\n  # The etcdctl container should always be first. It is intended to be used\n  # to open a remote shell via `oc rsh` that is ready to run `etcdctl`.\n  - name: etcdctl\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - \"/bin/bash\"\n      - \"-c\"\n      - \"trap TERM INT; sleep infinity \u0026 wait\"\n    resources:\n      requests:\n        memory: 60Mi\n        cpu: 10m\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n    env:\n    - name: \"ALL_ETCD_ENDPOINTS\"\n      value: \"https://10.0.0.5:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_API\"\n      value: \"3\"\n    - name: \"ETCDCTL_CACERT\"\n      value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n    - name: \"ETCDCTL_CERT\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n    - name: \"ETCDCTL_ENDPOINTS\"\n      value: \"https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_KEY\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n    - name: \"ETCD_CIPHER_SUITES\"\n      value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n    - name: \"ETCD_DATA_DIR\"\n      value: \"/var/lib/etcd\"\n    - name: \"ETCD_ELECTION_TIMEOUT\"\n      value: \"1000\"\n    - name: \"ETCD_ENABLE_PPROF\"\n      value: \"true\"\n    - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n      value: \"3\"\n    - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n      value: \"200ms\"\n    - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n      value: \"5s\"\n    - name: \"ETCD_HEARTBEAT_INTERVAL\"\n      value: \"100\"\n    - name: \"ETCD_IMAGE\"\n      value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n    - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n      value: \"existing\"\n    - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n      value: \"8589934592\"\n    - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n      value: \"true\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n      value: \"10.0.0.6\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n      value: \"10.0.0.6\"\n    - name: \"ETCD_STATIC_POD_VERSION\"\n      value: \"REVISION\"\n  - name: etcd\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n\n        etcdctl member list || true\n\n        # this has a non-zero return code if the command is non-zero.  If you use an export first, it doesn't and you\n        # will succeed when you should fail.\n        ETCD_INITIAL_CLUSTER=$(discover-etcd-initial-cluster \\\n          --cacert=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --cert=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --key=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --endpoints=${ALL_ETCD_ENDPOINTS} \\\n          --data-dir=/var/lib/etcd \\\n          --target-peer-url-host=${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST} \\\n          --target-name=NODE_NAME)\n        export ETCD_INITIAL_CLUSTER\n\n        # we cannot use the \"normal\" port conflict initcontainer because when we upgrade, the existing static pod will never yield,\n        # so we do the detection in etcd container itself.\n        echo -n \"Waiting for ports 2379, 2380 and 9978 to be released.\"\n        time while [ -n \"$(ss -Htan '( sport = 2379 or sport = 2380 or sport = 9978 )')\" ]; do\n          echo -n \".\"\n          sleep 1\n        done\n\n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n        env | grep ETCD | grep -v NODE\n\n        set -x\n        # See https://etcd.io/docs/v3.4.0/tuning/ for why we use ionice\n        exec nice -n -19 ionice -c2 -n0 etcd \\\n          --logger=zap \\\n          --log-level=info \\\n          --experimental-initial-corrupt-check=true \\\n          --snapshot-count=10000 \\\n          --initial-advertise-peer-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2380 \\\n          --cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --client-cert-auth=true \\\n          --peer-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --peer-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --peer-trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --peer-client-cert-auth=true \\\n          --advertise-client-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2379 \\\n          --listen-client-urls=https://0.0.0.0:2379,unixs://${NODE_NODE_ENVVAR_NAME_IP}:0 \\\n          --listen-peer-urls=https://0.0.0.0:2380 \\\n          --metrics=extensive \\\n          --listen-metrics-urls=https://0.0.0.0:9978 ||  mv /etc/kubernetes/etcd-backup-dir/etcd-member.yaml /etc/kubernetes/manifests\n    env:\n    - name: \"ALL_ETCD_ENDPOINTS\"\n      value: \"https://10.0.0.5:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_API\"\n      value: \"3\"\n    - name: \"ETCDCTL_CACERT\"\n      value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n    - name: \"ETCDCTL_CERT\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n    - name: \"ETCDCTL_ENDPOINTS\"\n      value: \"https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_KEY\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n    - name: \"ETCD_CIPHER_SUITES\"\n      value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n    - name: \"ETCD_DATA_DIR\"\n      value: \"/var/lib/etcd\"\n    - name: \"ETCD_ELECTION_TIMEOUT\"\n      value: \"1000\"\n    - name: \"ETCD_ENABLE_PPROF\"\n      value: \"true\"\n    - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n      value: \"3\"\n    - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n      value: \"200ms\"\n    - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n      value: \"5s\"\n    - name: \"ETCD_HEARTBEAT_INTERVAL\"\n      value: \"100\"\n    - name: \"ETCD_IMAGE\"\n      value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n    - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n      value: \"existing\"\n    - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n      value: \"8589934592\"\n    - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n      value: \"true\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n      value: \"10.0.0.6\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n      value: \"10.0.0.6\"\n    - name: \"ETCD_STATIC_POD_VERSION\"\n      value: \"REVISION\"\n    resources:\n      requests:\n        memory: 600Mi\n        cpu: 300m\n    readinessProbe:\n      httpGet:\n        port: 9980\n        path: readyz\n        scheme: HTTPS\n      timeoutSeconds: 30\n      failureThreshold: 5\n      periodSeconds: 5\n      successThreshold: 1\n    livenessProbe:\n      httpGet:\n        path: healthz\n        port: 9980\n        scheme: HTTPS\n      timeoutSeconds: 30\n      periodSeconds: 5\n      successThreshold: 1\n      failureThreshold: 5\n    startupProbe:\n      httpGet:\n        port: 9980\n        path: readyz\n        scheme: HTTPS\n      initialDelaySeconds: 10\n      timeoutSeconds: 1\n      periodSeconds: 10\n      successThreshold: 1\n      failureThreshold: 18\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n  - name: etcd-metrics\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n\n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n\n        exec nice -n -18 etcd grpc-proxy start \\\n          --endpoints https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:9978 \\\n          --metrics-addr https://0.0.0.0:9979 \\\n          --listen-addr 127.0.0.1:9977 \\\n          --advertise-client-url \"\"  \\\n          --key /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --key-file /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-metrics-NODE_NAME.key \\\n          --cert /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --cert-file /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-metrics-NODE_NAME.crt \\\n          --cacert /etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --trusted-ca-file /etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/metrics-ca-bundle.crt \\\n          --listen-cipher-suites ${ETCD_CIPHER_SUITES}\n    env:\n    - name: \"ALL_ETCD_ENDPOINTS\"\n      value: \"https://10.0.0.5:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_API\"\n      value: \"3\"\n    - name: \"ETCDCTL_CACERT\"\n      value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n    - name: \"ETCDCTL_CERT\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n    - name: \"ETCDCTL_ENDPOINTS\"\n      value: \"https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_KEY\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n    - name: \"ETCD_CIPHER_SUITES\"\n      value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n    - name: \"ETCD_DATA_DIR\"\n      value: \"/var/lib/etcd\"\n    - name: \"ETCD_ELECTION_TIMEOUT\"\n      value: \"1000\"\n    - name: \"ETCD_ENABLE_PPROF\"\n      value: \"true\"\n    - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n      value: \"3\"\n    - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n      value: \"200ms\"\n    - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n      value: \"5s\"\n    - name: \"ETCD_HEARTBEAT_INTERVAL\"\n      value: \"100\"\n    - name: \"ETCD_IMAGE\"\n      value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n    - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n      value: \"existing\"\n    - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n      value: \"8589934592\"\n    - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n      value: \"true\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n      value: \"10.0.0.6\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n      value: \"10.0.0.6\"\n    - name: \"ETCD_STATIC_POD_VERSION\"\n      value: \"REVISION\"\n    resources:\n      requests:\n        memory: 200Mi\n        cpu: 40m\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n  - name: etcd-readyz\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:f99379698faa42b7db0e7367c8e7f738a69f699f414a7567a5593a530fb6723d\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n        \n        exec nice -n -18 cluster-etcd-operator readyz \\\n          --target=https://localhost:2379 \\\n          --listen-port=9980 \\\n          --serving-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --serving-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --client-cert-file=$(ETCDCTL_CERT) \\\n          --client-key-file=$(ETCDCTL_KEY) \\\n          --client-cacert-file=$(ETCDCTL_CACERT) \\\n          --listen-cipher-suites=$(ETCD_CIPHER_SUITES)\n    securityContext:\n      privileged: true\n    ports:\n    - containerPort: 9980\n      name: readyz\n      protocol: TCP\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    env:\n    - name: \"ALL_ETCD_ENDPOINTS\"\n      value: \"https://10.0.0.5:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_API\"\n      value: \"3\"\n    - name: \"ETCDCTL_CACERT\"\n      value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n    - name: \"ETCDCTL_CERT\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n    - name: \"ETCDCTL_ENDPOINTS\"\n      value: \"https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_KEY\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n    - name: \"ETCD_CIPHER_SUITES\"\n      value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n    - name: \"ETCD_DATA_DIR\"\n      value: \"/var/lib/etcd\"\n    - name: \"ETCD_ELECTION_TIMEOUT\"\n      value: \"1000\"\n    - name: \"ETCD_ENABLE_PPROF\"\n      value: \"true\"\n    - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n      value: \"3\"\n    - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n      value: \"200ms\"\n    - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n      value: \"5s\"\n    - name: \"ETCD_HEARTBEAT_INTERVAL\"\n      value: \"100\"\n    - name: \"ETCD_IMAGE\"\n      value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n    - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n      value: \"existing\"\n    - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n      value: \"8589934592\"\n    - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n      value: \"true\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n      value: \"10.0.0.6\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n      value: \"10.0.0.6\"\n    volumeMounts:\n      - mountPath: /var/log/etcd/\n        name: log-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n  - name: etcd-rev\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:f99379698faa42b7db0e7367c8e7f738a69f699f414a7567a5593a530fb6723d\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n        \n        cluster-etcd-operator rev \\\n          --endpoints=$(ALL_ETCD_ENDPOINTS) \\\n          --client-cert-file=$(ETCDCTL_CERT) \\\n          --client-key-file=$(ETCDCTL_KEY) \\\n          --client-cacert-file=$(ETCDCTL_CACERT)\n    securityContext:\n      privileged: true\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    env:\n    - name: \"ALL_ETCD_ENDPOINTS\"\n      value: \"https://10.0.0.5:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_API\"\n      value: \"3\"\n    - name: \"ETCDCTL_CACERT\"\n      value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n    - name: \"ETCDCTL_CERT\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n    - name: \"ETCDCTL_ENDPOINTS\"\n      value: \"https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_KEY\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n    - name: \"ETCD_CIPHER_SUITES\"\n      value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n    - name: \"ETCD_DATA_DIR\"\n      value: \"/var/lib/etcd\"\n    - name: \"ETCD_ELECTION_TIMEOUT\"\n      value: \"1000\"\n    - name: \"ETCD_ENABLE_PPROF\"\n      value: \"true\"\n    - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n      value: \"3\"\n    - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n      value: \"200ms\"\n    - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n      value: \"5s\"\n    - name: \"ETCD_HEARTBEAT_INTERVAL\"\n      value: \"100\"\n    - name: \"ETCD_IMAGE\"\n      value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n    - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n      value: \"existing\"\n    - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n      value: \"8589934592\"\n    - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n      value: \"true\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n      value: \"10.0.0.6\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n      value: \"10.0.0.6\"\n    volumeMounts:\n    - mountPath: /var/lib/etcd\n      name: data-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n  hostNetwork: true\n  priorityClassName: system-node-critical\n  tolerations:\n  - operator: \"Exists\"\n  volumes:\n    - hostPath:\n        path: /etc/kubernetes/manifests\n      name: static-pod-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-pod-REVISION\n      name: resource-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-certs\n      name: cert-dir\n    - hostPath:\n        path: /var/lib/etcd\n        type: \"\"\n      name: data-dir\n    - hostPath:\n        path: /usr/local/bin\n      name: usr-local-bin\n    - hostPath:\n        path: /var/log/etcd\n      name: log-dir\n    - hostPath:\n        path: /etc/kubernetes\n      name: config-dir\n    - hostPath:\n        path: /var/lib/etcd-auto-backup\n      name: etcd-auto-backup-dir\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:04:50.923827003Z I1024 13:04:50.923789       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-pod -n openshift-etcd:
2024-10-24T13:04:50.923827003Z cause by changes in data.pod.yaml
2024-10-24T13:04:51.312838363Z I1024 13:04:51.312037       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:51.315796684Z I1024 13:04:51.315092       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-endpoints-2 -n openshift-etcd because it was missing
2024-10-24T13:04:51.903905605Z I1024 13:04:51.903633       1 request.go:700] Waited for 1.595457022s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:04:51.910949045Z E1024 13:04:51.910899       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:04:52.903904315Z I1024 13:04:52.903653       1 request.go:700] Waited for 1.588777003s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps
2024-10-24T13:04:52.917579776Z I1024 13:04:52.917381       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:52.917678545Z I1024 13:04:52.917631       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-all-bundles-2 -n openshift-etcd because it was missing
2024-10-24T13:04:53.733430587Z I1024 13:04:53.733351       1 core.go:352] ConfigMap "openshift-etcd/restore-etcd-pod" changes: {"apiVersion":"v1","data":{"pod.yaml":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: etcd\n  namespace: openshift-etcd\n  labels:\n    app: etcd\n    k8s-app: etcd\n    etcd: \"true\"\n    revision: \"REVISION\"\nspec:\n  containers:\n  - name: etcd\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n               \n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n        export ETCD_INITIAL_CLUSTER=\"${ETCD_NAME}=https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:2380\"\n        env | grep ETCD | grep -v NODE\n        export ETCD_NODE_PEER_URL=https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:2380\n        export REV_JSON=\"/var/lib/etcd-backup/revision.json\"\n        export SNAPSHOT_FILE=\"/var/lib/etcd-backup/snapshot.db\"\n\n        # checking if data directory is empty, if not etcdctl restore will fail         \n        if [ -n \"$(ls -A \"/var/lib/etcd\")\" ]; then\n          echo \"please delete the contents of the /var/lib/etcd directory before restoring, running the restore script will do this for you\"\n          exit 1\n        fi\n        \n        ETCD_ETCDCTL_BIN=\"etcdctl\"\n        if [ -x \"$(command -v etcdutl)\" ]; then\n          echo \"found etcdutl, using that instead of etcdctl for local operations\"\n          ETCD_ETCDCTL_BIN=\"etcdutl\"\n        fi      \n\n        # check if we have backup file to be restored\n        # if the file exist, check if it has not changed size in last 5 seconds\n        if [ ! -f \"${SNAPSHOT_FILE}\" ]; then\n          echo \"please make a copy of the snapshot db file, then move that copy to ${SNAPSHOT_FILE}\"\n          exit 1\n        else\n          filesize=$(stat --format=%s \"${SNAPSHOT_FILE}\")\n          sleep 5\n          newfilesize=$(stat --format=%s \"${SNAPSHOT_FILE}\")\n          if [ \"$filesize\" != \"$newfilesize\" ]; then\n            echo \"file size has changed since last 5 seconds, retry sometime after copying is complete\"\n            exit 1\n          fi\n        fi\n        \n        SNAPSHOT_REV=$(etcdutl snapshot status -wjson \"$SNAPSHOT_FILE\" | jq -r \".revision\")\n        echo \"snapshot is at revision ${SNAPSHOT_REV}\"\n        \n        if [ -n \"$(ls -A \"${REV_JSON}\")\" ]; then\n           # this will bump by the amount of the last known live revision + 20% slack.\n           # Note: the bump amount is an addition to the current revision stored in the snapshot.\n           # We're avoiding to do any math with SNAPSHOT_REV, uint64 has plenty of space to double revisions\n           # and we're assuming that full disaster restores are a very rare occurrence anyway.\n           BUMP_REV=$(jq -r \"(.maxRaftIndex*1.2|floor)\" \"${REV_JSON}\")\n           echo \"bumping revisions by ${BUMP_REV}\"\n        else\n           # we can't take SNAPSHOT_REV as an indicator here, because the snapshot might be much older\n           # than any currently live served revision. \n           # 1bn would be an etcd running at 1000 writes/s for about eleven days.\n           echo \"no revision.json found, assuming a 1bn revision bump\"\n           BUMP_REV=1000000000\n        fi\n        \n        UUID=$(uuidgen)\n        echo \"restoring to a single node cluster\"\n        ${ETCD_ETCDCTL_BIN} snapshot restore \"${SNAPSHOT_FILE}\" \\\n         --name $ETCD_NAME \\\n         --initial-cluster=$ETCD_INITIAL_CLUSTER \\\n         --initial-cluster-token \"openshift-etcd-${UUID}\" \\\n         --initial-advertise-peer-urls $ETCD_NODE_PEER_URL \\\n         --data-dir=\"/var/lib/etcd/restore-${UUID}\" \\\n         --mark-compacted \\\n         --bump-revision \"${BUMP_REV}\"\n\n        mv /var/lib/etcd/restore-${UUID}/* /var/lib/etcd/\n        # copy the revision.json back in case a second restore needs to be run afterwards\n        if [ -n \"$(ls -A \"${REV_JSON}\")\" ]; then\n           cp ${REV_JSON} /var/lib/etcd/\n        fi\n\n        rmdir /var/lib/etcd/restore-${UUID}\n        rm /var/lib/etcd-backup/snapshot.db\n\n        set -x\n        exec etcd \\\n          --logger=zap \\\n          --log-level=info \\\n          --initial-advertise-peer-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2380 \\\n          --cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --client-cert-auth=true \\\n          --peer-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --peer-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --peer-trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --peer-client-cert-auth=true \\\n          --advertise-client-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2379 \\\n          --listen-client-urls=https://0.0.0.0:2379 \\\n          --listen-peer-urls=https://0.0.0.0:2380 \\\n          --metrics=extensive \\\n          --listen-metrics-urls=https://0.0.0.0:9978\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.5:2379,https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"1000\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"100\"\n      - name: \"ETCD_IMAGE\"\n        value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n        value: \"10.0.0.6\"\n      - name: \"ETCD_STATIC_POD_REV\"\n        value: \"REVISION\"\n    resources:\n      requests:\n        memory: 600Mi\n        cpu: 300m\n    readinessProbe:\n      tcpSocket:\n        port: 2380\n      failureThreshold: 3\n      initialDelaySeconds: 3\n      periodSeconds: 5\n      successThreshold: 1\n      timeoutSeconds: 5\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n      - mountPath: /var/lib/etcd-backup/\n        name: backup-dir\n  hostNetwork: true\n  priorityClassName: system-node-critical\n  tolerations:\n  - operator: \"Exists\"\n  volumes:\n    - hostPath:\n        path: /etc/kubernetes/manifests\n      name: static-pod-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-certs\n      name: cert-dir\n    - hostPath:\n        path: /var/lib/etcd\n        type: \"\"\n      name: data-dir\n    - hostPath:\n        path: /var/lib/etcd-backup\n        type: \"\"\n      name: backup-dir\n","quorum-restore-pod.yaml":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: etcd\n  namespace: openshift-etcd\n  labels:\n    app: etcd\n    k8s-app: etcd\n    etcd: \"true\"\n    revision: \"REVISION\"\nspec:\n  containers:\n  - name: etcd\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n        \n        set -x\n        exec etcd \\\n          --logger=zap \\\n          --log-level=info \\\n          --force-new-cluster \\\n          --name=\"${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\" \\\n          --initial-cluster=\"${NODE_NODE_ENVVAR_NAME_ETCD_NAME}=https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:2380\" \\\n          --initial-advertise-peer-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2380 \\\n          --cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --client-cert-auth=true \\\n          --peer-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --peer-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --peer-trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --peer-client-cert-auth=true \\\n          --advertise-client-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2379 \\\n          --listen-client-urls=https://0.0.0.0:2379 \\\n          --listen-peer-urls=https://0.0.0.0:2380 \\\n          --metrics=extensive \\\n          --listen-metrics-urls=https://0.0.0.0:9978\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.5:2379,https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"1000\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"100\"\n      - name: \"ETCD_IMAGE\"\n        value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n        value: \"10.0.0.6\"\n      - name: \"ETCD_STATIC_POD_REV\"\n        value: \"REVISION\"\n    resources:\n      requests:\n        memory: 600Mi\n        cpu: 300m\n    readinessProbe:\n      tcpSocket:\n        port: 2380\n      failureThreshold: 3\n      initialDelaySeconds: 3\n      periodSeconds: 5\n      successThreshold: 1\n      timeoutSeconds: 5\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n      - mountPath: /var/lib/etcd-backup/\n        name: backup-dir\n  hostNetwork: true\n  priorityClassName: system-node-critical\n  tolerations:\n  - operator: \"Exists\"\n  volumes:\n    - hostPath:\n        path: /etc/kubernetes/manifests\n      name: static-pod-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-certs\n      name: cert-dir\n    - hostPath:\n        path: /var/lib/etcd\n        type: \"\"\n      name: data-dir\n    - hostPath:\n        path: /var/lib/etcd-backup\n        type: \"\"\n      name: backup-dir\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:04:53.735199217Z I1024 13:04:53.735092       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/restore-etcd-pod -n openshift-etcd:
2024-10-24T13:04:53.735199217Z cause by changes in data.pod.yaml,data.quorum-restore-pod.yaml
2024-10-24T13:04:53.735865157Z I1024 13:04:53.735720       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:53.910018097Z I1024 13:04:53.909929       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:04:53.910018097Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:04:53.910018097Z  CurrentRevision: (int32) 1,
2024-10-24T13:04:53.910018097Z  TargetRevision: (int32) 0,
2024-10-24T13:04:53.910018097Z  LastFailedRevision: (int32) 0,
2024-10-24T13:04:53.910018097Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:04:53.910018097Z  LastFailedReason: (string) "",
2024-10-24T13:04:53.910018097Z  LastFailedCount: (int) 0,
2024-10-24T13:04:53.910018097Z  LastFallbackCount: (int) 0,
2024-10-24T13:04:53.910018097Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:04:53.910018097Z }
2024-10-24T13:04:53.910018097Z  because static pod is ready
2024-10-24T13:04:53.939603687Z I1024 13:04:53.939531       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 0 to 1 because static pod is ready
2024-10-24T13:04:53.941087927Z I1024 13:04:53.941039       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:04:53.941666257Z I1024 13:04:53.941625       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:53.957163907Z I1024 13:04:53.957113       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.02 %, dbSize: 60010496
2024-10-24T13:04:54.000119857Z I1024 13:04:53.998251       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1" to "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1",Available changed from False to True ("StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1\nEtcdMembersAvailable: 2 members are available")
2024-10-24T13:04:54.102913177Z I1024 13:04:54.102868       1 request.go:700] Waited for 1.185392731s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets
2024-10-24T13:04:54.131691987Z I1024 13:04:54.131652       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-all-certs-2 -n openshift-etcd because it was missing
2024-10-24T13:04:54.712536368Z E1024 13:04:54.712486       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:04:54.712536368Z E1024 13:04:54.712508       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:04:54.713528068Z E1024 13:04:54.713493       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:04:55.103618499Z I1024 13:04:55.103569       1 request.go:700] Waited for 1.595406492s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa
2024-10-24T13:04:55.913707250Z W1024 13:04:55.912180       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:04:55.913707250Z W1024 13:04:55.912205       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:04:55.914094770Z I1024 13:04:55.914042       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "required configmap/etcd-endpoints has been created"
2024-10-24T13:04:55.914375289Z I1024 13:04:55.914352       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:55.935723240Z W1024 13:04:55.935647       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:04:55.935723240Z W1024 13:04:55.935676       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:04:55.937552470Z I1024 13:04:55.937526       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:55.954086900Z I1024 13:04:55.953979       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 60502016
2024-10-24T13:04:55.963636490Z I1024 13:04:55.963591       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 3 triggered by "required configmap/etcd-pod has changed"
2024-10-24T13:04:56.303074840Z I1024 13:04:56.302887       1 request.go:700] Waited for 1.759999592s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-10-24T13:04:57.303409181Z I1024 13:04:57.303106       1 request.go:700] Waited for 1.772617382s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-1-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:04:57.717619342Z I1024 13:04:57.716539       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:58.109538962Z E1024 13:04:58.109248       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:04:58.109538962Z E1024 13:04:58.109493       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:04:58.110685242Z E1024 13:04:58.110634       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:04:58.112109292Z E1024 13:04:58.112067       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:04:58.112109292Z E1024 13:04:58.112093       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:04:58.502861573Z I1024 13:04:58.502800       1 request.go:700] Waited for 1.572874802s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa
2024-10-24T13:04:58.910326863Z I1024 13:04:58.910266       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:04:58.910326863Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:04:58.910326863Z  CurrentRevision: (int32) 1,
2024-10-24T13:04:58.910326863Z  TargetRevision: (int32) 0,
2024-10-24T13:04:58.910326863Z  LastFailedRevision: (int32) 0,
2024-10-24T13:04:58.910326863Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:04:58.910326863Z  LastFailedReason: (string) "",
2024-10-24T13:04:58.910326863Z  LastFailedCount: (int) 0,
2024-10-24T13:04:58.910326863Z  LastFallbackCount: (int) 0,
2024-10-24T13:04:58.910326863Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:04:58.910326863Z }
2024-10-24T13:04:58.910326863Z  because static pod is ready
2024-10-24T13:04:58.930868943Z I1024 13:04:58.930824       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 0 to 1 because static pod is ready
2024-10-24T13:04:58.932001454Z I1024 13:04:58.931964       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:58.933727543Z I1024 13:04:58.933679       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 2","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 2\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:04:58.945689433Z I1024 13:04:58.945636       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1" to "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 2",Available message changed from "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1\nEtcdMembersAvailable: 2 members are available" to "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 2\nEtcdMembersAvailable: 2 members are available"
2024-10-24T13:04:58.949600143Z I1024 13:04:58.949571       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.03 %, dbSize: 60780544
2024-10-24T13:04:59.121788304Z I1024 13:04:59.119708       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-pod-3 -n openshift-etcd because it was missing
2024-10-24T13:04:59.121788304Z I1024 13:04:59.119947       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:04:59.504232044Z I1024 13:04:59.504138       1 request.go:700] Waited for 1.391684471s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:00.703672875Z I1024 13:05:00.703456       1 request.go:700] Waited for 1.583764332s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps
2024-10-24T13:05:00.713012635Z I1024 13:05:00.711602       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-endpoints-3 -n openshift-etcd because it was missing
2024-10-24T13:05:00.713012635Z I1024 13:05:00.711805       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:01.110691036Z E1024 13:05:01.110496       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:05:01.112059186Z E1024 13:05:01.112014       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:01.703637196Z I1024 13:05:01.703574       1 request.go:700] Waited for 1.187583542s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:01.708839486Z I1024 13:05:01.708797       1 installer_controller.go:534] node ci-op-2fcpj5j6-f6035-2lklf-master-0 static pod not found and needs new revision 2
2024-10-24T13:05:01.708875126Z I1024 13:05:01.708840       1 installer_controller.go:542] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:05:01.708875126Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:05:01.708875126Z  CurrentRevision: (int32) 0,
2024-10-24T13:05:01.708875126Z  TargetRevision: (int32) 2,
2024-10-24T13:05:01.708875126Z  LastFailedRevision: (int32) 0,
2024-10-24T13:05:01.708875126Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:05:01.708875126Z  LastFailedReason: (string) "",
2024-10-24T13:05:01.708875126Z  LastFailedCount: (int) 0,
2024-10-24T13:05:01.708875126Z  LastFallbackCount: (int) 0,
2024-10-24T13:05:01.708875126Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:05:01.708875126Z }
2024-10-24T13:05:01.732725877Z I1024 13:05:01.732684       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 0 to 2 because node ci-op-2fcpj5j6-f6035-2lklf-master-0 static pod not found
2024-10-24T13:05:01.734928447Z I1024 13:05:01.734888       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:01.753179087Z I1024 13:05:01.753119       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.03 %, dbSize: 61628416
2024-10-24T13:05:01.911069137Z I1024 13:05:01.910985       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-all-bundles-3 -n openshift-etcd because it was missing
2024-10-24T13:05:01.912520147Z I1024 13:05:01.912429       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:02.903147808Z I1024 13:05:02.903091       1 request.go:700] Waited for 1.170009272s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:03.520986919Z I1024 13:05:03.520873       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-all-certs-3 -n openshift-etcd because it was missing
2024-10-24T13:05:03.903404250Z I1024 13:05:03.903283       1 request.go:700] Waited for 1.593034353s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:03.908679990Z E1024 13:05:03.908622       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:03.909560360Z E1024 13:05:03.909518       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:05:03.910876060Z E1024 13:05:03.910839       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:03.910876060Z E1024 13:05:03.910862       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:04.508851030Z I1024 13:05:04.508797       1 installer_controller.go:534] node ci-op-2fcpj5j6-f6035-2lklf-master-0 static pod not found and needs new revision 2
2024-10-24T13:05:04.508851030Z I1024 13:05:04.508845       1 installer_controller.go:542] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:05:04.508851030Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:05:04.508851030Z  CurrentRevision: (int32) 0,
2024-10-24T13:05:04.508851030Z  TargetRevision: (int32) 2,
2024-10-24T13:05:04.508851030Z  LastFailedRevision: (int32) 0,
2024-10-24T13:05:04.508851030Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:05:04.508851030Z  LastFailedReason: (string) "",
2024-10-24T13:05:04.508851030Z  LastFailedCount: (int) 0,
2024-10-24T13:05:04.508851030Z  LastFallbackCount: (int) 0,
2024-10-24T13:05:04.508851030Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:05:04.508851030Z }
2024-10-24T13:05:04.711465401Z W1024 13:05:04.711397       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:05:04.711465401Z W1024 13:05:04.711429       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:05:04.711651790Z I1024 13:05:04.711625       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:04.711729501Z I1024 13:05:04.711688       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 3 triggered by "required configmap/etcd-pod has changed"
2024-10-24T13:05:04.733262061Z W1024 13:05:04.733210       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:05:04.733262061Z W1024 13:05:04.733239       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:05:04.733648651Z I1024 13:05:04.733610       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:04.754048721Z I1024 13:05:04.754014       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 62033920
2024-10-24T13:05:05.102663051Z I1024 13:05:05.102582       1 request.go:700] Waited for 1.191408961s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:06.103317153Z I1024 13:05:06.103059       1 request.go:700] Waited for 1.369577702s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:05:06.510273513Z E1024 13:05:06.510069       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:05:07.103433134Z I1024 13:05:07.103380       1 request.go:700] Waited for 1.395643762s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods
2024-10-24T13:05:07.116232954Z I1024 13:05:07.116171       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-2-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-etcd because it was missing
2024-10-24T13:05:08.108051775Z I1024 13:05:08.108005       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 2, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:05:08.133008745Z I1024 13:05:08.132972       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:08.133057755Z I1024 13:05:08.133021       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:05:08.146590615Z I1024 13:05:08.144897       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 2" to "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3",Available message changed from "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 2\nEtcdMembersAvailable: 2 members are available" to "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3\nEtcdMembersAvailable: 2 members are available"
2024-10-24T13:05:08.147309185Z I1024 13:05:08.147261       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:05:08.303565585Z I1024 13:05:08.303503       1 request.go:700] Waited for 1.187318281s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-10-24T13:05:08.708972825Z E1024 13:05:08.708925       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:08.708972825Z E1024 13:05:08.708951       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:08.709972416Z E1024 13:05:08.709931       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:05:08.711356046Z E1024 13:05:08.711323       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:08.711356046Z E1024 13:05:08.711343       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:09.503468566Z I1024 13:05:09.503409       1 request.go:700] Waited for 1.368697761s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:05:10.703839068Z I1024 13:05:10.703478       1 request.go:700] Waited for 1.594168602s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-2-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:10.715812698Z I1024 13:05:10.715788       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:05:10.715812698Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:05:10.715812698Z  CurrentRevision: (int32) 0,
2024-10-24T13:05:10.715812698Z  TargetRevision: (int32) 3,
2024-10-24T13:05:10.715812698Z  LastFailedRevision: (int32) 0,
2024-10-24T13:05:10.715812698Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:05:10.715812698Z  LastFailedReason: (string) "",
2024-10-24T13:05:10.715812698Z  LastFailedCount: (int) 0,
2024-10-24T13:05:10.715812698Z  LastFallbackCount: (int) 0,
2024-10-24T13:05:10.715812698Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:05:10.715812698Z }
2024-10-24T13:05:10.715812698Z  because new revision pending
2024-10-24T13:05:10.735644688Z I1024 13:05:10.735618       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:11.310691199Z E1024 13:05:11.310633       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:05:11.312339479Z E1024 13:05:11.312310       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:11.312339479Z E1024 13:05:11.312327       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:11.903639479Z I1024 13:05:11.903576       1 request.go:700] Waited for 1.167288471s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:05:13.102864961Z I1024 13:05:13.102816       1 request.go:700] Waited for 1.593564982s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd
2024-10-24T13:05:13.513530542Z I1024 13:05:13.513481       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-3-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-etcd because it was missing
2024-10-24T13:05:14.103368382Z I1024 13:05:14.103301       1 request.go:700] Waited for 1.195055041s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:14.105795262Z E1024 13:05:14.105719       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc: i/o timeout"
2024-10-24T13:05:14.109265652Z E1024 13:05:14.109211       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:05:14.110542462Z E1024 13:05:14.110507       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:14.708615093Z I1024 13:05:14.708552       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:05:15.303076853Z I1024 13:05:15.303019       1 request.go:700] Waited for 1.192157341s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:16.303691855Z I1024 13:05:16.303634       1 request.go:700] Waited for 1.194666512s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:05:16.509104035Z E1024 13:05:16.508682       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:16.510566225Z E1024 13:05:16.510503       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:05:16.511967235Z E1024 13:05:16.511909       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:16.511967235Z E1024 13:05:16.511931       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:17.108575515Z I1024 13:05:17.108501       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:05:18.309307527Z E1024 13:05:18.309211       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:05:18.310655227Z E1024 13:05:18.310608       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:18.310655227Z E1024 13:05:18.310630       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:18.708458418Z I1024 13:05:18.708404       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:05:19.509534589Z E1024 13:05:19.509479       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:05:19.830910780Z E1024 13:05:19.830829       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:19.832967180Z E1024 13:05:19.832942       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:20.509980460Z E1024 13:05:20.509916       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:05:28.551533840Z E1024 13:05:28.551214       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:28.566640190Z E1024 13:05:28.566604       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:28.568181730Z E1024 13:05:28.568131       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:05:29.637280531Z E1024 13:05:29.636964       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:29.637280531Z E1024 13:05:29.637242       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:29.638489271Z E1024 13:05:29.638455       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:05:30.661037452Z E1024 13:05:30.660834       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:30.661037452Z E1024 13:05:30.660984       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:30.662975592Z E1024 13:05:30.662916       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:05:35.686686718Z E1024 13:05:35.686468       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:35.686791208Z E1024 13:05:35.686774       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:35.703200558Z E1024 13:05:35.703139       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:05:39.761629959Z E1024 13:05:39.761430       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:39.761705239Z E1024 13:05:39.761690       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:39.776304068Z E1024 13:05:39.776246       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:05:40.514185695Z E1024 13:05:40.514141       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:40.514185695Z E1024 13:05:40.514166       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:40.975002319Z E1024 13:05:40.974703       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:05:40.976519728Z E1024 13:05:40.976493       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:40.976624048Z E1024 13:05:40.976611       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:41.769534592Z E1024 13:05:41.769127       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:05:43.722371819Z E1024 13:05:43.717354       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:43.722371819Z E1024 13:05:43.717384       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:43.732818178Z E1024 13:05:43.732745       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:05:44.113838766Z E1024 13:05:44.113796       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc: i/o timeout"
2024-10-24T13:05:45.365577583Z E1024 13:05:45.365227       1 guard_controller.go:300] Missing PodIP in operand etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:45.365577583Z E1024 13:05:45.365565       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:45.406253230Z I1024 13:05:45.406207       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:05:46.316496637Z I1024 13:05:46.316251       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:05:46.386878884Z E1024 13:05:46.386826       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Missing PodIP in operand etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]"
2024-10-24T13:05:46.389033333Z I1024 13:05:46.388893       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:46.393947033Z I1024 13:05:46.393908       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing PodIP in operand etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:05:46.405976842Z I1024 13:05:46.405924       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing PodIP in operand etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]\nEtcdMembersDegraded: No unhealthy members found"
2024-10-24T13:05:46.438163560Z I1024 13:05:46.438128       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:05:46.447190460Z I1024 13:05:46.447131       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 67047424
2024-10-24T13:05:46.523294835Z I1024 13:05:46.523218       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:05:46.568930263Z I1024 13:05:46.568881       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:05:47.363219556Z I1024 13:05:47.363155       1 request.go:700] Waited for 1.084807856s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-10-24T13:05:47.703559846Z I1024 13:05:47.703512       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:05:48.562202167Z I1024 13:05:48.562142       1 request.go:700] Waited for 1.593216478s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-10-24T13:05:49.563216898Z I1024 13:05:49.563154       1 request.go:700] Waited for 1.394521069s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-3-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:50.373084291Z E1024 13:05:50.373035       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:50.373158761Z I1024 13:05:50.373093       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-etcd because it was missing
2024-10-24T13:05:50.422345528Z I1024 13:05:50.422288       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:05:50.488231964Z I1024 13:05:50.488042       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:05:50.762203608Z I1024 13:05:50.762136       1 request.go:700] Waited for 1.174868061s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:05:50.768721648Z I1024 13:05:50.768682       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:05:50.773704978Z I1024 13:05:50.773656       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:05:50.943433118Z I1024 13:05:50.943221       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:05:51.571981972Z I1024 13:05:51.571910       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:05:51.633483458Z I1024 13:05:51.633402       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:05:51.762538770Z I1024 13:05:51.762480       1 request.go:700] Waited for 1.172459182s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa
2024-10-24T13:05:52.588494322Z E1024 13:05:52.588420       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:05:52.591763612Z I1024 13:05:52.591660       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:05:52.593221492Z I1024 13:05:52.593153       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:05:52.596467972Z I1024 13:05:52.596365       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:05:52.604324401Z I1024 13:05:52.603123       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing PodIP in operand etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 on node ci-op-2fcpj5j6-f6035-2lklf-master-0, Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1]\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1\nEtcdMembersDegraded: No unhealthy members found"
2024-10-24T13:05:52.625007300Z I1024 13:05:52.624932       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.02 %, dbSize: 67117056
2024-10-24T13:05:52.625007300Z I1024 13:05:52.624952       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.02 %, dbSize: 67620864
2024-10-24T13:05:52.658003548Z I1024 13:05:52.657955       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:05:52.763034182Z I1024 13:05:52.762967       1 request.go:700] Waited for 1.19333921s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-10-24T13:05:53.602106373Z I1024 13:05:53.602031       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:05:53.963157072Z I1024 13:05:53.963090       1 request.go:700] Waited for 1.37143808s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:05:54.569448397Z I1024 13:05:54.569376       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:05:55.163284902Z I1024 13:05:55.162920       1 request.go:700] Waited for 1.596158807s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa
2024-10-24T13:05:56.363253082Z I1024 13:05:56.363187       1 request.go:700] Waited for 1.141104403s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd
2024-10-24T13:05:57.288902138Z I1024 13:05:57.288858       1 core.go:220] Pod "openshift-etcd/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0" changes: {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{"k8s.ovn.org/pod-networks":null,"k8s.v1.cni.cncf.io/network-status":null,"target.workload.openshift.io/management":"{\"effect\": \"PreferredDuringScheduling\"}"},"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null},"spec":{"containers":[{"args":["-c","# properly handle TERM and exit as soon as it is signaled\nset -euo pipefail\ntrap 'jobs -p | xargs -r kill; exit 0' TERM\nsleep infinity \u0026 wait\n"],"command":["/bin/bash"],"image":"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:f99379698faa42b7db0e7367c8e7f738a69f699f414a7567a5593a530fb6723d","imagePullPolicy":"IfNotPresent","name":"guard","readinessProbe":{"failureThreshold":3,"httpGet":{"host":"10.0.0.3","path":"readyz","port":9980,"scheme":"HTTPS"},"periodSeconds":5,"successThreshold":1,"timeoutSeconds":5},"resources":{"requests":{"cpu":"10m","memory":"5Mi"}},"terminationMessagePolicy":"FallbackToLogsOnError"}],"dnsPolicy":null,"enableServiceLinks":null,"preemptionPolicy":null,"priority":null,"restartPolicy":null,"schedulerName":null,"securityContext":null,"serviceAccount":null,"serviceAccountName":null,"volumes":null},"status":{"conditions":null,"containerStatuses":null,"hostIP":null,"hostIPs":null,"phase":null,"podIP":null,"podIPs":null,"qosClass":null,"startTime":null}}
2024-10-24T13:05:57.677034916Z I1024 13:05:57.676994       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:05:58.068782663Z E1024 13:05:58.068707       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:58.069470253Z I1024 13:05:58.069386       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-etcd because it changed
2024-10-24T13:05:58.070084283Z E1024 13:05:58.070027       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:05:58.248054293Z I1024 13:05:58.247952       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:05:58.312316439Z I1024 13:05:58.312256       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:05:58.657254739Z I1024 13:05:58.657197       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:05:59.568424566Z E1024 13:05:59.568367       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:05:59.674743110Z I1024 13:05:59.674677       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:05:59.768386864Z I1024 13:05:59.768323       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:06:00.188311000Z I1024 13:06:00.187877       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:00.188406880Z I1024 13:06:00.188245       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1\nStaticPodsDegraded: pod/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 container \"etcd\" is terminated: Error: 529ebe931a1baebd, started, ci-op-2fcpj5j6-f6035-2lklf-master-2, https://10.0.0.6:2380, https://10.0.0.6:2379, false\nStaticPodsDegraded: a48f107742a8605c, started, etcd-bootstrap, https://10.0.0.5:2380, https://10.0.0.5:2379, false\nStaticPodsDegraded: could not parse revision.json, falling back to WAL parsing. Err=open /var/lib/etcd/revision.json: no such file or directorycould not find local cluster id: couldn't find cluster id in WAL or revision: open /var/lib/etcd/member/wal: no such file or directory\nStaticPodsDegraded: open /var/lib/etcd/revision.json: no such file or directory\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:06:00.203400838Z I1024 13:06:00.203236       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1\nStaticPodsDegraded: pod/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 container \"etcd\" is terminated: Error: 529ebe931a1baebd, started, ci-op-2fcpj5j6-f6035-2lklf-master-2, https://10.0.0.6:2380, https://10.0.0.6:2379, false\nStaticPodsDegraded: a48f107742a8605c, started, etcd-bootstrap, https://10.0.0.5:2380, https://10.0.0.5:2379, false\nStaticPodsDegraded: could not parse revision.json, falling back to WAL parsing. Err=open /var/lib/etcd/revision.json: no such file or directorycould not find local cluster id: couldn't find cluster id in WAL or revision: open /var/lib/etcd/member/wal: no such file or directory\nStaticPodsDegraded: open /var/lib/etcd/revision.json: no such file or directory\nEtcdMembersDegraded: No unhealthy members found"
2024-10-24T13:06:00.219933738Z I1024 13:06:00.219871       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.10 %, dbSize: 67858432
2024-10-24T13:06:00.219933738Z I1024 13:06:00.219888       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.07 %, dbSize: 68325376
2024-10-24T13:06:00.231873277Z I1024 13:06:00.231809       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:06:01.362574371Z I1024 13:06:01.362507       1 request.go:700] Waited for 1.173211382s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd
2024-10-24T13:06:01.969166226Z E1024 13:06:01.969103       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:06:02.562918411Z I1024 13:06:02.562857       1 request.go:700] Waited for 1.19497641s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa
2024-10-24T13:06:03.170155796Z I1024 13:06:03.170098       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:06:03.388919613Z I1024 13:06:03.388881       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1\nStaticPodsDegraded: pod/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 container \"etcd\" is waiting: CrashLoopBackOff: back-off 10s restarting failed container=etcd pod=etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0_openshift-etcd(4fe68f26f0b304a8b9c8a49e8cb07821)\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:06:03.389781953Z I1024 13:06:03.388933       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:03.401475292Z I1024 13:06:03.401395       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1\nStaticPodsDegraded: pod/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 container \"etcd\" is terminated: Error: 529ebe931a1baebd, started, ci-op-2fcpj5j6-f6035-2lklf-master-2, https://10.0.0.6:2380, https://10.0.0.6:2379, false\nStaticPodsDegraded: a48f107742a8605c, started, etcd-bootstrap, https://10.0.0.5:2380, https://10.0.0.5:2379, false\nStaticPodsDegraded: could not parse revision.json, falling back to WAL parsing. Err=open /var/lib/etcd/revision.json: no such file or directorycould not find local cluster id: couldn't find cluster id in WAL or revision: open /var/lib/etcd/member/wal: no such file or directory\nStaticPodsDegraded: open /var/lib/etcd/revision.json: no such file or directory\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1\nStaticPodsDegraded: pod/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 container \"etcd\" is waiting: CrashLoopBackOff: back-off 10s restarting failed container=etcd pod=etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0_openshift-etcd(4fe68f26f0b304a8b9c8a49e8cb07821)\nEtcdMembersDegraded: No unhealthy members found"
2024-10-24T13:06:03.426800821Z I1024 13:06:03.426722       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.02 %, dbSize: 68005888
2024-10-24T13:06:03.426800821Z I1024 13:06:03.426745       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.02 %, dbSize: 68526080
2024-10-24T13:06:03.435058351Z I1024 13:06:03.434989       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:06:03.769578201Z E1024 13:06:03.769528       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:04.563198724Z I1024 13:06:04.562852       1 request.go:700] Waited for 1.173840281s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-10-24T13:06:05.762505795Z I1024 13:06:05.762170       1 request.go:700] Waited for 1.192542021s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-10-24T13:06:06.169106281Z E1024 13:06:06.169042       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:06:06.368969379Z I1024 13:06:06.368911       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:06:08.168964214Z I1024 13:06:08.168478       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:06:10.511187927Z E1024 13:06:10.511137       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:10.523165697Z E1024 13:06:10.523111       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:06:10.538714306Z I1024 13:06:10.538650       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:06:11.024887178Z E1024 13:06:11.024843       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:11.053874446Z E1024 13:06:11.053824       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:06:11.066645425Z I1024 13:06:11.066608       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:06:11.120896372Z I1024 13:06:11.120851       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:06:14.116575717Z E1024 13:06:14.116075       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc: i/o timeout"
2024-10-24T13:06:14.656825776Z E1024 13:06:14.656767       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:14.657733835Z E1024 13:06:14.657680       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:06:14.672252174Z I1024 13:06:14.672180       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:06:20.779928687Z E1024 13:06:20.779492       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:20.785600587Z W1024 13:06:20.785569       1 dynamic_operator_client.go:343] .status.conditions["StaticPodsDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:06:20.785600587Z W1024 13:06:20.785586       1 dynamic_operator_client.go:346] .status.conditions["StaticPodsDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:06:20.790603857Z I1024 13:06:20.790571       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:06:20.812983975Z I1024 13:06:20.812959       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:20.815284705Z I1024 13:06:20.815259       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:06:20.825152965Z I1024 13:06:20.825096       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MemberAddAsLearner' successfully added new member https://10.0.0.3:2380
2024-10-24T13:06:20.829098685Z I1024 13:06:20.829062       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1\nStaticPodsDegraded: pod/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0 container \"etcd\" is waiting: CrashLoopBackOff: back-off 10s restarting failed container=etcd pod=etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0_openshift-etcd(4fe68f26f0b304a8b9c8a49e8cb07821)\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1\nEtcdMembersDegraded: No unhealthy members found"
2024-10-24T13:06:20.846197144Z I1024 13:06:20.846150       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.01 %, dbSize: 69083136
2024-10-24T13:06:20.852687763Z I1024 13:06:20.852618       1 clustermembercontroller.go:293] Not ready for promotion: etcd learner member (https://10.0.0.3:2380) is not yet in sync with leader's log 
2024-10-24T13:06:20.870559922Z W1024 13:06:20.870505       1 etcdcli.go:346] UnstartedEtcdMember found: [NAME-PENDING-10.0.0.3]
2024-10-24T13:06:20.870559922Z W1024 13:06:20.870519       1 etcdcli.go:351] UnhealthyEtcdMember found: [NAME-PENDING-10.0.0.3]
2024-10-24T13:06:20.972901746Z E1024 13:06:20.972852       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:06:21.273106609Z W1024 13:06:21.273007       1 etcdcli.go:346] UnstartedEtcdMember found: [NAME-PENDING-10.0.0.3]
2024-10-24T13:06:21.273182159Z W1024 13:06:21.273163       1 etcdcli.go:351] UnhealthyEtcdMember found: [NAME-PENDING-10.0.0.3]
2024-10-24T13:06:21.965568499Z I1024 13:06:21.965507       1 request.go:700] Waited for 1.152077492s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:22.427690122Z I1024 13:06:22.427629       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MemberPromote' successfully promoted learner member https://10.0.0.3:2380
2024-10-24T13:06:23.365868997Z I1024 13:06:23.365807       1 request.go:700] Waited for 1.012924141s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-10-24T13:06:23.570881175Z E1024 13:06:23.570825       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:23.972262672Z I1024 13:06:23.972194       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:06:25.577919498Z E1024 13:06:25.577587       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:06:26.000900524Z I1024 13:06:26.000828       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:06:26Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:06:26.011569503Z I1024 13:06:26.011296       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded changed from False to True ("GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1")
2024-10-24T13:06:26.366028842Z I1024 13:06:26.365968       1 request.go:700] Waited for 1.072564838s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:06:26.769825089Z I1024 13:06:26.769783       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:06:27.571300192Z E1024 13:06:27.571249       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:28.370856835Z E1024 13:06:28.370788       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:06:35.711109657Z E1024 13:06:35.710536       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:35.732915826Z I1024 13:06:35.732878       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 3, but has not made progress because static pod is pending
2024-10-24T13:06:35.917609465Z E1024 13:06:35.917561       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:06:35.918995365Z E1024 13:06:35.918947       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:36.911014477Z I1024 13:06:36.910962       1 request.go:700] Waited for 1.156071652s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-10-24T13:06:38.317453975Z I1024 13:06:38.317118       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:06:38.317453975Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:06:38.317453975Z  CurrentRevision: (int32) 3,
2024-10-24T13:06:38.317453975Z  TargetRevision: (int32) 0,
2024-10-24T13:06:38.317453975Z  LastFailedRevision: (int32) 0,
2024-10-24T13:06:38.317453975Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:06:38.317453975Z  LastFailedReason: (string) "",
2024-10-24T13:06:38.317453975Z  LastFailedCount: (int) 0,
2024-10-24T13:06:38.317453975Z  LastFallbackCount: (int) 0,
2024-10-24T13:06:38.317453975Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:06:38.317453975Z }
2024-10-24T13:06:38.317453975Z  because static pod is ready
2024-10-24T13:06:38.338348724Z I1024 13:06:38.338296       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 0 to 3 because static pod is ready
2024-10-24T13:06:38.339797914Z I1024 13:06:38.339707       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:06:26Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:06:38.340628154Z I1024 13:06:38.339712       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:38.355575693Z I1024 13:06:38.355519       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3" to "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3",Available message changed from "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3\nEtcdMembersAvailable: 2 members are available" to "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3\nEtcdMembersAvailable: 2 members are available"
2024-10-24T13:06:38.362926623Z I1024 13:06:38.362885       1 core.go:352] ConfigMap "openshift-etcd/etcd-endpoints" changes: {"data":{"2dee09550bc489af":"10.0.0.3"},"metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:06:38.364156082Z I1024 13:06:38.363394       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-endpoints -n openshift-etcd:
2024-10-24T13:06:38.364156082Z cause by changes in data.2dee09550bc489af
2024-10-24T13:06:38.364744082Z I1024 13:06:38.364705       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:38.366573612Z W1024 13:06:38.366499       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]]
2024-10-24T13:06:38.370552332Z I1024 13:06:38.370516       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.05 %, dbSize: 70397952
2024-10-24T13:06:38.370552332Z I1024 13:06:38.370535       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.02 %, dbSize: 70877184
2024-10-24T13:06:38.372124532Z I1024 13:06:38.372085       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 4 triggered by "required configmap/etcd-endpoints has changed"
2024-10-24T13:06:38.372423152Z W1024 13:06:38.372384       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]]
2024-10-24T13:06:38.388284481Z W1024 13:06:38.388255       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]]
2024-10-24T13:06:38.403283210Z W1024 13:06:38.403198       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]]
2024-10-24T13:06:38.417618989Z W1024 13:06:38.417591       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]]
2024-10-24T13:06:38.431463958Z W1024 13:06:38.431416       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]]
2024-10-24T13:06:39.511425025Z I1024 13:06:39.511240       1 request.go:700] Waited for 1.170173812s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-10-24T13:06:39.922458811Z I1024 13:06:39.922375       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:40.118347880Z E1024 13:06:40.118293       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:06:40.710851295Z I1024 13:06:40.710799       1 request.go:700] Waited for 1.393380768s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:41.324458590Z I1024 13:06:41.324402       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-pod-4 -n openshift-etcd because it was missing
2024-10-24T13:06:41.324573650Z I1024 13:06:41.324518       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:41.520799768Z I1024 13:06:41.520642       1 core.go:352] ConfigMap "openshift-etcd/etcd-scripts" changes: {"apiVersion":"v1","data":{"etcd.env":"export ALL_ETCD_ENDPOINTS=\"https://10.0.0.3:2379,https://10.0.0.5:2379,https://10.0.0.6:2379\"\nexport ETCDCTL_API=\"3\"\nexport ETCDCTL_CACERT=\"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\nexport ETCDCTL_CERT=\"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\nexport ETCDCTL_ENDPOINTS=\"https://10.0.0.3:2379,https://10.0.0.6:2379\"\nexport ETCDCTL_KEY=\"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\nexport ETCD_CIPHER_SUITES=\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\nexport ETCD_DATA_DIR=\"/var/lib/etcd\"\nexport ETCD_ELECTION_TIMEOUT=\"1000\"\nexport ETCD_ENABLE_PPROF=\"true\"\nexport ETCD_EXPERIMENTAL_MAX_LEARNERS=\"3\"\nexport ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION=\"200ms\"\nexport ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL=\"5s\"\nexport ETCD_HEARTBEAT_INTERVAL=\"100\"\nexport ETCD_IMAGE=\"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\nexport ETCD_INITIAL_CLUSTER_STATE=\"existing\"\nexport ETCD_QUOTA_BACKEND_BYTES=\"8589934592\"\nexport ETCD_SOCKET_REUSE_ADDRESS=\"true\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME=\"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST=\"10.0.0.3\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP=\"10.0.0.3\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME=\"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST=\"10.0.0.4\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP=\"10.0.0.4\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME=\"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST=\"10.0.0.6\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP=\"10.0.0.6\"\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:06:41.521366018Z I1024 13:06:41.521323       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-scripts -n openshift-etcd:
2024-10-24T13:06:41.521366018Z cause by changes in data.etcd.env
2024-10-24T13:06:41.522708108Z I1024 13:06:41.522673       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:41.711291487Z I1024 13:06:41.711228       1 request.go:700] Waited for 1.19541087s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd
2024-10-24T13:06:42.515402250Z I1024 13:06:42.515355       1 installer_controller.go:534] node ci-op-2fcpj5j6-f6035-2lklf-master-1 static pod not found and needs new revision 3
2024-10-24T13:06:42.515402250Z I1024 13:06:42.515393       1 installer_controller.go:542] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:06:42.515402250Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:06:42.515402250Z  CurrentRevision: (int32) 0,
2024-10-24T13:06:42.515402250Z  TargetRevision: (int32) 3,
2024-10-24T13:06:42.515402250Z  LastFailedRevision: (int32) 0,
2024-10-24T13:06:42.515402250Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:06:42.515402250Z  LastFailedReason: (string) "",
2024-10-24T13:06:42.515402250Z  LastFailedCount: (int) 0,
2024-10-24T13:06:42.515402250Z  LastFallbackCount: (int) 0,
2024-10-24T13:06:42.515402250Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:06:42.515402250Z }
2024-10-24T13:06:42.537312909Z I1024 13:06:42.537240       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 0 to 3 because node ci-op-2fcpj5j6-f6035-2lklf-master-1 static pod not found
2024-10-24T13:06:42.538209339Z I1024 13:06:42.538175       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:42.711430639Z I1024 13:06:42.711372       1 request.go:700] Waited for 1.386978719s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps
2024-10-24T13:06:42.719315508Z I1024 13:06:42.719259       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-endpoints-4 -n openshift-etcd because it was missing
2024-10-24T13:06:42.721073738Z I1024 13:06:42.721040       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:43.125345789Z I1024 13:06:43.125165       1 core.go:352] ConfigMap "openshift-etcd/etcd-pod" changes: {"apiVersion":"v1","data":{"pod.yaml":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: etcd\n  namespace: openshift-etcd\n  annotations:\n    kubectl.kubernetes.io/default-container: etcd\n    target.workload.openshift.io/management: '{\"effect\": \"PreferredDuringScheduling\"}'\n  labels:\n    app: etcd\n    k8s-app: etcd\n    etcd: \"true\"\n    revision: \"REVISION\"\nspec:\n  initContainers:\n    - name: setup\n      image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          echo -n \"Fixing etcd log permissions.\"\n          mkdir -p /var/log/etcd  \u0026\u0026 chmod 0600 /var/log/etcd\n          echo -n \"Fixing etcd auto backup permissions.\"\n          mkdir -p /var/lib/etcd-auto-backup  \u0026\u0026 chmod 0600 /var/lib/etcd-auto-backup\n      securityContext:\n        privileged: true\n      resources:\n        requests:\n          memory: 50Mi\n          cpu: 5m\n      volumeMounts:\n        - mountPath: /var/log/etcd\n          name: log-dir\n    - name: etcd-ensure-env-vars\n      image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          set -euo pipefail\n\n          : \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST?not set}\"\n          : \"${NODE_NODE_ENVVAR_NAME_ETCD_NAME?not set}\"\n          : \"${NODE_NODE_ENVVAR_NAME_IP?not set}\"\n\n          # check for ipv4 addresses as well as ipv6 addresses with extra square brackets\n          if [[ \"${NODE_NODE_ENVVAR_NAME_IP}\" != \"${NODE_IP}\" \u0026\u0026 \"${NODE_NODE_ENVVAR_NAME_IP}\" != \"[${NODE_IP}]\" ]]; then\n            # echo the error message to stderr\n            echo \"Expected node IP to be ${NODE_IP} got ${NODE_NODE_ENVVAR_NAME_IP}\" \u003e\u00262\n            exit 1\n          fi\n\n          # check for ipv4 addresses as well as ipv6 addresses with extra square brackets\n          if [[ \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" != \"${NODE_IP}\" \u0026\u0026 \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" != \"[${NODE_IP}]\" ]]; then\n            # echo the error message to stderr\n            echo \"Expected etcd url host to be ${NODE_IP} got ${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" \u003e\u00262\n            exit 1\n          fi\n\n      resources:\n        requests:\n          memory: 60Mi\n          cpu: 10m\n      securityContext:\n        privileged: true\n      env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.3:2379,https://10.0.0.5:2379,https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.3:2379,https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"1000\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"100\"\n      - name: \"ETCD_IMAGE\"\n        value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n        value: \"10.0.0.6\"\n      - name: NODE_IP\n        valueFrom:\n          fieldRef:\n            fieldPath: status.podIP\n    - name: etcd-resources-copy\n      image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          set -euo pipefail\n\n          rm -f $(grep -l '^### Created by cluster-etcd-operator' /usr/local/bin/*)\n          cp -p /etc/kubernetes/static-pod-certs/configmaps/etcd-scripts/*.sh /usr/local/bin\n\n      resources:\n        requests:\n          memory: 60Mi\n          cpu: 10m\n      securityContext:\n        privileged: true\n      volumeMounts:\n        - mountPath: /etc/kubernetes/static-pod-resources\n          name: resource-dir\n        - mountPath: /etc/kubernetes/static-pod-certs\n          name: cert-dir\n        - mountPath: /usr/local/bin\n          name: usr-local-bin\n  containers:\n  # The etcdctl container should always be first. It is intended to be used\n  # to open a remote shell via `oc rsh` that is ready to run `etcdctl`.\n  - name: etcdctl\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - \"/bin/bash\"\n      - \"-c\"\n      - \"trap TERM INT; sleep infinity \u0026 wait\"\n    resources:\n      requests:\n        memory: 60Mi\n        cpu: 10m\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n    env:\n    - name: \"ALL_ETCD_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.5:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_API\"\n      value: \"3\"\n    - name: \"ETCDCTL_CACERT\"\n      value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n    - name: \"ETCDCTL_CERT\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n    - name: \"ETCDCTL_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_KEY\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n    - name: \"ETCD_CIPHER_SUITES\"\n      value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n    - name: \"ETCD_DATA_DIR\"\n      value: \"/var/lib/etcd\"\n    - name: \"ETCD_ELECTION_TIMEOUT\"\n      value: \"1000\"\n    - name: \"ETCD_ENABLE_PPROF\"\n      value: \"true\"\n    - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n      value: \"3\"\n    - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n      value: \"200ms\"\n    - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n      value: \"5s\"\n    - name: \"ETCD_HEARTBEAT_INTERVAL\"\n      value: \"100\"\n    - name: \"ETCD_IMAGE\"\n      value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n    - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n      value: \"existing\"\n    - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n      value: \"8589934592\"\n    - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n      value: \"true\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n      value: \"10.0.0.6\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n      value: \"10.0.0.6\"\n    - name: \"ETCD_STATIC_POD_VERSION\"\n      value: \"REVISION\"\n  - name: etcd\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n\n        etcdctl member list || true\n\n        # this has a non-zero return code if the command is non-zero.  If you use an export first, it doesn't and you\n        # will succeed when you should fail.\n        ETCD_INITIAL_CLUSTER=$(discover-etcd-initial-cluster \\\n          --cacert=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --cert=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --key=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --endpoints=${ALL_ETCD_ENDPOINTS} \\\n          --data-dir=/var/lib/etcd \\\n          --target-peer-url-host=${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST} \\\n          --target-name=NODE_NAME)\n        export ETCD_INITIAL_CLUSTER\n\n        # we cannot use the \"normal\" port conflict initcontainer because when we upgrade, the existing static pod will never yield,\n        # so we do the detection in etcd container itself.\n        echo -n \"Waiting for ports 2379, 2380 and 9978 to be released.\"\n        time while [ -n \"$(ss -Htan '( sport = 2379 or sport = 2380 or sport = 9978 )')\" ]; do\n          echo -n \".\"\n          sleep 1\n        done\n\n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n        env | grep ETCD | grep -v NODE\n\n        set -x\n        # See https://etcd.io/docs/v3.4.0/tuning/ for why we use ionice\n        exec nice -n -19 ionice -c2 -n0 etcd \\\n          --logger=zap \\\n          --log-level=info \\\n          --experimental-initial-corrupt-check=true \\\n          --snapshot-count=10000 \\\n          --initial-advertise-peer-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2380 \\\n          --cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --client-cert-auth=true \\\n          --peer-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --peer-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --peer-trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --peer-client-cert-auth=true \\\n          --advertise-client-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2379 \\\n          --listen-client-urls=https://0.0.0.0:2379,unixs://${NODE_NODE_ENVVAR_NAME_IP}:0 \\\n          --listen-peer-urls=https://0.0.0.0:2380 \\\n          --metrics=extensive \\\n          --listen-metrics-urls=https://0.0.0.0:9978 ||  mv /etc/kubernetes/etcd-backup-dir/etcd-member.yaml /etc/kubernetes/manifests\n    env:\n    - name: \"ALL_ETCD_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.5:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_API\"\n      value: \"3\"\n    - name: \"ETCDCTL_CACERT\"\n      value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n    - name: \"ETCDCTL_CERT\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n    - name: \"ETCDCTL_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_KEY\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n    - name: \"ETCD_CIPHER_SUITES\"\n      value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n    - name: \"ETCD_DATA_DIR\"\n      value: \"/var/lib/etcd\"\n    - name: \"ETCD_ELECTION_TIMEOUT\"\n      value: \"1000\"\n    - name: \"ETCD_ENABLE_PPROF\"\n      value: \"true\"\n    - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n      value: \"3\"\n    - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n      value: \"200ms\"\n    - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n      value: \"5s\"\n    - name: \"ETCD_HEARTBEAT_INTERVAL\"\n      value: \"100\"\n    - name: \"ETCD_IMAGE\"\n      value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n    - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n      value: \"existing\"\n    - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n      value: \"8589934592\"\n    - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n      value: \"true\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n      value: \"10.0.0.6\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n      value: \"10.0.0.6\"\n    - name: \"ETCD_STATIC_POD_VERSION\"\n      value: \"REVISION\"\n    resources:\n      requests:\n        memory: 600Mi\n        cpu: 300m\n    readinessProbe:\n      httpGet:\n        port: 9980\n        path: readyz\n        scheme: HTTPS\n      timeoutSeconds: 30\n      failureThreshold: 5\n      periodSeconds: 5\n      successThreshold: 1\n    livenessProbe:\n      httpGet:\n        path: healthz\n        port: 9980\n        scheme: HTTPS\n      timeoutSeconds: 30\n      periodSeconds: 5\n      successThreshold: 1\n      failureThreshold: 5\n    startupProbe:\n      httpGet:\n        port: 9980\n        path: readyz\n        scheme: HTTPS\n      initialDelaySeconds: 10\n      timeoutSeconds: 1\n      periodSeconds: 10\n      successThreshold: 1\n      failureThreshold: 18\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n  - name: etcd-metrics\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n\n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n\n        exec nice -n -18 etcd grpc-proxy start \\\n          --endpoints https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:9978 \\\n          --metrics-addr https://0.0.0.0:9979 \\\n          --listen-addr 127.0.0.1:9977 \\\n          --advertise-client-url \"\"  \\\n          --key /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --key-file /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-metrics-NODE_NAME.key \\\n          --cert /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --cert-file /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-metrics-NODE_NAME.crt \\\n          --cacert /etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --trusted-ca-file /etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/metrics-ca-bundle.crt \\\n          --listen-cipher-suites ${ETCD_CIPHER_SUITES}\n    env:\n    - name: \"ALL_ETCD_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.5:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_API\"\n      value: \"3\"\n    - name: \"ETCDCTL_CACERT\"\n      value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n    - name: \"ETCDCTL_CERT\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n    - name: \"ETCDCTL_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_KEY\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n    - name: \"ETCD_CIPHER_SUITES\"\n      value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n    - name: \"ETCD_DATA_DIR\"\n      value: \"/var/lib/etcd\"\n    - name: \"ETCD_ELECTION_TIMEOUT\"\n      value: \"1000\"\n    - name: \"ETCD_ENABLE_PPROF\"\n      value: \"true\"\n    - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n      value: \"3\"\n    - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n      value: \"200ms\"\n    - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n      value: \"5s\"\n    - name: \"ETCD_HEARTBEAT_INTERVAL\"\n      value: \"100\"\n    - name: \"ETCD_IMAGE\"\n      value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n    - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n      value: \"existing\"\n    - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n      value: \"8589934592\"\n    - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n      value: \"true\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n      value: \"10.0.0.6\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n      value: \"10.0.0.6\"\n    - name: \"ETCD_STATIC_POD_VERSION\"\n      value: \"REVISION\"\n    resources:\n      requests:\n        memory: 200Mi\n        cpu: 40m\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n  - name: etcd-readyz\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:f99379698faa42b7db0e7367c8e7f738a69f699f414a7567a5593a530fb6723d\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n        \n        exec nice -n -18 cluster-etcd-operator readyz \\\n          --target=https://localhost:2379 \\\n          --listen-port=9980 \\\n          --serving-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --serving-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --client-cert-file=$(ETCDCTL_CERT) \\\n          --client-key-file=$(ETCDCTL_KEY) \\\n          --client-cacert-file=$(ETCDCTL_CACERT) \\\n          --listen-cipher-suites=$(ETCD_CIPHER_SUITES)\n    securityContext:\n      privileged: true\n    ports:\n    - containerPort: 9980\n      name: readyz\n      protocol: TCP\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    env:\n    - name: \"ALL_ETCD_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.5:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_API\"\n      value: \"3\"\n    - name: \"ETCDCTL_CACERT\"\n      value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n    - name: \"ETCDCTL_CERT\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n    - name: \"ETCDCTL_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_KEY\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n    - name: \"ETCD_CIPHER_SUITES\"\n      value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n    - name: \"ETCD_DATA_DIR\"\n      value: \"/var/lib/etcd\"\n    - name: \"ETCD_ELECTION_TIMEOUT\"\n      value: \"1000\"\n    - name: \"ETCD_ENABLE_PPROF\"\n      value: \"true\"\n    - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n      value: \"3\"\n    - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n      value: \"200ms\"\n    - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n      value: \"5s\"\n    - name: \"ETCD_HEARTBEAT_INTERVAL\"\n      value: \"100\"\n    - name: \"ETCD_IMAGE\"\n      value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n    - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n      value: \"existing\"\n    - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n      value: \"8589934592\"\n    - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n      value: \"true\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n      value: \"10.0.0.6\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n      value: \"10.0.0.6\"\n    volumeMounts:\n      - mountPath: /var/log/etcd/\n        name: log-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n  - name: etcd-rev\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:f99379698faa42b7db0e7367c8e7f738a69f699f414a7567a5593a530fb6723d\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n        \n        cluster-etcd-operator rev \\\n          --endpoints=$(ALL_ETCD_ENDPOINTS) \\\n          --client-cert-file=$(ETCDCTL_CERT) \\\n          --client-key-file=$(ETCDCTL_KEY) \\\n          --client-cacert-file=$(ETCDCTL_CACERT)\n    securityContext:\n      privileged: true\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    env:\n    - name: \"ALL_ETCD_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.5:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_API\"\n      value: \"3\"\n    - name: \"ETCDCTL_CACERT\"\n      value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n    - name: \"ETCDCTL_CERT\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n    - name: \"ETCDCTL_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_KEY\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n    - name: \"ETCD_CIPHER_SUITES\"\n      value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n    - name: \"ETCD_DATA_DIR\"\n      value: \"/var/lib/etcd\"\n    - name: \"ETCD_ELECTION_TIMEOUT\"\n      value: \"1000\"\n    - name: \"ETCD_ENABLE_PPROF\"\n      value: \"true\"\n    - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n      value: \"3\"\n    - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n      value: \"200ms\"\n    - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n      value: \"5s\"\n    - name: \"ETCD_HEARTBEAT_INTERVAL\"\n      value: \"100\"\n    - name: \"ETCD_IMAGE\"\n      value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n    - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n      value: \"existing\"\n    - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n      value: \"8589934592\"\n    - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n      value: \"true\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n      value: \"10.0.0.6\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n      value: \"10.0.0.6\"\n    volumeMounts:\n    - mountPath: /var/lib/etcd\n      name: data-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n  hostNetwork: true\n  priorityClassName: system-node-critical\n  tolerations:\n  - operator: \"Exists\"\n  volumes:\n    - hostPath:\n        path: /etc/kubernetes/manifests\n      name: static-pod-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-pod-REVISION\n      name: resource-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-certs\n      name: cert-dir\n    - hostPath:\n        path: /var/lib/etcd\n        type: \"\"\n      name: data-dir\n    - hostPath:\n        path: /usr/local/bin\n      name: usr-local-bin\n    - hostPath:\n        path: /var/log/etcd\n      name: log-dir\n    - hostPath:\n        path: /etc/kubernetes\n      name: config-dir\n    - hostPath:\n        path: /var/lib/etcd-auto-backup\n      name: etcd-auto-backup-dir\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:06:43.126130250Z I1024 13:06:43.126071       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-pod -n openshift-etcd:
2024-10-24T13:06:43.126130250Z cause by changes in data.pod.yaml
2024-10-24T13:06:43.126434229Z I1024 13:06:43.126410       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:43.711924678Z I1024 13:06:43.711432       1 request.go:700] Waited for 1.173516689s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:06:44.119014370Z E1024 13:06:44.118975       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc: i/o timeout"
2024-10-24T13:06:44.319426616Z I1024 13:06:44.319370       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-all-bundles-4 -n openshift-etcd because it was missing
2024-10-24T13:06:44.320514936Z I1024 13:06:44.320486       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:44.910666835Z I1024 13:06:44.910611       1 request.go:700] Waited for 1.594952889s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:45.911395725Z I1024 13:06:45.911338       1 request.go:700] Waited for 1.591996929s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets
2024-10-24T13:06:45.927510135Z I1024 13:06:45.925449       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-all-certs-4 -n openshift-etcd because it was missing
2024-10-24T13:06:46.322452578Z I1024 13:06:46.322389       1 core.go:352] ConfigMap "openshift-etcd/restore-etcd-pod" changes: {"apiVersion":"v1","data":{"pod.yaml":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: etcd\n  namespace: openshift-etcd\n  labels:\n    app: etcd\n    k8s-app: etcd\n    etcd: \"true\"\n    revision: \"REVISION\"\nspec:\n  containers:\n  - name: etcd\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n               \n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n        export ETCD_INITIAL_CLUSTER=\"${ETCD_NAME}=https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:2380\"\n        env | grep ETCD | grep -v NODE\n        export ETCD_NODE_PEER_URL=https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:2380\n        export REV_JSON=\"/var/lib/etcd-backup/revision.json\"\n        export SNAPSHOT_FILE=\"/var/lib/etcd-backup/snapshot.db\"\n\n        # checking if data directory is empty, if not etcdctl restore will fail         \n        if [ -n \"$(ls -A \"/var/lib/etcd\")\" ]; then\n          echo \"please delete the contents of the /var/lib/etcd directory before restoring, running the restore script will do this for you\"\n          exit 1\n        fi\n        \n        ETCD_ETCDCTL_BIN=\"etcdctl\"\n        if [ -x \"$(command -v etcdutl)\" ]; then\n          echo \"found etcdutl, using that instead of etcdctl for local operations\"\n          ETCD_ETCDCTL_BIN=\"etcdutl\"\n        fi      \n\n        # check if we have backup file to be restored\n        # if the file exist, check if it has not changed size in last 5 seconds\n        if [ ! -f \"${SNAPSHOT_FILE}\" ]; then\n          echo \"please make a copy of the snapshot db file, then move that copy to ${SNAPSHOT_FILE}\"\n          exit 1\n        else\n          filesize=$(stat --format=%s \"${SNAPSHOT_FILE}\")\n          sleep 5\n          newfilesize=$(stat --format=%s \"${SNAPSHOT_FILE}\")\n          if [ \"$filesize\" != \"$newfilesize\" ]; then\n            echo \"file size has changed since last 5 seconds, retry sometime after copying is complete\"\n            exit 1\n          fi\n        fi\n        \n        SNAPSHOT_REV=$(etcdutl snapshot status -wjson \"$SNAPSHOT_FILE\" | jq -r \".revision\")\n        echo \"snapshot is at revision ${SNAPSHOT_REV}\"\n        \n        if [ -n \"$(ls -A \"${REV_JSON}\")\" ]; then\n           # this will bump by the amount of the last known live revision + 20% slack.\n           # Note: the bump amount is an addition to the current revision stored in the snapshot.\n           # We're avoiding to do any math with SNAPSHOT_REV, uint64 has plenty of space to double revisions\n           # and we're assuming that full disaster restores are a very rare occurrence anyway.\n           BUMP_REV=$(jq -r \"(.maxRaftIndex*1.2|floor)\" \"${REV_JSON}\")\n           echo \"bumping revisions by ${BUMP_REV}\"\n        else\n           # we can't take SNAPSHOT_REV as an indicator here, because the snapshot might be much older\n           # than any currently live served revision. \n           # 1bn would be an etcd running at 1000 writes/s for about eleven days.\n           echo \"no revision.json found, assuming a 1bn revision bump\"\n           BUMP_REV=1000000000\n        fi\n        \n        UUID=$(uuidgen)\n        echo \"restoring to a single node cluster\"\n        ${ETCD_ETCDCTL_BIN} snapshot restore \"${SNAPSHOT_FILE}\" \\\n         --name $ETCD_NAME \\\n         --initial-cluster=$ETCD_INITIAL_CLUSTER \\\n         --initial-cluster-token \"openshift-etcd-${UUID}\" \\\n         --initial-advertise-peer-urls $ETCD_NODE_PEER_URL \\\n         --data-dir=\"/var/lib/etcd/restore-${UUID}\" \\\n         --mark-compacted \\\n         --bump-revision \"${BUMP_REV}\"\n\n        mv /var/lib/etcd/restore-${UUID}/* /var/lib/etcd/\n        # copy the revision.json back in case a second restore needs to be run afterwards\n        if [ -n \"$(ls -A \"${REV_JSON}\")\" ]; then\n           cp ${REV_JSON} /var/lib/etcd/\n        fi\n\n        rmdir /var/lib/etcd/restore-${UUID}\n        rm /var/lib/etcd-backup/snapshot.db\n\n        set -x\n        exec etcd \\\n          --logger=zap \\\n          --log-level=info \\\n          --initial-advertise-peer-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2380 \\\n          --cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --client-cert-auth=true \\\n          --peer-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --peer-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --peer-trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --peer-client-cert-auth=true \\\n          --advertise-client-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2379 \\\n          --listen-client-urls=https://0.0.0.0:2379 \\\n          --listen-peer-urls=https://0.0.0.0:2380 \\\n          --metrics=extensive \\\n          --listen-metrics-urls=https://0.0.0.0:9978\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.3:2379,https://10.0.0.5:2379,https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.3:2379,https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"1000\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"100\"\n      - name: \"ETCD_IMAGE\"\n        value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n        value: \"10.0.0.6\"\n      - name: \"ETCD_STATIC_POD_REV\"\n        value: \"REVISION\"\n    resources:\n      requests:\n        memory: 600Mi\n        cpu: 300m\n    readinessProbe:\n      tcpSocket:\n        port: 2380\n      failureThreshold: 3\n      initialDelaySeconds: 3\n      periodSeconds: 5\n      successThreshold: 1\n      timeoutSeconds: 5\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n      - mountPath: /var/lib/etcd-backup/\n        name: backup-dir\n  hostNetwork: true\n  priorityClassName: system-node-critical\n  tolerations:\n  - operator: \"Exists\"\n  volumes:\n    - hostPath:\n        path: /etc/kubernetes/manifests\n      name: static-pod-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-certs\n      name: cert-dir\n    - hostPath:\n        path: /var/lib/etcd\n        type: \"\"\n      name: data-dir\n    - hostPath:\n        path: /var/lib/etcd-backup\n        type: \"\"\n      name: backup-dir\n","quorum-restore-pod.yaml":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: etcd\n  namespace: openshift-etcd\n  labels:\n    app: etcd\n    k8s-app: etcd\n    etcd: \"true\"\n    revision: \"REVISION\"\nspec:\n  containers:\n  - name: etcd\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n        \n        set -x\n        exec etcd \\\n          --logger=zap \\\n          --log-level=info \\\n          --force-new-cluster \\\n          --name=\"${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\" \\\n          --initial-cluster=\"${NODE_NODE_ENVVAR_NAME_ETCD_NAME}=https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:2380\" \\\n          --initial-advertise-peer-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2380 \\\n          --cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --client-cert-auth=true \\\n          --peer-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --peer-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --peer-trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --peer-client-cert-auth=true \\\n          --advertise-client-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2379 \\\n          --listen-client-urls=https://0.0.0.0:2379 \\\n          --listen-peer-urls=https://0.0.0.0:2380 \\\n          --metrics=extensive \\\n          --listen-metrics-urls=https://0.0.0.0:9978\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.3:2379,https://10.0.0.5:2379,https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.3:2379,https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"1000\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"100\"\n      - name: \"ETCD_IMAGE\"\n        value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n        value: \"10.0.0.6\"\n      - name: \"ETCD_STATIC_POD_REV\"\n        value: \"REVISION\"\n    resources:\n      requests:\n        memory: 600Mi\n        cpu: 300m\n    readinessProbe:\n      tcpSocket:\n        port: 2380\n      failureThreshold: 3\n      initialDelaySeconds: 3\n      periodSeconds: 5\n      successThreshold: 1\n      timeoutSeconds: 5\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n      - mountPath: /var/lib/etcd-backup/\n        name: backup-dir\n  hostNetwork: true\n  priorityClassName: system-node-critical\n  tolerations:\n  - operator: \"Exists\"\n  volumes:\n    - hostPath:\n        path: /etc/kubernetes/manifests\n      name: static-pod-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-certs\n      name: cert-dir\n    - hostPath:\n        path: /var/lib/etcd\n        type: \"\"\n      name: data-dir\n    - hostPath:\n        path: /var/lib/etcd-backup\n        type: \"\"\n      name: backup-dir\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:06:46.324311417Z I1024 13:06:46.323134       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:46.324464567Z I1024 13:06:46.324409       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/restore-etcd-pod -n openshift-etcd:
2024-10-24T13:06:46.324464567Z cause by changes in data.pod.yaml,data.quorum-restore-pod.yaml
2024-10-24T13:06:46.516138724Z E1024 13:06:46.516084       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:46.517559964Z E1024 13:06:46.517513       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:06:46.911442826Z I1024 13:06:46.911377       1 request.go:700] Waited for 1.791743065s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:46.916081076Z I1024 13:06:46.916036       1 installer_controller.go:534] node ci-op-2fcpj5j6-f6035-2lklf-master-1 static pod not found and needs new revision 3
2024-10-24T13:06:46.916106856Z I1024 13:06:46.916086       1 installer_controller.go:542] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:06:46.916106856Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:06:46.916106856Z  CurrentRevision: (int32) 0,
2024-10-24T13:06:46.916106856Z  TargetRevision: (int32) 3,
2024-10-24T13:06:46.916106856Z  LastFailedRevision: (int32) 0,
2024-10-24T13:06:46.916106856Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:06:46.916106856Z  LastFailedReason: (string) "",
2024-10-24T13:06:46.916106856Z  LastFailedCount: (int) 0,
2024-10-24T13:06:46.916106856Z  LastFallbackCount: (int) 0,
2024-10-24T13:06:46.916106856Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:06:46.916106856Z }
2024-10-24T13:06:47.320474518Z I1024 13:06:47.320083       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:47.320526898Z W1024 13:06:47.320467       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:06:47.320526898Z W1024 13:06:47.320477       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:06:47.320830358Z I1024 13:06:47.320796       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 4 triggered by "required configmap/etcd-endpoints has changed"
2024-10-24T13:06:47.344205778Z W1024 13:06:47.344152       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:06:47.344300208Z W1024 13:06:47.344281       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:06:47.344861608Z I1024 13:06:47.344822       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:47.375493297Z I1024 13:06:47.375438       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required configmap/etcd-pod has changed"
2024-10-24T13:06:47.400336707Z I1024 13:06:47.400287       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.01 %, dbSize: 71454720
2024-10-24T13:06:47.400336707Z I1024 13:06:47.400312       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.01 %, dbSize: 71581696
2024-10-24T13:06:47.400336707Z I1024 13:06:47.400319       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.04 %, dbSize: 72110080
2024-10-24T13:06:47.911598637Z I1024 13:06:47.911538       1 request.go:700] Waited for 1.392411083s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:06:48.918516098Z I1024 13:06:48.918464       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:49.111603194Z I1024 13:06:49.111542       1 request.go:700] Waited for 1.57872287s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa
2024-10-24T13:06:49.723315302Z I1024 13:06:49.723263       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-3-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-etcd because it was missing
2024-10-24T13:06:50.112251215Z I1024 13:06:50.111811       1 request.go:700] Waited for 1.193705517s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps
2024-10-24T13:06:50.124129664Z I1024 13:06:50.124080       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-pod-5 -n openshift-etcd because it was missing
2024-10-24T13:06:50.127915204Z I1024 13:06:50.127879       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:50.915828179Z I1024 13:06:50.915783       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 3, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:06:50.938920309Z I1024 13:06:50.938882       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:50.940151209Z I1024 13:06:50.940096       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:06:26Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 4\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:06:50.952996248Z I1024 13:06:50.952967       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3" to "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 4",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3\nEtcdMembersAvailable: 2 members are available" to "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 4\nEtcdMembersAvailable: 2 members are available"
2024-10-24T13:06:51.004124427Z I1024 13:06:51.004079       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.03 %, dbSize: 72151040
2024-10-24T13:06:51.004124427Z I1024 13:06:51.004099       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.10 %, dbSize: 72331264
2024-10-24T13:06:51.004124427Z I1024 13:06:51.004105       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.03 %, dbSize: 72769536
2024-10-24T13:06:51.311165622Z I1024 13:06:51.311118       1 request.go:700] Waited for 1.395930284s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:51.521999948Z I1024 13:06:51.521955       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:51.522438087Z I1024 13:06:51.522312       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-endpoints-5 -n openshift-etcd because it was missing
2024-10-24T13:06:51.842484261Z I1024 13:06:51.842439       1 tlsconfig.go:181] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"admin-kubeconfig-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:31 +0000 UTC to 2034-10-22 12:49:31 +0000 UTC (now=2024-10-24 13:06:51.842400401 +0000 UTC))"
2024-10-24T13:06:51.842577681Z I1024 13:06:51.842560       1 tlsconfig.go:181] "Loaded client CA" index=1 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2024-10-25 12:49:34 +0000 UTC (now=2024-10-24 13:06:51.842536921 +0000 UTC))"
2024-10-24T13:06:51.842642421Z I1024 13:06:51.842626       1 tlsconfig.go:181] "Loaded client CA" index=2 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-control-plane-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2025-10-24 12:49:34 +0000 UTC (now=2024-10-24 13:06:51.842609451 +0000 UTC))"
2024-10-24T13:06:51.842698581Z I1024 13:06:51.842683       1 tlsconfig.go:181] "Loaded client CA" index=3 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-apiserver-to-kubelet-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2025-10-24 12:49:34 +0000 UTC (now=2024-10-24 13:06:51.842665121 +0000 UTC))"
2024-10-24T13:06:51.842772091Z I1024 13:06:51.842740       1 tlsconfig.go:181] "Loaded client CA" index=4 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-bootstrap-kubeconfig-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:32 +0000 UTC to 2034-10-22 12:49:32 +0000 UTC (now=2024-10-24 13:06:51.842722311 +0000 UTC))"
2024-10-24T13:06:51.842830071Z I1024 13:06:51.842817       1 tlsconfig.go:181] "Loaded client CA" index=5 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-csr-signer_@1729775012\" [] issuer=\"kubelet-signer\" (2024-10-24 13:03:31 +0000 UTC to 2024-10-25 12:49:34 +0000 UTC (now=2024-10-24 13:06:51.842800581 +0000 UTC))"
2024-10-24T13:06:51.842877581Z I1024 13:06:51.842865       1 tlsconfig.go:181] "Loaded client CA" index=6 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_node-system-admin-signer@1729775011\" [] issuer=\"<self>\" (2024-10-24 13:03:30 +0000 UTC to 2025-10-24 13:03:31 +0000 UTC (now=2024-10-24 13:06:51.842848541 +0000 UTC))"
2024-10-24T13:06:51.842923371Z I1024 13:06:51.842909       1 tlsconfig.go:181] "Loaded client CA" index=7 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"aggregator-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:32 +0000 UTC to 2024-10-25 12:49:32 +0000 UTC (now=2024-10-24 13:06:51.842894631 +0000 UTC))"
2024-10-24T13:06:51.843164041Z I1024 13:06:51.843145       1 tlsconfig.go:203] "Loaded serving cert" certName="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key" certDetail="\"metrics.openshift-etcd-operator.svc\" [serving] validServingFor=[metrics.openshift-etcd-operator.svc,metrics.openshift-etcd-operator.svc.cluster.local] issuer=\"openshift-service-serving-signer@1729775010\" (2024-10-24 13:03:39 +0000 UTC to 2026-10-24 13:03:40 +0000 UTC (now=2024-10-24 13:06:51.843122641 +0000 UTC))"
2024-10-24T13:06:51.843349741Z I1024 13:06:51.843330       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1729775083\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1729775083\" (2024-10-24 12:04:43 +0000 UTC to 2025-10-24 12:04:43 +0000 UTC (now=2024-10-24 13:06:51.843309221 +0000 UTC))"
2024-10-24T13:06:52.115680876Z E1024 13:06:52.115639       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:52.116888446Z E1024 13:06:52.116859       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:06:52.510910798Z I1024 13:06:52.510841       1 request.go:700] Waited for 1.572903259s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:06:53.319219473Z I1024 13:06:53.318987       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-all-bundles-5 -n openshift-etcd because it was missing
2024-10-24T13:06:53.319474713Z I1024 13:06:53.319446       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:53.511064679Z I1024 13:06:53.511019       1 request.go:700] Waited for 1.794864025s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd
2024-10-24T13:06:54.122072738Z I1024 13:06:54.122029       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:06:54.122072738Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:06:54.122072738Z  CurrentRevision: (int32) 0,
2024-10-24T13:06:54.122072738Z  TargetRevision: (int32) 4,
2024-10-24T13:06:54.122072738Z  LastFailedRevision: (int32) 0,
2024-10-24T13:06:54.122072738Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:06:54.122072738Z  LastFailedReason: (string) "",
2024-10-24T13:06:54.122072738Z  LastFailedCount: (int) 0,
2024-10-24T13:06:54.122072738Z  LastFallbackCount: (int) 0,
2024-10-24T13:06:54.122072738Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:06:54.122072738Z }
2024-10-24T13:06:54.122072738Z  because new revision pending
2024-10-24T13:06:54.146306607Z I1024 13:06:54.146072       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:54.194934116Z I1024 13:06:54.194870       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.02 %, dbSize: 72658944
2024-10-24T13:06:54.194934116Z I1024 13:06:54.194891       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.01 %, dbSize: 72769536
2024-10-24T13:06:54.194934116Z I1024 13:06:54.194898       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 73261056
2024-10-24T13:06:54.511349090Z I1024 13:06:54.511286       1 request.go:700] Waited for 1.393310793s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:06:54.726354106Z I1024 13:06:54.726284       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-all-certs-5 -n openshift-etcd because it was missing
2024-10-24T13:06:55.711100467Z I1024 13:06:55.711027       1 request.go:700] Waited for 1.5651884s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:06:56.521578422Z I1024 13:06:56.519645       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:56.521578422Z W1024 13:06:56.520623       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:06:56.521578422Z W1024 13:06:56.520636       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:06:56.521578422Z I1024 13:06:56.520910       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 5 triggered by "required configmap/etcd-pod has changed"
2024-10-24T13:06:56.550033261Z I1024 13:06:56.549990       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:56.711611008Z I1024 13:06:56.711555       1 request.go:700] Waited for 1.788535345s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd
2024-10-24T13:06:57.316873317Z I1024 13:06:57.316817       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:06:57.316873317Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:06:57.316873317Z  CurrentRevision: (int32) 0,
2024-10-24T13:06:57.316873317Z  TargetRevision: (int32) 4,
2024-10-24T13:06:57.316873317Z  LastFailedRevision: (int32) 0,
2024-10-24T13:06:57.316873317Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:06:57.316873317Z  LastFailedReason: (string) "",
2024-10-24T13:06:57.316873317Z  LastFailedCount: (int) 0,
2024-10-24T13:06:57.316873317Z  LastFallbackCount: (int) 0,
2024-10-24T13:06:57.316873317Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:06:57.316873317Z }
2024-10-24T13:06:57.316873317Z  because new revision pending
2024-10-24T13:06:57.337317247Z I1024 13:06:57.337275       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:06:57.337976717Z I1024 13:06:57.337953       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:06:26Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:06:57.351183876Z I1024 13:06:57.351042       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 4" to "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 4\nEtcdMembersAvailable: 2 members are available" to "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5\nEtcdMembersAvailable: 2 members are available"
2024-10-24T13:06:57.380632425Z I1024 13:06:57.380572       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.02 %, dbSize: 73379840
2024-10-24T13:06:57.380632425Z I1024 13:06:57.380589       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 73986048
2024-10-24T13:06:57.711614890Z I1024 13:06:57.711579       1 request.go:700] Waited for 1.169866648s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:06:58.515963444Z E1024 13:06:58.515895       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:58.516925624Z E1024 13:06:58.516890       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:06:58.711977051Z I1024 13:06:58.711940       1 request.go:700] Waited for 1.374066024s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-4-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:06:59.911333778Z I1024 13:06:59.911238       1 request.go:700] Waited for 1.392712954s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:07:00.115092314Z I1024 13:07:00.115031       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:07:00.115092314Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:07:00.115092314Z  CurrentRevision: (int32) 0,
2024-10-24T13:07:00.115092314Z  TargetRevision: (int32) 5,
2024-10-24T13:07:00.115092314Z  LastFailedRevision: (int32) 0,
2024-10-24T13:07:00.115092314Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:07:00.115092314Z  LastFailedReason: (string) "",
2024-10-24T13:07:00.115092314Z  LastFailedCount: (int) 0,
2024-10-24T13:07:00.115092314Z  LastFallbackCount: (int) 0,
2024-10-24T13:07:00.115092314Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:07:00.115092314Z }
2024-10-24T13:07:00.115092314Z  because new revision pending
2024-10-24T13:07:00.135265923Z I1024 13:07:00.135212       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:07:00.143159083Z I1024 13:07:00.143125       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:07:00.177631093Z I1024 13:07:00.177578       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.01 %, dbSize: 73502720
2024-10-24T13:07:00.177631093Z I1024 13:07:00.177599       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.05 %, dbSize: 73658368
2024-10-24T13:07:00.177631093Z I1024 13:07:00.177606       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.06 %, dbSize: 74153984
2024-10-24T13:07:01.311311761Z I1024 13:07:01.310947       1 request.go:700] Waited for 1.176440247s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:07:02.311260181Z I1024 13:07:02.310980       1 request.go:700] Waited for 1.394638614s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:07:02.522488468Z I1024 13:07:02.522429       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-etcd because it was missing
2024-10-24T13:07:03.315219692Z E1024 13:07:03.314905       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:03.316697912Z E1024 13:07:03.316655       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:07:03.318122982Z E1024 13:07:03.318094       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:03.516122528Z I1024 13:07:03.516074       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 5, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:07:03.711157144Z I1024 13:07:03.711097       1 request.go:700] Waited for 1.188544418s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-10-24T13:07:04.711484196Z I1024 13:07:04.711153       1 request.go:700] Waited for 1.193922958s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:05.910716983Z I1024 13:07:05.910648       1 request.go:700] Waited for 1.193658898s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:05.916664982Z I1024 13:07:05.916629       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:07:07.116850430Z E1024 13:07:07.116801       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:07:07.316012546Z I1024 13:07:07.315950       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:07:08.115958841Z E1024 13:07:08.115885       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:08.716212279Z E1024 13:07:08.716140       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:07:14.121583775Z E1024 13:07:14.121258       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc: i/o timeout"
2024-10-24T13:07:16.136828007Z E1024 13:07:16.136345       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:16.153714607Z E1024 13:07:16.153672       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:07:21.148851182Z I1024 13:07:21.148319       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:07:21.161519462Z E1024 13:07:21.161470       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:21.162922822Z E1024 13:07:21.162876       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:07:22.544981585Z E1024 13:07:22.544936       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:22.744731181Z I1024 13:07:22.744667       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:07:23.745883122Z E1024 13:07:23.745831       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:07:23.945176108Z I1024 13:07:23.945116       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:07:24.744344693Z E1024 13:07:24.744277       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:25.146999225Z E1024 13:07:25.146556       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:07:26.523119889Z E1024 13:07:26.523075       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:26.538403538Z E1024 13:07:26.538253       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:07:31.983864223Z E1024 13:07:31.983523       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:32.006148602Z E1024 13:07:32.006084       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:07:32.441496344Z E1024 13:07:32.441432       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:32.452625184Z E1024 13:07:32.452584       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:07:37.978827668Z E1024 13:07:37.978741       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:38.781097893Z E1024 13:07:38.781036       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:07:39.132503186Z E1024 13:07:39.132432       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: read udp 10.130.0.29:39537->172.30.0.10:53: read: connection refused"
2024-10-24T13:07:39.141398406Z E1024 13:07:39.141353       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: read udp 10.130.0.29:41292->172.30.0.10:53: read: connection refused"
2024-10-24T13:07:39.302288783Z E1024 13:07:39.302227       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: read udp 10.130.0.29:59270->172.30.0.10:53: read: connection refused"
2024-10-24T13:07:39.951915040Z E1024 13:07:39.951870       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: read udp 10.130.0.29:36155->172.30.0.10:53: read: connection refused"
2024-10-24T13:07:41.242372685Z E1024 13:07:41.242313       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: read udp 10.130.0.29:58857->172.30.0.10:53: read: connection refused"
2024-10-24T13:07:42.222972466Z E1024 13:07:42.222923       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:42.224520616Z E1024 13:07:42.224492       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:07:43.812201595Z E1024 13:07:43.812142       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: read udp 10.130.0.29:45420->172.30.0.10:53: read: connection refused"
2024-10-24T13:07:44.113178840Z E1024 13:07:44.113117       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: read udp 10.130.0.29:49669->172.30.0.10:53: read: connection refused"
2024-10-24T13:07:44.130911010Z I1024 13:07:44.130880       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:06:26Z","message":"GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:07:44.131480190Z I1024 13:07:44.131432       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:07:44.143691909Z I1024 13:07:44.141941       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:07:44.146140149Z I1024 13:07:44.145925       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5\nEtcdMembersAvailable: 2 members are available" to "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5\nEtcdMembersAvailable: 3 members are available"
2024-10-24T13:07:44.174696469Z I1024 13:07:44.174631       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 16.71 %, dbSize: 75694080
2024-10-24T13:07:44.174696469Z I1024 13:07:44.174662       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 16.69 %, dbSize: 75800576
2024-10-24T13:07:44.174696469Z I1024 13:07:44.174668       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 16.85 %, dbSize: 76234752
2024-10-24T13:07:47.736960304Z E1024 13:07:47.736913       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:48.337868160Z E1024 13:07:48.337812       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:07:48.942243986Z E1024 13:07:48.942196       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: read udp 10.130.0.29:50193->172.30.0.10:53: read: connection refused"
2024-10-24T13:07:52.396380481Z E1024 13:07:52.396328       1 guard_controller.go:294] Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:52.407260982Z E1024 13:07:52.407208       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:07:54.049665425Z I1024 13:07:54.049578       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:07:54.053300386Z E1024 13:07:54.053232       1 guard_controller.go:300] Missing PodIP in operand etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:54.071958738Z I1024 13:07:54.071910       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:07:54.084420859Z E1024 13:07:54.084340       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Missing PodIP in operand etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:07:54.085818389Z I1024 13:07:54.085702       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:06:26Z","message":"GuardControllerDegraded: Missing PodIP in operand etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:07:54.088049109Z I1024 13:07:54.088009       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:07:54.096029920Z I1024 13:07:54.095975       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node ci-op-2fcpj5j6-f6035-2lklf-master-1" to "GuardControllerDegraded: Missing PodIP in operand etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1 on node ci-op-2fcpj5j6-f6035-2lklf-master-1"
2024-10-24T13:07:54.100121320Z I1024 13:07:54.100067       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:07:54.141842484Z I1024 13:07:54.141783       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:07:54.167459907Z I1024 13:07:54.167408       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 13.34 %, dbSize: 75694080
2024-10-24T13:07:54.167459907Z I1024 13:07:54.167431       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 13.33 %, dbSize: 75800576
2024-10-24T13:07:54.167459907Z I1024 13:07:54.167437       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 13.50 %, dbSize: 76234752
2024-10-24T13:07:54.591772686Z I1024 13:07:54.591483       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:07:54.640948481Z I1024 13:07:54.640897       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:07:55.241204027Z I1024 13:07:55.241131       1 request.go:700] Waited for 1.152674278s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:07:56.245427511Z I1024 13:07:56.245374       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:07:56.441025430Z I1024 13:07:56.440965       1 request.go:700] Waited for 1.392181401s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-10-24T13:07:57.441628004Z I1024 13:07:57.441543       1 request.go:700] Waited for 1.194825582s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:07:58.246280839Z I1024 13:07:58.246216       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:07:59.241347362Z I1024 13:07:59.241279       1 request.go:700] Waited for 1.113859734s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-10-24T13:08:00.241359926Z I1024 13:08:00.241302       1 request.go:700] Waited for 1.195740512s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa
2024-10-24T13:08:00.373484468Z I1024 13:08:00.373045       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:08:00.427416813Z I1024 13:08:00.427357       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:08:00.646167114Z I1024 13:08:00.646119       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:08:01.852320927Z I1024 13:08:01.852267       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-etcd because it was missing
2024-10-24T13:08:01.853274557Z W1024 13:08:01.853233       1 dynamic_operator_client.go:346] .status.conditions["GuardControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:08:01.879088660Z I1024 13:08:01.879051       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:08:01.881633270Z I1024 13:08:01.881579       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:08:01.893493581Z I1024 13:08:01.893447       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:08:01.896538041Z I1024 13:08:01.895212       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded changed from True to False ("NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found")
2024-10-24T13:08:01.927363384Z I1024 13:08:01.927305       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 11.43 %, dbSize: 75694080
2024-10-24T13:08:01.927363384Z I1024 13:08:01.927326       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 11.37 %, dbSize: 75800576
2024-10-24T13:08:01.927363384Z I1024 13:08:01.927333       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 11.56 %, dbSize: 76234752
2024-10-24T13:08:01.940613995Z I1024 13:08:01.940570       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:08:02.446656373Z I1024 13:08:02.446257       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:08:02.877689313Z I1024 13:08:02.877638       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:08:02.921470718Z I1024 13:08:02.921381       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:08:03.041607369Z I1024 13:08:03.041559       1 request.go:700] Waited for 1.16628339s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:08:04.241875862Z I1024 13:08:04.240920       1 request.go:700] Waited for 1.38804837s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:08:05.047908897Z I1024 13:08:05.047853       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:08:06.249348820Z I1024 13:08:06.249290       1 core.go:220] Pod "openshift-etcd/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1" changes: {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{"target.workload.openshift.io/management":"{\"effect\": \"PreferredDuringScheduling\"}"},"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null},"spec":{"containers":[{"args":["-c","# properly handle TERM and exit as soon as it is signaled\nset -euo pipefail\ntrap 'jobs -p | xargs -r kill; exit 0' TERM\nsleep infinity \u0026 wait\n"],"command":["/bin/bash"],"image":"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:f99379698faa42b7db0e7367c8e7f738a69f699f414a7567a5593a530fb6723d","imagePullPolicy":"IfNotPresent","name":"guard","readinessProbe":{"failureThreshold":3,"httpGet":{"host":"10.0.0.4","path":"readyz","port":9980,"scheme":"HTTPS"},"periodSeconds":5,"successThreshold":1,"timeoutSeconds":5},"resources":{"requests":{"cpu":"10m","memory":"5Mi"}},"terminationMessagePolicy":"FallbackToLogsOnError"}],"dnsPolicy":null,"enableServiceLinks":null,"imagePullSecrets":null,"preemptionPolicy":null,"priority":null,"restartPolicy":null,"schedulerName":null,"securityContext":null,"serviceAccount":null,"serviceAccountName":null,"volumes":null},"status":{"phase":null,"qosClass":null}}
2024-10-24T13:08:07.050317565Z I1024 13:08:07.050245       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-etcd because it changed
2024-10-24T13:08:07.084331788Z I1024 13:08:07.084283       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:08:07.698830456Z I1024 13:08:07.697495       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:08:07.747507251Z I1024 13:08:07.747428       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:08:08.650220225Z I1024 13:08:08.649165       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:08:09.439281519Z E1024 13:08:09.439232       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:08:18.594961068Z I1024 13:08:18.594918       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:08:18.639501772Z I1024 13:08:18.639449       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:08:30.211331969Z I1024 13:08:30.211262       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:08:30.254333743Z I1024 13:08:30.254286       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:08:40.138501530Z I1024 13:08:40.138460       1 clustermembercontroller.go:374] Skipping etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-10-24T13:08:40.245497210Z I1024 13:08:40.245400       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MemberAddAsLearner' successfully added new member https://10.0.0.4:2380
2024-10-24T13:08:40.276700673Z I1024 13:08:40.276629       1 clustermembercontroller.go:293] Not ready for promotion: etcd learner member (https://10.0.0.4:2380) is not yet in sync with leader's log 
2024-10-24T13:08:40.292920784Z W1024 13:08:40.292843       1 etcdcli.go:346] UnstartedEtcdMember found: [NAME-PENDING-10.0.0.4]
2024-10-24T13:08:40.292920784Z W1024 13:08:40.292866       1 etcdcli.go:351] UnhealthyEtcdMember found: [NAME-PENDING-10.0.0.4]
2024-10-24T13:08:41.763549452Z I1024 13:08:41.763486       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:08:41.824624188Z I1024 13:08:41.824549       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:08:41.893981185Z I1024 13:08:41.893912       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 5, but has not made progress because static pod is pending
2024-10-24T13:08:42.690273289Z I1024 13:08:42.688839       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:08:43.080997746Z I1024 13:08:43.080936       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:08:43.292593646Z I1024 13:08:43.292502       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:08:43.911228024Z I1024 13:08:43.911170       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:08:44.128489804Z E1024 13:08:44.128373       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:08:44.276931218Z I1024 13:08:44.276878       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:08:44.297739620Z I1024 13:08:44.297684       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:08:44.299008670Z I1024 13:08:44.298484       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:08:44.299008670Z I1024 13:08:44.298538       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:08:44.338511664Z I1024 13:08:44.338438       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 8.88 %, dbSize: 75694080
2024-10-24T13:08:44.338511664Z I1024 13:08:44.338459       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 8.91 %, dbSize: 75800576
2024-10-24T13:08:44.338511664Z I1024 13:08:44.338465       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 9.09 %, dbSize: 76234752
2024-10-24T13:08:44.345859945Z I1024 13:08:44.344543       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:08:44.369790027Z I1024 13:08:44.368582       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:08:44.493687808Z I1024 13:08:44.493614       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:08:44.549793494Z I1024 13:08:44.549718       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:08:44.894773116Z I1024 13:08:44.894690       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:08:44.894773116Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:08:44.894773116Z  CurrentRevision: (int32) 5,
2024-10-24T13:08:44.894773116Z  TargetRevision: (int32) 0,
2024-10-24T13:08:44.894773116Z  LastFailedRevision: (int32) 0,
2024-10-24T13:08:44.894773116Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:08:44.894773116Z  LastFailedReason: (string) "",
2024-10-24T13:08:44.894773116Z  LastFailedCount: (int) 0,
2024-10-24T13:08:44.894773116Z  LastFallbackCount: (int) 0,
2024-10-24T13:08:44.894773116Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:08:44.894773116Z }
2024-10-24T13:08:44.894773116Z  because static pod is ready
2024-10-24T13:08:44.914898148Z I1024 13:08:44.914839       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 0 to 5 because static pod is ready
2024-10-24T13:08:44.922048199Z I1024 13:08:44.921999       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:08:44.922737329Z I1024 13:08:44.922623       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:08:44.938471510Z I1024 13:08:44.937920       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5" to "NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5\nEtcdMembersAvailable: 3 members are available" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5\nEtcdMembersAvailable: 3 members are available"
2024-10-24T13:08:44.982596754Z I1024 13:08:44.982528       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:08:44.986715095Z I1024 13:08:44.986663       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 8.58 %, dbSize: 75694080
2024-10-24T13:08:44.986715095Z I1024 13:08:44.986683       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 8.64 %, dbSize: 75800576
2024-10-24T13:08:44.986715095Z I1024 13:08:44.986689       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 8.79 %, dbSize: 76234752
2024-10-24T13:08:45.057864881Z I1024 13:08:45.057703       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:08:45.288217653Z I1024 13:08:45.288141       1 request.go:700] Waited for 1.079731021s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:08:46.288369597Z I1024 13:08:46.288291       1 request.go:700] Waited for 1.59283697s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-10-24T13:08:47.288686360Z I1024 13:08:47.288618       1 request.go:700] Waited for 1.59593457s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa
2024-10-24T13:08:48.488088923Z I1024 13:08:48.488039       1 request.go:700] Waited for 1.195408332s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd
2024-10-24T13:08:49.092628300Z I1024 13:08:49.092561       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:08:49.092628300Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:08:49.092628300Z  CurrentRevision: (int32) 5,
2024-10-24T13:08:49.092628300Z  TargetRevision: (int32) 0,
2024-10-24T13:08:49.092628300Z  LastFailedRevision: (int32) 0,
2024-10-24T13:08:49.092628300Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:08:49.092628300Z  LastFailedReason: (string) "",
2024-10-24T13:08:49.092628300Z  LastFailedCount: (int) 0,
2024-10-24T13:08:49.092628300Z  LastFallbackCount: (int) 0,
2024-10-24T13:08:49.092628300Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:08:49.092628300Z }
2024-10-24T13:08:49.092628300Z  because static pod is ready
2024-10-24T13:08:50.091720303Z I1024 13:08:50.091650       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:08:50.294925382Z I1024 13:08:50.294867       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:08:50.404949333Z E1024 13:08:50.404912       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:08:51.153192953Z I1024 13:08:51.153129       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:08:51.902246504Z I1024 13:08:51.902189       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:08:51.951082018Z I1024 13:08:51.951015       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:08:54.018267442Z I1024 13:08:54.017277       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:08:54.082028024Z I1024 13:08:54.081948       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:08:54.493283679Z I1024 13:08:54.493232       1 installer_controller.go:534] node ci-op-2fcpj5j6-f6035-2lklf-master-2 with revision 1 is the oldest and needs new revision 5
2024-10-24T13:08:54.493283679Z I1024 13:08:54.493273       1 installer_controller.go:542] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:08:54.493283679Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:08:54.493283679Z  CurrentRevision: (int32) 1,
2024-10-24T13:08:54.493283679Z  TargetRevision: (int32) 5,
2024-10-24T13:08:54.493283679Z  LastFailedRevision: (int32) 0,
2024-10-24T13:08:54.493283679Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:08:54.493283679Z  LastFailedReason: (string) "",
2024-10-24T13:08:54.493283679Z  LastFailedCount: (int) 0,
2024-10-24T13:08:54.493283679Z  LastFallbackCount: (int) 0,
2024-10-24T13:08:54.493283679Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:08:54.493283679Z }
2024-10-24T13:08:54.516123070Z I1024 13:08:54.516062       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 1 to 5 because node ci-op-2fcpj5j6-f6035-2lklf-master-2 with revision 1 is the oldest
2024-10-24T13:08:54.517803950Z I1024 13:08:54.517717       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:08:54.524558220Z I1024 13:08:54.524529       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:08:54.524667560Z I1024 13:08:54.524539       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:08:54.561229201Z I1024 13:08:54.561176       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:08:54.582563232Z I1024 13:08:54.582503       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:08:54.595171502Z I1024 13:08:54.595123       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:08:54.595824812Z I1024 13:08:54.595706       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 6.57 %, dbSize: 75694080
2024-10-24T13:08:54.595824812Z I1024 13:08:54.595725       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 6.60 %, dbSize: 75800576
2024-10-24T13:08:54.595824812Z I1024 13:08:54.595732       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 6.78 %, dbSize: 76234752
2024-10-24T13:08:55.688231200Z I1024 13:08:55.688173       1 request.go:700] Waited for 1.1700426s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:08:58.895416542Z I1024 13:08:58.895318       1 installer_controller.go:534] node ci-op-2fcpj5j6-f6035-2lklf-master-2 with revision 1 is the oldest and needs new revision 5
2024-10-24T13:08:58.895416542Z I1024 13:08:58.895357       1 installer_controller.go:542] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:08:58.895416542Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:08:58.895416542Z  CurrentRevision: (int32) 1,
2024-10-24T13:08:58.895416542Z  TargetRevision: (int32) 5,
2024-10-24T13:08:58.895416542Z  LastFailedRevision: (int32) 0,
2024-10-24T13:08:58.895416542Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:08:58.895416542Z  LastFailedReason: (string) "",
2024-10-24T13:08:58.895416542Z  LastFailedCount: (int) 0,
2024-10-24T13:08:58.895416542Z  LastFallbackCount: (int) 0,
2024-10-24T13:08:58.895416542Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:08:58.895416542Z }
2024-10-24T13:08:59.308388906Z I1024 13:08:59.307411       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-etcd because it was missing
2024-10-24T13:08:59.494948262Z I1024 13:08:59.494861       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 5, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:08:59.741785661Z I1024 13:08:59.741706       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:08:59.788897542Z I1024 13:08:59.788842       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:09:00.141095515Z I1024 13:09:00.141030       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:09:00.414263524Z I1024 13:09:00.414202       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:09:00.894663691Z I1024 13:09:00.894592       1 clustermembercontroller.go:336] Ignoring member (ci-op-2fcpj5j6-f6035-2lklf-master-1) for promotion: no Machine found referencing this member's IP (10.0.0.4)
2024-10-24T13:09:01.093329748Z I1024 13:09:01.093262       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:09:01.142528969Z E1024 13:09:01.142494       1 base_controller.go:271] "Unhandled Error" err="MachineDeletionHooksController reconciliation failed: Operation cannot be fulfilled on machines.machine.openshift.io \"ci-op-2fcpj5j6-f6035-2lklf-master-2\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:09:01.144506539Z I1024 13:09:01.144455       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:09:01.145133710Z I1024 13:09:01.145087       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"MachineDeletionHooksControllerDegraded: Operation cannot be fulfilled on machines.machine.openshift.io \"ci-op-2fcpj5j6-f6035-2lklf-master-2\": the object has been modified; please apply your changes to the latest version and try again\nNodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:09:01.157215610Z I1024 13:09:01.157151       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found" to "MachineDeletionHooksControllerDegraded: Operation cannot be fulfilled on machines.machine.openshift.io \"ci-op-2fcpj5j6-f6035-2lklf-master-2\": the object has been modified; please apply your changes to the latest version and try again\nNodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found"
2024-10-24T13:09:01.187584171Z I1024 13:09:01.187538       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MemberPromote' successfully promoted learner member https://10.0.0.4:2380
2024-10-24T13:09:01.188318301Z I1024 13:09:01.188276       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 6.15 %, dbSize: 75694080
2024-10-24T13:09:01.188318301Z I1024 13:09:01.188300       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 6.16 %, dbSize: 75800576
2024-10-24T13:09:01.188318301Z I1024 13:09:01.188307       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 6.33 %, dbSize: 76234752
2024-10-24T13:09:02.289702889Z I1024 13:09:02.289655       1 request.go:700] Waited for 1.145955219s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:09:03.488346640Z I1024 13:09:03.488295       1 request.go:700] Waited for 1.592773695s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:09:03.693896778Z I1024 13:09:03.693842       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:09:04.695243433Z E1024 13:09:04.695188       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on peer cert sync for node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-peer-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:04.894428140Z E1024 13:09:04.894363       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:05.090311076Z E1024 13:09:05.090258       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:05.094351426Z E1024 13:09:05.094314       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:05.288712593Z E1024 13:09:05.288654       1 guard_controller.go:366] Unable to apply pod etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2 changes: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:05.290596683Z W1024 13:09:05.290552       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:05.290624703Z E1024 13:09:05.290591       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Unable to apply pod etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2 changes: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:05.294666433Z E1024 13:09:05.294625       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:05.495005520Z E1024 13:09:05.494944       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:05.495485330Z E1024 13:09:05.495442       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:05.692462856Z E1024 13:09:05.692406       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:05.694141206Z E1024 13:09:05.694094       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:05.895066834Z E1024 13:09:05.895009       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:06.217659865Z E1024 13:09:06.217611       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:06.690484531Z E1024 13:09:06.690428       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:06.860426487Z E1024 13:09:06.860361       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:07.690436365Z W1024 13:09:07.690378       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:07.690496096Z E1024 13:09:07.690435       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:07.890935153Z E1024 13:09:07.890879       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:08.143432072Z E1024 13:09:08.143377       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:08.290259447Z E1024 13:09:08.290203       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:08.891966468Z E1024 13:09:08.891899       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:09.889972213Z E1024 13:09:09.889927       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:10.091781900Z W1024 13:09:10.091705       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:10.091822349Z E1024 13:09:10.091781       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:10.290888297Z E1024 13:09:10.290847       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:10.491910264Z E1024 13:09:10.491865       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:10.510340664Z E1024 13:09:10.510255       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:10.689036470Z I1024 13:09:10.688961       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:10.690395630Z E1024 13:09:10.690368       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:10.705601271Z E1024 13:09:10.705546       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:11.163936776Z W1024 13:09:11.163878       1 dynamic_operator_client.go:346] .status.conditions["MachineDeletionHooksControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:09:11.164961556Z E1024 13:09:11.164920       1 base_controller.go:271] "Unhandled Error" err="MachineDeletionHooksController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"MachineDeletionHooksController-reportDegraded\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=MachineDeletionHooksController-reportDegraded&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:11.167025407Z W1024 13:09:11.166989       1 dynamic_operator_client.go:346] .status.conditions["MachineDeletionHooksControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:09:11.167891447Z E1024 13:09:11.167828       1 base_controller.go:271] "Unhandled Error" err="MachineDeletionHooksController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"MachineDeletionHooksController-reportDegraded\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=MachineDeletionHooksController-reportDegraded&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:11.177889317Z W1024 13:09:11.177854       1 dynamic_operator_client.go:346] .status.conditions["MachineDeletionHooksControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:09:11.179013997Z E1024 13:09:11.178986       1 base_controller.go:271] "Unhandled Error" err="MachineDeletionHooksController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"MachineDeletionHooksController-reportDegraded\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=MachineDeletionHooksController-reportDegraded&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:11.222619949Z W1024 13:09:11.222554       1 dynamic_operator_client.go:346] .status.conditions["MachineDeletionHooksControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:09:11.223811978Z E1024 13:09:11.223673       1 base_controller.go:271] "Unhandled Error" err="MachineDeletionHooksController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"MachineDeletionHooksController-reportDegraded\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=MachineDeletionHooksController-reportDegraded&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:11.307045452Z W1024 13:09:11.306986       1 dynamic_operator_client.go:346] .status.conditions["MachineDeletionHooksControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:09:11.307845702Z E1024 13:09:11.307817       1 base_controller.go:271] "Unhandled Error" err="MachineDeletionHooksController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"MachineDeletionHooksController-reportDegraded\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=MachineDeletionHooksController-reportDegraded&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:11.470820267Z W1024 13:09:11.470712       1 dynamic_operator_client.go:346] .status.conditions["MachineDeletionHooksControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:09:11.471928817Z E1024 13:09:11.471885       1 base_controller.go:271] "Unhandled Error" err="MachineDeletionHooksController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"MachineDeletionHooksController-reportDegraded\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=MachineDeletionHooksController-reportDegraded&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:11.688694345Z I1024 13:09:11.688627       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:11.689928235Z E1024 13:09:11.689904       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:11.794482438Z W1024 13:09:11.794414       1 dynamic_operator_client.go:346] .status.conditions["MachineDeletionHooksControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:09:11.795517578Z E1024 13:09:11.795480       1 base_controller.go:271] "Unhandled Error" err="MachineDeletionHooksController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"MachineDeletionHooksController-reportDegraded\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=MachineDeletionHooksController-reportDegraded&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:11.890413292Z E1024 13:09:11.890361       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:12.437728910Z W1024 13:09:12.437670       1 dynamic_operator_client.go:346] .status.conditions["MachineDeletionHooksControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:09:12.438703030Z E1024 13:09:12.438659       1 base_controller.go:271] "Unhandled Error" err="MachineDeletionHooksController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"MachineDeletionHooksController-reportDegraded\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=MachineDeletionHooksController-reportDegraded&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:12.492293052Z E1024 13:09:12.492246       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:12.689677689Z I1024 13:09:12.689550       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:12.690884269Z E1024 13:09:12.690843       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:13.090725072Z W1024 13:09:13.090670       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:13.090832682Z E1024 13:09:13.090730       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:13.292791319Z E1024 13:09:13.292696       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:13.689374313Z I1024 13:09:13.689284       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:13.690913523Z E1024 13:09:13.690876       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:13.721364004Z W1024 13:09:13.721284       1 dynamic_operator_client.go:346] .status.conditions["MachineDeletionHooksControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:09:13.722479314Z E1024 13:09:13.722434       1 base_controller.go:271] "Unhandled Error" err="MachineDeletionHooksController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"MachineDeletionHooksController-reportDegraded\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=MachineDeletionHooksController-reportDegraded&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:13.890781920Z E1024 13:09:13.890692       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:14.689134558Z I1024 13:09:14.689060       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:14.690510348Z E1024 13:09:14.690463       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:15.689209212Z I1024 13:09:15.689122       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:15.690407802Z E1024 13:09:15.690327       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:15.890712839Z E1024 13:09:15.890643       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:16.090819556Z W1024 13:09:16.090716       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:16.090890076Z E1024 13:09:16.090835       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:16.285332413Z W1024 13:09:16.285264       1 dynamic_operator_client.go:346] .status.conditions["MachineDeletionHooksControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:09:16.286314423Z E1024 13:09:16.286278       1 base_controller.go:271] "Unhandled Error" err="MachineDeletionHooksController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"MachineDeletionHooksController-reportDegraded\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=MachineDeletionHooksController-reportDegraded&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:16.288713513Z I1024 13:09:16.288663       1 request.go:700] Waited for 1.000163855s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:09:16.291333033Z E1024 13:09:16.291303       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:16.493369120Z E1024 13:09:16.493306       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:16.689478897Z I1024 13:09:16.689407       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:16.690574157Z E1024 13:09:16.690541       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:17.690294812Z E1024 13:09:17.690244       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:17.888735928Z I1024 13:09:17.888654       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:17.890017929Z E1024 13:09:17.889905       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:18.891280413Z W1024 13:09:18.891218       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:18.891280413Z E1024 13:09:18.891267       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:19.090926900Z E1024 13:09:19.090867       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:19.488683524Z I1024 13:09:19.488622       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:19.489579464Z E1024 13:09:19.489534       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:19.690694811Z E1024 13:09:19.690624       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:20.292520213Z E1024 13:09:20.292464       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:21.289745827Z E1024 13:09:21.289694       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:21.409377571Z W1024 13:09:21.409316       1 dynamic_operator_client.go:346] .status.conditions["MachineDeletionHooksControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:09:21.410044661Z E1024 13:09:21.410009       1 base_controller.go:271] "Unhandled Error" err="MachineDeletionHooksController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"MachineDeletionHooksController-reportDegraded\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=MachineDeletionHooksController-reportDegraded&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:21.490480554Z W1024 13:09:21.490444       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:21.490516974Z E1024 13:09:21.490488       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:21.688770731Z I1024 13:09:21.688673       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:21.689715361Z E1024 13:09:21.689678       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:21.890119368Z E1024 13:09:21.890059       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:23.090282459Z E1024 13:09:23.090221       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:23.491839924Z E1024 13:09:23.491786       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:24.090869665Z W1024 13:09:24.090808       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:24.090937225Z E1024 13:09:24.090878       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:24.490115619Z E1024 13:09:24.490065       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:24.690905855Z E1024 13:09:24.690842       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:25.089610529Z I1024 13:09:25.089494       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:25.090688929Z E1024 13:09:25.090651       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:26.290981191Z E1024 13:09:26.290923       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:26.491268458Z W1024 13:09:26.491195       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:26.491268458Z E1024 13:09:26.491252       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:26.891548751Z E1024 13:09:26.891480       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:27.491466282Z E1024 13:09:27.491404       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:27.690857459Z E1024 13:09:27.690812       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:28.690460734Z W1024 13:09:28.690400       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:28.690533394Z E1024 13:09:28.690458       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:28.890674871Z E1024 13:09:28.890627       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:29.892907666Z E1024 13:09:29.892831       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:30.066456262Z E1024 13:09:30.066390       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:09:30.067145782Z E1024 13:09:30.067100       1 leaderelection.go:436] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:30.490544626Z E1024 13:09:30.490424       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:30.690323923Z W1024 13:09:30.690264       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:30.690378333Z E1024 13:09:30.690322       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:30.889280980Z I1024 13:09:30.889208       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:30.890303710Z E1024 13:09:30.890275       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:31.091975417Z E1024 13:09:31.091889       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:31.187971060Z E1024 13:09:31.187909       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:31.653437407Z W1024 13:09:31.653369       1 dynamic_operator_client.go:346] .status.conditions["MachineDeletionHooksControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:09:31.654449187Z E1024 13:09:31.654409       1 base_controller.go:271] "Unhandled Error" err="MachineDeletionHooksController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"MachineDeletionHooksController-reportDegraded\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=MachineDeletionHooksController-reportDegraded&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:31.889683875Z E1024 13:09:31.889615       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:32.891526730Z W1024 13:09:32.891483       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:32.891570490Z E1024 13:09:32.891539       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:33.089626516Z E1024 13:09:33.089575       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:33.292770833Z E1024 13:09:33.292700       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:33.690368157Z E1024 13:09:33.690320       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:34.490567034Z E1024 13:09:34.490508       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:34.690658261Z E1024 13:09:34.690592       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:35.289938772Z E1024 13:09:35.289866       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:36.090868509Z E1024 13:09:36.090812       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:36.292291296Z E1024 13:09:36.292242       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:36.690590210Z E1024 13:09:36.690539       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:37.091106514Z E1024 13:09:37.091042       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:37.489858218Z E1024 13:09:37.489808       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:37.890355092Z E1024 13:09:37.890301       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:38.290339616Z E1024 13:09:38.290256       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:38.690175269Z E1024 13:09:38.690099       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:39.290968550Z E1024 13:09:39.290921       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:40.090386118Z E1024 13:09:40.090336       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:40.493413211Z E1024 13:09:40.493347       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:41.090628782Z E1024 13:09:41.090569       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:41.290527289Z E1024 13:09:41.290470       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:41.688819703Z I1024 13:09:41.688721       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:41.689950072Z E1024 13:09:41.689897       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:41.890356839Z E1024 13:09:41.890288       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:42.290452583Z E1024 13:09:42.290393       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:42.690791277Z E1024 13:09:42.690703       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:43.091042611Z E1024 13:09:43.090982       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:43.690549400Z E1024 13:09:43.690496       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:44.109657884Z I1024 13:09:44.109598       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:44.110547414Z E1024 13:09:44.110497       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658c0f0ee44c  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-10-24 13:09:44.109442124 +0000 UTC m=+300.635230281,LastTimestamp:2024-10-24 13:09:44.109442124 +0000 UTC m=+300.635230281,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-10-24T13:09:44.110775204Z E1024 13:09:44.110720       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:44.110802334Z I1024 13:09:44.110775       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:44.120562355Z I1024 13:09:44.120500       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:44.121689824Z E1024 13:09:44.121642       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:44.121736845Z I1024 13:09:44.121683       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:44.123562985Z E1024 13:09:44.123523       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:09:44.135875355Z I1024 13:09:44.135814       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:44.137175345Z E1024 13:09:44.137103       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:44.137245775Z I1024 13:09:44.137164       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:44.160412146Z I1024 13:09:44.160324       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:44.161736216Z E1024 13:09:44.161707       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:44.161797666Z I1024 13:09:44.161733       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:44.205583057Z I1024 13:09:44.205420       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:44.206919237Z E1024 13:09:44.206851       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:44.206919237Z I1024 13:09:44.206883       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:44.207673757Z W1024 13:09:44.207641       1 dynamic_operator_client.go:346] .status.conditions["MachineDeletionHooksControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:09:44.309935801Z E1024 13:09:44.309861       1 base_controller.go:271] "Unhandled Error" err="MachineDeletionHooksController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"MachineDeletionHooksController-reportDegraded\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=MachineDeletionHooksController-reportDegraded&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:44.510467188Z E1024 13:09:44.510399       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:44.510524897Z I1024 13:09:44.510474       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:44.511315067Z E1024 13:09:44.511268       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658c26f4512c  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-10-24 13:09:44.510353708 +0000 UTC m=+301.036141865,LastTimestamp:2024-10-24 13:09:44.510353708 +0000 UTC m=+301.036141865,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-10-24T13:09:44.607864171Z E1024 13:09:44.607800       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:44.710359614Z I1024 13:09:44.710297       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:44.718444124Z E1024 13:09:44.718369       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658c26f4512c  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-10-24 13:09:44.510353708 +0000 UTC m=+301.036141865,LastTimestamp:2024-10-24 13:09:44.510353708 +0000 UTC m=+301.036141865,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-10-24T13:09:44.910050990Z W1024 13:09:44.909988       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:44.910107381Z E1024 13:09:44.910058       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:45.089039797Z E1024 13:09:45.088966       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:45.109998017Z E1024 13:09:45.109939       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:45.310478994Z E1024 13:09:45.310413       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:45.310478994Z I1024 13:09:45.310452       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:45.488468421Z E1024 13:09:45.488420       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:45.509694371Z E1024 13:09:45.509642       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:45.509738231Z I1024 13:09:45.509709       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:45.510425231Z E1024 13:09:45.510395       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658c6283b22b  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-10-24 13:09:45.509605931 +0000 UTC m=+302.035394128,LastTimestamp:2024-10-24 13:09:45.509605931 +0000 UTC m=+302.035394128,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-10-24T13:09:45.710589138Z E1024 13:09:45.710481       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:45.710589138Z I1024 13:09:45.710536       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:45.909285715Z I1024 13:09:45.909226       1 request.go:700] Waited for 1.017711105s due to client-side throttling, not priority and fairness, request: PATCH:https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true
2024-10-24T13:09:45.910077745Z E1024 13:09:45.910028       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:46.110361552Z E1024 13:09:46.110281       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:46.110361552Z I1024 13:09:46.110331       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:46.288903758Z E1024 13:09:46.288855       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:46.310607839Z I1024 13:09:46.310530       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:46.452549893Z E1024 13:09:46.452449       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658c6283b22b  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-10-24 13:09:45.509605931 +0000 UTC m=+302.035394128,LastTimestamp:2024-10-24 13:09:45.509605931 +0000 UTC m=+302.035394128,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-10-24T13:09:46.509469316Z E1024 13:09:46.509397       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:46.509469316Z I1024 13:09:46.509435       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:46.710268142Z E1024 13:09:46.710203       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:46.710268142Z I1024 13:09:46.710248       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:46.909948419Z E1024 13:09:46.909894       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:46.910000769Z I1024 13:09:46.909936       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:47.088253316Z I1024 13:09:47.088192       1 request.go:700] Waited for 1.1708818s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:09:47.109512446Z E1024 13:09:47.109456       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:47.109512446Z I1024 13:09:47.109496       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:47.310405243Z E1024 13:09:47.310349       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:47.489620590Z E1024 13:09:47.489556       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:47.510069390Z I1024 13:09:47.510002       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:47.709796847Z E1024 13:09:47.709733       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:47.910301494Z E1024 13:09:47.910178       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:47.910301494Z I1024 13:09:47.910219       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:48.110505640Z E1024 13:09:48.110451       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:48.288880827Z E1024 13:09:48.288831       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:48.309864467Z E1024 13:09:48.309810       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:48.309896847Z I1024 13:09:48.309850       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:48.509645834Z E1024 13:09:48.509591       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:48.509645834Z I1024 13:09:48.509631       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:48.710227211Z E1024 13:09:48.710169       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:48.710277831Z I1024 13:09:48.710218       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:48.910453948Z E1024 13:09:48.910389       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:49.026401022Z E1024 13:09:49.026345       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658c0f0ee44c  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-10-24 13:09:44.109442124 +0000 UTC m=+300.635230281,LastTimestamp:2024-10-24 13:09:44.109442124 +0000 UTC m=+300.635230281,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-10-24T13:09:49.089550504Z E1024 13:09:49.089498       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:49.110480335Z E1024 13:09:49.110433       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:49.309780982Z E1024 13:09:49.309700       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:49.510834139Z I1024 13:09:49.510730       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:49.710137485Z E1024 13:09:49.710058       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:49.710137485Z I1024 13:09:49.710097       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:49.889500761Z E1024 13:09:49.889426       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:49.909482512Z E1024 13:09:49.909421       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:49.909482512Z I1024 13:09:49.909461       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:50.110384589Z E1024 13:09:50.110324       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:50.110384589Z I1024 13:09:50.110366       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:50.309955816Z E1024 13:09:50.309886       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:50.509908073Z E1024 13:09:50.509839       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:50.509908073Z I1024 13:09:50.509889       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:50.709968710Z E1024 13:09:50.709918       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:50.710021970Z I1024 13:09:50.709952       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:50.889716226Z E1024 13:09:50.889649       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:50.909738747Z E1024 13:09:50.909685       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:51.291972889Z E1024 13:09:51.291900       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:51.394763373Z I1024 13:09:51.394674       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:51.510564777Z E1024 13:09:51.510485       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:51.510564777Z I1024 13:09:51.510526       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:51.710337344Z E1024 13:09:51.710287       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:51.710374304Z I1024 13:09:51.710331       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:51.910430971Z E1024 13:09:51.910369       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:51.910430971Z I1024 13:09:51.910413       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:52.110072227Z E1024 13:09:52.110016       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:52.137341608Z W1024 13:09:52.137297       1 dynamic_operator_client.go:346] .status.conditions["MachineDeletionHooksControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:09:52.289661344Z E1024 13:09:52.289570       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:52.310033085Z E1024 13:09:52.309961       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:52.509887191Z E1024 13:09:52.509811       1 base_controller.go:271] "Unhandled Error" err="MachineDeletionHooksController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"MachineDeletionHooksController-reportDegraded\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=MachineDeletionHooksController-reportDegraded&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:52.710401198Z E1024 13:09:52.710348       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:52.887945954Z I1024 13:09:52.887887       1 request.go:700] Waited for 1.015564684s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:09:52.910443905Z E1024 13:09:52.910384       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:52.910443905Z I1024 13:09:52.910423       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:53.110087242Z E1024 13:09:53.110013       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:53.690703822Z E1024 13:09:53.690646       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:53.690703822Z I1024 13:09:53.690683       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:53.891466388Z E1024 13:09:53.891398       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:54.073966984Z I1024 13:09:54.073891       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:54.075082204Z E1024 13:09:54.075046       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:54.075082204Z I1024 13:09:54.075071       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:54.110102716Z E1024 13:09:54.110055       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:54.310069033Z E1024 13:09:54.310013       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:54.488703609Z E1024 13:09:54.488649       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:54.509979290Z E1024 13:09:54.509933       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:54.510020990Z I1024 13:09:54.509996       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:54.719550647Z E1024 13:09:54.719492       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658c26f4512c  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-10-24 13:09:44.510353708 +0000 UTC m=+301.036141865,LastTimestamp:2024-10-24 13:09:44.510353708 +0000 UTC m=+301.036141865,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-10-24T13:09:54.889643243Z E1024 13:09:54.889584       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:54.889643243Z I1024 13:09:54.889624       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:55.090680630Z E1024 13:09:55.090621       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:55.291421157Z E1024 13:09:55.291357       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:55.690441001Z E1024 13:09:55.690384       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:56.069072404Z E1024 13:09:56.069000       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:09:56.069701714Z E1024 13:09:56.069660       1 leaderelection.go:436] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:56.089403285Z E1024 13:09:56.089363       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:56.453645307Z E1024 13:09:56.453578       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658c6283b22b  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-10-24 13:09:45.509605931 +0000 UTC m=+302.035394128,LastTimestamp:2024-10-24 13:09:45.509605931 +0000 UTC m=+302.035394128,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-10-24T13:09:56.490889548Z E1024 13:09:56.490825       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:56.490889548Z I1024 13:09:56.490861       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:56.691226124Z E1024 13:09:56.691175       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:56.891366011Z E1024 13:09:56.891280       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:09:57.288848611Z E1024 13:09:57.288786       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:57.490412166Z E1024 13:09:57.490342       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:57.890478955Z E1024 13:09:57.890405       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:58.290465985Z E1024 13:09:58.290403       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:58.690978905Z E1024 13:09:58.690919       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:59.028536483Z E1024 13:09:59.028471       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658c0f0ee44c  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-10-24 13:09:44.109442124 +0000 UTC m=+300.635230281,LastTimestamp:2024-10-24 13:09:44.109442124 +0000 UTC m=+300.635230281,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-10-24T13:09:59.090278474Z E1024 13:09:59.090221       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:59.228504566Z I1024 13:09:59.228441       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:59.229852347Z E1024 13:09:59.229806       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:59.229852347Z I1024 13:09:59.229836       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:59.290906728Z E1024 13:09:59.290839       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:59.290906728Z I1024 13:09:59.290875       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:59.643159576Z E1024 13:09:59.643109       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:09:59.643159576Z I1024 13:09:59.643145       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:09:59.891468863Z E1024 13:09:59.891407       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:00.090887998Z E1024 13:10:00.090830       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:00.890783347Z E1024 13:10:00.890703       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:01.092843060Z E1024 13:10:01.092796       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:01.490096160Z E1024 13:10:01.490042       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:01.890124869Z E1024 13:10:01.890060       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:02.290744430Z E1024 13:10:02.290686       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:02.489398865Z I1024 13:10:02.489306       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:02.490577255Z E1024 13:10:02.490544       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.1801658447092137\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658447092137  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:10.688850231 +0000 UTC m=+267.214638388,LastTimestamp:2024-10-24 13:10:02.489115135 +0000 UTC m=+319.014903302,Count:14,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:10:02.490675245Z E1024 13:10:02.490648       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:02.889647304Z E1024 13:10:02.889589       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:03.091126539Z E1024 13:10:03.091058       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:03.491095208Z E1024 13:10:03.491033       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:03.890279917Z E1024 13:10:03.890225       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:04.290187957Z E1024 13:10:04.290140       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:04.690798186Z E1024 13:10:04.690677       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:04.690798186Z I1024 13:10:04.690730       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:04.720803297Z E1024 13:10:04.720699       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658c26f4512c  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-10-24 13:09:44.510353708 +0000 UTC m=+301.036141865,LastTimestamp:2024-10-24 13:09:44.510353708 +0000 UTC m=+301.036141865,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-10-24T13:10:04.890017671Z E1024 13:10:04.889959       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:05.291944911Z E1024 13:10:05.291880       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:05.490478615Z E1024 13:10:05.490416       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:06.290480423Z E1024 13:10:06.290422       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:06.455775007Z E1024 13:10:06.455679       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658c6283b22b  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-10-24 13:09:45.509605931 +0000 UTC m=+302.035394128,LastTimestamp:2024-10-24 13:09:45.509605931 +0000 UTC m=+302.035394128,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-10-24T13:10:06.491642118Z W1024 13:10:06.491572       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:06.491720228Z E1024 13:10:06.491634       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:06.891629908Z E1024 13:10:06.891560       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:07.290623538Z E1024 13:10:07.290565       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:07.690378408Z E1024 13:10:07.690311       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:08.092124027Z E1024 13:10:08.092041       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:08.491107917Z E1024 13:10:08.491038       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:08.890959596Z E1024 13:10:08.890897       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:09.030467199Z E1024 13:10:09.030402       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658c0f0ee44c  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-10-24 13:09:44.109442124 +0000 UTC m=+300.635230281,LastTimestamp:2024-10-24 13:09:44.109442124 +0000 UTC m=+300.635230281,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-10-24T13:10:09.291090245Z E1024 13:10:09.291020       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:09.476294260Z I1024 13:10:09.476222       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:09.477284810Z E1024 13:10:09.477232       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:09.477284810Z I1024 13:10:09.477264       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:09.691217095Z E1024 13:10:09.691152       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:09.896944650Z E1024 13:10:09.896905       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:09.897010310Z I1024 13:10:09.896942       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:10.090376084Z E1024 13:10:10.090304       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:10.490744634Z E1024 13:10:10.490687       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:10.889586773Z E1024 13:10:10.889524       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:11.120360299Z E1024 13:10:11.120297       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.1801658447092137\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658447092137  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:10.688850231 +0000 UTC m=+267.214638388,LastTimestamp:2024-10-24 13:10:02.489115135 +0000 UTC m=+319.014903302,Count:14,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:10:11.290426282Z E1024 13:10:11.290359       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:11.689863792Z E1024 13:10:11.689809       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:12.090171051Z E1024 13:10:12.090113       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:12.150422613Z E1024 13:10:12.150368       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:12.490889391Z E1024 13:10:12.490839       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:12.890557651Z E1024 13:10:12.890493       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:13.290153910Z E1024 13:10:13.290096       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:13.489663815Z E1024 13:10:13.489611       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:13.890741415Z E1024 13:10:13.890686       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:14.290566554Z E1024 13:10:14.290510       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:14.690715354Z E1024 13:10:14.690652       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:14.722346875Z E1024 13:10:14.722280       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658c26f4512c  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-10-24 13:09:44.510353708 +0000 UTC m=+301.036141865,LastTimestamp:2024-10-24 13:09:44.510353708 +0000 UTC m=+301.036141865,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-10-24T13:10:15.090291244Z E1024 13:10:15.090235       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:15.291290468Z E1024 13:10:15.291222       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:15.291357928Z I1024 13:10:15.291278       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:15.690371088Z E1024 13:10:15.690301       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:15.891285863Z E1024 13:10:15.891196       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:16.290664852Z E1024 13:10:16.290612       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:16.457283156Z E1024 13:10:16.457234       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658c6283b22b  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-10-24 13:09:45.509605931 +0000 UTC m=+302.035394128,LastTimestamp:2024-10-24 13:09:45.509605931 +0000 UTC m=+302.035394128,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-10-24T13:10:16.690274211Z E1024 13:10:16.690221       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:17.090937641Z E1024 13:10:17.090881       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:17.490450441Z E1024 13:10:17.490388       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:17.891230431Z E1024 13:10:17.891158       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:18.290660621Z E1024 13:10:18.290606       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:18.690948590Z E1024 13:10:18.690894       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:19.031712448Z E1024 13:10:19.031659       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658c0f0ee44c  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-10-24 13:09:44.109442124 +0000 UTC m=+300.635230281,LastTimestamp:2024-10-24 13:09:44.109442124 +0000 UTC m=+300.635230281,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-10-24T13:10:19.094185979Z E1024 13:10:19.094112       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:19.490850389Z E1024 13:10:19.490789       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:19.890986348Z E1024 13:10:19.890926       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:20.290202658Z E1024 13:10:20.290135       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:20.690121038Z E1024 13:10:20.690047       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:21.090408727Z E1024 13:10:21.090353       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:21.122001458Z E1024 13:10:21.121923       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.1801658447092137\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658447092137  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:10.688850231 +0000 UTC m=+267.214638388,LastTimestamp:2024-10-24 13:10:02.489115135 +0000 UTC m=+319.014903302,Count:14,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:10:21.491294727Z E1024 13:10:21.491192       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:21.890643556Z E1024 13:10:21.890578       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:22.068658001Z E1024 13:10:22.068566       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:10:22.069491921Z E1024 13:10:22.069442       1 leaderelection.go:436] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:22.290866896Z E1024 13:10:22.290810       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:22.690843235Z E1024 13:10:22.690785       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:23.090533895Z E1024 13:10:23.090468       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:23.491148534Z E1024 13:10:23.491018       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:23.891116674Z E1024 13:10:23.891053       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:24.290867943Z E1024 13:10:24.290818       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:24.691371863Z E1024 13:10:24.691288       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:24.724173204Z E1024 13:10:24.724120       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658c26f4512c  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-10-24 13:09:44.510353708 +0000 UTC m=+301.036141865,LastTimestamp:2024-10-24 13:09:44.510353708 +0000 UTC m=+301.036141865,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-10-24T13:10:25.091030732Z E1024 13:10:25.090968       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:25.491016992Z E1024 13:10:25.490945       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:25.890890971Z E1024 13:10:25.890842       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:26.290846601Z E1024 13:10:26.290787       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:26.458681705Z E1024 13:10:26.458628       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658c6283b22b  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-10-24 13:09:45.509605931 +0000 UTC m=+302.035394128,LastTimestamp:2024-10-24 13:09:45.509605931 +0000 UTC m=+302.035394128,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-10-24T13:10:26.690874550Z E1024 13:10:26.690809       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:27.090409330Z E1024 13:10:27.090349       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:27.489951439Z E1024 13:10:27.489903       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:27.890256169Z E1024 13:10:27.890201       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:28.290498798Z E1024 13:10:28.290436       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:28.690874317Z E1024 13:10:28.690813       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:29.032927776Z E1024 13:10:29.032869       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658c0f0ee44c  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-10-24 13:09:44.109442124 +0000 UTC m=+300.635230281,LastTimestamp:2024-10-24 13:09:44.109442124 +0000 UTC m=+300.635230281,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-10-24T13:10:29.090508217Z E1024 13:10:29.090448       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:29.490936097Z E1024 13:10:29.490878       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:29.890669646Z E1024 13:10:29.890599       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:29.961309857Z I1024 13:10:29.961224       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:29.962601867Z E1024 13:10:29.962558       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:29.962646457Z I1024 13:10:29.962596       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:30.290325655Z E1024 13:10:30.290267       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:30.390354817Z E1024 13:10:30.390285       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:30.390354817Z I1024 13:10:30.390332       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:30.690511905Z E1024 13:10:30.690456       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:31.090626705Z E1024 13:10:31.090573       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:31.123721235Z E1024 13:10:31.123665       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.1801658447092137\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658447092137  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:09:10.688850231 +0000 UTC m=+267.214638388,LastTimestamp:2024-10-24 13:10:02.489115135 +0000 UTC m=+319.014903302,Count:14,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:10:31.490648604Z E1024 13:10:31.490603       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:31.890894583Z E1024 13:10:31.890836       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:32.290744003Z E1024 13:10:32.290680       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:32.691038012Z E1024 13:10:32.690971       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:33.090508862Z E1024 13:10:33.090429       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:33.491125502Z E1024 13:10:33.491046       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:33.891145462Z E1024 13:10:33.891088       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:34.289430091Z E1024 13:10:34.289348       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:34.491370986Z E1024 13:10:34.491303       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:34.725833762Z E1024 13:10:34.725768       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658c26f4512c  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-10-24 13:09:44.510353708 +0000 UTC m=+301.036141865,LastTimestamp:2024-10-24 13:09:44.510353708 +0000 UTC m=+301.036141865,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-10-24T13:10:34.890297586Z E1024 13:10:34.890219       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:35.691308624Z E1024 13:10:35.691233       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:35.890915859Z E1024 13:10:35.890862       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:36.290697908Z E1024 13:10:36.290623       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:36.290697908Z I1024 13:10:36.290664       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:36.460980212Z E1024 13:10:36.460925       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.1801658c6283b22b  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-10-24 13:09:45.509605931 +0000 UTC m=+302.035394128,LastTimestamp:2024-10-24 13:09:45.509605931 +0000 UTC m=+302.035394128,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-10-24T13:10:36.491246153Z E1024 13:10:36.491188       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:36.691598348Z E1024 13:10:36.691533       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:10:37.090852708Z E1024 13:10:37.090801       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:37.490153677Z E1024 13:10:37.490100       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:37.890274497Z E1024 13:10:37.890213       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:10:43.467389581Z I1024 13:10:43.467331       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-2" for revision 5 for the 1st time because installer pod failed: installer:  172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467389581Z W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467389581Z W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467389581Z W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467389581Z W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467389581Z W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467389581Z W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467389581Z W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467389581Z F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:10:43.467467230Z I1024 13:10:43.467413       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:10:43.467467230Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:10:43.467467230Z  CurrentRevision: (int32) 1,
2024-10-24T13:10:43.467467230Z  TargetRevision: (int32) 5,
2024-10-24T13:10:43.467467230Z  LastFailedRevision: (int32) 5,
2024-10-24T13:10:43.467467230Z  LastFailedTime: (*v1.Time)(0xc002f0d350)(2024-10-24 13:10:43.46732084 +0000 UTC m=+359.993109007),
2024-10-24T13:10:43.467467230Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:10:43.467467230Z  LastFailedCount: (int) 1,
2024-10-24T13:10:43.467467230Z  LastFallbackCount: (int) 0,
2024-10-24T13:10:43.467467230Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:10:43.467467230Z   (string) (len=2059) "installer:  172.30.0.1:443: connect: connection refused\nW1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:10:43.467467230Z  }
2024-10-24T13:10:43.467467230Z }
2024-10-24T13:10:43.467467230Z  because installer pod failed: installer:  172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467467230Z W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467467230Z W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467467230Z W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467467230Z W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467467230Z W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467467230Z W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467467230Z W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467467230Z F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:10:43.467500460Z I1024 13:10:43.467440       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:  172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467500460Z W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467500460Z W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467500460Z W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467500460Z W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467500460Z W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467500460Z W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467500460Z W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:10:43.467500460Z F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:10:44.125926956Z E1024 13:10:44.125845       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:10:44.147455347Z I1024 13:10:44.147386       1 helpers.go:184] lister was stale at resourceVersion=16545, live get showed resourceVersion=17050
2024-10-24T13:10:44.208669968Z W1024 13:10:44.208628       1 dynamic_operator_client.go:346] .status.conditions["MachineDeletionHooksControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:10:44.234056489Z I1024 13:10:44.233990       1 core.go:352] ConfigMap "openshift-etcd/etcd-endpoints" changes: {"data":{"d70ee276ae23755c":"10.0.0.4"},"metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:10:44.234200688Z I1024 13:10:44.234157       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-endpoints -n openshift-etcd:
2024-10-24T13:10:44.234200688Z cause by changes in data.d70ee276ae23755c
2024-10-24T13:11:10.986779177Z I1024 13:11:10.986700       1 helpers.go:184] lister was stale at resourceVersion=16545, live get showed resourceVersion=17061
2024-10-24T13:11:13.973573878Z I1024 13:11:13.973503       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:14.432285543Z W1024 13:11:14.432226       1 dynamic_operator_client.go:346] .status.conditions["MachineDeletionHooksControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:30.373385932Z I1024 13:11:30.373308       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:30.375144982Z I1024 13:11:30.374536       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.375426412Z I1024 13:11:30.375405       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.379143512Z I1024 13:11:30.379082       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.379357662Z I1024 13:11:30.379294       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.379733062Z I1024 13:11:30.379693       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.380038352Z I1024 13:11:30.380008       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.380446062Z I1024 13:11:30.380412       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.380666742Z I1024 13:11:30.380638       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.380769392Z W1024 13:11:30.380722       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.3:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]]
2024-10-24T13:11:30.381289802Z I1024 13:11:30.381220       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.381798762Z I1024 13:11:30.381711       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.382008572Z I1024 13:11:30.381975       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.382316502Z I1024 13:11:30.382286       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.382520202Z I1024 13:11:30.382490       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.382826192Z I1024 13:11:30.382796       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.383028602Z I1024 13:11:30.382997       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.383335712Z I1024 13:11:30.383306       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.383633882Z I1024 13:11:30.383588       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.383874452Z I1024 13:11:30.383821       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.384127062Z I1024 13:11:30.384095       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.384395662Z I1024 13:11:30.384327       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.384612522Z I1024 13:11:30.384571       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.384849672Z I1024 13:11:30.384796       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.385089802Z I1024 13:11:30.385018       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.385284322Z I1024 13:11:30.385234       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.385544502Z I1024 13:11:30.385456       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.391293752Z W1024 13:11:30.391237       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.3:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]]
2024-10-24T13:11:30.391881362Z W1024 13:11:30.391566       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.3:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]]
2024-10-24T13:11:30.391881362Z W1024 13:11:30.391776       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.3:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]]
2024-10-24T13:11:30.393853872Z W1024 13:11:30.391950       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.3:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]]
2024-10-24T13:11:30.393853872Z I1024 13:11:30.392879       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-2" for revision 5 for the 1st time because installer pod failed: installer:  172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393853872Z W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393853872Z W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393853872Z W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393853872Z W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393853872Z W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393853872Z W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393853872Z W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393853872Z F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:30.393853872Z I1024 13:11:30.392953       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:11:30.393853872Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:11:30.393853872Z  CurrentRevision: (int32) 1,
2024-10-24T13:11:30.393853872Z  TargetRevision: (int32) 5,
2024-10-24T13:11:30.393853872Z  LastFailedRevision: (int32) 5,
2024-10-24T13:11:30.393853872Z  LastFailedTime: (*v1.Time)(0xc000e0a798)(2024-10-24 13:11:30.392867512 +0000 UTC m=+406.918655679),
2024-10-24T13:11:30.393853872Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:11:30.393853872Z  LastFailedCount: (int) 1,
2024-10-24T13:11:30.393853872Z  LastFallbackCount: (int) 0,
2024-10-24T13:11:30.393853872Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:11:30.393853872Z   (string) (len=2059) "installer:  172.30.0.1:443: connect: connection refused\nW1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:11:30.393853872Z  }
2024-10-24T13:11:30.393853872Z }
2024-10-24T13:11:30.393853872Z  because installer pod failed: installer:  172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393853872Z W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393853872Z W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393853872Z W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393853872Z W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393853872Z W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393853872Z W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393853872Z W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393853872Z F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:30.393853872Z I1024 13:11:30.392961       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:  172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393853872Z W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393853872Z W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393853872Z W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393920022Z W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393920022Z W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393920022Z W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393920022Z W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:30.393920022Z F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:30.396911592Z I1024 13:11:30.396876       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 6 triggered by "required configmap/etcd-endpoints has changed"
2024-10-24T13:11:30.410305802Z W1024 13:11:30.410231       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.3:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]]
2024-10-24T13:11:30.413660063Z W1024 13:11:30.413634       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.3:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]]
2024-10-24T13:11:30.414223092Z I1024 13:11:30.414168       1 core.go:352] ConfigMap "openshift-etcd/etcd-scripts" changes: {"apiVersion":"v1","data":{"etcd.env":"export ALL_ETCD_ENDPOINTS=\"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.5:2379,https://10.0.0.6:2379\"\nexport ETCDCTL_API=\"3\"\nexport ETCDCTL_CACERT=\"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\nexport ETCDCTL_CERT=\"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\nexport ETCDCTL_ENDPOINTS=\"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\nexport ETCDCTL_KEY=\"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\nexport ETCD_CIPHER_SUITES=\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\nexport ETCD_DATA_DIR=\"/var/lib/etcd\"\nexport ETCD_ELECTION_TIMEOUT=\"1000\"\nexport ETCD_ENABLE_PPROF=\"true\"\nexport ETCD_EXPERIMENTAL_MAX_LEARNERS=\"3\"\nexport ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION=\"200ms\"\nexport ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL=\"5s\"\nexport ETCD_HEARTBEAT_INTERVAL=\"100\"\nexport ETCD_IMAGE=\"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\nexport ETCD_INITIAL_CLUSTER_STATE=\"existing\"\nexport ETCD_QUOTA_BACKEND_BYTES=\"8589934592\"\nexport ETCD_SOCKET_REUSE_ADDRESS=\"true\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME=\"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST=\"10.0.0.3\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP=\"10.0.0.3\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME=\"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST=\"10.0.0.4\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP=\"10.0.0.4\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME=\"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST=\"10.0.0.6\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP=\"10.0.0.6\"\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:11:30.414312212Z I1024 13:11:30.414268       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.414714553Z I1024 13:11:30.414606       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-scripts -n openshift-etcd:
2024-10-24T13:11:30.414714553Z cause by changes in data.etcd.env
2024-10-24T13:11:30.426430423Z W1024 13:11:30.426384       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.3:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]]
2024-10-24T13:11:30.430186253Z I1024 13:11:30.430090       1 core.go:352] ConfigMap "openshift-etcd/etcd-pod" changes: {"apiVersion":"v1","data":{"pod.yaml":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: etcd\n  namespace: openshift-etcd\n  annotations:\n    kubectl.kubernetes.io/default-container: etcd\n    target.workload.openshift.io/management: '{\"effect\": \"PreferredDuringScheduling\"}'\n  labels:\n    app: etcd\n    k8s-app: etcd\n    etcd: \"true\"\n    revision: \"REVISION\"\nspec:\n  initContainers:\n    - name: setup\n      image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          echo -n \"Fixing etcd log permissions.\"\n          mkdir -p /var/log/etcd  \u0026\u0026 chmod 0600 /var/log/etcd\n          echo -n \"Fixing etcd auto backup permissions.\"\n          mkdir -p /var/lib/etcd-auto-backup  \u0026\u0026 chmod 0600 /var/lib/etcd-auto-backup\n      securityContext:\n        privileged: true\n      resources:\n        requests:\n          memory: 50Mi\n          cpu: 5m\n      volumeMounts:\n        - mountPath: /var/log/etcd\n          name: log-dir\n    - name: etcd-ensure-env-vars\n      image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          set -euo pipefail\n\n          : \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST?not set}\"\n          : \"${NODE_NODE_ENVVAR_NAME_ETCD_NAME?not set}\"\n          : \"${NODE_NODE_ENVVAR_NAME_IP?not set}\"\n\n          # check for ipv4 addresses as well as ipv6 addresses with extra square brackets\n          if [[ \"${NODE_NODE_ENVVAR_NAME_IP}\" != \"${NODE_IP}\" \u0026\u0026 \"${NODE_NODE_ENVVAR_NAME_IP}\" != \"[${NODE_IP}]\" ]]; then\n            # echo the error message to stderr\n            echo \"Expected node IP to be ${NODE_IP} got ${NODE_NODE_ENVVAR_NAME_IP}\" \u003e\u00262\n            exit 1\n          fi\n\n          # check for ipv4 addresses as well as ipv6 addresses with extra square brackets\n          if [[ \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" != \"${NODE_IP}\" \u0026\u0026 \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" != \"[${NODE_IP}]\" ]]; then\n            # echo the error message to stderr\n            echo \"Expected etcd url host to be ${NODE_IP} got ${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" \u003e\u00262\n            exit 1\n          fi\n\n      resources:\n        requests:\n          memory: 60Mi\n          cpu: 10m\n      securityContext:\n        privileged: true\n      env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.5:2379,https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"1000\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"100\"\n      - name: \"ETCD_IMAGE\"\n        value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n        value: \"10.0.0.6\"\n      - name: NODE_IP\n        valueFrom:\n          fieldRef:\n            fieldPath: status.podIP\n    - name: etcd-resources-copy\n      image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          set -euo pipefail\n\n          rm -f $(grep -l '^### Created by cluster-etcd-operator' /usr/local/bin/*)\n          cp -p /etc/kubernetes/static-pod-certs/configmaps/etcd-scripts/*.sh /usr/local/bin\n\n      resources:\n        requests:\n          memory: 60Mi\n          cpu: 10m\n      securityContext:\n        privileged: true\n      volumeMounts:\n        - mountPath: /etc/kubernetes/static-pod-resources\n          name: resource-dir\n        - mountPath: /etc/kubernetes/static-pod-certs\n          name: cert-dir\n        - mountPath: /usr/local/bin\n          name: usr-local-bin\n  containers:\n  # The etcdctl container should always be first. It is intended to be used\n  # to open a remote shell via `oc rsh` that is ready to run `etcdctl`.\n  - name: etcdctl\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - \"/bin/bash\"\n      - \"-c\"\n      - \"trap TERM INT; sleep infinity \u0026 wait\"\n    resources:\n      requests:\n        memory: 60Mi\n        cpu: 10m\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n    env:\n    - name: \"ALL_ETCD_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.5:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_API\"\n      value: \"3\"\n    - name: \"ETCDCTL_CACERT\"\n      value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n    - name: \"ETCDCTL_CERT\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n    - name: \"ETCDCTL_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_KEY\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n    - name: \"ETCD_CIPHER_SUITES\"\n      value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n    - name: \"ETCD_DATA_DIR\"\n      value: \"/var/lib/etcd\"\n    - name: \"ETCD_ELECTION_TIMEOUT\"\n      value: \"1000\"\n    - name: \"ETCD_ENABLE_PPROF\"\n      value: \"true\"\n    - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n      value: \"3\"\n    - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n      value: \"200ms\"\n    - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n      value: \"5s\"\n    - name: \"ETCD_HEARTBEAT_INTERVAL\"\n      value: \"100\"\n    - name: \"ETCD_IMAGE\"\n      value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n    - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n      value: \"existing\"\n    - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n      value: \"8589934592\"\n    - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n      value: \"true\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n      value: \"10.0.0.6\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n      value: \"10.0.0.6\"\n    - name: \"ETCD_STATIC_POD_VERSION\"\n      value: \"REVISION\"\n  - name: etcd\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n\n        etcdctl member list || true\n\n        # this has a non-zero return code if the command is non-zero.  If you use an export first, it doesn't and you\n        # will succeed when you should fail.\n        ETCD_INITIAL_CLUSTER=$(discover-etcd-initial-cluster \\\n          --cacert=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --cert=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --key=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --endpoints=${ALL_ETCD_ENDPOINTS} \\\n          --data-dir=/var/lib/etcd \\\n          --target-peer-url-host=${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST} \\\n          --target-name=NODE_NAME)\n        export ETCD_INITIAL_CLUSTER\n\n        # we cannot use the \"normal\" port conflict initcontainer because when we upgrade, the existing static pod will never yield,\n        # so we do the detection in etcd container itself.\n        echo -n \"Waiting for ports 2379, 2380 and 9978 to be released.\"\n        time while [ -n \"$(ss -Htan '( sport = 2379 or sport = 2380 or sport = 9978 )')\" ]; do\n          echo -n \".\"\n          sleep 1\n        done\n\n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n        env | grep ETCD | grep -v NODE\n\n        set -x\n        # See https://etcd.io/docs/v3.4.0/tuning/ for why we use ionice\n        exec nice -n -19 ionice -c2 -n0 etcd \\\n          --logger=zap \\\n          --log-level=info \\\n          --experimental-initial-corrupt-check=true \\\n          --snapshot-count=10000 \\\n          --initial-advertise-peer-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2380 \\\n          --cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --client-cert-auth=true \\\n          --peer-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --peer-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --peer-trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --peer-client-cert-auth=true \\\n          --advertise-client-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2379 \\\n          --listen-client-urls=https://0.0.0.0:2379,unixs://${NODE_NODE_ENVVAR_NAME_IP}:0 \\\n          --listen-peer-urls=https://0.0.0.0:2380 \\\n          --metrics=extensive \\\n          --listen-metrics-urls=https://0.0.0.0:9978 ||  mv /etc/kubernetes/etcd-backup-dir/etcd-member.yaml /etc/kubernetes/manifests\n    env:\n    - name: \"ALL_ETCD_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.5:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_API\"\n      value: \"3\"\n    - name: \"ETCDCTL_CACERT\"\n      value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n    - name: \"ETCDCTL_CERT\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n    - name: \"ETCDCTL_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_KEY\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n    - name: \"ETCD_CIPHER_SUITES\"\n      value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n    - name: \"ETCD_DATA_DIR\"\n      value: \"/var/lib/etcd\"\n    - name: \"ETCD_ELECTION_TIMEOUT\"\n      value: \"1000\"\n    - name: \"ETCD_ENABLE_PPROF\"\n      value: \"true\"\n    - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n      value: \"3\"\n    - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n      value: \"200ms\"\n    - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n      value: \"5s\"\n    - name: \"ETCD_HEARTBEAT_INTERVAL\"\n      value: \"100\"\n    - name: \"ETCD_IMAGE\"\n      value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n    - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n      value: \"existing\"\n    - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n      value: \"8589934592\"\n    - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n      value: \"true\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n      value: \"10.0.0.6\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n      value: \"10.0.0.6\"\n    - name: \"ETCD_STATIC_POD_VERSION\"\n      value: \"REVISION\"\n    resources:\n      requests:\n        memory: 600Mi\n        cpu: 300m\n    readinessProbe:\n      httpGet:\n        port: 9980\n        path: readyz\n        scheme: HTTPS\n      timeoutSeconds: 30\n      failureThreshold: 5\n      periodSeconds: 5\n      successThreshold: 1\n    livenessProbe:\n      httpGet:\n        path: healthz\n        port: 9980\n        scheme: HTTPS\n      timeoutSeconds: 30\n      periodSeconds: 5\n      successThreshold: 1\n      failureThreshold: 5\n    startupProbe:\n      httpGet:\n        port: 9980\n        path: readyz\n        scheme: HTTPS\n      initialDelaySeconds: 10\n      timeoutSeconds: 1\n      periodSeconds: 10\n      successThreshold: 1\n      failureThreshold: 18\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n  - name: etcd-metrics\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n\n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n\n        exec nice -n -18 etcd grpc-proxy start \\\n          --endpoints https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:9978 \\\n          --metrics-addr https://0.0.0.0:9979 \\\n          --listen-addr 127.0.0.1:9977 \\\n          --advertise-client-url \"\"  \\\n          --key /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --key-file /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-metrics-NODE_NAME.key \\\n          --cert /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --cert-file /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-metrics-NODE_NAME.crt \\\n          --cacert /etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --trusted-ca-file /etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/metrics-ca-bundle.crt \\\n          --listen-cipher-suites ${ETCD_CIPHER_SUITES}\n    env:\n    - name: \"ALL_ETCD_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.5:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_API\"\n      value: \"3\"\n    - name: \"ETCDCTL_CACERT\"\n      value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n    - name: \"ETCDCTL_CERT\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n    - name: \"ETCDCTL_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_KEY\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n    - name: \"ETCD_CIPHER_SUITES\"\n      value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n    - name: \"ETCD_DATA_DIR\"\n      value: \"/var/lib/etcd\"\n    - name: \"ETCD_ELECTION_TIMEOUT\"\n      value: \"1000\"\n    - name: \"ETCD_ENABLE_PPROF\"\n      value: \"true\"\n    - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n      value: \"3\"\n    - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n      value: \"200ms\"\n    - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n      value: \"5s\"\n    - name: \"ETCD_HEARTBEAT_INTERVAL\"\n      value: \"100\"\n    - name: \"ETCD_IMAGE\"\n      value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n    - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n      value: \"existing\"\n    - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n      value: \"8589934592\"\n    - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n      value: \"true\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n      value: \"10.0.0.6\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n      value: \"10.0.0.6\"\n    - name: \"ETCD_STATIC_POD_VERSION\"\n      value: \"REVISION\"\n    resources:\n      requests:\n        memory: 200Mi\n        cpu: 40m\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n  - name: etcd-readyz\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:f99379698faa42b7db0e7367c8e7f738a69f699f414a7567a5593a530fb6723d\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n        \n        exec nice -n -18 cluster-etcd-operator readyz \\\n          --target=https://localhost:2379 \\\n          --listen-port=9980 \\\n          --serving-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --serving-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --client-cert-file=$(ETCDCTL_CERT) \\\n          --client-key-file=$(ETCDCTL_KEY) \\\n          --client-cacert-file=$(ETCDCTL_CACERT) \\\n          --listen-cipher-suites=$(ETCD_CIPHER_SUITES)\n    securityContext:\n      privileged: true\n    ports:\n    - containerPort: 9980\n      name: readyz\n      protocol: TCP\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    env:\n    - name: \"ALL_ETCD_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.5:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_API\"\n      value: \"3\"\n    - name: \"ETCDCTL_CACERT\"\n      value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n    - name: \"ETCDCTL_CERT\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n    - name: \"ETCDCTL_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_KEY\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n    - name: \"ETCD_CIPHER_SUITES\"\n      value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n    - name: \"ETCD_DATA_DIR\"\n      value: \"/var/lib/etcd\"\n    - name: \"ETCD_ELECTION_TIMEOUT\"\n      value: \"1000\"\n    - name: \"ETCD_ENABLE_PPROF\"\n      value: \"true\"\n    - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n      value: \"3\"\n    - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n      value: \"200ms\"\n    - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n      value: \"5s\"\n    - name: \"ETCD_HEARTBEAT_INTERVAL\"\n      value: \"100\"\n    - name: \"ETCD_IMAGE\"\n      value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n    - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n      value: \"existing\"\n    - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n      value: \"8589934592\"\n    - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n      value: \"true\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n      value: \"10.0.0.6\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n      value: \"10.0.0.6\"\n    volumeMounts:\n      - mountPath: /var/log/etcd/\n        name: log-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n  - name: etcd-rev\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:f99379698faa42b7db0e7367c8e7f738a69f699f414a7567a5593a530fb6723d\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n        \n        cluster-etcd-operator rev \\\n          --endpoints=$(ALL_ETCD_ENDPOINTS) \\\n          --client-cert-file=$(ETCDCTL_CERT) \\\n          --client-key-file=$(ETCDCTL_KEY) \\\n          --client-cacert-file=$(ETCDCTL_CACERT)\n    securityContext:\n      privileged: true\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    env:\n    - name: \"ALL_ETCD_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.5:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_API\"\n      value: \"3\"\n    - name: \"ETCDCTL_CACERT\"\n      value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n    - name: \"ETCDCTL_CERT\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n    - name: \"ETCDCTL_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_KEY\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n    - name: \"ETCD_CIPHER_SUITES\"\n      value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n    - name: \"ETCD_DATA_DIR\"\n      value: \"/var/lib/etcd\"\n    - name: \"ETCD_ELECTION_TIMEOUT\"\n      value: \"1000\"\n    - name: \"ETCD_ENABLE_PPROF\"\n      value: \"true\"\n    - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n      value: \"3\"\n    - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n      value: \"200ms\"\n    - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n      value: \"5s\"\n    - name: \"ETCD_HEARTBEAT_INTERVAL\"\n      value: \"100\"\n    - name: \"ETCD_IMAGE\"\n      value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n    - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n      value: \"existing\"\n    - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n      value: \"8589934592\"\n    - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n      value: \"true\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n      value: \"10.0.0.6\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n      value: \"10.0.0.6\"\n    volumeMounts:\n    - mountPath: /var/lib/etcd\n      name: data-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n  hostNetwork: true\n  priorityClassName: system-node-critical\n  tolerations:\n  - operator: \"Exists\"\n  volumes:\n    - hostPath:\n        path: /etc/kubernetes/manifests\n      name: static-pod-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-pod-REVISION\n      name: resource-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-certs\n      name: cert-dir\n    - hostPath:\n        path: /var/lib/etcd\n        type: \"\"\n      name: data-dir\n    - hostPath:\n        path: /usr/local/bin\n      name: usr-local-bin\n    - hostPath:\n        path: /var/log/etcd\n      name: log-dir\n    - hostPath:\n        path: /etc/kubernetes\n      name: config-dir\n    - hostPath:\n        path: /var/lib/etcd-auto-backup\n      name: etcd-auto-backup-dir\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:11:30.433472512Z I1024 13:11:30.430744       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-pod -n openshift-etcd:
2024-10-24T13:11:30.433472512Z cause by changes in data.pod.yaml
2024-10-24T13:11:30.433472512Z I1024 13:11:30.431382       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.433472512Z I1024 13:11:30.432420       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:30.439458693Z W1024 13:11:30.439150       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.3:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]]
2024-10-24T13:11:30.440091743Z I1024 13:11:30.440045       1 helpers.go:260] lister was stale at resourceVersion=16545, live get showed resourceVersion=17305
2024-10-24T13:11:30.475394533Z W1024 13:11:30.475332       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.3:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]]
2024-10-24T13:11:30.781923466Z I1024 13:11:30.781840       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-pod-6 -n openshift-etcd because it was missing
2024-10-24T13:11:30.805824276Z I1024 13:11:30.805786       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:31.181530431Z I1024 13:11:31.180835       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:31.182891101Z I1024 13:11:31.182821       1 core.go:352] ConfigMap "openshift-etcd/restore-etcd-pod" changes: {"apiVersion":"v1","data":{"pod.yaml":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: etcd\n  namespace: openshift-etcd\n  labels:\n    app: etcd\n    k8s-app: etcd\n    etcd: \"true\"\n    revision: \"REVISION\"\nspec:\n  containers:\n  - name: etcd\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n               \n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n        export ETCD_INITIAL_CLUSTER=\"${ETCD_NAME}=https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:2380\"\n        env | grep ETCD | grep -v NODE\n        export ETCD_NODE_PEER_URL=https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:2380\n        export REV_JSON=\"/var/lib/etcd-backup/revision.json\"\n        export SNAPSHOT_FILE=\"/var/lib/etcd-backup/snapshot.db\"\n\n        # checking if data directory is empty, if not etcdctl restore will fail         \n        if [ -n \"$(ls -A \"/var/lib/etcd\")\" ]; then\n          echo \"please delete the contents of the /var/lib/etcd directory before restoring, running the restore script will do this for you\"\n          exit 1\n        fi\n        \n        ETCD_ETCDCTL_BIN=\"etcdctl\"\n        if [ -x \"$(command -v etcdutl)\" ]; then\n          echo \"found etcdutl, using that instead of etcdctl for local operations\"\n          ETCD_ETCDCTL_BIN=\"etcdutl\"\n        fi      \n\n        # check if we have backup file to be restored\n        # if the file exist, check if it has not changed size in last 5 seconds\n        if [ ! -f \"${SNAPSHOT_FILE}\" ]; then\n          echo \"please make a copy of the snapshot db file, then move that copy to ${SNAPSHOT_FILE}\"\n          exit 1\n        else\n          filesize=$(stat --format=%s \"${SNAPSHOT_FILE}\")\n          sleep 5\n          newfilesize=$(stat --format=%s \"${SNAPSHOT_FILE}\")\n          if [ \"$filesize\" != \"$newfilesize\" ]; then\n            echo \"file size has changed since last 5 seconds, retry sometime after copying is complete\"\n            exit 1\n          fi\n        fi\n        \n        SNAPSHOT_REV=$(etcdutl snapshot status -wjson \"$SNAPSHOT_FILE\" | jq -r \".revision\")\n        echo \"snapshot is at revision ${SNAPSHOT_REV}\"\n        \n        if [ -n \"$(ls -A \"${REV_JSON}\")\" ]; then\n           # this will bump by the amount of the last known live revision + 20% slack.\n           # Note: the bump amount is an addition to the current revision stored in the snapshot.\n           # We're avoiding to do any math with SNAPSHOT_REV, uint64 has plenty of space to double revisions\n           # and we're assuming that full disaster restores are a very rare occurrence anyway.\n           BUMP_REV=$(jq -r \"(.maxRaftIndex*1.2|floor)\" \"${REV_JSON}\")\n           echo \"bumping revisions by ${BUMP_REV}\"\n        else\n           # we can't take SNAPSHOT_REV as an indicator here, because the snapshot might be much older\n           # than any currently live served revision. \n           # 1bn would be an etcd running at 1000 writes/s for about eleven days.\n           echo \"no revision.json found, assuming a 1bn revision bump\"\n           BUMP_REV=1000000000\n        fi\n        \n        UUID=$(uuidgen)\n        echo \"restoring to a single node cluster\"\n        ${ETCD_ETCDCTL_BIN} snapshot restore \"${SNAPSHOT_FILE}\" \\\n         --name $ETCD_NAME \\\n         --initial-cluster=$ETCD_INITIAL_CLUSTER \\\n         --initial-cluster-token \"openshift-etcd-${UUID}\" \\\n         --initial-advertise-peer-urls $ETCD_NODE_PEER_URL \\\n         --data-dir=\"/var/lib/etcd/restore-${UUID}\" \\\n         --mark-compacted \\\n         --bump-revision \"${BUMP_REV}\"\n\n        mv /var/lib/etcd/restore-${UUID}/* /var/lib/etcd/\n        # copy the revision.json back in case a second restore needs to be run afterwards\n        if [ -n \"$(ls -A \"${REV_JSON}\")\" ]; then\n           cp ${REV_JSON} /var/lib/etcd/\n        fi\n\n        rmdir /var/lib/etcd/restore-${UUID}\n        rm /var/lib/etcd-backup/snapshot.db\n\n        set -x\n        exec etcd \\\n          --logger=zap \\\n          --log-level=info \\\n          --initial-advertise-peer-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2380 \\\n          --cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --client-cert-auth=true \\\n          --peer-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --peer-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --peer-trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --peer-client-cert-auth=true \\\n          --advertise-client-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2379 \\\n          --listen-client-urls=https://0.0.0.0:2379 \\\n          --listen-peer-urls=https://0.0.0.0:2380 \\\n          --metrics=extensive \\\n          --listen-metrics-urls=https://0.0.0.0:9978\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.5:2379,https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"1000\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"100\"\n      - name: \"ETCD_IMAGE\"\n        value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n        value: \"10.0.0.6\"\n      - name: \"ETCD_STATIC_POD_REV\"\n        value: \"REVISION\"\n    resources:\n      requests:\n        memory: 600Mi\n        cpu: 300m\n    readinessProbe:\n      tcpSocket:\n        port: 2380\n      failureThreshold: 3\n      initialDelaySeconds: 3\n      periodSeconds: 5\n      successThreshold: 1\n      timeoutSeconds: 5\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n      - mountPath: /var/lib/etcd-backup/\n        name: backup-dir\n  hostNetwork: true\n  priorityClassName: system-node-critical\n  tolerations:\n  - operator: \"Exists\"\n  volumes:\n    - hostPath:\n        path: /etc/kubernetes/manifests\n      name: static-pod-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-certs\n      name: cert-dir\n    - hostPath:\n        path: /var/lib/etcd\n        type: \"\"\n      name: data-dir\n    - hostPath:\n        path: /var/lib/etcd-backup\n        type: \"\"\n      name: backup-dir\n","quorum-restore-pod.yaml":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: etcd\n  namespace: openshift-etcd\n  labels:\n    app: etcd\n    k8s-app: etcd\n    etcd: \"true\"\n    revision: \"REVISION\"\nspec:\n  containers:\n  - name: etcd\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n        \n        set -x\n        exec etcd \\\n          --logger=zap \\\n          --log-level=info \\\n          --force-new-cluster \\\n          --name=\"${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\" \\\n          --initial-cluster=\"${NODE_NODE_ENVVAR_NAME_ETCD_NAME}=https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:2380\" \\\n          --initial-advertise-peer-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2380 \\\n          --cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --client-cert-auth=true \\\n          --peer-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --peer-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --peer-trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --peer-client-cert-auth=true \\\n          --advertise-client-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2379 \\\n          --listen-client-urls=https://0.0.0.0:2379 \\\n          --listen-peer-urls=https://0.0.0.0:2380 \\\n          --metrics=extensive \\\n          --listen-metrics-urls=https://0.0.0.0:9978\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.5:2379,https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"1000\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"100\"\n      - name: \"ETCD_IMAGE\"\n        value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n        value: \"10.0.0.6\"\n      - name: \"ETCD_STATIC_POD_REV\"\n        value: \"REVISION\"\n    resources:\n      requests:\n        memory: 600Mi\n        cpu: 300m\n    readinessProbe:\n      tcpSocket:\n        port: 2380\n      failureThreshold: 3\n      initialDelaySeconds: 3\n      periodSeconds: 5\n      successThreshold: 1\n      timeoutSeconds: 5\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n      - mountPath: /var/lib/etcd-backup/\n        name: backup-dir\n  hostNetwork: true\n  priorityClassName: system-node-critical\n  tolerations:\n  - operator: \"Exists\"\n  volumes:\n    - hostPath:\n        path: /etc/kubernetes/manifests\n      name: static-pod-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-certs\n      name: cert-dir\n    - hostPath:\n        path: /var/lib/etcd\n        type: \"\"\n      name: data-dir\n    - hostPath:\n        path: /var/lib/etcd-backup\n        type: \"\"\n      name: backup-dir\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:11:31.183222551Z I1024 13:11:31.183164       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/restore-etcd-pod -n openshift-etcd:
2024-10-24T13:11:31.183222551Z cause by changes in data.pod.yaml,data.quorum-restore-pod.yaml
2024-10-24T13:11:31.378040962Z I1024 13:11:31.376706       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:31.378040962Z I1024 13:11:31.377927       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-endpoints-6 -n openshift-etcd because it was missing
2024-10-24T13:11:31.579688664Z I1024 13:11:31.579621       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-2" for revision 5 for the 1st time because installer pod failed: installer:  172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579688664Z W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579688664Z W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579688664Z W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579688664Z W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579688664Z W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579688664Z W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579688664Z W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579688664Z F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:31.579788965Z I1024 13:11:31.579678       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:  172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579788965Z W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579788965Z W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579788965Z W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579788965Z W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579788965Z W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579788965Z W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579788965Z W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579788965Z F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:31.579788965Z I1024 13:11:31.579737       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:11:31.579788965Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:11:31.579788965Z  CurrentRevision: (int32) 1,
2024-10-24T13:11:31.579788965Z  TargetRevision: (int32) 5,
2024-10-24T13:11:31.579788965Z  LastFailedRevision: (int32) 5,
2024-10-24T13:11:31.579788965Z  LastFailedTime: (*v1.Time)(0xc00229dba8)(2024-10-24 13:11:31.579608055 +0000 UTC m=+408.105396221),
2024-10-24T13:11:31.579788965Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:11:31.579788965Z  LastFailedCount: (int) 1,
2024-10-24T13:11:31.579788965Z  LastFallbackCount: (int) 0,
2024-10-24T13:11:31.579788965Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:11:31.579788965Z   (string) (len=2059) "installer:  172.30.0.1:443: connect: connection refused\nW1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:11:31.579788965Z  }
2024-10-24T13:11:31.579788965Z }
2024-10-24T13:11:31.579788965Z  because installer pod failed: installer:  172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579788965Z W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579788965Z W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579788965Z W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579788965Z W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579788965Z W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579788965Z W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579788965Z W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:31.579788965Z F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:31.616136735Z I1024 13:11:31.616067       1 helpers.go:260] lister was stale at resourceVersion=16545, live get showed resourceVersion=17686
2024-10-24T13:11:31.979744298Z I1024 13:11:31.979676       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:31.979862339Z I1024 13:11:31.979830       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-all-bundles-6 -n openshift-etcd because it was missing
2024-10-24T13:11:32.192663331Z I1024 13:11:32.192600       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:32.587419215Z I1024 13:11:32.587361       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-all-certs-6 -n openshift-etcd because it was missing
2024-10-24T13:11:32.781898377Z I1024 13:11:32.779825       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-2" for revision 5 for the 1st time because installer pod failed: installer:  172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.781898377Z W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.781898377Z W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.781898377Z W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.781898377Z W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.781898377Z W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.781898377Z W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.781898377Z W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.781898377Z F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:32.781898377Z I1024 13:11:32.780421       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:11:32.781898377Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:11:32.781898377Z  CurrentRevision: (int32) 1,
2024-10-24T13:11:32.781898377Z  TargetRevision: (int32) 5,
2024-10-24T13:11:32.781898377Z  LastFailedRevision: (int32) 5,
2024-10-24T13:11:32.781898377Z  LastFailedTime: (*v1.Time)(0xc002e05f38)(2024-10-24 13:11:32.779744257 +0000 UTC m=+409.305532444),
2024-10-24T13:11:32.781898377Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:11:32.781898377Z  LastFailedCount: (int) 1,
2024-10-24T13:11:32.781898377Z  LastFallbackCount: (int) 0,
2024-10-24T13:11:32.781898377Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:11:32.781898377Z   (string) (len=2059) "installer:  172.30.0.1:443: connect: connection refused\nW1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:11:32.781898377Z  }
2024-10-24T13:11:32.781898377Z }
2024-10-24T13:11:32.781898377Z  because installer pod failed: installer:  172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.781898377Z W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.781898377Z W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.781898377Z W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.781898377Z W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.781898377Z W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.781898377Z W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.781898377Z W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.781898377Z F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:32.784786787Z I1024 13:11:32.780161       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:  172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.784786787Z W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.784786787Z W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.784786787Z W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.784786787Z W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.784786787Z W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.784786787Z W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.784786787Z W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:32.784786787Z F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:32.815222448Z I1024 13:11:32.815171       1 helpers.go:260] lister was stale at resourceVersion=16545, live get showed resourceVersion=17711
2024-10-24T13:11:33.178872411Z I1024 13:11:33.178302       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:33.178872411Z W1024 13:11:33.178486       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:33.178872411Z W1024 13:11:33.178507       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:33.178872411Z I1024 13:11:33.178818       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 6 triggered by "required configmap/etcd-endpoints has changed"
2024-10-24T13:11:33.200608271Z W1024 13:11:33.200555       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:33.200812121Z W1024 13:11:33.200695       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:33.236790372Z W1024 13:11:33.236116       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:33.236790372Z W1024 13:11:33.236152       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:33.268201532Z W1024 13:11:33.268123       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:33.268201532Z W1024 13:11:33.268151       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:33.311395343Z W1024 13:11:33.311292       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:33.311395343Z W1024 13:11:33.311317       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:33.375612363Z W1024 13:11:33.375549       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:33.375612363Z W1024 13:11:33.375575       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:33.479112935Z W1024 13:11:33.479038       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:33.479112935Z W1024 13:11:33.479065       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:33.583331826Z I1024 13:11:33.583279       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:33.659025027Z W1024 13:11:33.658947       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:33.659025027Z W1024 13:11:33.658972       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:33.775079448Z I1024 13:11:33.775003       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-2" for revision 5 for the 1st time because installer pod failed: installer:  172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.775079448Z W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.775079448Z W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.775079448Z W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.775079448Z W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.775079448Z W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.775079448Z W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.775079448Z W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.775079448Z F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:33.775131557Z I1024 13:11:33.775102       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:11:33.775131557Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:11:33.775131557Z  CurrentRevision: (int32) 1,
2024-10-24T13:11:33.775131557Z  TargetRevision: (int32) 5,
2024-10-24T13:11:33.775131557Z  LastFailedRevision: (int32) 5,
2024-10-24T13:11:33.775131557Z  LastFailedTime: (*v1.Time)(0xc003225878)(2024-10-24 13:11:33.774981108 +0000 UTC m=+410.300769265),
2024-10-24T13:11:33.775131557Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:11:33.775131557Z  LastFailedCount: (int) 1,
2024-10-24T13:11:33.775131557Z  LastFallbackCount: (int) 0,
2024-10-24T13:11:33.775131557Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:11:33.775131557Z   (string) (len=2059) "installer:  172.30.0.1:443: connect: connection refused\nW1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:11:33.775131557Z  }
2024-10-24T13:11:33.775131557Z }
2024-10-24T13:11:33.775131557Z  because installer pod failed: installer:  172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.775131557Z W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.775131557Z W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.775131557Z W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.775131557Z W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.775131557Z W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.775131557Z W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.775131557Z W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.775131557Z F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:33.776320398Z I1024 13:11:33.776284       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:  172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.776320398Z W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.776320398Z W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.776320398Z W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.776320398Z W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.776320398Z W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.776320398Z W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.776320398Z W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:33.776320398Z F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:33.808514918Z I1024 13:11:33.808089       1 helpers.go:260] lister was stale at resourceVersion=16545, live get showed resourceVersion=17751
2024-10-24T13:11:34.006289620Z W1024 13:11:34.005834       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:34.006289620Z W1024 13:11:34.005858       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:34.269996483Z E1024 13:11:34.269911       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:11:34.577096786Z I1024 13:11:34.577019       1 installer_controller.go:501] Will retry "ci-op-2fcpj5j6-f6035-2lklf-master-2" for revision 5 for the 1st time because installer pod failed: installer:  172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577096786Z W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577096786Z W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577096786Z W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577096786Z W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577096786Z W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577096786Z W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577096786Z W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577096786Z F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:34.577193136Z I1024 13:11:34.577115       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:11:34.577193136Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:11:34.577193136Z  CurrentRevision: (int32) 1,
2024-10-24T13:11:34.577193136Z  TargetRevision: (int32) 5,
2024-10-24T13:11:34.577193136Z  LastFailedRevision: (int32) 5,
2024-10-24T13:11:34.577193136Z  LastFailedTime: (*v1.Time)(0xc003b22708)(2024-10-24 13:11:34.577003276 +0000 UTC m=+411.102791463),
2024-10-24T13:11:34.577193136Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:11:34.577193136Z  LastFailedCount: (int) 1,
2024-10-24T13:11:34.577193136Z  LastFallbackCount: (int) 0,
2024-10-24T13:11:34.577193136Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:11:34.577193136Z   (string) (len=2059) "installer:  172.30.0.1:443: connect: connection refused\nW1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:11:34.577193136Z  }
2024-10-24T13:11:34.577193136Z }
2024-10-24T13:11:34.577193136Z  because installer pod failed: installer:  172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577193136Z W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577193136Z W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577193136Z W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577193136Z W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577193136Z W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577193136Z W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577193136Z W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577193136Z F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:34.577193136Z I1024 13:11:34.577144       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:  172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577193136Z W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577193136Z W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577193136Z W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577193136Z W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577193136Z W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577193136Z W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577193136Z W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:11:34.577193136Z F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition
2024-10-24T13:11:34.609886906Z I1024 13:11:34.609838       1 helpers.go:260] lister was stale at resourceVersion=16545, live get showed resourceVersion=17759
2024-10-24T13:11:34.669130047Z W1024 13:11:34.669067       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:34.669130047Z W1024 13:11:34.669090       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:35.826600229Z I1024 13:11:35.826552       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:35.827175629Z I1024 13:11:35.827139       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:35.974540801Z W1024 13:11:35.974498       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:35.974540801Z W1024 13:11:35.974518       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:37.931936002Z I1024 13:11:37.931868       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=etcds from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:37.933158042Z I1024 13:11:37.933121       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:37.934170672Z I1024 13:11:37.933932       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 7 triggered by "secret \"etcd-all-certs-6\" not found"
2024-10-24T13:11:37.934240462Z I1024 13:11:37.934201       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-6
2024-10-24T13:11:37.934409162Z I1024 13:11:37.934375       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:37.947415822Z I1024 13:11:37.947362       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:37.953681963Z I1024 13:11:37.953625       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "MachineDeletionHooksControllerDegraded: Operation cannot be fulfilled on machines.machine.openshift.io \"ci-op-2fcpj5j6-f6035-2lklf-master-2\": the object has been modified; please apply your changes to the latest version and try again\nNodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found",Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5" to "NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6",Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5\nEtcdMembersAvailable: 3 members are available" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 4 members are available"
2024-10-24T13:11:37.961119742Z I1024 13:11:37.961061       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:11:37.961996322Z E1024 13:11:37.961964       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-6"
2024-10-24T13:11:37.963774702Z I1024 13:11:37.963726       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-6\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:37.964339093Z I1024 13:11:37.964319       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:37.965879762Z I1024 13:11:37.965789       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:37.972555893Z I1024 13:11:37.972505       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-pod-7 -n openshift-etcd because it was missing
2024-10-24T13:11:37.972717712Z E1024 13:11:37.972672       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-6"
2024-10-24T13:11:37.972889443Z I1024 13:11:37.972847       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-6
2024-10-24T13:11:37.974610183Z E1024 13:11:37.974568       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:37.976810173Z E1024 13:11:37.976154       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-6"
2024-10-24T13:11:37.976810173Z I1024 13:11:37.976304       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-6
2024-10-24T13:11:37.982607452Z I1024 13:11:37.982578       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-6\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:37.986372193Z E1024 13:11:37.986332       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-6"
2024-10-24T13:11:37.991585603Z I1024 13:11:37.990257       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-6
2024-10-24T13:11:38.006531883Z E1024 13:11:38.003186       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:38.020475713Z I1024 13:11:38.020426       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-6\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:38.032337153Z E1024 13:11:38.032122       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-6"
2024-10-24T13:11:38.032337153Z I1024 13:11:38.032162       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-6
2024-10-24T13:11:38.033458123Z E1024 13:11:38.033412       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:38.038940973Z I1024 13:11:38.038894       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.04 %, dbSize: 76681216
2024-10-24T13:11:38.038940973Z I1024 13:11:38.038917       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.07 %, dbSize: 76787712
2024-10-24T13:11:38.038940973Z I1024 13:11:38.038924       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 0.09 %, dbSize: 76582912
2024-10-24T13:11:38.038940973Z I1024 13:11:38.038930       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.07 %, dbSize: 77107200
2024-10-24T13:11:38.058243644Z I1024 13:11:38.055588       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-6\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:38.073193584Z E1024 13:11:38.073068       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:38.099473634Z I1024 13:11:38.099411       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:11:38.113745224Z E1024 13:11:38.113664       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-6"
2024-10-24T13:11:38.113745224Z I1024 13:11:38.113702       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-6
2024-10-24T13:11:38.116238174Z I1024 13:11:38.116200       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-6\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:38.123560984Z E1024 13:11:38.123486       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:38.124652794Z I1024 13:11:38.124590       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.02 %, dbSize: 76754944
2024-10-24T13:11:38.124652794Z I1024 13:11:38.124618       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.08 %, dbSize: 76849152
2024-10-24T13:11:38.124652794Z I1024 13:11:38.124626       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.03 %, dbSize: 77144064
2024-10-24T13:11:38.205906335Z I1024 13:11:38.205817       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-6\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:38.212949565Z E1024 13:11:38.212875       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:38.275976376Z I1024 13:11:38.275890       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-6
2024-10-24T13:11:38.275976376Z E1024 13:11:38.275927       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-6"
2024-10-24T13:11:38.375136757Z I1024 13:11:38.375078       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-6\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:38.384533707Z E1024 13:11:38.384463       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:38.597931189Z I1024 13:11:38.597859       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-6
2024-10-24T13:11:38.597999479Z E1024 13:11:38.597971       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-6"
2024-10-24T13:11:38.706848680Z I1024 13:11:38.706790       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-6\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:38.714340101Z E1024 13:11:38.714314       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:38.741653121Z E1024 13:11:38.741602       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-6"
2024-10-24T13:11:38.741867351Z I1024 13:11:38.741838       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-6
2024-10-24T13:11:38.742208011Z I1024 13:11:38.742190       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:38.744195831Z I1024 13:11:38.744144       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-endpoints-7 -n openshift-etcd because it was missing
2024-10-24T13:11:39.132570465Z I1024 13:11:39.132505       1 request.go:700] Waited for 1.112630452s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa
2024-10-24T13:11:39.240333656Z I1024 13:11:39.240246       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-6
2024-10-24T13:11:39.240333656Z E1024 13:11:39.240309       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-6"
2024-10-24T13:11:39.340484797Z I1024 13:11:39.340408       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-6\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:39.348713677Z E1024 13:11:39.348598       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:39.350562807Z I1024 13:11:39.350516       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-6\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:39.357772877Z E1024 13:11:39.357689       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:39.359533917Z I1024 13:11:39.359486       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-6\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:39.369788818Z E1024 13:11:39.369721       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:39.536162920Z I1024 13:11:39.536089       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:39.743702031Z E1024 13:11:39.743650       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-6"
2024-10-24T13:11:39.744023852Z I1024 13:11:39.744004       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:39.745409111Z I1024 13:11:39.745349       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-6
2024-10-24T13:11:39.745601272Z I1024 13:11:39.745553       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-all-bundles-7 -n openshift-etcd because it was missing
2024-10-24T13:11:40.758276282Z I1024 13:11:40.758210       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-all-certs-7 -n openshift-etcd because it was missing
2024-10-24T13:11:41.707537172Z I1024 13:11:41.707476       1 reflector.go:368] Caches populated for *v1.Job from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:41.741875782Z E1024 13:11:41.741824       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-6"
2024-10-24T13:11:41.742181472Z I1024 13:11:41.742139       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-6
2024-10-24T13:11:41.743477742Z I1024 13:11:41.743444       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 7 triggered by "secret \"etcd-all-certs-6\" not found"
2024-10-24T13:11:41.743684802Z I1024 13:11:41.743663       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:41.744807842Z W1024 13:11:41.744692       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:41.744807842Z W1024 13:11:41.744713       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:41.776090923Z I1024 13:11:41.776041       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:41.776270223Z I1024 13:11:41.776207       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 8 triggered by "secret \"etcd-all-certs-7\" not found"
2024-10-24T13:11:41.776939743Z I1024 13:11:41.776903       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-7
2024-10-24T13:11:41.777612963Z I1024 13:11:41.777577       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-6\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:41.787240583Z E1024 13:11:41.786856       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:41.796578603Z I1024 13:11:41.796406       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:11:41.800423783Z E1024 13:11:41.800389       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-7"
2024-10-24T13:11:41.802045163Z E1024 13:11:41.802018       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-7"
2024-10-24T13:11:41.802453453Z I1024 13:11:41.802398       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-7
2024-10-24T13:11:41.804314823Z I1024 13:11:41.804285       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-7\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:41.805427783Z E1024 13:11:41.805253       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-7"
2024-10-24T13:11:41.806227313Z I1024 13:11:41.806197       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-7
2024-10-24T13:11:41.809588733Z I1024 13:11:41.806924       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:41.821293093Z E1024 13:11:41.821252       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:41.854977704Z I1024 13:11:41.854925       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.04 %, dbSize: 77074432
2024-10-24T13:11:41.854977704Z I1024 13:11:41.854957       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.05 %, dbSize: 77144064
2024-10-24T13:11:41.854977704Z I1024 13:11:41.854964       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.02 %, dbSize: 77402112
2024-10-24T13:11:41.898854664Z I1024 13:11:41.898620       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:11:41.919866194Z I1024 13:11:41.919734       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-7\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:41.926541095Z I1024 13:11:41.926504       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.05 %, dbSize: 77115392
2024-10-24T13:11:41.926541095Z I1024 13:11:41.926530       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.01 %, dbSize: 77144064
2024-10-24T13:11:41.926575464Z I1024 13:11:41.926537       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.03 %, dbSize: 77443072
2024-10-24T13:11:41.929220664Z E1024 13:11:41.929182       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:41.932575975Z I1024 13:11:41.932507       1 request.go:700] Waited for 1.089079691s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/kube-system/secrets?resourceVersion=16076
2024-10-24T13:11:41.935574694Z I1024 13:11:41.935532       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:42.545146651Z I1024 13:11:42.545093       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-7\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:42.556065051Z E1024 13:11:42.556005       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:42.557736661Z I1024 13:11:42.557690       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-7\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:42.565616411Z E1024 13:11:42.565562       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:42.932920795Z I1024 13:11:42.932843       1 request.go:700] Waited for 1.156791332s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:11:43.143023457Z I1024 13:11:43.140614       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:43.143023457Z E1024 13:11:43.141214       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-7"
2024-10-24T13:11:43.143023457Z I1024 13:11:43.141399       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-7
2024-10-24T13:11:43.933387755Z I1024 13:11:43.933318       1 request.go:700] Waited for 1.387891604s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:11:44.114930007Z E1024 13:11:44.114890       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:11:44.140193218Z I1024 13:11:44.140136       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:44.141416407Z E1024 13:11:44.141387       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-7"
2024-10-24T13:11:44.141875147Z I1024 13:11:44.141843       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-7
2024-10-24T13:11:44.143248748Z E1024 13:11:44.143209       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-7"
2024-10-24T13:11:44.143248748Z I1024 13:11:44.143235       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-7
2024-10-24T13:11:44.147206787Z I1024 13:11:44.147139       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-7
2024-10-24T13:11:44.148156477Z E1024 13:11:44.148036       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-7"
2024-10-24T13:11:44.211413158Z I1024 13:11:44.210294       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-7\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:44.228171278Z E1024 13:11:44.223231       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:44.744016204Z I1024 13:11:44.743908       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-pod-8 -n openshift-etcd because it was missing
2024-10-24T13:11:44.744286104Z I1024 13:11:44.744256       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:44.744701684Z E1024 13:11:44.744664       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-7"
2024-10-24T13:11:44.744951134Z I1024 13:11:44.744913       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-7
2024-10-24T13:11:44.933514886Z I1024 13:11:44.933406       1 request.go:700] Waited for 1.591464127s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:11:45.336030300Z I1024 13:11:45.335949       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:46.133155818Z I1024 13:11:46.133079       1 request.go:700] Waited for 1.793327029s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:11:46.543315293Z I1024 13:11:46.541665       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-endpoints-8 -n openshift-etcd because it was missing
2024-10-24T13:11:46.543315293Z I1024 13:11:46.541677       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:46.543315293Z E1024 13:11:46.542423       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-7"
2024-10-24T13:11:46.543315293Z I1024 13:11:46.542576       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-7
2024-10-24T13:11:47.135413559Z I1024 13:11:47.135346       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:47.333343801Z I1024 13:11:47.333166       1 request.go:700] Waited for 1.794859209s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa
2024-10-24T13:11:47.545049353Z I1024 13:11:47.544990       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-7\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:47.554768134Z E1024 13:11:47.554712       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:47.556490693Z I1024 13:11:47.556414       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-7\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:47.557572544Z I1024 13:11:47.557537       1 reflector.go:368] Caches populated for *v1beta1.Machine from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:47.563417074Z E1024 13:11:47.563374       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:48.345135962Z I1024 13:11:48.345073       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:48.345698452Z I1024 13:11:48.345646       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-7
2024-10-24T13:11:48.345796102Z I1024 13:11:48.345736       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-all-bundles-8 -n openshift-etcd because it was missing
2024-10-24T13:11:48.345796102Z E1024 13:11:48.345784       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-7"
2024-10-24T13:11:48.533417174Z I1024 13:11:48.533303       1 request.go:700] Waited for 1.593751827s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-10-24T13:11:48.992423669Z I1024 13:11:48.992365       1 reflector.go:368] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:49.350204082Z I1024 13:11:49.350139       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-all-certs-8 -n openshift-etcd because it was missing
2024-10-24T13:11:50.341428923Z I1024 13:11:50.341361       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:50.343055413Z E1024 13:11:50.343007       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-7"
2024-10-24T13:11:50.343195103Z W1024 13:11:50.343146       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:50.343261403Z W1024 13:11:50.343234       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:50.343381713Z I1024 13:11:50.343355       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-7
2024-10-24T13:11:50.343450553Z I1024 13:11:50.343429       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 8 triggered by "secret \"etcd-all-certs-7\" not found"
2024-10-24T13:11:50.368477453Z W1024 13:11:50.368423       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:50.368536143Z W1024 13:11:50.368522       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:50.388588004Z I1024 13:11:50.388521       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-8
2024-10-24T13:11:50.389196513Z I1024 13:11:50.389112       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 9 triggered by "secret \"etcd-all-certs-8\" not found"
2024-10-24T13:11:50.389907783Z I1024 13:11:50.389876       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:50.391034274Z I1024 13:11:50.390996       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-7\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:50.399361373Z E1024 13:11:50.399313       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:50.411784754Z I1024 13:11:50.410326       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:11:50.418797304Z E1024 13:11:50.416144       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-8"
2024-10-24T13:11:50.422182884Z I1024 13:11:50.420586       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:50.422182884Z I1024 13:11:50.421575       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-8\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 8\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:50.427375374Z E1024 13:11:50.426587       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-8"
2024-10-24T13:11:50.434418224Z E1024 13:11:50.434364       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:50.444559844Z I1024 13:11:50.444503       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-8
2024-10-24T13:11:50.493272925Z I1024 13:11:50.491069       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.10 %, dbSize: 77836288
2024-10-24T13:11:50.493272925Z I1024 13:11:50.491094       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.07 %, dbSize: 77914112
2024-10-24T13:11:50.493272925Z I1024 13:11:50.491100       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 0.09 %, dbSize: 77701120
2024-10-24T13:11:50.493272925Z I1024 13:11:50.491106       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.11 %, dbSize: 78192640
2024-10-24T13:11:50.531896775Z I1024 13:11:50.531848       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:11:50.555225515Z I1024 13:11:50.555179       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.05 %, dbSize: 77836288
2024-10-24T13:11:50.555225515Z I1024 13:11:50.555199       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.07 %, dbSize: 77914112
2024-10-24T13:11:50.555225515Z I1024 13:11:50.555206       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 0.04 %, dbSize: 77701120
2024-10-24T13:11:50.555225515Z I1024 13:11:50.555212       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.06 %, dbSize: 78192640
2024-10-24T13:11:50.607318896Z I1024 13:11:50.607274       1 reflector.go:368] Caches populated for *v1.Etcd from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:50.940551079Z I1024 13:11:50.940487       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-8\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 8\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:50.950637639Z E1024 13:11:50.950612       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:50.952306869Z I1024 13:11:50.952270       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-8\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 8\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:50.959097129Z E1024 13:11:50.959070       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:51.344059684Z I1024 13:11:51.343684       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:51.345404383Z E1024 13:11:51.344774       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-8"
2024-10-24T13:11:51.345404383Z I1024 13:11:51.344938       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-8
2024-10-24T13:11:51.533534595Z I1024 13:11:51.533478       1 request.go:700] Waited for 1.143042903s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:11:51.936428940Z I1024 13:11:51.936372       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:52.336905454Z I1024 13:11:52.336851       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:52.733014038Z I1024 13:11:52.732941       1 request.go:700] Waited for 1.791831879s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:11:53.142525122Z I1024 13:11:53.142474       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-pod-9 -n openshift-etcd because it was missing
2024-10-24T13:11:53.145554052Z E1024 13:11:53.143157       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-8"
2024-10-24T13:11:53.145586253Z I1024 13:11:53.144284       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-8
2024-10-24T13:11:53.145597483Z I1024 13:11:53.144614       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:53.326892485Z I1024 13:11:53.326852       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:53.733234829Z I1024 13:11:53.733172       1 request.go:700] Waited for 1.592522157s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-10-24T13:11:54.543789147Z I1024 13:11:54.542246       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:54.543789147Z I1024 13:11:54.543210       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-endpoints-9 -n openshift-etcd because it was missing
2024-10-24T13:11:54.544784637Z E1024 13:11:54.544669       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-8"
2024-10-24T13:11:54.544914627Z I1024 13:11:54.544845       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-8
2024-10-24T13:11:55.141972904Z I1024 13:11:55.141909       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-8\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 8\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:55.152046404Z E1024 13:11:55.152001       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:55.154006684Z I1024 13:11:55.153969       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-8\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 8\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:55.161146364Z E1024 13:11:55.161043       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:55.345560936Z I1024 13:11:55.345504       1 reflector.go:368] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:55.545807298Z E1024 13:11:55.544684       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-8"
2024-10-24T13:11:55.559543098Z I1024 13:11:55.559496       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:55.559921598Z I1024 13:11:55.559868       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-8
2024-10-24T13:11:55.559952178Z I1024 13:11:55.559916       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-all-bundles-9 -n openshift-etcd because it was missing
2024-10-24T13:11:56.050355393Z I1024 13:11:56.050288       1 reflector.go:368] Caches populated for *v1.Role from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:56.148568135Z I1024 13:11:56.148232       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-all-certs-9 -n openshift-etcd because it was missing
2024-10-24T13:11:56.741664941Z I1024 13:11:56.741588       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 9 triggered by "secret \"etcd-all-certs-8\" not found"
2024-10-24T13:11:56.743846011Z W1024 13:11:56.742628       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:56.743846011Z W1024 13:11:56.743838       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:56.744025581Z E1024 13:11:56.743463       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-8"
2024-10-24T13:11:56.744048331Z I1024 13:11:56.743600       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-8
2024-10-24T13:11:56.744459801Z I1024 13:11:56.744375       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:56.774843771Z W1024 13:11:56.774773       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:11:56.774843771Z W1024 13:11:56.774800       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:11:56.775717691Z I1024 13:11:56.775680       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:56.776004351Z I1024 13:11:56.775964       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-8\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 8\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:56.776208891Z I1024 13:11:56.776157       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-9
2024-10-24T13:11:56.783067251Z E1024 13:11:56.783024       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:56.790577961Z I1024 13:11:56.790530       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:11:56.800901341Z I1024 13:11:56.800789       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 10 triggered by "secret \"etcd-all-certs-9\" not found"
2024-10-24T13:11:56.801194191Z E1024 13:11:56.801138       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-9"
2024-10-24T13:11:56.803928811Z E1024 13:11:56.803887       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-9"
2024-10-24T13:11:56.805336062Z I1024 13:11:56.805237       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:56.808957101Z I1024 13:11:56.808918       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-9
2024-10-24T13:11:56.813241272Z I1024 13:11:56.813185       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-9\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 9\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:11:56.828836872Z E1024 13:11:56.828776       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:11:56.847940032Z I1024 13:11:56.846844       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.08 %, dbSize: 78397440
2024-10-24T13:11:56.847940032Z I1024 13:11:56.846867       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.09 %, dbSize: 78516224
2024-10-24T13:11:56.847940032Z I1024 13:11:56.846874       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 0.03 %, dbSize: 78266368
2024-10-24T13:11:56.847940032Z I1024 13:11:56.846879       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.05 %, dbSize: 78729216
2024-10-24T13:11:56.903742042Z I1024 13:11:56.903694       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:11:56.916638812Z I1024 13:11:56.916587       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.02 %, dbSize: 78397440
2024-10-24T13:11:56.916638812Z I1024 13:11:56.916605       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.09 %, dbSize: 78516224
2024-10-24T13:11:56.916638812Z I1024 13:11:56.916611       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 0.03 %, dbSize: 78266368
2024-10-24T13:11:56.916638812Z I1024 13:11:56.916616       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.05 %, dbSize: 78770176
2024-10-24T13:11:57.933412013Z I1024 13:11:57.933370       1 request.go:700] Waited for 1.132617841s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps
2024-10-24T13:11:57.941042504Z I1024 13:11:57.940999       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:57.941897894Z E1024 13:11:57.941873       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-9"
2024-10-24T13:11:57.942150973Z I1024 13:11:57.942126       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-9
2024-10-24T13:11:58.337210967Z I1024 13:11:58.337166       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:58.536571700Z I1024 13:11:58.536527       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:11:59.133428596Z I1024 13:11:59.133369       1 request.go:700] Waited for 1.592519877s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:11:59.548473681Z I1024 13:11:59.547177       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-pod-10 -n openshift-etcd because it was missing
2024-10-24T13:11:59.550526571Z I1024 13:11:59.548971       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:11:59.550526571Z E1024 13:11:59.549277       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-9"
2024-10-24T13:11:59.550526571Z I1024 13:11:59.549303       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-9
2024-10-24T13:12:00.140691537Z I1024 13:12:00.140625       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-9\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 9\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:12:00.150402927Z E1024 13:12:00.150326       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:12:00.151982787Z I1024 13:12:00.151938       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-9\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 9\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:12:00.160408457Z E1024 13:12:00.160386       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:12:00.343100459Z E1024 13:12:00.341000       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-9"
2024-10-24T13:12:00.343100459Z I1024 13:12:00.341392       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:00.343399109Z I1024 13:12:00.343351       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-9
2024-10-24T13:12:00.343446889Z I1024 13:12:00.343414       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-endpoints-10 -n openshift-etcd because it was missing
2024-10-24T13:12:01.148449538Z I1024 13:12:01.148381       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:01.149825538Z E1024 13:12:01.149698       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-9"
2024-10-24T13:12:01.150201598Z I1024 13:12:01.150143       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-9
2024-10-24T13:12:01.155273268Z I1024 13:12:01.155196       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-all-bundles-10 -n openshift-etcd because it was missing
2024-10-24T13:12:01.323127000Z I1024 13:12:01.323067       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:01.324144710Z I1024 13:12:01.324016       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-9\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 9\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:12:01.342259060Z I1024 13:12:01.342179       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-9\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found",Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6" to "NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 9",Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 4 members are available" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 9\nEtcdMembersAvailable: 4 members are available"
2024-10-24T13:12:01.783037285Z I1024 13:12:01.782962       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:01.947132176Z I1024 13:12:01.945779       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-all-certs-10 -n openshift-etcd because it was missing
2024-10-24T13:12:01.947132176Z I1024 13:12:01.946597       1 reflector.go:368] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:02.349522971Z I1024 13:12:02.349433       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:02.944797787Z I1024 13:12:02.942319       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:02.944797787Z W1024 13:12:02.944201       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:12:02.944797787Z W1024 13:12:02.944213       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:12:02.944797787Z I1024 13:12:02.944603       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 10 triggered by "secret \"etcd-all-certs-9\" not found"
2024-10-24T13:12:02.945742047Z I1024 13:12:02.945698       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-9
2024-10-24T13:12:02.945862827Z E1024 13:12:02.945831       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-9"
2024-10-24T13:12:02.979177797Z W1024 13:12:02.978559       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:12:02.979177797Z W1024 13:12:02.978581       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:12:02.979177797Z I1024 13:12:02.978920       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:02.982866307Z I1024 13:12:02.982808       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-10
2024-10-24T13:12:03.004219497Z I1024 13:12:03.004155       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 11 triggered by "secret \"etcd-all-certs-10\" not found"
2024-10-24T13:12:03.021774888Z I1024 13:12:03.021695       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:03.022449708Z E1024 13:12:03.022419       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-10"
2024-10-24T13:12:03.022877228Z I1024 13:12:03.022811       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-10\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 10\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:12:03.023908308Z E1024 13:12:03.023880       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-10"
2024-10-24T13:12:03.025212747Z I1024 13:12:03.025161       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-10
2024-10-24T13:12:03.044898848Z I1024 13:12:03.044443       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-9\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-10\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found",Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 9" to "NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 10",Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 9\nEtcdMembersAvailable: 4 members are available" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 10\nEtcdMembersAvailable: 4 members are available"
2024-10-24T13:12:03.070384498Z I1024 13:12:03.070306       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.02 %, dbSize: 79138816
2024-10-24T13:12:03.070384498Z I1024 13:12:03.070330       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.01 %, dbSize: 79224832
2024-10-24T13:12:03.070384498Z I1024 13:12:03.070338       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 0.01 %, dbSize: 79024128
2024-10-24T13:12:03.070384498Z I1024 13:12:03.070344       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 79532032
2024-10-24T13:12:03.129813789Z I1024 13:12:03.129737       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.01 %, dbSize: 79179776
2024-10-24T13:12:03.129813789Z I1024 13:12:03.129780       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.02 %, dbSize: 79273984
2024-10-24T13:12:03.129813789Z I1024 13:12:03.129787       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 0.02 %, dbSize: 79073280
2024-10-24T13:12:03.129813789Z I1024 13:12:03.129792       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 79532032
2024-10-24T13:12:03.132824429Z I1024 13:12:03.132791       1 request.go:700] Waited for 1.185572383s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:12:03.736182715Z I1024 13:12:03.736129       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:03.938585157Z I1024 13:12:03.938525       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:04.332967951Z I1024 13:12:04.332885       1 request.go:700] Waited for 1.351634095s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:12:04.543102193Z I1024 13:12:04.543032       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:04.544555583Z I1024 13:12:04.544518       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-10
2024-10-24T13:12:04.544627594Z E1024 13:12:04.544606       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-10"
2024-10-24T13:12:05.333443182Z I1024 13:12:05.333378       1 request.go:700] Waited for 1.513156986s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/endpoints?resourceVersion=16322
2024-10-24T13:12:05.336081512Z I1024 13:12:05.336012       1 reflector.go:368] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:05.949462178Z E1024 13:12:05.949388       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-10"
2024-10-24T13:12:05.949637948Z I1024 13:12:05.949587       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-pod-11 -n openshift-etcd because it was missing
2024-10-24T13:12:05.950978978Z I1024 13:12:05.950932       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:05.953604768Z I1024 13:12:05.952326       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-10
2024-10-24T13:12:06.732842176Z I1024 13:12:06.732769       1 request.go:700] Waited for 1.144651232s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets?resourceVersion=16076
2024-10-24T13:12:06.736013616Z I1024 13:12:06.735990       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:07.141445024Z E1024 13:12:07.141378       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-10"
2024-10-24T13:12:07.144030054Z I1024 13:12:07.143977       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-endpoints-11 -n openshift-etcd because it was missing
2024-10-24T13:12:07.144336554Z I1024 13:12:07.144296       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-10
2024-10-24T13:12:07.144592984Z I1024 13:12:07.144547       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:07.337196562Z I1024 13:12:07.337143       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:07.733311067Z I1024 13:12:07.733253       1 request.go:700] Waited for 1.370899155s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa
2024-10-24T13:12:08.142874382Z I1024 13:12:08.141410       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:08.142874382Z I1024 13:12:08.141439       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-all-bundles-11 -n openshift-etcd because it was missing
2024-10-24T13:12:08.142874382Z E1024 13:12:08.142344       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-10"
2024-10-24T13:12:08.143081582Z I1024 13:12:08.143054       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-10
2024-10-24T13:12:08.947066103Z I1024 13:12:08.946993       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-all-certs-11 -n openshift-etcd because it was missing
2024-10-24T13:12:09.742917004Z E1024 13:12:09.742856       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-10"
2024-10-24T13:12:09.744187364Z W1024 13:12:09.743825       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:12:09.744187364Z W1024 13:12:09.743847       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:12:09.744187364Z I1024 13:12:09.744062       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 11 triggered by "secret \"etcd-all-certs-10\" not found"
2024-10-24T13:12:09.745236824Z I1024 13:12:09.745159       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:09.745677724Z I1024 13:12:09.745542       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-10
2024-10-24T13:12:09.767162834Z I1024 13:12:09.767090       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:09.767687403Z W1024 13:12:09.767297       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:12:09.767687403Z W1024 13:12:09.767323       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:12:09.777324924Z I1024 13:12:09.777287       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-11
2024-10-24T13:12:09.794901383Z I1024 13:12:09.794831       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 12 triggered by "secret \"etcd-all-certs-11\" not found"
2024-10-24T13:12:09.801944213Z E1024 13:12:09.801896       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-11"
2024-10-24T13:12:09.805024893Z I1024 13:12:09.804990       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-11\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 11\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:12:09.805154783Z E1024 13:12:09.805133       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-11"
2024-10-24T13:12:09.805347773Z I1024 13:12:09.805320       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-11
2024-10-24T13:12:09.805414603Z I1024 13:12:09.805389       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:09.825091253Z I1024 13:12:09.825032       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-10\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-11\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found",Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 10" to "NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 11",Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 10\nEtcdMembersAvailable: 4 members are available" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 11\nEtcdMembersAvailable: 4 members are available"
2024-10-24T13:12:09.859581502Z I1024 13:12:09.859540       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.04 %, dbSize: 79646720
2024-10-24T13:12:09.859687393Z I1024 13:12:09.859669       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.02 %, dbSize: 79740928
2024-10-24T13:12:09.859726722Z I1024 13:12:09.859713       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 80019456
2024-10-24T13:12:09.912218212Z I1024 13:12:09.912164       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.02 %, dbSize: 79687680
2024-10-24T13:12:09.912218212Z I1024 13:12:09.912189       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.04 %, dbSize: 79785984
2024-10-24T13:12:09.912218212Z I1024 13:12:09.912196       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 0.02 %, dbSize: 79581184
2024-10-24T13:12:09.912218212Z I1024 13:12:09.912202       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 80019456
2024-10-24T13:12:10.346648117Z I1024 13:12:10.346580       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:10.347269117Z I1024 13:12:10.347210       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: etcd-all-certs-11
2024-10-24T13:12:10.347348877Z E1024 13:12:10.347319       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: missing required resources: secrets: etcd-all-certs-11"
2024-10-24T13:12:10.933336360Z I1024 13:12:10.933283       1 request.go:700] Waited for 1.158052526s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:12:11.148393508Z I1024 13:12:11.148328       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:12.132910706Z I1024 13:12:12.132835       1 request.go:700] Waited for 1.386845394s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:12:12.547699531Z I1024 13:12:12.547636       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:12.552643371Z I1024 13:12:12.551918       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-pod-12 -n openshift-etcd because it was missing
2024-10-24T13:12:13.137679814Z I1024 13:12:13.137595       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:12:13.137679814Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:12:13.137679814Z  CurrentRevision: (int32) 1,
2024-10-24T13:12:13.137679814Z  TargetRevision: (int32) 11,
2024-10-24T13:12:13.137679814Z  LastFailedRevision: (int32) 5,
2024-10-24T13:12:13.137679814Z  LastFailedTime: (*v1.Time)(0xc002df7ba8)(2024-10-24 13:11:34 +0000 UTC),
2024-10-24T13:12:13.137679814Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:12:13.137679814Z  LastFailedCount: (int) 1,
2024-10-24T13:12:13.137679814Z  LastFallbackCount: (int) 0,
2024-10-24T13:12:13.137679814Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:12:13.137679814Z   (string) (len=2059) "installer:  172.30.0.1:443: connect: connection refused\nW1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:12:13.137679814Z  }
2024-10-24T13:12:13.137679814Z }
2024-10-24T13:12:13.137679814Z  because new revision pending
2024-10-24T13:12:13.162386814Z I1024 13:12:13.162319       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-11\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 11\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:12:13.169508244Z I1024 13:12:13.162894       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:13.181335574Z I1024 13:12:13.180952       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-11\nNodeInstallerDegraded: 1 nodes are failing on revision 5:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-11\nEtcdMembersDegraded: No unhealthy members found"
2024-10-24T13:12:13.182212804Z I1024 13:12:13.182171       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:12:13.188015884Z I1024 13:12:13.187952       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:12:13.188885274Z I1024 13:12:13.188838       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:12:13.227564504Z I1024 13:12:13.227498       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 11\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:12:13.230198704Z I1024 13:12:13.230150       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:13.244718673Z I1024 13:12:13.240376       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:12:13.244718673Z I1024 13:12:13.243944       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nInstallerControllerDegraded: missing required resources: secrets: etcd-all-certs-11\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found"
2024-10-24T13:12:13.288721263Z I1024 13:12:13.288498       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:12:13.289022103Z I1024 13:12:13.288983       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.06 %, dbSize: 80003072
2024-10-24T13:12:13.289022103Z I1024 13:12:13.289005       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.03 %, dbSize: 80056320
2024-10-24T13:12:13.289022103Z I1024 13:12:13.289012       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 0.02 %, dbSize: 79867904
2024-10-24T13:12:13.289022103Z I1024 13:12:13.289017       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.05 %, dbSize: 80334848
2024-10-24T13:12:13.303420203Z I1024 13:12:13.303358       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:12:13.332731232Z I1024 13:12:13.332670       1 request.go:700] Waited for 1.392811623s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:12:13.343064372Z I1024 13:12:13.342997       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.04 %, dbSize: 80003072
2024-10-24T13:12:13.343064372Z I1024 13:12:13.343022       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.03 %, dbSize: 80056320
2024-10-24T13:12:13.343064372Z I1024 13:12:13.343029       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 0.02 %, dbSize: 79867904
2024-10-24T13:12:13.343064372Z I1024 13:12:13.343035       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.03 %, dbSize: 80334848
2024-10-24T13:12:13.542333160Z I1024 13:12:13.540917       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-endpoints-12 -n openshift-etcd because it was missing
2024-10-24T13:12:13.542333160Z I1024 13:12:13.541271       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:14.333346121Z I1024 13:12:14.333293       1 request.go:700] Waited for 1.170301967s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:12:15.143101171Z I1024 13:12:15.143037       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:15.143331521Z I1024 13:12:15.143298       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-all-bundles-12 -n openshift-etcd because it was missing
2024-10-24T13:12:15.333502319Z I1024 13:12:15.333458       1 request.go:700] Waited for 1.591488601s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-10-24T13:12:16.352690317Z I1024 13:12:16.352633       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-11-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-etcd because it was missing
2024-10-24T13:12:16.532540695Z I1024 13:12:16.532482       1 request.go:700] Waited for 1.592211552s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:12:16.749221803Z I1024 13:12:16.747355       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-all-certs-12 -n openshift-etcd because it was missing
2024-10-24T13:12:17.532842934Z I1024 13:12:17.532785       1 request.go:700] Waited for 1.181525207s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-10-24T13:12:17.715396232Z I1024 13:12:17.715329       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:12:17.739780061Z I1024 13:12:17.739688       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:12:18.142997407Z W1024 13:12:18.142938       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:12:18.143082817Z W1024 13:12:18.143067       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:12:18.143431727Z I1024 13:12:18.143401       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 12 triggered by "secret \"etcd-all-certs-11\" not found"
2024-10-24T13:12:18.144895536Z I1024 13:12:18.144825       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:18.167195596Z W1024 13:12:18.167137       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:12:18.167195596Z W1024 13:12:18.167167       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:12:18.171798156Z I1024 13:12:18.170668       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:18.243984795Z I1024 13:12:18.243924       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.01 %, dbSize: 80183296
2024-10-24T13:12:18.243984795Z I1024 13:12:18.243951       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.01 %, dbSize: 80252928
2024-10-24T13:12:18.243984795Z I1024 13:12:18.243961       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 0.01 %, dbSize: 80048128
2024-10-24T13:12:18.243984795Z I1024 13:12:18.243967       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 80531456
2024-10-24T13:12:18.533163572Z I1024 13:12:18.533097       1 request.go:700] Waited for 1.380933054s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd
2024-10-24T13:12:19.733583148Z I1024 13:12:19.733511       1 request.go:700] Waited for 1.562272403s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:12:20.739714127Z I1024 13:12:20.739659       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:12:20.764681327Z I1024 13:12:20.764646       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:12:20.765258817Z I1024 13:12:20.765186       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:20.779548386Z I1024 13:12:20.779198       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 11" to "NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12",Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 11\nEtcdMembersAvailable: 4 members are available" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available"
2024-10-24T13:12:20.824216956Z I1024 13:12:20.824146       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.03 %, dbSize: 80297984
2024-10-24T13:12:20.824216956Z I1024 13:12:20.824174       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.02 %, dbSize: 80367616
2024-10-24T13:12:20.824216956Z I1024 13:12:20.824182       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 0.03 %, dbSize: 80171008
2024-10-24T13:12:20.824216956Z I1024 13:12:20.824188       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.03 %, dbSize: 80646144
2024-10-24T13:12:20.933213445Z I1024 13:12:20.933155       1 request.go:700] Waited for 1.591447002s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:12:21.933447523Z I1024 13:12:21.933386       1 request.go:700] Waited for 1.169659076s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:12:22.933474491Z I1024 13:12:22.933414       1 request.go:700] Waited for 1.389851923s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:12:23.145469619Z I1024 13:12:23.145417       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:12:23.145469619Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:12:23.145469619Z  CurrentRevision: (int32) 1,
2024-10-24T13:12:23.145469619Z  TargetRevision: (int32) 12,
2024-10-24T13:12:23.145469619Z  LastFailedRevision: (int32) 5,
2024-10-24T13:12:23.145469619Z  LastFailedTime: (*v1.Time)(0xc002c3c0c0)(2024-10-24 13:11:34 +0000 UTC),
2024-10-24T13:12:23.145469619Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:12:23.145469619Z  LastFailedCount: (int) 1,
2024-10-24T13:12:23.145469619Z  LastFallbackCount: (int) 0,
2024-10-24T13:12:23.145469619Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:12:23.145469619Z   (string) (len=2059) "installer:  172.30.0.1:443: connect: connection refused\nW1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:12:23.145469619Z  }
2024-10-24T13:12:23.145469619Z }
2024-10-24T13:12:23.145469619Z  because new revision pending
2024-10-24T13:12:23.173413778Z I1024 13:12:23.173357       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:12:23.195494928Z I1024 13:12:23.195452       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:12:23.239876458Z I1024 13:12:23.239814       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.01 %, dbSize: 80457728
2024-10-24T13:12:23.239876458Z I1024 13:12:23.239833       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.01 %, dbSize: 80527360
2024-10-24T13:12:23.239876458Z I1024 13:12:23.239840       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 0.02 %, dbSize: 80334848
2024-10-24T13:12:23.239876458Z I1024 13:12:23.239845       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.02 %, dbSize: 80805888
2024-10-24T13:12:23.241438268Z I1024 13:12:23.241381       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:12:24.333508775Z I1024 13:12:24.333440       1 request.go:700] Waited for 1.158542467s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:12:25.333548894Z I1024 13:12:25.333483       1 request.go:700] Waited for 1.593411502s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa
2024-10-24T13:12:25.733631210Z E1024 13:12:25.733569       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:25.774825709Z E1024 13:12:25.774745       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on serving metrics cert sync for node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-serving-metrics-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:25.933901127Z I1024 13:12:25.933831       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'PodCreateFailed' Failed to create Pod/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-etcd: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:25.934015487Z I1024 13:12:25.933991       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 12 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Post "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:25.935559677Z E1024 13:12:25.935501       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:25.974633767Z E1024 13:12:25.974577       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:26.133947305Z W1024 13:12:26.133860       1 reflector.go:561] k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: failed to list *v1.Service: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services?resourceVersion=16112": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:26.133947305Z E1024 13:12:26.133930       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Failed to watch *v1.Service: failed to list *v1.Service: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services?resourceVersion=16112\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:26.175552424Z E1024 13:12:26.175501       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:26.335609642Z E1024 13:12:26.335563       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:26.375138312Z E1024 13:12:26.375084       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:26.533274951Z I1024 13:12:26.533210       1 request.go:700] Waited for 1.389897195s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-10-24T13:12:26.535299870Z E1024 13:12:26.535253       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:26.574818760Z E1024 13:12:26.574700       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:26.774848098Z E1024 13:12:26.774794       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:26.934290976Z E1024 13:12:26.934228       1 guard_controller.go:366] Unable to apply pod etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1 changes: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:26.974768625Z E1024 13:12:26.974686       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:27.133793144Z E1024 13:12:27.133726       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:27.175151163Z E1024 13:12:27.175083       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:27.334008431Z I1024 13:12:27.333931       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 12 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:27.335109631Z E1024 13:12:27.335062       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:27.374305701Z E1024 13:12:27.374253       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:27.533342839Z I1024 13:12:27.533278       1 request.go:700] Waited for 1.196331377s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:12:27.937901724Z E1024 13:12:27.937824       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:28.135562102Z W1024 13:12:28.135480       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:28.135562102Z E1024 13:12:28.135544       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused, Unable to apply pod etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1 changes: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:28.333760630Z E1024 13:12:28.333692       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:28.533779428Z I1024 13:12:28.533702       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 12 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:28.534821208Z E1024 13:12:28.534743       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:28.657008646Z E1024 13:12:28.656955       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:28.733379085Z I1024 13:12:28.733330       1 request.go:700] Waited for 1.199074176s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:12:28.935466383Z E1024 13:12:28.935398       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:28.949697673Z W1024 13:12:28.949641       1 reflector.go:561] k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: failed to list *v1.Infrastructure: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/infrastructures?resourceVersion=16142": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:28.949767293Z E1024 13:12:28.949712       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Failed to watch *v1.Infrastructure: failed to list *v1.Infrastructure: Get \"https://172.30.0.1:443/apis/config.openshift.io/v1/infrastructures?resourceVersion=16142\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:29.534050736Z E1024 13:12:29.533996       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:29.734144704Z I1024 13:12:29.734087       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 12 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:29.735711224Z E1024 13:12:29.735654       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:29.933558242Z I1024 13:12:29.933493       1 request.go:700] Waited for 1.199352426s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:12:29.936041791Z E1024 13:12:29.935978       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:30.734061052Z E1024 13:12:30.733993       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:30.933898890Z I1024 13:12:30.933850       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 12 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:30.935345140Z E1024 13:12:30.935305       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:31.133442178Z I1024 13:12:31.133382       1 request.go:700] Waited for 1.196052446s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:12:31.219391607Z E1024 13:12:31.219328       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:31.335555896Z E1024 13:12:31.335498       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:31.734892411Z W1024 13:12:31.734833       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:31.734951581Z E1024 13:12:31.734894       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:31.933382158Z E1024 13:12:31.933308       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:32.107969327Z E1024 13:12:32.107906       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:12:32.108593207Z E1024 13:12:32.108526       1 leaderelection.go:436] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:32.133530816Z I1024 13:12:32.133469       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 12 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:32.134698376Z E1024 13:12:32.134657       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:32.332852864Z I1024 13:12:32.332789       1 request.go:700] Waited for 1.198290916s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:12:32.737600999Z E1024 13:12:32.737539       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:33.133724025Z E1024 13:12:33.133662       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:33.333408222Z I1024 13:12:33.333350       1 request.go:700] Waited for 1.196869337s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:12:33.334520692Z I1024 13:12:33.334472       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 12 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:33.335694392Z E1024 13:12:33.335645       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:33.535378660Z E1024 13:12:33.535316       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:33.735202938Z E1024 13:12:33.735146       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:34.334617790Z I1024 13:12:34.334551       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 12 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:34.335925941Z E1024 13:12:34.335882       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:34.532889918Z I1024 13:12:34.532832       1 request.go:700] Waited for 1.077388287s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-10-24T13:12:34.533763598Z E1024 13:12:34.533727       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:35.335294329Z W1024 13:12:35.335235       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:35.335351309Z E1024 13:12:35.335293       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:35.533371656Z I1024 13:12:35.533310       1 request.go:700] Waited for 1.195665896s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:12:35.534434146Z I1024 13:12:35.534374       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 12 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:35.535779026Z E1024 13:12:35.535736       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:35.935059482Z E1024 13:12:35.935004       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:36.333644867Z E1024 13:12:36.333568       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:36.342032557Z E1024 13:12:36.341974       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:36.732826823Z I1024 13:12:36.732707       1 request.go:700] Waited for 1.195071547s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:12:36.733897023Z I1024 13:12:36.733812       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 12 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:36.735322322Z E1024 13:12:36.735267       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:36.935548720Z E1024 13:12:36.935476       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:37.336917006Z E1024 13:12:37.336854       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:37.733877181Z I1024 13:12:37.733806       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 12 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:37.735192291Z E1024 13:12:37.735141       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:38.135363516Z E1024 13:12:38.135329       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:38.536554182Z W1024 13:12:38.536484       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:38.536554182Z E1024 13:12:38.536535       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:38.733159859Z I1024 13:12:38.733105       1 request.go:700] Waited for 1.117448817s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-10-24T13:12:38.734161059Z E1024 13:12:38.734111       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:39.734769738Z E1024 13:12:39.734696       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:39.935807555Z E1024 13:12:39.935733       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:40.941228674Z E1024 13:12:40.941171       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:41.136361691Z W1024 13:12:41.136289       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:41.136361691Z E1024 13:12:41.136342       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:41.536014267Z E1024 13:12:41.535956       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:42.133614900Z E1024 13:12:42.133554       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:42.336401688Z E1024 13:12:42.336344       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:43.335245436Z E1024 13:12:43.335185       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:43.734298801Z I1024 13:12:43.734229       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 12 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:43.735353631Z E1024 13:12:43.735307       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:43.935313959Z W1024 13:12:43.935273       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:43.935360769Z E1024 13:12:43.935344       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:44.127845207Z E1024 13:12:44.127793       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:12:44.223785116Z E1024 13:12:44.223706       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:44.223841186Z I1024 13:12:44.223797       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:44.246162725Z E1024 13:12:44.246112       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:44.246271695Z I1024 13:12:44.246210       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:44.266528365Z E1024 13:12:44.266463       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:44.266576515Z I1024 13:12:44.266527       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:44.301837735Z E1024 13:12:44.301742       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:44.301897675Z I1024 13:12:44.301834       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:44.354278674Z E1024 13:12:44.354225       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:44.354340804Z I1024 13:12:44.354291       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:44.445100033Z E1024 13:12:44.445046       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:44.445145293Z I1024 13:12:44.445103       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:44.537414952Z E1024 13:12:44.537356       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:44.608207501Z E1024 13:12:44.608147       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:44.619034901Z E1024 13:12:44.618982       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:44.619105721Z I1024 13:12:44.619054       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:44.935926777Z E1024 13:12:44.935879       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:44.951005537Z E1024 13:12:44.950967       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:44.951081257Z I1024 13:12:44.951053       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:45.135085375Z E1024 13:12:45.135018       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:45.135153645Z I1024 13:12:45.135079       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:45.333360713Z I1024 13:12:45.333306       1 request.go:700] Waited for 1.120374927s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:12:45.337333543Z E1024 13:12:45.337280       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:45.535744850Z E1024 13:12:45.535691       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:45.608979810Z E1024 13:12:45.608927       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:45.609028580Z I1024 13:12:45.608991       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:46.334063272Z E1024 13:12:46.333999       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:46.532893309Z I1024 13:12:46.532836       1 request.go:700] Waited for 1.391170474s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:12:46.535261149Z E1024 13:12:46.535222       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:46.535337019Z I1024 13:12:46.535285       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:46.584931358Z E1024 13:12:46.584888       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-signer\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:46.736302937Z E1024 13:12:46.736189       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:46.899639775Z E1024 13:12:46.899581       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:46.899697615Z I1024 13:12:46.899651       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:47.335409350Z W1024 13:12:47.335364       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:47.335463910Z E1024 13:12:47.335426       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:47.533416708Z I1024 13:12:47.533362       1 request.go:700] Waited for 1.399700544s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:12:47.735467695Z E1024 13:12:47.735410       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:47.735529715Z I1024 13:12:47.735474       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:47.936876473Z E1024 13:12:47.936811       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:48.135181770Z E1024 13:12:48.135124       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:48.534238406Z E1024 13:12:48.534178       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:48.733214644Z I1024 13:12:48.733151       1 request.go:700] Waited for 1.396070333s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:12:48.936647991Z E1024 13:12:48.936586       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:49.134875669Z E1024 13:12:49.134814       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:49.134939699Z I1024 13:12:49.134877       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:49.336661877Z E1024 13:12:49.336611       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:49.474982836Z E1024 13:12:49.474919       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:49.475053556Z I1024 13:12:49.474991       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:49.733333763Z I1024 13:12:49.733277       1 request.go:700] Waited for 1.395962745s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa
2024-10-24T13:12:49.737602282Z E1024 13:12:49.737559       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:50.335975265Z E1024 13:12:50.335920       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:50.336025405Z I1024 13:12:50.335983       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:50.536151283Z E1024 13:12:50.536096       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:50.733431221Z I1024 13:12:50.733371       1 request.go:700] Waited for 1.198966576s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-10-24T13:12:50.735362601Z E1024 13:12:50.735305       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:51.136357986Z W1024 13:12:51.136278       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:51.136417157Z E1024 13:12:51.136356       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:51.535037272Z E1024 13:12:51.534976       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:51.535107612Z I1024 13:12:51.535054       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:51.736253919Z E1024 13:12:51.736202       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:51.933048427Z I1024 13:12:51.932989       1 request.go:700] Waited for 1.195777816s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-10-24T13:12:52.536159040Z E1024 13:12:52.536106       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:52.735491958Z E1024 13:12:52.735408       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:52.735558738Z I1024 13:12:52.735486       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:52.936211585Z E1024 13:12:52.936149       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:53.133003193Z I1024 13:12:53.132944       1 request.go:700] Waited for 1.198933396s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-10-24T13:12:53.135463354Z E1024 13:12:53.135407       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:53.939043354Z I1024 13:12:53.938967       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:53.939396894Z E1024 13:12:53.939225       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:54.332906110Z I1024 13:12:54.332843       1 request.go:700] Waited for 1.074494598s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:12:54.336429320Z E1024 13:12:54.336387       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:54.537692827Z E1024 13:12:54.537639       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:54.607076616Z E1024 13:12:54.607034       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:54.607128607Z I1024 13:12:54.607093       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:54.735440355Z W1024 13:12:54.735394       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:54.735496355Z E1024 13:12:54.735455       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:55.133777990Z I1024 13:12:55.133677       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 12 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:55.134992010Z E1024 13:12:55.134952       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:55.334850208Z E1024 13:12:55.334791       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:55.733005864Z I1024 13:12:55.732955       1 request.go:700] Waited for 1.151570996s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:12:55.735114193Z E1024 13:12:55.735068       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:55.735183044Z I1024 13:12:55.735138       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:56.135669729Z E1024 13:12:56.135615       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:56.336608206Z E1024 13:12:56.336551       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:56.733262172Z I1024 13:12:56.733214       1 request.go:700] Waited for 1.199201816s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa
2024-10-24T13:12:57.334995405Z E1024 13:12:57.334945       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:57.735803850Z W1024 13:12:57.735717       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:57.735872380Z E1024 13:12:57.735830       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:57.935122258Z E1024 13:12:57.935069       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:57.935177648Z I1024 13:12:57.935134       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:58.110010216Z E1024 13:12:58.109942       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:12:58.110959986Z E1024 13:12:58.110901       1 leaderelection.go:436] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:12:58.536342791Z E1024 13:12:58.536290       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:58.732681849Z I1024 13:12:58.732625       1 request.go:700] Waited for 1.113497867s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:12:58.736484049Z E1024 13:12:58.736439       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:12:59.135314504Z E1024 13:12:59.135266       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:12:59.335268582Z E1024 13:12:59.335213       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:00.535283508Z W1024 13:13:00.535243       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:00.535336508Z E1024 13:13:00.535283       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:00.935616563Z E1024 13:13:00.935560       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:01.335290569Z E1024 13:13:01.335228       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:01.335348259Z I1024 13:13:01.335302       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:01.736182954Z E1024 13:13:01.736118       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:02.137723780Z E1024 13:13:02.137660       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:02.332594308Z I1024 13:13:02.332528       1 request.go:700] Waited for 1.034307388s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:13:02.336692928Z E1024 13:13:02.336630       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:02.735420133Z E1024 13:13:02.735362       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:03.136295418Z W1024 13:13:03.136226       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:03.136368619Z E1024 13:13:03.136304       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:03.735950372Z E1024 13:13:03.735902       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:04.336743335Z E1024 13:13:04.336677       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:04.534796483Z E1024 13:13:04.534724       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:04.858155769Z E1024 13:13:04.858103       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:04.858210909Z I1024 13:13:04.858157       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:05.735569609Z E1024 13:13:05.735514       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:05.935932436Z E1024 13:13:05.935874       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:06.736550757Z E1024 13:13:06.736478       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:07.134991372Z E1024 13:13:07.134953       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:07.135057622Z I1024 13:13:07.135023       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:07.334708330Z E1024 13:13:07.334641       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:07.734817795Z W1024 13:13:07.734772       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:07.734871275Z E1024 13:13:07.734828       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:08.136363801Z E1024 13:13:08.136298       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:08.534791057Z E1024 13:13:08.534726       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:09.137960840Z E1024 13:13:09.137903       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:09.334539037Z E1024 13:13:09.334482       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:09.533984495Z E1024 13:13:09.533932       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:09.935718390Z E1024 13:13:09.935658       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:10.335984676Z E1024 13:13:10.335927       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:10.735129121Z E1024 13:13:10.735069       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:11.135357027Z E1024 13:13:11.135315       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:11.535293812Z E1024 13:13:11.535240       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:11.934361362Z W1024 13:13:11.934288       1 reflector.go:561] k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: failed to list *v1.Service: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services?resourceVersion=16112": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:11.934411442Z E1024 13:13:11.934357       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Failed to watch *v1.Service: failed to list *v1.Service: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services?resourceVersion=16112\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:12.134985526Z E1024 13:13:12.134934       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:12.540427484Z E1024 13:13:12.537624       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:12.935669173Z E1024 13:13:12.935621       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:13.335366402Z E1024 13:13:13.335301       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:13.735355540Z E1024 13:13:13.735282       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:14.135244609Z E1024 13:13:14.135179       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:14.535640008Z E1024 13:13:14.535579       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:14.934943937Z E1024 13:13:14.934875       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:15.335009485Z E1024 13:13:15.334954       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:15.735080084Z E1024 13:13:15.735021       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:15.933796499Z I1024 13:13:15.933696       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 12 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:15.934921098Z E1024 13:13:15.934866       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:16.335466817Z E1024 13:13:16.335420       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:16.734934246Z E1024 13:13:16.734877       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:17.135196344Z E1024 13:13:17.135135       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:17.535631433Z E1024 13:13:17.535568       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:17.734743968Z E1024 13:13:17.734681       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:17.734895208Z I1024 13:13:17.734787       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:18.135410776Z E1024 13:13:18.135354       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:18.436049943Z W1024 13:13:18.435965       1 reflector.go:561] k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: failed to list *v1.Infrastructure: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/infrastructures?resourceVersion=16142": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:13:18.436049943Z E1024 13:13:18.436037       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Failed to watch *v1.Infrastructure: failed to list *v1.Infrastructure: Get \"https://172.30.0.1:443/apis/config.openshift.io/v1/infrastructures?resourceVersion=16142\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:18.534923745Z E1024 13:13:18.534871       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:18.736741279Z E1024 13:13:18.736664       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:19.134889558Z E1024 13:13:19.134835       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:19.535565486Z E1024 13:13:19.535506       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:20.335066914Z E1024 13:13:20.335003       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:20.936996827Z E1024 13:13:20.936942       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:13:21.135893101Z E1024 13:13:21.135816       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:21.535184860Z E1024 13:13:21.535126       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:21.986143084Z E1024 13:13:21.986068       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:13:44.127960809Z E1024 13:13:44.127915       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:13:51.499159902Z I1024 13:13:51.499061       1 reflector.go:368] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:13:56.929213876Z I1024 13:13:56.929145       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-etcd because it was missing
2024-10-24T13:13:56.934019725Z I1024 13:13:56.933963       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 12, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:13:59.664617811Z I1024 13:13:59.664552       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=etcds from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:13:59.666221121Z I1024 13:13:59.666162       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nTargetConfigControllerDegraded: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod\": dial tcp 172.30.0.1:443: connect: connection refused\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:13:59.667954081Z I1024 13:13:59.667912       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:13:59.678908060Z I1024 13:13:59.678857       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nTargetConfigControllerDegraded: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod\": dial tcp 172.30.0.1:443: connect: connection refused\nEtcdMembersDegraded: No unhealthy members found"
2024-10-24T13:13:59.683878490Z I1024 13:13:59.683824       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 12, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:13:59.685162120Z I1024 13:13:59.685105       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:13:59.727376457Z I1024 13:13:59.727262       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:13:59.744194655Z I1024 13:13:59.744088       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.02 %, dbSize: 81920000
2024-10-24T13:13:59.744194655Z I1024 13:13:59.744114       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.01 %, dbSize: 81969152
2024-10-24T13:13:59.744194655Z I1024 13:13:59.744122       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 82235392
2024-10-24T13:13:59.797669581Z I1024 13:13:59.797517       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:13:59.808385580Z I1024 13:13:59.808316       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.01 %, dbSize: 81960960
2024-10-24T13:14:00.865368218Z I1024 13:14:00.865313       1 request.go:700] Waited for 1.129724992s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:14:01.671856664Z I1024 13:14:01.671802       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 12, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:14:05.840098288Z I1024 13:14:05.840025       1 reflector.go:368] Caches populated for *v1beta1.Machine from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:05.882015674Z I1024 13:14:05.881947       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:06.300449152Z I1024 13:14:06.300356       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:10.577699276Z I1024 13:14:10.577627       1 reflector.go:368] Caches populated for *v1.Role from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:10.776358440Z I1024 13:14:10.776289       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:12.220085827Z I1024 13:14:12.220024       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:15.455434334Z I1024 13:14:15.455358       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:17.568104346Z I1024 13:14:17.568031       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:19.896256289Z I1024 13:14:19.896214       1 reflector.go:368] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:20.895519755Z I1024 13:14:20.895467       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:21.104943493Z I1024 13:14:21.104895       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 12 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": rpc error: code = Unknown desc = malformed header: missing HTTP content-type
2024-10-24T13:14:22.472510148Z I1024 13:14:22.472455       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:23.148222521Z E1024 13:14:23.148171       1 leaderelection.go:429] Failed to update lock optimitically: rpc error: code = DeadlineExceeded desc = context deadline exceeded, falling back to slow path
2024-10-24T13:14:23.707541981Z I1024 13:14:23.707500       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:26.689212968Z I1024 13:14:26.689146       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:28.183567886Z E1024 13:14:28.183470       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: rpc error: code = Unknown desc = malformed header: missing HTTP content-type"
2024-10-24T13:14:28.758463635Z I1024 13:14:28.758413       1 reflector.go:368] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:30.266356112Z I1024 13:14:30.266314       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:30.896739078Z I1024 13:14:30.896700       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:32.575680106Z I1024 13:14:32.575624       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:34.520236140Z I1024 13:14:34.520170       1 reflector.go:368] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:35.120277397Z I1024 13:14:35.120232       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:37.041313122Z I1024 13:14:37.041269       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:38.300036613Z I1024 13:14:38.299989       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:38.732553960Z I1024 13:14:38.732505       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:39.298246549Z I1024 13:14:39.298178       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:40.117860004Z I1024 13:14:40.117808       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:40.135362593Z I1024 13:14:40.135290       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:14:44.130526775Z E1024 13:14:44.130484       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:14:53.708453831Z W1024 13:14:53.708392       1 etcdcli_pool.go:94] cached client considered unhealthy after 0 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2024-10-24T13:14:53.708453831Z I1024 13:14:53.708428       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:15:09.299383349Z W1024 13:15:09.299312       1 etcdcli_pool.go:94] cached client considered unhealthy after 0 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2024-10-24T13:15:09.299504649Z I1024 13:15:09.299480       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:15:12.226099889Z E1024 13:15:12.226046       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: EtcdCertSignerController failed to sync all master certificates during bootstrap: error on ensuring etcd-signer cert: the server was unable to return a response in the time allotted, but may still be processing the request (get secrets etcd-signer)"
2024-10-24T13:15:14.211665181Z W1024 13:15:14.211607       1 etcdcli_pool.go:94] cached client considered unhealthy after 0 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2024-10-24T13:15:14.211665181Z I1024 13:15:14.211630       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:15:18.421060691Z I1024 13:15:18.420996       1 trace.go:236] Trace[1295258899]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:14:44.292) (total time: 34128ms):
2024-10-24T13:15:18.421060691Z Trace[1295258899]: ---"Objects listed" error:<nil> 34128ms (13:15:18.420)
2024-10-24T13:15:18.421060691Z Trace[1295258899]: [34.128769685s] [34.128769685s] END
2024-10-24T13:15:18.421134781Z I1024 13:15:18.421117       1 reflector.go:368] Caches populated for *v1.Job from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:18.487572697Z E1024 13:15:18.484614       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type"
2024-10-24T13:15:18.581015712Z I1024 13:15:18.580954       1 trace.go:236] Trace[1035194230]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:14:42.648) (total time: 35931ms):
2024-10-24T13:15:18.581015712Z Trace[1035194230]: ---"Objects listed" error:<nil> 35931ms (13:15:18.580)
2024-10-24T13:15:18.581015712Z Trace[1035194230]: [35.931907936s] [35.931907936s] END
2024-10-24T13:15:18.581128802Z I1024 13:15:18.581112       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:18.645101168Z I1024 13:15:18.645045       1 trace.go:236] Trace[1746176029]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:14:59.216) (total time: 19420ms):
2024-10-24T13:15:18.645101168Z Trace[1746176029]: ---"Objects listed" error:<nil> 19420ms (13:15:18.637)
2024-10-24T13:15:18.645101168Z Trace[1746176029]: [19.420572339s] [19.420572339s] END
2024-10-24T13:15:18.645215439Z I1024 13:15:18.645195       1 reflector.go:368] Caches populated for *v1.Etcd from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:18.696852096Z I1024 13:15:18.696783       1 trace.go:236] Trace[42193502]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:15:04.443) (total time: 14253ms):
2024-10-24T13:15:18.696852096Z Trace[42193502]: ---"Objects listed" error:<nil> 14253ms (13:15:18.696)
2024-10-24T13:15:18.696852096Z Trace[42193502]: [14.253438961s] [14.253438961s] END
2024-10-24T13:15:18.696967845Z I1024 13:15:18.696948       1 reflector.go:368] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:18.720604504Z I1024 13:15:18.720538       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:15:19.075295835Z I1024 13:15:19.075248       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:19.075726465Z I1024 13:15:19.075703       1 trace.go:236] Trace[2146645400]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:14:46.212) (total time: 32856ms):
2024-10-24T13:15:19.075726465Z Trace[2146645400]: ---"Objects listed" error:<nil> 32856ms (13:15:19.068)
2024-10-24T13:15:19.075726465Z Trace[2146645400]: [32.856218364s] [32.856218364s] END
2024-10-24T13:15:19.075799685Z I1024 13:15:19.075780       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:19.120444832Z I1024 13:15:19.120394       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:19.121306972Z I1024 13:15:19.121252       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nTargetConfigControllerDegraded: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod\": dial tcp 172.30.0.1:443: connect: connection refused\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found"
2024-10-24T13:15:19.148241181Z I1024 13:15:19.148197       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:15:19.165341850Z E1024 13:15:19.165308       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:19.173618370Z I1024 13:15:19.173552       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:15:19.321395421Z E1024 13:15:19.321342       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:15:19.472977363Z E1024 13:15:19.472929       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)"
2024-10-24T13:15:19.577870267Z I1024 13:15:19.577806       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:20.357511725Z I1024 13:15:20.356658       1 trace.go:236] Trace[1876150558]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:14:51.655) (total time: 28701ms):
2024-10-24T13:15:20.357511725Z Trace[1876150558]: ---"Objects listed" error:<nil> 28701ms (13:15:20.356)
2024-10-24T13:15:20.357511725Z Trace[1876150558]: [28.701391592s] [28.701391592s] END
2024-10-24T13:15:20.366737964Z I1024 13:15:20.366682       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:20.372656374Z I1024 13:15:20.358076       1 trace.go:236] Trace[2096788983]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:14:48.761) (total time: 31596ms):
2024-10-24T13:15:20.372656374Z Trace[2096788983]: ---"Objects listed" error:<nil> 31596ms (13:15:20.357)
2024-10-24T13:15:20.372656374Z Trace[2096788983]: [31.596108833s] [31.596108833s] END
2024-10-24T13:15:20.373156524Z I1024 13:15:20.373130       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:20.427991311Z I1024 13:15:20.427936       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:20.431600571Z I1024 13:15:20.431554       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.433127961Z I1024 13:15:20.433093       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.433541701Z I1024 13:15:20.433520       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.456525320Z I1024 13:15:20.456477       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.469860899Z I1024 13:15:20.469810       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.475266298Z I1024 13:15:20.475224       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.475738789Z I1024 13:15:20.475702       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.476109699Z I1024 13:15:20.476067       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.476473648Z I1024 13:15:20.476440       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.476802658Z I1024 13:15:20.476772       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.477166548Z I1024 13:15:20.477127       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.477538139Z I1024 13:15:20.477518       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.477864089Z I1024 13:15:20.477844       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.478368088Z I1024 13:15:20.478200       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.480047238Z I1024 13:15:20.479611       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.480047238Z I1024 13:15:20.480016       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.480526998Z I1024 13:15:20.480497       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.481082668Z I1024 13:15:20.481047       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.484030278Z I1024 13:15:20.484009       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.491057528Z I1024 13:15:20.491035       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.491252078Z I1024 13:15:20.491235       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.492587868Z I1024 13:15:20.492556       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.498832947Z I1024 13:15:20.495276       1 trace.go:236] Trace[1580583644]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243 (24-Oct-2024 13:14:56.509) (total time: 23986ms):
2024-10-24T13:15:20.498832947Z Trace[1580583644]: ---"Objects listed" error:<nil> 23986ms (13:15:20.495)
2024-10-24T13:15:20.498832947Z Trace[1580583644]: [23.986189469s] [23.986189469s] END
2024-10-24T13:15:20.498832947Z I1024 13:15:20.495302       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:20.506741937Z I1024 13:15:20.501962       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.506741937Z I1024 13:15:20.502125       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.506741937Z I1024 13:15:20.502368       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.506741937Z I1024 13:15:20.502674       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.508738846Z I1024 13:15:20.508464       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.508813177Z I1024 13:15:20.508782       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.522215206Z I1024 13:15:20.515945       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.522215206Z I1024 13:15:20.521021       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.522215206Z I1024 13:15:20.522041       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.523126396Z I1024 13:15:20.523104       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.525847086Z I1024 13:15:20.523455       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.526239625Z I1024 13:15:20.526217       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:20.592628782Z I1024 13:15:20.592562       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:15:20.965788172Z I1024 13:15:20.961963       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 12, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:15:20.980852821Z I1024 13:15:20.980070       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:15:22.089629282Z I1024 13:15:22.089579       1 request.go:700] Waited for 1.073537463s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:15:22.741110934Z I1024 13:15:22.741031       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 12, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:15:24.189015652Z I1024 13:15:24.188965       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:15:24.342411745Z I1024 13:15:24.342359       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:15:25.695839877Z I1024 13:15:25.695778       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 12, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:15:25.710992167Z W1024 13:15:25.710921       1 etcdcli_pool.go:94] cached client considered unhealthy after 1 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2024-10-24T13:15:25.710992167Z I1024 13:15:25.710946       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:15:29.725686064Z I1024 13:15:29.725617       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:15:44.124186767Z I1024 13:15:44.124142       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:15:44.124349587Z I1024 13:15:44.124188       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:15:44.135728716Z E1024 13:15:44.135680       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:15:44.643410385Z I1024 13:15:44.643334       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:15:48.196420832Z I1024 13:15:48.196337       1 helpers.go:184] lister was stale at resourceVersion=18870, live get showed resourceVersion=19314
2024-10-24T13:15:48.225354111Z E1024 13:15:48.225285       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: failed to get member list: context deadline exceeded"
2024-10-24T13:15:48.303543838Z I1024 13:15:48.303463       1 helpers.go:184] lister was stale at resourceVersion=18870, live get showed resourceVersion=20414
2024-10-24T13:15:48.327219137Z E1024 13:15:48.327130       1 base_controller.go:271] "Unhandled Error" err="BootstrapTeardownController reconciliation failed: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded"
2024-10-24T13:15:49.892793610Z I1024 13:15:49.892667       1 reflector.go:368] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:50.718717054Z I1024 13:15:50.718645       1 reflector.go:368] Caches populated for *v1beta1.Machine from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:51.044780600Z I1024 13:15:51.044153       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:53.291442844Z I1024 13:15:53.291352       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:54.884009555Z I1024 13:15:54.883958       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:56.770287055Z I1024 13:15:56.770221       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:56.783636284Z I1024 13:15:56.783558       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:58.857736615Z I1024 13:15:58.857674       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:59.726083568Z W1024 13:15:59.726021       1 etcdcli_pool.go:94] cached client considered unhealthy after 0 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2024-10-24T13:15:59.726083568Z I1024 13:15:59.726046       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:15:59.804968774Z I1024 13:15:59.803339       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:15:59.899426811Z I1024 13:15:59.898838       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:03.867555610Z I1024 13:16:03.867471       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:03.912325759Z I1024 13:16:03.912268       1 reflector.go:368] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:05.236901801Z I1024 13:16:05.236863       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:05.751593230Z I1024 13:16:05.751537       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:06.581935944Z I1024 13:16:06.581887       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:07.874189728Z I1024 13:16:07.873885       1 reflector.go:368] Caches populated for *v1.Role from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:08.413248005Z I1024 13:16:08.412458       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:10.744211646Z I1024 13:16:10.744129       1 reflector.go:368] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:12.122437556Z I1024 13:16:12.122390       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:12.235648701Z I1024 13:16:12.235582       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:14.123073191Z E1024 13:16:14.123024       1 health.go:115] health check for member (etcd-bootstrap) failed: err(context deadline exceeded)
2024-10-24T13:16:14.123393870Z E1024 13:16:14.123349       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: etcd-bootstrap, took=29.983425255s, err=health check failed: context deadline exceeded
2024-10-24T13:16:14.124272340Z E1024 13:16:14.124241       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:16:14.135902160Z E1024 13:16:14.135850       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:16:14.148337449Z E1024 13:16:14.148282       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:16:14.170414618Z E1024 13:16:14.170369       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:16:14.212731017Z E1024 13:16:14.212684       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:16:14.294924573Z E1024 13:16:14.294793       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:16:14.458669766Z E1024 13:16:14.458620       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:16:14.762093343Z I1024 13:16:14.762056       1 reflector.go:368] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:14.780844812Z E1024 13:16:14.780785       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:16:14.946403755Z I1024 13:16:14.946355       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:15.163519536Z I1024 13:16:15.163257       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:15.238046113Z I1024 13:16:15.237982       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:15.424926095Z E1024 13:16:15.424839       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:16:16.707394090Z E1024 13:16:16.707345       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:16:17.013474377Z I1024 13:16:17.013411       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=etcds from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:17.014106267Z E1024 13:16:17.014062       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:16:17.014200127Z I1024 13:16:17.014077       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:16:17.016343527Z I1024 13:16:17.016302       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdEndpointsDegraded: failed to get member list: context deadline exceeded\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type\nEtcdMembersDegraded: No unhealthy members found\nBootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:16:18.343074789Z E1024 13:16:18.343023       1 health.go:115] health check for member (etcd-bootstrap) failed: err(context deadline exceeded)
2024-10-24T13:16:18.343445339Z W1024 13:16:18.343413       1 etcdcli.go:351] UnhealthyEtcdMember found: [etcd-bootstrap]
2024-10-24T13:16:18.344442939Z W1024 13:16:18.344412       1 bootstrap_teardown_controller.go:144] Removing bootstrap member [a48f107742a8605c]
2024-10-24T13:16:19.269586980Z E1024 13:16:19.269536       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:16:19.669478883Z I1024 13:16:19.669407       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:16:19.751937759Z E1024 13:16:19.751892       1 leaderelection.go:429] Failed to update lock optimitically: rpc error: code = DeadlineExceeded desc = context deadline exceeded, falling back to slow path
2024-10-24T13:16:24.114711402Z E1024 13:16:24.113084       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:16:24.121602982Z I1024 13:16:24.121550       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdEndpointsDegraded: failed to get member list: context deadline exceeded\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type\nEtcdMembersDegraded: No unhealthy members found\nBootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:16:29.511252695Z E1024 13:16:29.511187       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:16:31.171127640Z E1024 13:16:31.171058       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:16:31.183084299Z I1024 13:16:31.183044       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdEndpointsDegraded: failed to get member list: context deadline exceeded\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type\nEtcdMembersDegraded: No unhealthy members found\nBootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:16:31.728898344Z W1024 13:16:31.728838       1 etcdcli_pool.go:94] cached client considered unhealthy after 1 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2024-10-24T13:16:31.728898344Z I1024 13:16:31.728859       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:16:38.195142602Z E1024 13:16:38.195077       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:16:38.217104110Z I1024 13:16:38.217046       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdEndpointsDegraded: failed to get member list: context deadline exceeded\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type\nEtcdMembersDegraded: No unhealthy members found\nBootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:16:44.138287780Z E1024 13:16:44.138193       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:16:45.226815412Z E1024 13:16:45.226732       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:16:45.228740202Z I1024 13:16:45.228689       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdEndpointsDegraded: failed to get member list: context deadline exceeded\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type\nEtcdMembersDegraded: No unhealthy members found\nBootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:16:47.014264357Z W1024 13:16:47.014203       1 etcdcli_pool.go:94] cached client considered unhealthy after 0 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2024-10-24T13:16:47.014264357Z I1024 13:16:47.014229       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:16:48.129355206Z I1024 13:16:48.129273       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Timeout: request did not complete within requested timeout - context deadline exceeded
2024-10-24T13:16:48.345820189Z W1024 13:16:48.345728       1 etcdcli_pool.go:94] cached client considered unhealthy after 0 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2024-10-24T13:16:48.345820189Z I1024 13:16:48.345780       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:16:49.993426185Z E1024 13:16:49.993368       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:16:51.291994010Z E1024 13:16:51.291935       1 guard_controller.go:366] Unable to apply pod etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1 changes: the server was unable to return a response in the time allotted, but may still be processing the request (get pods etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1)
2024-10-24T13:16:52.238572024Z E1024 13:16:52.238511       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:16:52.240243644Z I1024 13:16:52.240207       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdEndpointsDegraded: failed to get member list: context deadline exceeded\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type\nEtcdMembersDegraded: No unhealthy members found\nBootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:16:55.144466029Z I1024 13:16:55.144375       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' rpc error: code = DeadlineExceeded desc = context deadline exceeded
2024-10-24T13:16:56.789001266Z E1024 13:16:56.788934       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps etcd-all-bundles)"
2024-10-24T13:16:56.789456186Z I1024 13:16:56.789353       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 12 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": the server was unable to return a response in the time allotted, but may still be processing the request (get pods installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2)
2024-10-24T13:16:58.307205033Z W1024 13:16:58.307128       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": rpc error: code = DeadlineExceeded desc = context deadline exceeded
2024-10-24T13:16:58.307205033Z E1024 13:16:58.307181       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Unable to apply pod etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1 changes: the server was unable to return a response in the time allotted, but may still be processing the request (get pods etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1)"
2024-10-24T13:16:59.249410147Z E1024 13:16:59.249360       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:16:59.251117726Z I1024 13:16:59.251082       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdEndpointsDegraded: failed to get member list: context deadline exceeded\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type\nEtcdMembersDegraded: No unhealthy members found\nBootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:17:02.160293590Z E1024 13:17:02.160217       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: [Timeout: request did not complete within requested timeout - context deadline exceeded, rpc error: code = DeadlineExceeded desc = context deadline exceeded]"
2024-10-24T13:17:02.160293590Z I1024 13:17:02.160268       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' rpc error: code = DeadlineExceeded desc = context deadline exceeded
2024-10-24T13:17:02.161456800Z E1024 13:17:02.161409       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: etcd-bootstrap, took=29.983425255s, err=health check failed: context deadline exceeded
2024-10-24T13:17:03.804390516Z E1024 13:17:03.804322       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: the server was unable to return a response in the time allotted, but may still be processing the request (get pods installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2)"
2024-10-24T13:17:05.730217011Z W1024 13:17:05.730145       1 etcdcli_pool.go:94] cached client considered unhealthy after 2 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2024-10-24T13:17:05.730217011Z I1024 13:17:05.730174       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:17:05.730699810Z W1024 13:17:05.730664       1 etcdcli.go:351] UnhealthyEtcdMember found: [etcd-bootstrap]
2024-10-24T13:17:06.259910068Z E1024 13:17:06.259858       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:17:06.261859038Z I1024 13:17:06.261816       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdEndpointsDegraded: failed to get member list: context deadline exceeded\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type\nEtcdMembersDegraded: No unhealthy members found\nBootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:17:09.179429031Z I1024 13:17:09.179350       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' rpc error: code = DeadlineExceeded desc = context deadline exceeded
2024-10-24T13:17:13.271386930Z E1024 13:17:13.271315       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:17:13.273081030Z I1024 13:17:13.273042       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:08:01Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdEndpointsDegraded: failed to get member list: context deadline exceeded\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type\nEtcdMembersDegraded: No unhealthy members found\nBootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:17:15.258142599Z E1024 13:17:15.258095       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: the server was unable to return a response in the time allotted, but may still be processing the request (get pods)"
2024-10-24T13:17:16.197128523Z I1024 13:17:16.197053       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' rpc error: code = DeadlineExceeded desc = context deadline exceeded
2024-10-24T13:17:19.017049014Z W1024 13:17:19.016987       1 etcdcli_pool.go:94] cached client considered unhealthy after 1 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2024-10-24T13:17:19.017049014Z I1024 13:17:19.017013       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:17:19.792020772Z E1024 13:17:19.791921       1 leaderelection.go:436] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: the server was unable to return a response in the time allotted, but may still be processing the request (get leases.coordination.k8s.io openshift-cluster-etcd-operator-lock)
2024-10-24T13:17:20.281920772Z E1024 13:17:20.281858       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:17:20.283529442Z I1024 13:17:20.283486       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:17:20Z","message":"BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdEndpointsDegraded: failed to get member list: context deadline exceeded\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type","reason":"BootstrapTeardown_Error::EtcdEndpoints_ErrorUpdatingEtcdEndpoints::EtcdStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:17:20.347667837Z W1024 13:17:20.347594       1 etcdcli_pool.go:94] cached client considered unhealthy after 1 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2024-10-24T13:17:20.347667837Z I1024 13:17:20.347618       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:17:22.132669693Z E1024 13:17:22.132618       1 event.go:359] "Server rejected event (will not retry!)" err="Timeout: request did not complete within requested timeout - context deadline exceeded" event="&Event{ObjectMeta:{etcd-operator.180165eec8995324  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Timeout: request did not complete within requested timeout - context deadline exceeded,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-10-24 13:16:48.129094436 +0000 UTC m=+724.654882603,LastTimestamp:2024-10-24 13:16:48.129094436 +0000 UTC m=+724.654882603,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-10-24T13:17:23.210956376Z E1024 13:17:23.210897       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:17:23.211017246Z I1024 13:17:23.210955       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' rpc error: code = DeadlineExceeded desc = context deadline exceeded
2024-10-24T13:17:23.212131376Z I1024 13:17:23.212107       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:17:24.033051769Z E1024 13:17:24.032979       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps etcd-scripts)"
2024-10-24T13:17:24.033094709Z I1024 13:17:24.033029       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' rpc error: code = DeadlineExceeded desc = context deadline exceeded
2024-10-24T13:17:24.348743794Z I1024 13:17:24.348690       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:17:27.291860065Z E1024 13:17:27.291772       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:17:27.293513815Z I1024 13:17:27.293462       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:17:27Z","message":"BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdEndpointsDegraded: failed to get member list: context deadline exceeded\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type","reason":"BootstrapTeardown_Error::EtcdEndpoints_ErrorUpdatingEtcdEndpoints::EtcdStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:17:30.792628162Z E1024 13:17:30.792549       1 event.go:359] "Server rejected event (will not retry!)" err="Timeout: request did not complete within requested timeout - context deadline exceeded" event="&Event{ObjectMeta:{etcd-operator.180165f0ccc85a1a  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 12 count 1 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-2\": the server was unable to return a response in the time allotted, but may still be processing the request (get pods installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2),Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:16:56.789219866 +0000 UTC m=+733.315008053,LastTimestamp:2024-10-24 13:16:56.789219866 +0000 UTC m=+733.315008053,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:17:34.302174097Z E1024 13:17:34.302090       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:17:34.303814937Z I1024 13:17:34.303740       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:17:34Z","message":"BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdEndpointsDegraded: failed to get member list: context deadline exceeded\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type","reason":"BootstrapTeardown_Error::EtcdEndpoints_ErrorUpdatingEtcdEndpoints::EtcdStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:17:35.732415061Z W1024 13:17:35.732343       1 etcdcli_pool.go:94] cached client considered unhealthy after 0 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2024-10-24T13:17:35.732415061Z I1024 13:17:35.732368       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:17:37.733141028Z I1024 13:17:37.733062       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:17:40.167918350Z E1024 13:17:40.167844       1 event.go:359] "Server rejected event (will not retry!)" err="rpc error: code = DeadlineExceeded desc = context deadline exceeded" event="&Event{ObjectMeta:{etcd-operator.180165f724a24ae5  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:rpc error: code = DeadlineExceeded desc = context deadline exceeded,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-10-24 13:17:24.032924389 +0000 UTC m=+760.558712557,LastTimestamp:2024-10-24 13:17:24.032924389 +0000 UTC m=+760.558712557,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-10-24T13:17:41.312200788Z E1024 13:17:41.312124       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:17:41.313883687Z I1024 13:17:41.313846       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:17:41Z","message":"BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdEndpointsDegraded: failed to get member list: context deadline exceeded\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type","reason":"BootstrapTeardown_Error::EtcdEndpoints_ErrorUpdatingEtcdEndpoints::EtcdStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:17:44.126944749Z E1024 13:17:44.126888       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:17:48.323452509Z E1024 13:17:48.323394       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:17:48.325158909Z I1024 13:17:48.325106       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:17:48Z","message":"BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdEndpointsDegraded: failed to get member list: context deadline exceeded\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type","reason":"BootstrapTeardown_Error::EtcdEndpoints_ErrorUpdatingEtcdEndpoints::EtcdStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:17:52.799793337Z E1024 13:17:52.799693       1 leaderelection.go:429] Failed to update lock optimitically: rpc error: code = DeadlineExceeded desc = context deadline exceeded, falling back to slow path
2024-10-24T13:17:53.018381929Z W1024 13:17:53.018303       1 etcdcli_pool.go:94] cached client considered unhealthy after 2 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2024-10-24T13:17:53.018381929Z I1024 13:17:53.018323       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:17:53.220600283Z W1024 13:17:53.220541       1 etcdcli_pool.go:94] cached client considered unhealthy after 0 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2024-10-24T13:17:53.220600283Z I1024 13:17:53.220565       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:17:54.356794111Z W1024 13:17:54.356699       1 etcdcli_pool.go:94] cached client considered unhealthy after 2 tries, trying again. Err: error during cache client health connection check: context deadline exceeded
2024-10-24T13:17:54.356794111Z I1024 13:17:54.356724       1 etcdcli_pool.go:157] closing cached client
2024-10-24T13:17:55.222170281Z I1024 13:17:55.222104       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:17:55.333163161Z E1024 13:17:55.333117       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:17:55.334950261Z I1024 13:17:55.334900       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:17:55Z","message":"BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdEndpointsDegraded: failed to get member list: context deadline exceeded\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type","reason":"BootstrapTeardown_Error::EtcdEndpoints_ErrorUpdatingEtcdEndpoints::EtcdStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:17:56.793428693Z E1024 13:17:56.793342       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap the server was unable to return a response in the time allotted, but may still be processing the request (get configmaps etcd-all-bundles)"
2024-10-24T13:17:59.689172779Z E1024 13:17:59.689082       1 leaderelection.go:436] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": context deadline exceeded
2024-10-24T13:17:59.689172779Z I1024 13:17:59.689132       1 leaderelection.go:297] failed to renew lease openshift-etcd-operator/openshift-cluster-etcd-operator-lock: timed out waiting for the condition
2024-10-24T13:18:00.035254671Z E1024 13:18:00.035202       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: failed to get member list: giving up getting a cached client after 3 tries"
2024-10-24T13:18:00.035309931Z I1024 13:18:00.035270       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' rpc error: code = DeadlineExceeded desc = context deadline exceeded
2024-10-24T13:18:00.036704441Z I1024 13:18:00.036650       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:18:01.375342103Z E1024 13:18:01.375263       1 bootstrap_teardown_controller.go:79] error while updating BootstrapTeardownDegraded status with actual error [error while removing bootstrap member [a48f107742a8605c]: giving up getting a cached client after 3 tries], [rpc error: code = DeadlineExceeded desc = context deadline exceeded]
2024-10-24T13:18:01.375386993Z E1024 13:18:01.375335       1 base_controller.go:271] "Unhandled Error" err="BootstrapTeardownController reconciliation failed: error while removing bootstrap member [a48f107742a8605c]: giving up getting a cached client after 3 tries"
2024-10-24T13:18:01.376661992Z I1024 13:18:01.376636       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:18:02.344308874Z E1024 13:18:02.344264       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:18:03.809697206Z I1024 13:18:03.809626       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 12 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": the server was unable to return a response in the time allotted, but may still be processing the request (get pods installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-2)
2024-10-24T13:18:03.809771055Z E1024 13:18:03.809684       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded"
2024-10-24T13:18:06.696988631Z E1024 13:18:06.696918       1 leaderelection.go:322] Failed to release lock: rpc error: code = DeadlineExceeded desc = context deadline exceeded
2024-10-24T13:18:06.697055061Z W1024 13:18:06.697010       1 leaderelection.go:84] leader election lost
