2024-10-24T13:18:07.272218495Z I1024 13:18:07.271844       1 profiler.go:21] Starting profiling endpoint at http://127.0.0.1:6060/debug/pprof/
2024-10-24T13:18:07.272218495Z I1024 13:18:07.272190       1 observer_polling.go:159] Starting file observer
2024-10-24T13:18:07.272558015Z I1024 13:18:07.272517       1 cmd.go:250] Using service-serving-cert provided certificates
2024-10-24T13:18:07.272580625Z I1024 13:18:07.272549       1 leaderelection.go:121] The leader election gives 4 retries and allows for 30s of clock skew. The kube-apiserver downtime tolerance is 78s. Worst non-graceful lease acquisition is 2m43s. Worst graceful lease acquisition is {26s}.
2024-10-24T13:18:07.272967884Z I1024 13:18:07.272930       1 observer_polling.go:159] Starting file observer
2024-10-24T13:19:00.438064407Z I1024 13:19:00.437990       1 builder.go:298] openshift-cluster-etcd-operator version v0.0.0-alpha.0-1564-g26e5aee-26e5aee9
2024-10-24T13:19:00.865262910Z I1024 13:19:00.865219       1 secure_serving.go:57] Forcing use of http/1.1 only
2024-10-24T13:19:00.865348640Z W1024 13:19:00.865331       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256' detected.
2024-10-24T13:19:00.865397900Z W1024 13:19:00.865375       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256' detected.
2024-10-24T13:19:00.865397900Z W1024 13:19:00.865387       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_128_GCM_SHA256' detected.
2024-10-24T13:19:00.865397900Z W1024 13:19:00.865393       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_256_GCM_SHA384' detected.
2024-10-24T13:19:00.865431100Z W1024 13:19:00.865399       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_128_CBC_SHA' detected.
2024-10-24T13:19:00.865431100Z W1024 13:19:00.865403       1 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_256_CBC_SHA' detected.
2024-10-24T13:19:00.887925149Z I1024 13:19:00.887860       1 leaderelection.go:254] attempting to acquire leader lease openshift-etcd-operator/openshift-cluster-etcd-operator-lock...
2024-10-24T13:19:00.890177069Z I1024 13:19:00.889855       1 requestheader_controller.go:172] Starting RequestHeaderAuthRequestController
2024-10-24T13:19:00.890177069Z I1024 13:19:00.889937       1 shared_informer.go:313] Waiting for caches to sync for RequestHeaderAuthRequestController
2024-10-24T13:19:00.890177069Z I1024 13:19:00.890024       1 configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2024-10-24T13:19:00.890177069Z I1024 13:19:00.890115       1 shared_informer.go:313] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-10-24T13:19:00.890212839Z I1024 13:19:00.890177       1 configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2024-10-24T13:19:00.890212839Z I1024 13:19:00.890185       1 shared_informer.go:313] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-10-24T13:19:00.890613219Z I1024 13:19:00.890572       1 secure_serving.go:213] Serving securely on [::]:8443
2024-10-24T13:19:00.890707609Z I1024 13:19:00.890641       1 dynamic_serving_content.go:135] "Starting controller" name="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key"
2024-10-24T13:19:00.890875369Z I1024 13:19:00.890854       1 tlsconfig.go:243] "Starting DynamicServingCertificateController"
2024-10-24T13:19:00.992973567Z I1024 13:19:00.992888       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-10-24T13:19:00.993036387Z I1024 13:19:00.993002       1 shared_informer.go:320] Caches are synced for RequestHeaderAuthRequestController
2024-10-24T13:19:00.993135897Z I1024 13:19:00.993112       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-10-24T13:21:48.217671490Z I1024 13:21:48.217595       1 leaderelection.go:268] successfully acquired lease openshift-etcd-operator/openshift-cluster-etcd-operator-lock
2024-10-24T13:21:48.217978211Z I1024 13:21:48.217895       1 event.go:377] Event(v1.ObjectReference{Kind:"Lease", Namespace:"openshift-etcd-operator", Name:"openshift-cluster-etcd-operator-lock", UID:"c84f0bae-a1b8-4371-af39-b17979ae2fc2", APIVersion:"coordination.k8s.io/v1", ResourceVersion:"22568", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' etcd-operator-7bbcf99d5c-9746p_9ca2cd62-2569-4e04-9881-695eebe9adb6 became leader
2024-10-24T13:21:48.234891822Z I1024 13:21:48.234824       1 starter.go:169] recorded cluster versions: map[etcd:4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest operator:4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest raw-internal:4.18.0-0.ci.test-2024-10-24-124520-ci-op-2fcpj5j6-latest]
2024-10-24T13:21:48.242669762Z I1024 13:21:48.242599       1 simple_featuregate_reader.go:171] Starting feature-gate-detector
2024-10-24T13:21:48.248393512Z I1024 13:21:48.248336       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'FeatureGatesInitialized' FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AWSEFSDriverVolumeMetrics", "AdminNetworkPolicy", "AlibabaPlatform", "AzureWorkloadIdentity", "BareMetalLoadBalancer", "BuildCSIVolumes", "ChunkSizeMiB", "CloudDualStackNodeIPs", "DisableKubeletCloudCredentialProviders", "GCPLabelsTags", "HardwareSpeed", "IngressControllerLBSubnetsAWS", "KMSv1", "ManagedBootImages", "MetricsServer", "MultiArchInstallAWS", "MultiArchInstallGCP", "NetworkDiagnosticsConfig", "NetworkLiveMigration", "NodeDisruptionPolicy", "OpenShiftPodSecurityAdmission", "PrivateHostedZoneAWS", "SetEIPForNLBIngressController", "VSphereControlPlaneMachineSet", "VSphereDriverConfiguration", "VSphereStaticIPs", "ValidatingAdmissionPolicy"}, Disabled:[]v1.FeatureGateName{"AWSClusterHostedDNS", "AdditionalRoutingCapabilities", "AutomatedEtcdBackup", "BootcNodeManagement", "CSIDriverSharedResource", "ClusterAPIInstall", "ClusterAPIInstallIBMCloud", "ClusterMonitoringConfig", "DNSNameResolver", "DynamicResourceAllocation", "EtcdBackendQuota", "EventedPLEG", "Example", "ExternalOIDC", "GCPClusterHostedDNS", "GatewayAPI", "ImageStreamImportMode", "IngressControllerDynamicConfigurationManager", "InsightsConfig", "InsightsConfigAPI", "InsightsOnDemandDataGather", "InsightsRuntimeExtractor", "MachineAPIMigration", "MachineAPIOperatorDisableMachineHealthCheckController", "MachineAPIProviderOpenStack", "MachineConfigNodes", "ManagedBootImagesAWS", "MaxUnavailableStatefulSet", "MetricsCollectionProfiles", "MixedCPUsAllocation", "MultiArchInstallAzure", "NetworkSegmentation", "NewOLM", "NodeSwap", "OVNObservability", "OnClusterBuild", "PersistentIPsForVirtualization", "PinnedImages", "PlatformOperators", "ProcMountType", "RouteAdvertisements", "RouteExternalCertificate", "ServiceAccountTokenNodeBinding", "SignatureStores", "SigstoreImageVerification", "TranslateStreamCloseWebsocketRequests", "UpgradeStatus", "UserNamespacesPodSecurityStandards", "UserNamespacesSupport", "VSphereMultiNetworks", "VSphereMultiVCenters", "VolumeGroupSnapshot"}}
2024-10-24T13:21:48.248393512Z I1024 13:21:48.248354       1 starter.go:451] FeatureGates initializedenabled[AWSEFSDriverVolumeMetrics AdminNetworkPolicy AlibabaPlatform AzureWorkloadIdentity BareMetalLoadBalancer BuildCSIVolumes ChunkSizeMiB CloudDualStackNodeIPs DisableKubeletCloudCredentialProviders GCPLabelsTags HardwareSpeed IngressControllerLBSubnetsAWS KMSv1 ManagedBootImages MetricsServer MultiArchInstallAWS MultiArchInstallGCP NetworkDiagnosticsConfig NetworkLiveMigration NodeDisruptionPolicy OpenShiftPodSecurityAdmission PrivateHostedZoneAWS SetEIPForNLBIngressController VSphereControlPlaneMachineSet VSphereDriverConfiguration VSphereStaticIPs ValidatingAdmissionPolicy]disabled[AWSClusterHostedDNS AdditionalRoutingCapabilities AutomatedEtcdBackup BootcNodeManagement CSIDriverSharedResource ClusterAPIInstall ClusterAPIInstallIBMCloud ClusterMonitoringConfig DNSNameResolver DynamicResourceAllocation EtcdBackendQuota EventedPLEG Example ExternalOIDC GCPClusterHostedDNS GatewayAPI ImageStreamImportMode IngressControllerDynamicConfigurationManager InsightsConfig InsightsConfigAPI InsightsOnDemandDataGather InsightsRuntimeExtractor MachineAPIMigration MachineAPIOperatorDisableMachineHealthCheckController MachineAPIProviderOpenStack MachineConfigNodes ManagedBootImagesAWS MaxUnavailableStatefulSet MetricsCollectionProfiles MixedCPUsAllocation MultiArchInstallAzure NetworkSegmentation NewOLM NodeSwap OVNObservability OnClusterBuild PersistentIPsForVirtualization PinnedImages PlatformOperators ProcMountType RouteAdvertisements RouteExternalCertificate ServiceAccountTokenNodeBinding SignatureStores SigstoreImageVerification TranslateStreamCloseWebsocketRequests UpgradeStatus UserNamespacesPodSecurityStandards UserNamespacesSupport VSphereMultiNetworks VSphereMultiVCenters VolumeGroupSnapshot]
2024-10-24T13:21:48.248445442Z I1024 13:21:48.248397       1 starter.go:506] waiting for cluster version informer sync...
2024-10-24T13:21:48.264001742Z I1024 13:21:48.263941       1 starter.go:529] Detected available machine API, starting vertical scaling related controllers and informers...
2024-10-24T13:21:48.265589763Z I1024 13:21:48.264363       1 base_controller.go:68] Waiting for caches to sync for ClusterMemberRemovalController
2024-10-24T13:21:48.265589763Z I1024 13:21:48.264376       1 base_controller.go:68] Waiting for caches to sync for MachineDeletionHooksController
2024-10-24T13:21:48.265589763Z I1024 13:21:48.264703       1 base_controller.go:68] Waiting for caches to sync for MissingStaticPodController
2024-10-24T13:21:48.265589763Z I1024 13:21:48.264796       1 base_controller.go:68] Waiting for caches to sync for EtcdEndpointsController
2024-10-24T13:21:48.265589763Z I1024 13:21:48.264848       1 base_controller.go:68] Waiting for caches to sync for etcd
2024-10-24T13:21:48.265589763Z I1024 13:21:48.264992       1 base_controller.go:68] Waiting for caches to sync for NodeController
2024-10-24T13:21:48.265589763Z I1024 13:21:48.264997       1 base_controller.go:68] Waiting for caches to sync for DefragController
2024-10-24T13:21:48.265589763Z I1024 13:21:48.265016       1 base_controller.go:68] Waiting for caches to sync for ConfigObserver
2024-10-24T13:21:48.265589763Z I1024 13:21:48.265031       1 base_controller.go:68] Waiting for caches to sync for ClusterMemberController
2024-10-24T13:21:48.265589763Z I1024 13:21:48.265048       1 base_controller.go:68] Waiting for caches to sync for EtcdMembersController
2024-10-24T13:21:48.265589763Z I1024 13:21:48.265053       1 envvarcontroller.go:236] Starting EnvVarController
2024-10-24T13:21:48.265589763Z I1024 13:21:48.265062       1 base_controller.go:68] Waiting for caches to sync for BootstrapTeardownController
2024-10-24T13:21:48.265589763Z I1024 13:21:48.265067       1 base_controller.go:68] Waiting for caches to sync for etcd-InstallerState
2024-10-24T13:21:48.265589763Z I1024 13:21:48.265076       1 base_controller.go:68] Waiting for caches to sync for UnsupportedConfigOverridesController
2024-10-24T13:21:48.265589763Z I1024 13:21:48.265079       1 base_controller.go:68] Waiting for caches to sync for PruneController
2024-10-24T13:21:48.265589763Z I1024 13:21:48.265087       1 base_controller.go:68] Waiting for caches to sync for ScriptController
2024-10-24T13:21:48.265589763Z I1024 13:21:48.265054       1 base_controller.go:74] Caches are synced for EtcdMembersController 
2024-10-24T13:21:48.265589763Z I1024 13:21:48.265096       1 base_controller.go:68] Waiting for caches to sync for RevisionController
2024-10-24T13:21:48.265589763Z I1024 13:21:48.265099       1 base_controller.go:111] Starting #1 worker of EtcdMembersController controller ...
2024-10-24T13:21:48.265589763Z I1024 13:21:48.265070       1 base_controller.go:68] Waiting for caches to sync for etcd-StaticPodState
2024-10-24T13:21:48.265589763Z I1024 13:21:48.265205       1 base_controller.go:68] Waiting for caches to sync for BackingResourceController-StaticResources
2024-10-24T13:21:48.265589763Z I1024 13:21:48.265222       1 base_controller.go:68] Waiting for caches to sync for UnsupportedConfigOverridesController
2024-10-24T13:21:48.265589763Z I1024 13:21:48.265234       1 base_controller.go:68] Waiting for caches to sync for LoggingSyncer
2024-10-24T13:21:48.265589763Z I1024 13:21:48.265238       1 base_controller.go:68] Waiting for caches to sync for FSyncController
2024-10-24T13:21:48.265589763Z I1024 13:21:48.265243       1 base_controller.go:74] Caches are synced for FSyncController 
2024-10-24T13:21:48.265589763Z I1024 13:21:48.265246       1 base_controller.go:68] Waiting for caches to sync for GuardController
2024-10-24T13:21:48.265589763Z I1024 13:21:48.265248       1 base_controller.go:111] Starting #1 worker of FSyncController controller ...
2024-10-24T13:21:48.265589763Z E1024 13:21:48.265335       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: getting cache client could not retrieve endpoints: node lister not synced"
2024-10-24T13:21:48.265927213Z I1024 13:21:48.265869       1 base_controller.go:68] Waiting for caches to sync for EtcdStaticResources-StaticResources
2024-10-24T13:21:48.265963332Z I1024 13:21:48.265935       1 base_controller.go:68] Waiting for caches to sync for InstallerController
2024-10-24T13:21:48.266005372Z I1024 13:21:48.265974       1 base_controller.go:68] Waiting for caches to sync for TargetConfigController
2024-10-24T13:21:48.266187603Z I1024 13:21:48.266138       1 base_controller.go:68] Waiting for caches to sync for EtcdCertSignerController
2024-10-24T13:21:48.266352562Z I1024 13:21:48.266307       1 base_controller.go:68] Waiting for caches to sync for EtcdCertCleanerController
2024-10-24T13:21:48.266352562Z I1024 13:21:48.266326       1 base_controller.go:74] Caches are synced for EtcdCertCleanerController 
2024-10-24T13:21:48.266352562Z I1024 13:21:48.266332       1 base_controller.go:111] Starting #1 worker of EtcdCertCleanerController controller ...
2024-10-24T13:21:48.266374633Z I1024 13:21:48.266339       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' etcds.operator.openshift.io "cluster" not found
2024-10-24T13:21:48.266814633Z I1024 13:21:48.265069       1 base_controller.go:68] Waiting for caches to sync for StatusSyncer_etcd
2024-10-24T13:21:48.288690743Z E1024 13:21:48.288626       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:21:48.300206194Z E1024 13:21:48.300158       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:21:48.305410264Z E1024 13:21:48.305364       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: getting cache client could not retrieve endpoints: configmaps lister not synced"
2024-10-24T13:21:48.315586505Z E1024 13:21:48.315561       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:21:48.316658965Z I1024 13:21:48.316632       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:21:48.329563615Z I1024 13:21:48.329528       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:21:48.329563615Z I1024 13:21:48.329547       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:21:48.329595795Z I1024 13:21:48.329575       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:21:48.330217975Z I1024 13:21:48.329531       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:21:48.343475905Z E1024 13:21:48.343440       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:21:48.365005516Z I1024 13:21:48.364967       1 base_controller.go:74] Caches are synced for EtcdEndpointsController 
2024-10-24T13:21:48.365005516Z I1024 13:21:48.364983       1 base_controller.go:111] Starting #1 worker of EtcdEndpointsController controller ...
2024-10-24T13:21:48.365005516Z I1024 13:21:48.364984       1 base_controller.go:74] Caches are synced for MachineDeletionHooksController 
2024-10-24T13:21:48.365005516Z I1024 13:21:48.364994       1 base_controller.go:111] Starting #1 worker of MachineDeletionHooksController controller ...
2024-10-24T13:21:48.365138716Z I1024 13:21:48.365116       1 base_controller.go:74] Caches are synced for BootstrapTeardownController 
2024-10-24T13:21:48.365194296Z I1024 13:21:48.365178       1 base_controller.go:111] Starting #1 worker of BootstrapTeardownController controller ...
2024-10-24T13:21:48.365274986Z I1024 13:21:48.365257       1 base_controller.go:74] Caches are synced for LoggingSyncer 
2024-10-24T13:21:48.365317346Z I1024 13:21:48.365114       1 base_controller.go:74] Caches are synced for UnsupportedConfigOverridesController 
2024-10-24T13:21:48.365317346Z I1024 13:21:48.365312       1 base_controller.go:111] Starting #1 worker of UnsupportedConfigOverridesController controller ...
2024-10-24T13:21:48.365483276Z I1024 13:21:48.365391       1 base_controller.go:74] Caches are synced for UnsupportedConfigOverridesController 
2024-10-24T13:21:48.365483276Z I1024 13:21:48.365410       1 base_controller.go:111] Starting #1 worker of UnsupportedConfigOverridesController controller ...
2024-10-24T13:21:48.365483276Z I1024 13:21:48.365113       1 base_controller.go:74] Caches are synced for DefragController 
2024-10-24T13:21:48.365483276Z I1024 13:21:48.365470       1 base_controller.go:111] Starting #1 worker of DefragController controller ...
2024-10-24T13:21:48.365553196Z I1024 13:21:48.365127       1 base_controller.go:74] Caches are synced for PruneController 
2024-10-24T13:21:48.365553196Z I1024 13:21:48.365513       1 base_controller.go:111] Starting #1 worker of PruneController controller ...
2024-10-24T13:21:48.365803176Z I1024 13:21:48.365149       1 base_controller.go:74] Caches are synced for ClusterMemberRemovalController 
2024-10-24T13:21:48.365803176Z I1024 13:21:48.365782       1 base_controller.go:111] Starting #1 worker of ClusterMemberRemovalController controller ...
2024-10-24T13:21:48.365803176Z I1024 13:21:48.365147       1 base_controller.go:74] Caches are synced for NodeController 
2024-10-24T13:21:48.365842437Z I1024 13:21:48.365804       1 base_controller.go:111] Starting #1 worker of NodeController controller ...
2024-10-24T13:21:48.365867877Z I1024 13:21:48.365299       1 base_controller.go:111] Starting #1 worker of LoggingSyncer controller ...
2024-10-24T13:21:48.366489226Z I1024 13:21:48.366429       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:21:48.367537577Z I1024 13:21:48.367496       1 base_controller.go:74] Caches are synced for StatusSyncer_etcd 
2024-10-24T13:21:48.367537577Z I1024 13:21:48.367510       1 base_controller.go:111] Starting #1 worker of StatusSyncer_etcd controller ...
2024-10-24T13:21:48.368285256Z I1024 13:21:48.368255       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:21:48Z","message":"BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdEndpointsDegraded: failed to get member list: context deadline exceeded\nEtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type","reason":"BootstrapTeardown_Error::EtcdEndpoints_ErrorUpdatingEtcdEndpoints::EtcdMembersController_ErrorUpdatingReportEtcdMembers::EtcdStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:21:48.389276537Z I1024 13:21:48.389203       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded changed from False to True ("BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdEndpointsDegraded: failed to get member list: context deadline exceeded\nEtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type")
2024-10-24T13:21:48.390945397Z I1024 13:21:48.390815       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:21:48.390945397Z I1024 13:21:48.390874       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:21:48.399159887Z E1024 13:21:48.399132       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:21:48.413140938Z I1024 13:21:48.412986       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:21:48.413682608Z I1024 13:21:48.413640       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:21:48Z","message":"BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type","reason":"BootstrapTeardown_Error::EtcdMembersController_ErrorUpdatingReportEtcdMembers::EtcdStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:21:48.430387679Z I1024 13:21:48.430350       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdEndpointsDegraded: failed to get member list: context deadline exceeded\nEtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type" to "BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type"
2024-10-24T13:21:48.482655141Z I1024 13:21:48.482597       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:48.484512441Z E1024 13:21:48.484463       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:21:48.650650508Z E1024 13:21:48.650599       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:21:48.667556048Z I1024 13:21:48.667518       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:48.870347736Z I1024 13:21:48.870296       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:48.965190459Z I1024 13:21:48.965120       1 base_controller.go:74] Caches are synced for ClusterMemberController 
2024-10-24T13:21:48.965190459Z I1024 13:21:48.965146       1 base_controller.go:111] Starting #1 worker of ClusterMemberController controller ...
2024-10-24T13:21:48.965283839Z I1024 13:21:48.965229       1 base_controller.go:74] Caches are synced for etcd-StaticPodState 
2024-10-24T13:21:48.965366859Z I1024 13:21:48.965348       1 base_controller.go:111] Starting #1 worker of etcd-StaticPodState controller ...
2024-10-24T13:21:48.965424229Z I1024 13:21:48.965348       1 base_controller.go:74] Caches are synced for MissingStaticPodController 
2024-10-24T13:21:48.965464760Z I1024 13:21:48.965420       1 base_controller.go:111] Starting #1 worker of MissingStaticPodController controller ...
2024-10-24T13:21:48.965475640Z I1024 13:21:48.965330       1 base_controller.go:74] Caches are synced for GuardController 
2024-10-24T13:21:48.965486540Z I1024 13:21:48.965478       1 base_controller.go:111] Starting #1 worker of GuardController controller ...
2024-10-24T13:21:48.965532840Z I1024 13:21:48.965312       1 base_controller.go:74] Caches are synced for etcd-InstallerState 
2024-10-24T13:21:48.965596869Z I1024 13:21:48.965581       1 base_controller.go:111] Starting #1 worker of etcd-InstallerState controller ...
2024-10-24T13:21:48.978251650Z E1024 13:21:48.978204       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:21:48.979571390Z I1024 13:21:48.979511       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:21:48.979646500Z I1024 13:21:48.979549       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T13:21:49.069499724Z I1024 13:21:49.069449       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:49.267454111Z I1024 13:21:49.267412       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:49.464825779Z I1024 13:21:49.464763       1 request.go:700] Waited for 1.196661676s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets?limit=500&resourceVersion=0
2024-10-24T13:21:49.479849089Z I1024 13:21:49.479780       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:49.565210243Z I1024 13:21:49.565163       1 base_controller.go:74] Caches are synced for etcd 
2024-10-24T13:21:49.565210243Z I1024 13:21:49.565188       1 base_controller.go:111] Starting #1 worker of etcd controller ...
2024-10-24T13:21:49.565280443Z I1024 13:21:49.565251       1 base_controller.go:74] Caches are synced for RevisionController 
2024-10-24T13:21:49.565280443Z I1024 13:21:49.565262       1 base_controller.go:111] Starting #1 worker of RevisionController controller ...
2024-10-24T13:21:49.566476893Z I1024 13:21:49.566426       1 base_controller.go:74] Caches are synced for InstallerController 
2024-10-24T13:21:49.566586973Z I1024 13:21:49.566566       1 base_controller.go:111] Starting #1 worker of InstallerController controller ...
2024-10-24T13:21:49.566773393Z I1024 13:21:49.566451       1 base_controller.go:74] Caches are synced for EtcdCertSignerController 
2024-10-24T13:21:49.566773393Z I1024 13:21:49.566741       1 base_controller.go:111] Starting #1 worker of EtcdCertSignerController controller ...
2024-10-24T13:21:49.590460494Z I1024 13:21:49.590430       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:21:49.624490255Z E1024 13:21:49.624420       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:21:49.667426777Z I1024 13:21:49.667353       1 reflector.go:368] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:49.766149640Z I1024 13:21:49.766078       1 base_controller.go:74] Caches are synced for ScriptController 
2024-10-24T13:21:49.766149640Z I1024 13:21:49.766104       1 base_controller.go:74] Caches are synced for ConfigObserver 
2024-10-24T13:21:49.766149640Z I1024 13:21:49.766110       1 base_controller.go:111] Starting #1 worker of ScriptController controller ...
2024-10-24T13:21:49.766149640Z I1024 13:21:49.766112       1 base_controller.go:74] Caches are synced for TargetConfigController 
2024-10-24T13:21:49.766149640Z I1024 13:21:49.766129       1 base_controller.go:111] Starting #1 worker of TargetConfigController controller ...
2024-10-24T13:21:49.766149640Z I1024 13:21:49.766088       1 envvarcontroller.go:242] caches synced
2024-10-24T13:21:49.766227370Z I1024 13:21:49.766112       1 base_controller.go:111] Starting #1 worker of ConfigObserver controller ...
2024-10-24T13:21:49.766227370Z E1024 13:21:49.766211       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: TargetConfigController missing env var values"
2024-10-24T13:21:49.791922342Z E1024 13:21:49.791869       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": missing env var values"
2024-10-24T13:21:49.793139441Z I1024 13:21:49.793115       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:21:49.793295252Z I1024 13:21:49.793269       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:21:48Z","message":"BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nScriptControllerDegraded: \"configmap/etcd-pod\": missing env var values\nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type","reason":"BootstrapTeardown_Error::EtcdMembersController_ErrorUpdatingReportEtcdMembers::EtcdStaticResources_SyncError::ScriptController_Error::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:21:49.811847482Z I1024 13:21:49.810939       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type" to "BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nScriptControllerDegraded: \"configmap/etcd-pod\": missing env var values\nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type"
2024-10-24T13:21:49.828443083Z I1024 13:21:49.828405       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:21:49.867424444Z I1024 13:21:49.867367       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:21:49.966154788Z I1024 13:21:49.966095       1 base_controller.go:74] Caches are synced for EtcdStaticResources-StaticResources 
2024-10-24T13:21:49.966154788Z I1024 13:21:49.966118       1 base_controller.go:111] Starting #1 worker of EtcdStaticResources-StaticResources controller ...
2024-10-24T13:21:49.966246518Z I1024 13:21:49.966191       1 base_controller.go:74] Caches are synced for BackingResourceController-StaticResources 
2024-10-24T13:21:49.966246518Z I1024 13:21:49.966225       1 base_controller.go:111] Starting #1 worker of BackingResourceController-StaticResources controller ...
2024-10-24T13:21:50.464888667Z I1024 13:21:50.464833       1 request.go:700] Waited for 1.498434897s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:21:50.909731404Z E1024 13:21:50.909685       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:21:51.105259782Z I1024 13:21:51.105111       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:21:51.105982872Z I1024 13:21:51.105945       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:21:48Z","message":"BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type","reason":"BootstrapTeardown_Error::EtcdMembersController_ErrorUpdatingReportEtcdMembers::EtcdStaticResources_SyncError::TargetConfigController_SynchronizationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:21:51.127274493Z I1024 13:21:51.127210       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nScriptControllerDegraded: \"configmap/etcd-pod\": missing env var values\nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type" to "BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type"
2024-10-24T13:21:51.142030584Z I1024 13:21:51.141931       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:21:51.464914566Z I1024 13:21:51.464853       1 request.go:700] Waited for 1.498165148s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:21:52.228731835Z I1024 13:21:52.228665       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:21:52.299838738Z I1024 13:21:52.299791       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:21:48Z","message":"BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: ","reason":"BootstrapTeardown_Error::EtcdMembersController_ErrorUpdatingReportEtcdMembers::EtcdStaticResources_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:21:52.300386098Z I1024 13:21:52.300362       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:21:52.316508308Z I1024 13:21:52.313534       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: \nTargetConfigControllerDegraded: \"configmap/etcd-pod\": rpc error: code = Unknown desc = malformed header: missing HTTP content-type" to "BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: "
2024-10-24T13:21:52.346857360Z I1024 13:21:52.346806       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:21:52.465476144Z I1024 13:21:52.465429       1 request.go:700] Waited for 1.362304102s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:21:53.476040233Z E1024 13:21:53.475976       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:21:53.478991593Z I1024 13:21:53.478938       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:21:53.478991593Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:21:53.478991593Z  CurrentRevision: (int32) 12,
2024-10-24T13:21:53.478991593Z  TargetRevision: (int32) 0,
2024-10-24T13:21:53.478991593Z  LastFailedRevision: (int32) 5,
2024-10-24T13:21:53.478991593Z  LastFailedTime: (*v1.Time)(0xc002c222d0)(2024-10-24 13:11:34 +0000 UTC),
2024-10-24T13:21:53.478991593Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:21:53.478991593Z  LastFailedCount: (int) 1,
2024-10-24T13:21:53.478991593Z  LastFallbackCount: (int) 0,
2024-10-24T13:21:53.478991593Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:21:53.478991593Z   (string) (len=2059) "installer:  172.30.0.1:443: connect: connection refused\nW1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:21:53.478991593Z  }
2024-10-24T13:21:53.478991593Z }
2024-10-24T13:21:53.478991593Z  because static pod is ready
2024-10-24T13:21:53.509540084Z I1024 13:21:53.509460       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 1 to 12 because static pod is ready
2024-10-24T13:21:53.512614164Z I1024 13:21:53.512552       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:21:53.513606394Z I1024 13:21:53.513555       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:21:48Z","message":"BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: ","reason":"BootstrapTeardown_Error::EtcdMembersController_ErrorUpdatingReportEtcdMembers::EtcdStaticResources_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:21:53.533126385Z I1024 13:21:53.532809       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12" to "NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12",Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 12\nEtcdMembersAvailable: 4 members are available" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12\nEtcdMembersAvailable: 4 members are available"
2024-10-24T13:21:53.564299886Z I1024 13:21:53.564206       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:21:53.665044860Z I1024 13:21:53.664976       1 request.go:700] Waited for 1.366078312s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-10-24T13:21:53.956359881Z I1024 13:21:53.955431       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:21:54.062844515Z I1024 13:21:54.062725       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:21:54.646145368Z I1024 13:21:54.646092       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:21:54.665349428Z I1024 13:21:54.665276       1 request.go:700] Waited for 1.371844122s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:21:54.704140610Z I1024 13:21:54.704097       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:21:54.784119373Z I1024 13:21:54.783909       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:21:55.503411920Z W1024 13:21:55.503334       1 dynamic_operator_client.go:346] .status.conditions["EtcdStaticResourcesDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:21:55.530606821Z I1024 13:21:55.530541       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:21:48Z","message":"BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced","reason":"BootstrapTeardown_Error::EtcdMembersController_ErrorUpdatingReportEtcdMembers","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:21:55.533228311Z I1024 13:21:55.533176       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:21:55.547455512Z I1024 13:21:55.547381       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced\nEtcdStaticResourcesDegraded: \"etcd/ns.yaml\" (string): the server was unable to return a response in the time allotted, but may still be processing the request (get namespaces openshift-etcd)\nEtcdStaticResourcesDegraded: " to "BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced"
2024-10-24T13:21:55.586476244Z I1024 13:21:55.586405       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:21:55.865470374Z I1024 13:21:55.865390       1 request.go:700] Waited for 1.374053922s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:21:56.358690243Z I1024 13:21:56.358616       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:21:56.491804758Z I1024 13:21:56.491730       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:21:57.064951890Z I1024 13:21:57.064887       1 request.go:700] Waited for 1.361814702s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:21:57.373313962Z I1024 13:21:57.373253       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:21:57.438123084Z I1024 13:21:57.438029       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:21:58.601707019Z E1024 13:21:58.601645       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host"
2024-10-24T13:22:00.684335669Z I1024 13:22:00.684282       1 installer_controller.go:534] node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 3 is the oldest and needs new revision 12
2024-10-24T13:22:00.684335669Z I1024 13:22:00.684327       1 installer_controller.go:542] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:22:00.684335669Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:22:00.684335669Z  CurrentRevision: (int32) 3,
2024-10-24T13:22:00.684335669Z  TargetRevision: (int32) 12,
2024-10-24T13:22:00.684335669Z  LastFailedRevision: (int32) 0,
2024-10-24T13:22:00.684335669Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:22:00.684335669Z  LastFailedReason: (string) "",
2024-10-24T13:22:00.684335669Z  LastFailedCount: (int) 0,
2024-10-24T13:22:00.684335669Z  LastFallbackCount: (int) 0,
2024-10-24T13:22:00.684335669Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:22:00.684335669Z }
2024-10-24T13:22:00.735808641Z I1024 13:22:00.735744       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:00.741111581Z I1024 13:22:00.741047       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 3 to 12 because node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 3 is the oldest
2024-10-24T13:22:00.816415664Z I1024 13:22:00.816355       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:22:01.864717404Z I1024 13:22:01.864650       1 request.go:700] Waited for 1.127745623s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-10-24T13:22:02.624229213Z I1024 13:22:02.624153       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:22:03.183356395Z I1024 13:22:03.183189       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-etcd because it was missing
2024-10-24T13:22:03.267655368Z I1024 13:22:03.264583       1 request.go:700] Waited for 1.117755693s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:22:03.346974911Z I1024 13:22:03.346882       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:22:03.388346253Z I1024 13:22:03.388305       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:22:03.444841565Z I1024 13:22:03.444394       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:22:04.265026036Z I1024 13:22:04.264967       1 request.go:700] Waited for 1.083140521s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-10-24T13:22:04.473534654Z I1024 13:22:04.473467       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 12, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:22:04.943204522Z I1024 13:22:04.943122       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:22:04.977993244Z I1024 13:22:04.977939       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:22:05.465677652Z I1024 13:22:05.465235       1 request.go:700] Waited for 1.391060013s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-10-24T13:22:06.665128478Z I1024 13:22:06.665065       1 request.go:700] Waited for 1.183643046s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-10-24T13:22:07.072074513Z I1024 13:22:07.072005       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 12, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:22:07.864972514Z I1024 13:22:07.864910       1 request.go:700] Waited for 1.190860466s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-10-24T13:22:08.850931432Z E1024 13:22:08.850855       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp 172.30.206.161:9091: connect: connection refused"
2024-10-24T13:22:08.892070943Z I1024 13:22:08.891999       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 12, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:22:11.645715209Z I1024 13:22:11.645646       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:22:13.057711293Z I1024 13:22:13.057640       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:22:13.114407415Z I1024 13:22:13.114336       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:22:18.326906394Z E1024 13:22:18.326831       1 health.go:115] health check for member (etcd-bootstrap) failed: err(context deadline exceeded)
2024-10-24T13:22:18.327125474Z E1024 13:22:18.327100       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: etcd-bootstrap, took=29.983322448s, err=health check failed: context deadline exceeded
2024-10-24T13:22:18.327458304Z E1024 13:22:18.327431       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:22:18.328967814Z E1024 13:22:18.328921       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:22:18.336517914Z E1024 13:22:18.336467       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:22:18.358498225Z E1024 13:22:18.358443       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:22:18.381428796Z E1024 13:22:18.381366       1 health.go:115] health check for member (etcd-bootstrap) failed: err(context deadline exceeded)
2024-10-24T13:22:18.382516066Z W1024 13:22:18.382361       1 etcdcli.go:351] UnhealthyEtcdMember found: [etcd-bootstrap]
2024-10-24T13:22:18.384017166Z W1024 13:22:18.383816       1 bootstrap_teardown_controller.go:144] Removing bootstrap member [a48f107742a8605c]
2024-10-24T13:22:18.384800026Z I1024 13:22:18.384541       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:18.385482496Z E1024 13:22:18.385458       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:22:18.391179437Z I1024 13:22:18.391083       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:21:48Z","message":"BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced\nEtcdMembersDegraded: 3 of 4 members are available, etcd-bootstrap is unhealthy","reason":"BootstrapTeardown_Error::EtcdMembersController_ErrorUpdatingReportEtcdMembers::EtcdMembers_UnhealthyMembers","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:22:18.403341417Z E1024 13:22:18.403288       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:22:18.409945748Z I1024 13:22:18.409917       1 bootstrap_teardown_controller.go:151] Successfully removed bootstrap member [a48f107742a8605c]
2024-10-24T13:22:18.410106107Z I1024 13:22:18.410049       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MemberRemove' removed member with ID: 11857714448295288924
2024-10-24T13:22:18.422789918Z I1024 13:22:18.422714       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced" to "BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced\nEtcdMembersDegraded: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:22:18.439308249Z E1024 13:22:18.436374       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:22:18.439308249Z I1024 13:22:18.436938       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:21:48Z","message":"BootstrapTeardownDegraded: error while updating NotEnoughEtcdMembers: client rate limiter Wait returned an error: context deadline exceeded\nEtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced\nEtcdMembersDegraded: 3 of 4 members are available, etcd-bootstrap is unhealthy","reason":"BootstrapTeardown_Error::EtcdMembersController_ErrorUpdatingReportEtcdMembers::EtcdMembers_UnhealthyMembers","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12\nEtcdMembersAvailable: 3 of 4 members are available, etcd-bootstrap is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:22:18.439308249Z I1024 13:22:18.437733       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:18.465731600Z I1024 13:22:18.465641       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12\nEtcdMembersAvailable: 4 members are available" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12\nEtcdMembersAvailable: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:22:18.471578330Z I1024 13:22:18.471531       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:22:18.498816351Z I1024 13:22:18.498773       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:18.499891801Z E1024 13:22:18.499833       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:22:18.508636481Z I1024 13:22:18.508599       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:22:18.540278332Z I1024 13:22:18.540212       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:22:18.550937023Z E1024 13:22:18.550879       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:22:18.551425033Z I1024 13:22:18.551393       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"EtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced\nNodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 3 of 4 members are available, etcd-bootstrap is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12\nEtcdMembersAvailable: 3 of 4 members are available, etcd-bootstrap is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:22:18.552912003Z I1024 13:22:18.552869       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:18.566253374Z E1024 13:22:18.566201       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:22:18.567007624Z I1024 13:22:18.566958       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded changed from True to False ("EtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced\nNodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 3 of 4 members are available, etcd-bootstrap is unhealthy")
2024-10-24T13:22:18.587222594Z I1024 13:22:18.587164       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 12, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:22:18.755155661Z I1024 13:22:18.755093       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:18.755404770Z E1024 13:22:18.755349       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:22:18.974734849Z E1024 13:22:18.974667       1 health.go:115] health check for member (etcd-bootstrap) failed: err(context deadline exceeded)
2024-10-24T13:22:18.975002119Z W1024 13:22:18.974941       1 etcdcli.go:351] UnhealthyEtcdMember found: [etcd-bootstrap]
2024-10-24T13:22:19.145397226Z I1024 13:22:19.145317       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:22:19.366255424Z E1024 13:22:19.366191       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:22:19.371189154Z I1024 13:22:19.371151       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:22:19.371866134Z I1024 13:22:19.371844       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 3 of 4 members are available, etcd-bootstrap is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12\nEtcdMembersAvailable: 3 of 4 members are available, etcd-bootstrap is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:22:19.388393775Z I1024 13:22:19.388329       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "EtcdMembersControllerDegraded: getting cache client could not retrieve endpoints: configmaps lister not synced\nNodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 3 of 4 members are available, etcd-bootstrap is unhealthy" to "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:22:19.388728995Z I1024 13:22:19.388685       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 3 of 4 members are available, etcd-bootstrap is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12\nEtcdMembersAvailable: 3 of 4 members are available, etcd-bootstrap is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:22:19.401895255Z E1024 13:22:19.401828       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:22:19.544439801Z I1024 13:22:19.544369       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:22:19.580694802Z I1024 13:22:19.580647       1 request.go:700] Waited for 1.067144021s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa
2024-10-24T13:22:20.001806038Z I1024 13:22:20.001712       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:22:20.580964010Z I1024 13:22:20.580906       1 request.go:700] Waited for 1.191248786s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-10-24T13:22:20.989268496Z I1024 13:22:20.989212       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 12, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:22:21.128797622Z E1024 13:22:21.128729       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:22:21.581001169Z I1024 13:22:21.580942       1 request.go:700] Waited for 1.187528986s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:22:21.662798042Z I1024 13:22:21.662716       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:22:23.192123591Z I1024 13:22:23.192062       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 12, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:22:29.338744376Z E1024 13:22:29.338691       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: Post \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query\": dial tcp 172.30.206.161:9091: connect: connection refused"
2024-10-24T13:22:31.944907466Z I1024 13:22:31.944857       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:22:35.515567182Z I1024 13:22:35.515519       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 12, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:22:37.716145137Z I1024 13:22:37.716092       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 12, but has not made progress because waiting for static pod of revision 12, found 3
2024-10-24T13:22:41.610446976Z E1024 13:22:41.610380       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, etcd-bootstrap is unhealthy"
2024-10-24T13:22:43.248453719Z I1024 13:22:43.248384       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:22:43.719383997Z I1024 13:22:43.719324       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:22:47.557799464Z I1024 13:22:47.557705       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 12, but has not made progress because waiting for static pod of revision 12, found 3
2024-10-24T13:22:48.265955631Z E1024 13:22:48.265890       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: etcd-bootstrap, took=29.983322448s, err=health check failed: context deadline exceeded
2024-10-24T13:22:48.285544742Z E1024 13:22:48.285506       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client_error: client error: 401"
2024-10-24T13:22:49.597498462Z I1024 13:22:49.597442       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:23:02.420061219Z I1024 13:23:02.419994       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:23:05.498114320Z E1024 13:23:05.498040       1 health.go:115] health check for member (ci-op-2fcpj5j6-f6035-2lklf-master-0) failed: err(context deadline exceeded)
2024-10-24T13:23:05.498364660Z W1024 13:23:05.498234       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-2fcpj5j6-f6035-2lklf-master-0]
2024-10-24T13:23:06.979296395Z I1024 13:23:06.979224       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 12, but has not made progress because static pod is pending
2024-10-24T13:23:07.970533247Z I1024 13:23:07.970472       1 request.go:700] Waited for 1.162155868s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:23:09.979461944Z I1024 13:23:09.979403       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 12, but has not made progress because static pod is pending
2024-10-24T13:23:10.320559042Z E1024 13:23:10.320504       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client_error: client error: 401"
2024-10-24T13:23:12.179724535Z I1024 13:23:12.179657       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 12, but has not made progress because static pod is pending
2024-10-24T13:23:12.549582444Z I1024 13:23:12.549488       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:23:14.242899293Z I1024 13:23:14.242840       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:23:22.674466937Z I1024 13:23:22.674389       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:23:35.503955614Z E1024 13:23:35.503867       1 health.go:115] health check for member (ci-op-2fcpj5j6-f6035-2lklf-master-0) failed: err(context deadline exceeded)
2024-10-24T13:23:35.504086303Z W1024 13:23:35.504041       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-2fcpj5j6-f6035-2lklf-master-0]
2024-10-24T13:23:48.281743930Z E1024 13:23:48.281674       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client_error: client error: 401"
2024-10-24T13:23:48.377217582Z E1024 13:23:48.377168       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:48.377266792Z I1024 13:23:48.377243       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:48.378062432Z E1024 13:23:48.378034       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.18016650a1555b11  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-10-24 13:23:48.377123601 +0000 UTC m=+341.153976244,LastTimestamp:2024-10-24 13:23:48.377123601 +0000 UTC m=+341.153976244,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-10-24T13:23:48.394098952Z E1024 13:23:48.394058       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:48.394127562Z I1024 13:23:48.394094       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:48.415136982Z E1024 13:23:48.415091       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:48.415197722Z I1024 13:23:48.415158       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:48.447683123Z E1024 13:23:48.447640       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:48.447735243Z I1024 13:23:48.447677       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:48.498788925Z E1024 13:23:48.498711       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:48.498831685Z I1024 13:23:48.498795       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:48.591372787Z E1024 13:23:48.591300       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:48.591372787Z I1024 13:23:48.591336       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:48.762329011Z E1024 13:23:48.762272       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:48.762403920Z I1024 13:23:48.762326       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:48.967795195Z E1024 13:23:48.967714       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:48.971134566Z E1024 13:23:48.971095       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:48.975207736Z E1024 13:23:48.975163       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:48.981473446Z E1024 13:23:48.981407       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:48.987460696Z E1024 13:23:48.987392       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:49.094153318Z E1024 13:23:49.094040       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:49.094153318Z I1024 13:23:49.094083       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:49.367574564Z E1024 13:23:49.367503       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:49.568044999Z E1024 13:23:49.567983       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:49.570264229Z E1024 13:23:49.570199       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:49.575331839Z E1024 13:23:49.575285       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:49.587382219Z E1024 13:23:49.587323       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:49.609682050Z E1024 13:23:49.609621       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:49.652625711Z E1024 13:23:49.652568       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:49.734699843Z E1024 13:23:49.734650       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:49.744970383Z E1024 13:23:49.744925       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:49.745003283Z I1024 13:23:49.744967       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:49.767510664Z E1024 13:23:49.767466       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:49.897736177Z E1024 13:23:49.897676       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:49.936906538Z E1024 13:23:49.936839       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.18016650a1555b11  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-10-24 13:23:48.377123601 +0000 UTC m=+341.153976244,LastTimestamp:2024-10-24 13:23:48.377123601 +0000 UTC m=+341.153976244,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-10-24T13:23:50.169086573Z E1024 13:23:50.169013       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:50.169142733Z I1024 13:23:50.169072       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:50.170013223Z E1024 13:23:50.169964       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.180166510c22b409  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-10-24 13:23:50.168966153 +0000 UTC m=+342.945818815,LastTimestamp:2024-10-24 13:23:50.168966153 +0000 UTC m=+342.945818815,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-10-24T13:23:50.220188834Z E1024 13:23:50.220133       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:50.568421342Z E1024 13:23:50.568359       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:50.770504767Z E1024 13:23:50.770451       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:50.863155049Z E1024 13:23:50.863099       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:51.036715023Z E1024 13:23:51.036645       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:51.036715023Z I1024 13:23:51.036688       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:51.167275936Z I1024 13:23:51.167235       1 request.go:700] Waited for 1.199390577s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:23:51.368722561Z E1024 13:23:51.368665       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:51.368797301Z I1024 13:23:51.368712       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:51.569964695Z E1024 13:23:51.569894       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:51.767871840Z E1024 13:23:51.767814       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:51.969956295Z E1024 13:23:51.969900       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:52.145896279Z E1024 13:23:52.145837       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:52.367620814Z I1024 13:23:52.367574       1 request.go:700] Waited for 1.199642918s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:23:52.369761234Z E1024 13:23:52.369703       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:52.569824848Z E1024 13:23:52.569767       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:52.569869428Z I1024 13:23:52.569814       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:52.579264889Z E1024 13:23:52.579207       1 health.go:115] health check for member (ci-op-2fcpj5j6-f6035-2lklf-master-0) failed: err(context deadline exceeded)
2024-10-24T13:23:52.579474809Z E1024 13:23:52.579415       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy"
2024-10-24T13:23:52.579474809Z E1024 13:23:52.579460       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-2fcpj5j6-f6035-2lklf-master-0, took=29.995585664s, err=health check failed: context deadline exceeded
2024-10-24T13:23:52.581647278Z I1024 13:23:52.581604       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:52.583159599Z I1024 13:23:52.583130       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:52.583231979Z E1024 13:23:52.583158       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.180166519bed17ab  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-10-24 13:23:52.581371819 +0000 UTC m=+345.358224460,LastTimestamp:2024-10-24 13:23:52.581371819 +0000 UTC m=+345.358224460,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-10-24T13:23:52.584834289Z E1024 13:23:52.584794       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:52.584867089Z I1024 13:23:52.584838       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:52.591964779Z E1024 13:23:52.591920       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-2fcpj5j6-f6035-2lklf-master-0, took=29.995585664s, err=health check failed: context deadline exceeded
2024-10-24T13:23:52.593286909Z I1024 13:23:52.593242       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:52.594728679Z I1024 13:23:52.594694       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:52.595739669Z E1024 13:23:52.595701       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:52.595784579Z I1024 13:23:52.595732       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:52.607844759Z E1024 13:23:52.607817       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-2fcpj5j6-f6035-2lklf-master-0, took=29.995585664s, err=health check failed: context deadline exceeded
2024-10-24T13:23:52.609175679Z I1024 13:23:52.609131       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:52.610798879Z I1024 13:23:52.610696       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:52.611874719Z E1024 13:23:52.611842       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:52.611931259Z I1024 13:23:52.611884       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:52.633282090Z E1024 13:23:52.633218       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-2fcpj5j6-f6035-2lklf-master-0, took=29.995585664s, err=health check failed: context deadline exceeded
2024-10-24T13:23:52.770860033Z I1024 13:23:52.770796       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:52.970863218Z I1024 13:23:52.970790       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:53.167141452Z E1024 13:23:53.167075       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:53.170024372Z E1024 13:23:53.169983       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:53.370106617Z E1024 13:23:53.370033       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:53.370106617Z I1024 13:23:53.370071       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:53.412263728Z E1024 13:23:53.412218       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-2fcpj5j6-f6035-2lklf-master-0, took=29.995585664s, err=health check failed: context deadline exceeded
2024-10-24T13:23:53.566628341Z I1024 13:23:53.566558       1 request.go:700] Waited for 1.155296546s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:23:53.570208742Z I1024 13:23:53.570139       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:53.770208436Z I1024 13:23:53.770146       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:53.969760381Z E1024 13:23:53.969690       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:53.969822791Z I1024 13:23:53.969732       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:54.170365615Z E1024 13:23:54.170312       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:54.170365615Z I1024 13:23:54.170348       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:54.370597970Z E1024 13:23:54.370534       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:54.370597970Z I1024 13:23:54.370574       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:54.452158072Z E1024 13:23:54.452098       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-2fcpj5j6-f6035-2lklf-master-0, took=29.995585664s, err=health check failed: context deadline exceeded
2024-10-24T13:23:54.570439335Z E1024 13:23:54.570374       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:54.708047768Z E1024 13:23:54.707977       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:54.767551409Z E1024 13:23:54.767492       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:54.770214849Z E1024 13:23:54.770166       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:54.970870534Z E1024 13:23:54.970813       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:55.170112528Z I1024 13:23:55.170040       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:55.370909913Z E1024 13:23:55.370857       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:55.370950403Z I1024 13:23:55.370899       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:55.392242004Z E1024 13:23:55.392194       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.180166519bed17ab  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-10-24 13:23:52.581371819 +0000 UTC m=+345.358224460,LastTimestamp:2024-10-24 13:23:52.581371819 +0000 UTC m=+345.358224460,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-10-24T13:23:55.569829088Z E1024 13:23:55.569780       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:55.770617372Z I1024 13:23:55.770539       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:55.918294136Z E1024 13:23:55.918243       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.180166510c22b409  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-10-24 13:23:50.168966153 +0000 UTC m=+342.945818815,LastTimestamp:2024-10-24 13:23:50.168966153 +0000 UTC m=+342.945818815,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-10-24T13:23:55.970112617Z E1024 13:23:55.970054       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:56.170714752Z E1024 13:23:56.170649       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:56.170714752Z I1024 13:23:56.170691       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:56.332402045Z E1024 13:23:56.332336       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-2fcpj5j6-f6035-2lklf-master-0, took=29.995585664s, err=health check failed: context deadline exceeded
2024-10-24T13:23:56.370767746Z E1024 13:23:56.370682       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:56.570784401Z E1024 13:23:56.570720       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:56.570846911Z I1024 13:23:56.570783       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:56.768040655Z E1024 13:23:56.767982       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:56.770844566Z I1024 13:23:56.770798       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:56.970723960Z I1024 13:23:56.970665       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:57.170689804Z E1024 13:23:57.170629       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:57.369915429Z E1024 13:23:57.369855       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:57.369915429Z I1024 13:23:57.369888       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:57.691767527Z E1024 13:23:57.691670       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-2fcpj5j6-f6035-2lklf-master-0, took=29.995585664s, err=health check failed: context deadline exceeded
2024-10-24T13:23:57.693583797Z I1024 13:23:57.693512       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:57.766964978Z I1024 13:23:57.766909       1 request.go:700] Waited for 1.034286714s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:23:57.770734338Z I1024 13:23:57.770682       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:57.970836983Z E1024 13:23:57.970776       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:57.970836983Z I1024 13:23:57.970794       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:58.170778798Z E1024 13:23:58.170702       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:58.170778798Z I1024 13:23:58.170739       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:58.286862081Z E1024 13:23:58.286800       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:23:58.287483041Z E1024 13:23:58.287428       1 leaderelection.go:436] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:58.370623692Z E1024 13:23:58.370567       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:58.570085297Z E1024 13:23:58.570020       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:58.770813082Z E1024 13:23:58.770727       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:58.812878523Z E1024 13:23:58.812807       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-2fcpj5j6-f6035-2lklf-master-0, took=29.995585664s, err=health check failed: context deadline exceeded
2024-10-24T13:23:58.970928496Z E1024 13:23:58.970871       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:59.170495041Z E1024 13:23:59.170443       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:59.170495041Z I1024 13:23:59.170479       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:59.370300545Z I1024 13:23:59.370252       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:59.570005240Z E1024 13:23:59.569958       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:59.570005240Z I1024 13:23:59.569991       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:23:59.770351165Z E1024 13:23:59.770298       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:23:59.830887806Z E1024 13:23:59.830837       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:23:59.938230329Z E1024 13:23:59.938162       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.18016650a1555b11  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-10-24 13:23:48.377123601 +0000 UTC m=+341.153976244,LastTimestamp:2024-10-24 13:23:48.377123601 +0000 UTC m=+341.153976244,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-10-24T13:23:59.970796909Z I1024 13:23:59.970744       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:00.168022924Z E1024 13:24:00.167970       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:00.169849544Z E1024 13:24:00.169810       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:00.370191899Z E1024 13:24:00.370123       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:00.370243628Z I1024 13:24:00.370178       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:00.570936303Z E1024 13:24:00.570884       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:00.770583258Z E1024 13:24:00.770529       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:00.770583258Z I1024 13:24:00.770563       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:01.171125467Z E1024 13:24:01.171060       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:01.651650898Z E1024 13:24:01.651582       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-2fcpj5j6-f6035-2lklf-master-0, took=29.995585664s, err=health check failed: context deadline exceeded
2024-10-24T13:24:01.653073529Z I1024 13:24:01.653030       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:01.654210278Z I1024 13:24:01.654152       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:01.655276058Z E1024 13:24:01.655243       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:01.655304289Z I1024 13:24:01.655273       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:01.770983001Z E1024 13:24:01.770915       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:01.971334646Z E1024 13:24:01.971278       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:02.768348664Z E1024 13:24:02.768290       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:02.768348664Z I1024 13:24:02.768324       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:02.968935528Z E1024 13:24:02.968885       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:03.169555383Z E1024 13:24:03.169491       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:03.370818258Z E1024 13:24:03.370725       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:04.216707297Z E1024 13:24:04.216631       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-2fcpj5j6-f6035-2lklf-master-0, took=29.995585664s, err=health check failed: context deadline exceeded
2024-10-24T13:24:04.218316627Z I1024 13:24:04.218272       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:04.219838058Z I1024 13:24:04.219801       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:04.220865757Z E1024 13:24:04.220849       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:04.220888587Z I1024 13:24:04.220874       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:04.369621101Z E1024 13:24:04.369344       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:04.571672446Z E1024 13:24:04.571597       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:05.368958324Z E1024 13:24:05.368902       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:05.394232415Z E1024 13:24:05.394185       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.180166519bed17ab  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-10-24 13:23:52.581371819 +0000 UTC m=+345.358224460,LastTimestamp:2024-10-24 13:23:52.581371819 +0000 UTC m=+345.358224460,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-10-24T13:24:05.512124167Z E1024 13:24:05.512041       1 health.go:115] health check for member (ci-op-2fcpj5j6-f6035-2lklf-master-0) failed: err(context deadline exceeded)
2024-10-24T13:24:05.512408378Z W1024 13:24:05.512364       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-2fcpj5j6-f6035-2lklf-master-0]
2024-10-24T13:24:05.573325138Z E1024 13:24:05.573266       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:05.919976367Z E1024 13:24:05.919919       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.180166510c22b409  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-10-24 13:23:50.168966153 +0000 UTC m=+342.945818815,LastTimestamp:2024-10-24 13:23:50.168966153 +0000 UTC m=+342.945818815,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-10-24T13:24:05.968192698Z E1024 13:24:05.968141       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:06.168876253Z E1024 13:24:06.168816       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:06.168876253Z I1024 13:24:06.168860       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:06.770537926Z E1024 13:24:06.770475       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:06.969487741Z E1024 13:24:06.969432       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:07.172543286Z E1024 13:24:07.172478       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:08.169259839Z E1024 13:24:08.169203       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:08.569548828Z E1024 13:24:08.569494       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:09.169006212Z E1024 13:24:09.168947       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:09.342640476Z E1024 13:24:09.342581       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-2fcpj5j6-f6035-2lklf-master-0, took=29.995585664s, err=health check failed: context deadline exceeded
2024-10-24T13:24:09.344579606Z I1024 13:24:09.344502       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:09.345728076Z I1024 13:24:09.345681       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:09.346928406Z E1024 13:24:09.346859       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:09.346928406Z I1024 13:24:09.346892       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:09.370610327Z E1024 13:24:09.370577       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:09.822768187Z E1024 13:24:09.822689       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:09.822827227Z I1024 13:24:09.822738       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:09.939331530Z E1024 13:24:09.939271       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.18016650a1555b11  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-10-24 13:23:48.377123601 +0000 UTC m=+341.153976244,LastTimestamp:2024-10-24 13:23:48.377123601 +0000 UTC m=+341.153976244,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-10-24T13:24:09.969285890Z E1024 13:24:09.969254       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:10.073908403Z E1024 13:24:10.073828       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:10.769535469Z E1024 13:24:10.769462       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:10.971917534Z E1024 13:24:10.971860       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:11.569085148Z E1024 13:24:11.569018       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:11.769538252Z E1024 13:24:11.769473       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:11.769538252Z I1024 13:24:11.769522       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:12.570450141Z E1024 13:24:12.570385       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:12.969852730Z E1024 13:24:12.969770       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:13.169630255Z E1024 13:24:13.169571       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:13.773110959Z E1024 13:24:13.773042       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:13.969677513Z E1024 13:24:13.969618       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:14.368592992Z E1024 13:24:14.368537       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:14.968894796Z E1024 13:24:14.968823       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:15.396084805Z E1024 13:24:15.396024       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.180166519bed17ab  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-10-24 13:23:52.581371819 +0000 UTC m=+345.358224460,LastTimestamp:2024-10-24 13:23:52.581371819 +0000 UTC m=+345.358224460,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-10-24T13:24:15.769104674Z E1024 13:24:15.768994       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:15.922213148Z E1024 13:24:15.922134       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.180166510c22b409  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-10-24 13:23:50.168966153 +0000 UTC m=+342.945818815,LastTimestamp:2024-10-24 13:23:50.168966153 +0000 UTC m=+342.945818815,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-10-24T13:24:15.971206979Z E1024 13:24:15.971140       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:16.369106518Z E1024 13:24:16.369048       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:16.567810863Z E1024 13:24:16.567715       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:16.969317582Z E1024 13:24:16.969251       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:17.369239372Z E1024 13:24:17.369194       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:18.169897680Z E1024 13:24:18.169825       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:18.971678788Z E1024 13:24:18.971614       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:19.368481688Z E1024 13:24:19.368435       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:19.569447753Z E1024 13:24:19.569402       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:19.588907833Z E1024 13:24:19.588853       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-2fcpj5j6-f6035-2lklf-master-0, took=29.995585664s, err=health check failed: context deadline exceeded
2024-10-24T13:24:19.590573663Z I1024 13:24:19.590500       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:19.591770193Z I1024 13:24:19.591698       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:19.592823763Z E1024 13:24:19.592798       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:19.592859903Z I1024 13:24:19.592824       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:19.940668501Z E1024 13:24:19.940616       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.18016650a1555b11  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-10-24 13:23:48.377123601 +0000 UTC m=+341.153976244,LastTimestamp:2024-10-24 13:23:48.377123601 +0000 UTC m=+341.153976244,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-10-24T13:24:19.971090802Z E1024 13:24:19.971047       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:20.369429161Z E1024 13:24:20.369357       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:20.769121760Z E1024 13:24:20.769065       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:21.169364090Z E1024 13:24:21.169294       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:21.568786049Z E1024 13:24:21.568724       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:22.368918347Z E1024 13:24:22.368856       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:22.569208752Z E1024 13:24:22.569127       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:22.569208752Z I1024 13:24:22.569186       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:23.171151266Z E1024 13:24:23.171088       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:23.375254580Z E1024 13:24:23.375190       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:23.568934615Z E1024 13:24:23.568862       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:23.969459664Z E1024 13:24:23.969395       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:24.289642061Z E1024 13:24:24.289555       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:24:24.290398742Z E1024 13:24:24.290336       1 leaderelection.go:436] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:24.369059933Z E1024 13:24:24.368998       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:24.769819443Z E1024 13:24:24.769761       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:25.169881462Z E1024 13:24:25.169740       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:25.397705807Z E1024 13:24:25.397641       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.180166519bed17ab  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-10-24 13:23:52.581371819 +0000 UTC m=+345.358224460,LastTimestamp:2024-10-24 13:23:52.581371819 +0000 UTC m=+345.358224460,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-10-24T13:24:25.568638541Z E1024 13:24:25.568573       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:25.923501819Z E1024 13:24:25.923437       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.180166510c22b409  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-10-24 13:23:50.168966153 +0000 UTC m=+342.945818815,LastTimestamp:2024-10-24 13:23:50.168966153 +0000 UTC m=+342.945818815,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-10-24T13:24:25.968831420Z E1024 13:24:25.968778       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:26.368867910Z E1024 13:24:26.368798       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:26.769369529Z E1024 13:24:26.769321       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:27.169766208Z E1024 13:24:27.169687       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:27.569236447Z E1024 13:24:27.569177       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:27.968599196Z E1024 13:24:27.968549       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:28.368868146Z E1024 13:24:28.368810       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:29.169134124Z E1024 13:24:29.169067       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:29.771551768Z E1024 13:24:29.771487       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:24:29.941682962Z E1024 13:24:29.941623       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.18016650a1555b11  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-10-24 13:23:48.377123601 +0000 UTC m=+341.153976244,LastTimestamp:2024-10-24 13:23:48.377123601 +0000 UTC m=+341.153976244,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-10-24T13:24:29.969206582Z E1024 13:24:29.969165       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:30.320414691Z E1024 13:24:30.320364       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:30.320473901Z I1024 13:24:30.320403       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:24:30.557016066Z E1024 13:24:30.556958       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:30.770111291Z E1024 13:24:30.770044       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:30.970220566Z E1024 13:24:30.970168       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:31.368974885Z E1024 13:24:31.368915       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:31.769148354Z E1024 13:24:31.769090       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:32.169136544Z E1024 13:24:32.169081       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:32.569232383Z E1024 13:24:32.569176       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:32.969692842Z E1024 13:24:32.969631       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:33.368476141Z E1024 13:24:33.368416       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:33.769180951Z E1024 13:24:33.769121       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:34.169904830Z E1024 13:24:34.169837       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:34.568980499Z E1024 13:24:34.568918       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:34.969307228Z E1024 13:24:34.969248       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:35.369426018Z E1024 13:24:35.369370       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:35.398492978Z E1024 13:24:35.398442       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.180166519bed17ab  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-10-24 13:23:52.581371819 +0000 UTC m=+345.358224460,LastTimestamp:2024-10-24 13:23:52.581371819 +0000 UTC m=+345.358224460,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-10-24T13:24:35.769149277Z E1024 13:24:35.769092       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:35.925003680Z E1024 13:24:35.924946       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.180166510c22b409  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-10-24 13:23:50.168966153 +0000 UTC m=+342.945818815,LastTimestamp:2024-10-24 13:23:50.168966153 +0000 UTC m=+342.945818815,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-10-24T13:24:36.168821786Z E1024 13:24:36.168770       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:36.568790905Z E1024 13:24:36.568719       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:36.970052655Z E1024 13:24:36.970003       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:37.368287394Z E1024 13:24:37.368228       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:37.569361548Z E1024 13:24:37.569293       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:37.970102368Z E1024 13:24:37.970040       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:24:40.074262606Z E1024 13:24:40.074212       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-2fcpj5j6-f6035-2lklf-master-0, took=29.995585664s, err=health check failed: context deadline exceeded
2024-10-24T13:24:40.154150108Z I1024 13:24:40.154083       1 helpers.go:184] lister was stale at resourceVersion=25117, live get showed resourceVersion=27220
2024-10-24T13:24:48.266803905Z E1024 13:24:48.266737       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-2fcpj5j6-f6035-2lklf-master-0, took=29.995585664s, err=health check failed: context deadline exceeded
2024-10-24T13:24:48.282550266Z E1024 13:24:48.282520       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client_error: client error: 401"
2024-10-24T13:24:48.301222916Z I1024 13:24:48.301160       1 helpers.go:184] lister was stale at resourceVersion=25117, live get showed resourceVersion=27222
2024-10-24T13:24:48.336227887Z I1024 13:24:48.336168       1 helpers.go:184] lister was stale at resourceVersion=25117, live get showed resourceVersion=27222
2024-10-24T13:24:49.589106026Z I1024 13:24:49.589046       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:25:11.549603193Z I1024 13:25:11.549498       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:25:14.564697952Z I1024 13:25:14.564632       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 32.96 %, dbSize: 114200576
2024-10-24T13:25:14.564697952Z I1024 13:25:14.564668       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 32.94 %, dbSize: 114241536
2024-10-24T13:25:14.564697952Z I1024 13:25:14.564675       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 32.55 %, dbSize: 113631232
2024-10-24T13:25:29.250843130Z I1024 13:25:29.250789       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:34.058919424Z I1024 13:25:34.058858       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:34.082439424Z I1024 13:25:34.082371       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:25:34.104792023Z I1024 13:25:34.104735       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:25:35.596745448Z I1024 13:25:35.596685       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:35.640129788Z I1024 13:25:35.640064       1 reflector.go:368] Caches populated for *v1.Job from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:37.293526982Z I1024 13:25:37.293448       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:37.410248422Z I1024 13:25:37.410167       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:37.699540111Z I1024 13:25:37.699492       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=etcds from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:37.700408961Z I1024 13:25:37.700346       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:37.700983741Z I1024 13:25:37.700865       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:37.712483591Z I1024 13:25:37.712338       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 3 of 4 members are available, etcd-bootstrap is unhealthy" to "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy",Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12\nEtcdMembersAvailable: 3 of 4 members are available, etcd-bootstrap is unhealthy" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy"
2024-10-24T13:25:37.725704501Z I1024 13:25:37.725658       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:25:37.753051751Z I1024 13:25:37.752983       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 31.71 %, dbSize: 114200576
2024-10-24T13:25:37.753051751Z I1024 13:25:37.753002       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 31.68 %, dbSize: 114241536
2024-10-24T13:25:37.753051751Z I1024 13:25:37.753008       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 31.28 %, dbSize: 113631232
2024-10-24T13:25:38.888007287Z I1024 13:25:38.887952       1 request.go:700] Waited for 1.186176686s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:25:39.491204084Z I1024 13:25:39.491148       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:39.693665734Z I1024 13:25:39.693577       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:39.888104263Z I1024 13:25:39.888046       1 request.go:700] Waited for 1.192765125s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:25:40.360615002Z I1024 13:25:40.360550       1 reflector.go:368] Caches populated for *v1.Role from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:40.492155741Z I1024 13:25:40.492083       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:40.524193471Z I1024 13:25:40.524128       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:25:40.546641141Z I1024 13:25:40.546571       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:25:41.088246689Z I1024 13:25:41.088194       1 request.go:700] Waited for 1.193125276s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:25:41.095002009Z I1024 13:25:41.094954       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:25:41.095002009Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:25:41.095002009Z  CurrentRevision: (int32) 12,
2024-10-24T13:25:41.095002009Z  TargetRevision: (int32) 0,
2024-10-24T13:25:41.095002009Z  LastFailedRevision: (int32) 0,
2024-10-24T13:25:41.095002009Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:25:41.095002009Z  LastFailedReason: (string) "",
2024-10-24T13:25:41.095002009Z  LastFailedCount: (int) 0,
2024-10-24T13:25:41.095002009Z  LastFallbackCount: (int) 0,
2024-10-24T13:25:41.095002009Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:25:41.095002009Z }
2024-10-24T13:25:41.095002009Z  because static pod is ready
2024-10-24T13:25:41.121312699Z I1024 13:25:41.121243       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 3 to 12 because static pod is ready
2024-10-24T13:25:41.122016689Z I1024 13:25:41.121798       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:41.122708829Z I1024 13:25:41.122668       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 5; 2 nodes are at revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 12\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:41.132066369Z E1024 13:25:41.132019       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:41.139448429Z I1024 13:25:41.139411       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 5; 2 nodes are at revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 12\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:41.147110899Z E1024 13:25:41.147066       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:41.153709159Z I1024 13:25:41.153665       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:25:41.160530399Z I1024 13:25:41.160486       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 5; 2 nodes are at revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 12\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:41.161692428Z I1024 13:25:41.161651       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 31.51 %, dbSize: 114200576
2024-10-24T13:25:41.161692428Z I1024 13:25:41.161668       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 31.48 %, dbSize: 114241536
2024-10-24T13:25:41.161692428Z I1024 13:25:41.161672       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 31.09 %, dbSize: 113631232
2024-10-24T13:25:41.170479448Z E1024 13:25:41.170442       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:41.192387978Z I1024 13:25:41.192330       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 5; 2 nodes are at revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 12\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:41.201150349Z E1024 13:25:41.201104       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:41.242889218Z I1024 13:25:41.242828       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 5; 2 nodes are at revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 12\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:41.251104438Z E1024 13:25:41.251062       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:41.298067478Z I1024 13:25:41.298004       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 5; 2 nodes are at revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 12\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:41.305672918Z E1024 13:25:41.305611       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:41.307387928Z I1024 13:25:41.307344       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 5; 2 nodes are at revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 12\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:41.316644238Z E1024 13:25:41.316589       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:41.333827408Z I1024 13:25:41.333737       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 5; 2 nodes are at revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 12\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:41.342792478Z E1024 13:25:41.342727       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:41.490770748Z I1024 13:25:41.490691       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:41.984800896Z I1024 13:25:41.984692       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 5; 2 nodes are at revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 12\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:41.992789556Z E1024 13:25:41.992707       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:25:42.088297326Z I1024 13:25:42.088213       1 request.go:700] Waited for 1.392483804s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-10-24T13:25:42.301020715Z I1024 13:25:42.300973       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:42.321447155Z I1024 13:25:42.321414       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:25:42.347021465Z I1024 13:25:42.346979       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:25:42.762484723Z I1024 13:25:42.762423       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:42.763467613Z I1024 13:25:42.763310       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 5; 2 nodes are at revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 12\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:42.776481573Z I1024 13:25:42.776408       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12" to "NodeInstallerProgressing: 1 node is at revision 5; 2 nodes are at revision 12",Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 12\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 12\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy"
2024-10-24T13:25:42.840730023Z I1024 13:25:42.840679       1 reflector.go:368] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:43.088646622Z I1024 13:25:43.088603       1 request.go:700] Waited for 1.966651063s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:25:43.304030601Z I1024 13:25:43.303944       1 reflector.go:368] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:43.537791550Z I1024 13:25:43.537641       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:25:44.959997915Z I1024 13:25:44.959945       1 reflector.go:368] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:45.241357795Z I1024 13:25:45.241280       1 reflector.go:368] Caches populated for *v1.Etcd from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:45.288668474Z I1024 13:25:45.288619       1 request.go:700] Waited for 1.110483177s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces?resourceVersion=26158
2024-10-24T13:25:45.293567554Z I1024 13:25:45.293507       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:46.488300670Z I1024 13:25:46.488252       1 request.go:700] Waited for 1.392036205s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:25:46.692023999Z I1024 13:25:46.691948       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:46.725993439Z I1024 13:25:46.725927       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:25:46.748018149Z I1024 13:25:46.747964       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:25:47.093622678Z I1024 13:25:47.093553       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:47.688401366Z I1024 13:25:47.688345       1 request.go:700] Waited for 1.253747586s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps?resourceVersion=26161
2024-10-24T13:25:47.696348666Z I1024 13:25:47.696268       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:47.698554746Z I1024 13:25:47.698499       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.706983026Z I1024 13:25:47.706922       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.708407016Z I1024 13:25:47.708358       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.708728586Z I1024 13:25:47.708692       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.709196006Z I1024 13:25:47.709115       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.710534456Z I1024 13:25:47.710496       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.714624236Z I1024 13:25:47.714514       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.717807946Z I1024 13:25:47.717769       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.722594216Z I1024 13:25:47.722552       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.724356016Z I1024 13:25:47.724325       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.724615346Z I1024 13:25:47.724584       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.724867896Z I1024 13:25:47.724844       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.725141906Z I1024 13:25:47.725116       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.725399196Z I1024 13:25:47.725375       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.725633746Z I1024 13:25:47.725607       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.725825436Z I1024 13:25:47.725801       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.726092176Z I1024 13:25:47.726063       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.726394726Z I1024 13:25:47.726368       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.726646466Z I1024 13:25:47.726625       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.727068736Z I1024 13:25:47.727038       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.727279776Z I1024 13:25:47.727255       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.727589806Z I1024 13:25:47.727520       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.727806906Z I1024 13:25:47.727782       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.728041006Z I1024 13:25:47.728016       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.728303836Z I1024 13:25:47.728278       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.728555606Z I1024 13:25:47.728531       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.728871026Z I1024 13:25:47.728845       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.729132396Z I1024 13:25:47.729106       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.729562906Z I1024 13:25:47.729537       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.729799986Z I1024 13:25:47.729778       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.730056256Z I1024 13:25:47.729987       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.730289636Z I1024 13:25:47.730257       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.737181596Z I1024 13:25:47.730504       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.737470396Z I1024 13:25:47.737380       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.737470396Z I1024 13:25:47.734786       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:25:47.737923226Z I1024 13:25:47.737851       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:47.767689506Z I1024 13:25:47.767639       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:25:47.796170996Z I1024 13:25:47.796102       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:25:48.283480544Z E1024 13:25:48.283429       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client_error: client error: 401"
2024-10-24T13:25:48.296118654Z I1024 13:25:48.295227       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:48.296118654Z I1024 13:25:48.295559       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 5; 2 nodes are at revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 12\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:48.306468914Z I1024 13:25:48.306372       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy" to "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found"
2024-10-24T13:25:48.324355274Z I1024 13:25:48.324225       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:25:48.344826644Z I1024 13:25:48.344766       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 30.99 %, dbSize: 114200576
2024-10-24T13:25:48.344826644Z I1024 13:25:48.344792       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 30.92 %, dbSize: 114241536
2024-10-24T13:25:48.344826644Z I1024 13:25:48.344798       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 30.52 %, dbSize: 113631232
2024-10-24T13:25:48.358735983Z I1024 13:25:48.358649       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:48.360505604Z I1024 13:25:48.359976       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 5; 2 nodes are at revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 12\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:25:48.377650303Z I1024 13:25:48.377567       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 12\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 12\nEtcdMembersAvailable: 3 members are available"
2024-10-24T13:25:48.412479843Z I1024 13:25:48.412404       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 30.95 %, dbSize: 114200576
2024-10-24T13:25:48.412479843Z I1024 13:25:48.412436       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 30.92 %, dbSize: 114241536
2024-10-24T13:25:48.412479843Z I1024 13:25:48.412443       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 30.50 %, dbSize: 113631232
2024-10-24T13:25:48.515286643Z I1024 13:25:48.515212       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:25:48.695431762Z I1024 13:25:48.695379       1 installer_controller.go:534] node ci-op-2fcpj5j6-f6035-2lklf-master-1 with revision 5 is the oldest and needs new revision 12
2024-10-24T13:25:48.695491482Z I1024 13:25:48.695448       1 installer_controller.go:542] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:25:48.695491482Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:25:48.695491482Z  CurrentRevision: (int32) 5,
2024-10-24T13:25:48.695491482Z  TargetRevision: (int32) 12,
2024-10-24T13:25:48.695491482Z  LastFailedRevision: (int32) 0,
2024-10-24T13:25:48.695491482Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:25:48.695491482Z  LastFailedReason: (string) "",
2024-10-24T13:25:48.695491482Z  LastFailedCount: (int) 0,
2024-10-24T13:25:48.695491482Z  LastFallbackCount: (int) 0,
2024-10-24T13:25:48.695491482Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:25:48.695491482Z }
2024-10-24T13:25:48.719114042Z I1024 13:25:48.719054       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 5 to 12 because node ci-op-2fcpj5j6-f6035-2lklf-master-1 with revision 5 is the oldest
2024-10-24T13:25:48.721408962Z I1024 13:25:48.721362       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:25:48.732596512Z I1024 13:25:48.732176       1 reflector.go:368] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:48.774802562Z I1024 13:25:48.774712       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 30.92 %, dbSize: 114200576
2024-10-24T13:25:48.774802562Z I1024 13:25:48.774737       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 30.90 %, dbSize: 114241536
2024-10-24T13:25:48.774802562Z I1024 13:25:48.774743       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 30.50 %, dbSize: 113631232
2024-10-24T13:25:49.488190100Z I1024 13:25:49.488126       1 request.go:700] Waited for 1.193588096s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:25:49.516283699Z I1024 13:25:49.516227       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:25:49.916102658Z I1024 13:25:49.916020       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:25:50.606729706Z I1024 13:25:50.606664       1 reflector.go:368] Caches populated for *v1beta1.Machine from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:50.687993956Z I1024 13:25:50.687936       1 request.go:700] Waited for 1.593351665s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:25:51.493953683Z I1024 13:25:51.493871       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:51.688570132Z I1024 13:25:51.688511       1 request.go:700] Waited for 1.789129154s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-10-24T13:25:52.292057450Z I1024 13:25:52.291994       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:52.888102428Z I1024 13:25:52.888035       1 request.go:700] Waited for 1.790189444s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:25:54.088551854Z I1024 13:25:54.088495       1 request.go:700] Waited for 1.391857196s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:25:54.195402773Z E1024 13:25:54.195330       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client query returned empty vector"
2024-10-24T13:25:54.413564313Z I1024 13:25:54.413489       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:54.491607002Z I1024 13:25:54.491535       1 reflector.go:368] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:55.687070318Z I1024 13:25:55.686994       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:55.687778908Z I1024 13:25:55.687733       1 request.go:700] Waited for 1.194836566s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-10-24T13:25:56.495044405Z I1024 13:25:56.494945       1 installer_controller.go:534] node ci-op-2fcpj5j6-f6035-2lklf-master-1 with revision 5 is the oldest and needs new revision 12
2024-10-24T13:25:56.495044405Z I1024 13:25:56.494987       1 installer_controller.go:542] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:25:56.495044405Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:25:56.495044405Z  CurrentRevision: (int32) 5,
2024-10-24T13:25:56.495044405Z  TargetRevision: (int32) 12,
2024-10-24T13:25:56.495044405Z  LastFailedRevision: (int32) 0,
2024-10-24T13:25:56.495044405Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:25:56.495044405Z  LastFailedReason: (string) "",
2024-10-24T13:25:56.495044405Z  LastFailedCount: (int) 0,
2024-10-24T13:25:56.495044405Z  LastFallbackCount: (int) 0,
2024-10-24T13:25:56.495044405Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:25:56.495044405Z }
2024-10-24T13:25:57.491666942Z I1024 13:25:57.491602       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:58.112685509Z I1024 13:25:58.112606       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-etcd because it was missing
2024-10-24T13:25:58.292115808Z I1024 13:25:58.292049       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:58.887921307Z I1024 13:25:58.887875       1 request.go:700] Waited for 1.057944137s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/secrets?resourceVersion=26155
2024-10-24T13:25:58.891241287Z I1024 13:25:58.891195       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:25:59.498534405Z I1024 13:25:59.498432       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 12, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:25:59.888392123Z I1024 13:25:59.888300       1 request.go:700] Waited for 1.383545685s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:26:00.888842469Z I1024 13:26:00.888793       1 request.go:700] Waited for 1.189806146s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:26:01.695245266Z I1024 13:26:01.695166       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 12, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:26:02.123158715Z I1024 13:26:02.123071       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:26:03.094139382Z I1024 13:26:03.094028       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 12, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:26:04.853730586Z I1024 13:26:04.853685       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:26:08.253888344Z I1024 13:26:08.253839       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:26:17.887082981Z I1024 13:26:17.887016       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:26:30.803053846Z I1024 13:26:30.802983       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 12, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:26:33.552453307Z I1024 13:26:33.552380       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 12, but has not made progress because waiting for static pod of revision 12, found 5
2024-10-24T13:26:35.188955011Z I1024 13:26:35.188532       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:26:35.497733110Z I1024 13:26:35.497658       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:26:35.528975110Z I1024 13:26:35.528902       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 12, but has not made progress because waiting for static pod of revision 12, found 5
2024-10-24T13:26:35.530709250Z I1024 13:26:35.530641       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:26:42.679734715Z I1024 13:26:42.679648       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 12, but has not made progress because waiting for static pod of revision 12, found 5
2024-10-24T13:26:46.565282792Z I1024 13:26:46.565207       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:26:48.284974986Z E1024 13:26:48.284914       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client_error: client error: 401"
2024-10-24T13:26:49.596162012Z I1024 13:26:49.596075       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:26:56.807643757Z I1024 13:26:56.807573       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:27:00.789725982Z E1024 13:27:00.789644       1 health.go:115] health check for member (ci-op-2fcpj5j6-f6035-2lklf-master-1) failed: err(context deadline exceeded)
2024-10-24T13:27:00.789933522Z W1024 13:27:00.789889       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-2fcpj5j6-f6035-2lklf-master-1]
2024-10-24T13:27:08.900006176Z I1024 13:27:08.899934       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 12, but has not made progress because static pod is pending
2024-10-24T13:27:10.091434461Z I1024 13:27:10.091381       1 request.go:700] Waited for 1.034497825s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:27:11.091611788Z I1024 13:27:11.091487       1 request.go:700] Waited for 1.193749106s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:27:12.102194984Z I1024 13:27:12.102117       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 12, but has not made progress because static pod is pending
2024-10-24T13:27:14.300840606Z I1024 13:27:14.300779       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 12, but has not made progress because static pod is pending
2024-10-24T13:27:18.276185471Z E1024 13:27:18.276087       1 health.go:115] health check for member (ci-op-2fcpj5j6-f6035-2lklf-master-1) failed: err(context deadline exceeded)
2024-10-24T13:27:18.276449961Z E1024 13:27:18.276387       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-2fcpj5j6-f6035-2lklf-master-1, took=29.989495775s, err=health check failed: context deadline exceeded
2024-10-24T13:27:18.308407301Z E1024 13:27:18.308355       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy"
2024-10-24T13:27:18.309243901Z I1024 13:27:18.309215       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 5; 2 nodes are at revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 12\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:27:18.309955961Z I1024 13:27:18.309931       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:27:18.315251511Z E1024 13:27:18.315226       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy"
2024-10-24T13:27:18.322524411Z I1024 13:27:18.321421       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy"
2024-10-24T13:27:18.327807361Z E1024 13:27:18.327705       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy"
2024-10-24T13:27:18.345869191Z I1024 13:27:18.345809       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:27:18.349701881Z E1024 13:27:18.349631       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy"
2024-10-24T13:27:18.364245190Z I1024 13:27:18.364160       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:27:18.364806830Z I1024 13:27:18.364715       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:03:45Z","message":"NodeInstallerProgressing: 1 node is at revision 5; 2 nodes are at revision 12","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 12\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:27:18.366687831Z E1024 13:27:18.366507       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy"
2024-10-24T13:27:18.387986770Z I1024 13:27:18.384126       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 12\nEtcdMembersAvailable: 3 members are available" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 12\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy"
2024-10-24T13:27:18.391451760Z E1024 13:27:18.391386       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy"
2024-10-24T13:27:18.402429730Z I1024 13:27:18.402359       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:27:18.500299040Z I1024 13:27:18.500226       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 12, but has not made progress because static pod is pending
2024-10-24T13:27:18.554483170Z E1024 13:27:18.554418       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy"
2024-10-24T13:27:18.876459637Z E1024 13:27:18.876386       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy"
2024-10-24T13:27:19.491592093Z I1024 13:27:19.491518       1 request.go:700] Waited for 1.181601202s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:27:19.518707993Z E1024 13:27:19.518669       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy"
2024-10-24T13:27:20.691914606Z I1024 13:27:20.691846       1 request.go:700] Waited for 1.385789062s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:27:20.800931465Z E1024 13:27:20.800877       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy"
2024-10-24T13:27:22.298831616Z I1024 13:27:22.298729       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 12, but has not made progress because static pod is pending
2024-10-24T13:27:23.363098770Z E1024 13:27:23.363022       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy"
2024-10-24T13:27:28.485548918Z E1024 13:27:28.485235       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy"
2024-10-24T13:27:29.523000542Z I1024 13:27:29.522936       1 request.go:700] Waited for 1.056341163s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-10-24T13:27:29.931220560Z I1024 13:27:29.931141       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:27:29.931220560Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:27:29.931220560Z  CurrentRevision: (int32) 12,
2024-10-24T13:27:29.931220560Z  TargetRevision: (int32) 0,
2024-10-24T13:27:29.931220560Z  LastFailedRevision: (int32) 0,
2024-10-24T13:27:29.931220560Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:27:29.931220560Z  LastFailedReason: (string) "",
2024-10-24T13:27:29.931220560Z  LastFailedCount: (int) 0,
2024-10-24T13:27:29.931220560Z  LastFallbackCount: (int) 0,
2024-10-24T13:27:29.931220560Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:27:29.931220560Z }
2024-10-24T13:27:29.931220560Z  because static pod is ready
2024-10-24T13:27:29.957301140Z I1024 13:27:29.957212       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 5 to 12 because static pod is ready
2024-10-24T13:27:29.958612360Z I1024 13:27:29.958577       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:27:29.959392180Z E1024 13:27:29.959365       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3309593037038193071 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-0\" peerURLs:\"https://10.0.0.3:2380\" clientURLs:\"https://10.0.0.3:2379\"  Healthy:true Took:5.05586ms Error:<nil>} {Member:ID:5953405296437866173 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-2\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:4.80342ms Error:<nil>} {Member:ID:15496572367184033116 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-1\" peerURLs:\"https://10.0.0.4:2380\" clientURLs:\"https://10.0.0.4:2379\"  Healthy:false Took:29.989495775s Error:health check failed: context deadline exceeded}]"
2024-10-24T13:27:29.959576540Z E1024 13:27:29.959548       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy"
2024-10-24T13:27:29.959671430Z I1024 13:27:29.959593       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:27:29Z","message":"NodeInstallerProgressing: 3 nodes are at revision 12\nEtcdMembersProgressing: No unstarted etcd members found","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 12\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:27:29.967224350Z E1024 13:27:29.967171       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3309593037038193071 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-0\" peerURLs:\"https://10.0.0.3:2380\" clientURLs:\"https://10.0.0.3:2379\"  Healthy:true Took:5.05586ms Error:<nil>} {Member:ID:5953405296437866173 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-2\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:4.80342ms Error:<nil>} {Member:ID:15496572367184033116 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-1\" peerURLs:\"https://10.0.0.4:2380\" clientURLs:\"https://10.0.0.4:2379\"  Healthy:false Took:29.989495775s Error:health check failed: context deadline exceeded}]"
2024-10-24T13:27:29.974298770Z I1024 13:27:29.972769       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing changed from True to False ("NodeInstallerProgressing: 3 nodes are at revision 12\nEtcdMembersProgressing: No unstarted etcd members found"),Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 12\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 12\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy"
2024-10-24T13:27:29.979433120Z E1024 13:27:29.979384       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3309593037038193071 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-0\" peerURLs:\"https://10.0.0.3:2380\" clientURLs:\"https://10.0.0.3:2379\"  Healthy:true Took:5.05586ms Error:<nil>} {Member:ID:5953405296437866173 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-2\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:4.80342ms Error:<nil>} {Member:ID:15496572367184033116 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-1\" peerURLs:\"https://10.0.0.4:2380\" clientURLs:\"https://10.0.0.4:2379\"  Healthy:false Took:29.989495775s Error:health check failed: context deadline exceeded}]"
2024-10-24T13:27:30.001800709Z E1024 13:27:30.001700       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3309593037038193071 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-0\" peerURLs:\"https://10.0.0.3:2380\" clientURLs:\"https://10.0.0.3:2379\"  Healthy:true Took:5.05586ms Error:<nil>} {Member:ID:5953405296437866173 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-2\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:4.80342ms Error:<nil>} {Member:ID:15496572367184033116 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-1\" peerURLs:\"https://10.0.0.4:2380\" clientURLs:\"https://10.0.0.4:2379\"  Healthy:false Took:29.989495775s Error:health check failed: context deadline exceeded}]"
2024-10-24T13:27:30.003508369Z I1024 13:27:30.003465       1 core.go:352] ConfigMap "openshift-etcd/etcd-endpoints" changes: {"metadata":{"annotations":{"alpha.installer.openshift.io/etcd-bootstrap":null,"alpha.installer.openshift.io/etcd-bootstrap-":"10.0.0.5"},"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:27:30.003974569Z I1024 13:27:30.003936       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-endpoints -n openshift-etcd:
2024-10-24T13:27:30.004976410Z E1024 13:27:30.004917       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3309593037038193071 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-0\" peerURLs:\"https://10.0.0.3:2380\" clientURLs:\"https://10.0.0.3:2379\"  Healthy:true Took:5.05586ms Error:<nil>} {Member:ID:5953405296437866173 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-2\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:4.80342ms Error:<nil>} {Member:ID:15496572367184033116 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-1\" peerURLs:\"https://10.0.0.4:2380\" clientURLs:\"https://10.0.0.4:2379\"  Healthy:false Took:29.989495775s Error:health check failed: context deadline exceeded}]"
2024-10-24T13:27:30.006225509Z I1024 13:27:30.005284       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:27:30.006225509Z W1024 13:27:30.005566       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.6:2379]]
2024-10-24T13:27:30.006540450Z W1024 13:27:30.005719       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.6:2379]]
2024-10-24T13:27:30.007227929Z W1024 13:27:30.007194       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.6:2379]]
2024-10-24T13:27:30.016682990Z W1024 13:27:30.016644       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.6:2379]]
2024-10-24T13:27:30.016743899Z W1024 13:27:30.016645       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.6:2379]]
2024-10-24T13:27:30.016889450Z W1024 13:27:30.016644       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.6:2379]]
2024-10-24T13:27:30.018556449Z W1024 13:27:30.018288       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.6:2379]]
2024-10-24T13:27:30.028015909Z W1024 13:27:30.027957       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.6:2379]]
2024-10-24T13:27:30.030977469Z W1024 13:27:30.030911       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.5:2379 https://10.0.0.6:2379]] vs. [[https://10.0.0.3:2379 https://10.0.0.4:2379 https://10.0.0.6:2379]]
2024-10-24T13:27:30.043635139Z E1024 13:27:30.043581       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3309593037038193071 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-0\" peerURLs:\"https://10.0.0.3:2380\" clientURLs:\"https://10.0.0.3:2379\"  Healthy:true Took:5.05586ms Error:<nil>} {Member:ID:5953405296437866173 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-2\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:4.80342ms Error:<nil>} {Member:ID:15496572367184033116 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-1\" peerURLs:\"https://10.0.0.4:2380\" clientURLs:\"https://10.0.0.4:2379\"  Healthy:false Took:29.989495775s Error:health check failed: context deadline exceeded}]"
2024-10-24T13:27:30.206414768Z E1024 13:27:30.206334       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3309593037038193071 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-0\" peerURLs:\"https://10.0.0.3:2380\" clientURLs:\"https://10.0.0.3:2379\"  Healthy:true Took:5.05586ms Error:<nil>} {Member:ID:5953405296437866173 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-2\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:4.80342ms Error:<nil>} {Member:ID:15496572367184033116 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-1\" peerURLs:\"https://10.0.0.4:2380\" clientURLs:\"https://10.0.0.4:2379\"  Healthy:false Took:29.989495775s Error:health check failed: context deadline exceeded}]"
2024-10-24T13:27:30.528540806Z E1024 13:27:30.528463       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3309593037038193071 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-0\" peerURLs:\"https://10.0.0.3:2380\" clientURLs:\"https://10.0.0.3:2379\"  Healthy:true Took:5.05586ms Error:<nil>} {Member:ID:5953405296437866173 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-2\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:4.80342ms Error:<nil>} {Member:ID:15496572367184033116 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-1\" peerURLs:\"https://10.0.0.4:2380\" clientURLs:\"https://10.0.0.4:2379\"  Healthy:false Took:29.989495775s Error:health check failed: context deadline exceeded}]"
2024-10-24T13:27:31.122921882Z I1024 13:27:31.122868       1 request.go:700] Waited for 1.164435322s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:27:31.171576612Z E1024 13:27:31.171504       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3309593037038193071 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-0\" peerURLs:\"https://10.0.0.3:2380\" clientURLs:\"https://10.0.0.3:2379\"  Healthy:true Took:5.05586ms Error:<nil>} {Member:ID:5953405296437866173 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-2\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:4.80342ms Error:<nil>} {Member:ID:15496572367184033116 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-1\" peerURLs:\"https://10.0.0.4:2380\" clientURLs:\"https://10.0.0.4:2379\"  Healthy:false Took:29.989495775s Error:health check failed: context deadline exceeded}]"
2024-10-24T13:27:32.123314806Z I1024 13:27:32.123257       1 request.go:700] Waited for 1.391241701s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-12-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:27:32.453887974Z E1024 13:27:32.453811       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3309593037038193071 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-0\" peerURLs:\"https://10.0.0.3:2380\" clientURLs:\"https://10.0.0.3:2379\"  Healthy:true Took:5.05586ms Error:<nil>} {Member:ID:5953405296437866173 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-2\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:4.80342ms Error:<nil>} {Member:ID:15496572367184033116 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-1\" peerURLs:\"https://10.0.0.4:2380\" clientURLs:\"https://10.0.0.4:2379\"  Healthy:false Took:29.989495775s Error:health check failed: context deadline exceeded}]"
2024-10-24T13:27:32.602324674Z I1024 13:27:32.602256       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:27:32.603271613Z E1024 13:27:32.603215       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy"
2024-10-24T13:27:32.604088473Z E1024 13:27:32.604020       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3309593037038193071 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-0\" peerURLs:\"https://10.0.0.3:2380\" clientURLs:\"https://10.0.0.3:2379\"  Healthy:true Took:5.05586ms Error:<nil>} {Member:ID:5953405296437866173 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-2\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:4.80342ms Error:<nil>} {Member:ID:15496572367184033116 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-1\" peerURLs:\"https://10.0.0.4:2380\" clientURLs:\"https://10.0.0.4:2379\"  Healthy:false Took:29.989495775s Error:health check failed: context deadline exceeded}]"
2024-10-24T13:27:32.944309631Z I1024 13:27:32.944234       1 core.go:352] ConfigMap "openshift-etcd/etcd-pod" changes: {"apiVersion":"v1","data":{"pod.yaml":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: etcd\n  namespace: openshift-etcd\n  annotations:\n    kubectl.kubernetes.io/default-container: etcd\n    target.workload.openshift.io/management: '{\"effect\": \"PreferredDuringScheduling\"}'\n  labels:\n    app: etcd\n    k8s-app: etcd\n    etcd: \"true\"\n    revision: \"REVISION\"\nspec:\n  initContainers:\n    - name: setup\n      image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          echo -n \"Fixing etcd log permissions.\"\n          mkdir -p /var/log/etcd  \u0026\u0026 chmod 0600 /var/log/etcd\n          echo -n \"Fixing etcd auto backup permissions.\"\n          mkdir -p /var/lib/etcd-auto-backup  \u0026\u0026 chmod 0600 /var/lib/etcd-auto-backup\n      securityContext:\n        privileged: true\n      resources:\n        requests:\n          memory: 50Mi\n          cpu: 5m\n      volumeMounts:\n        - mountPath: /var/log/etcd\n          name: log-dir\n    - name: etcd-ensure-env-vars\n      image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          set -euo pipefail\n\n          : \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST?not set}\"\n          : \"${NODE_NODE_ENVVAR_NAME_ETCD_NAME?not set}\"\n          : \"${NODE_NODE_ENVVAR_NAME_IP?not set}\"\n\n          # check for ipv4 addresses as well as ipv6 addresses with extra square brackets\n          if [[ \"${NODE_NODE_ENVVAR_NAME_IP}\" != \"${NODE_IP}\" \u0026\u0026 \"${NODE_NODE_ENVVAR_NAME_IP}\" != \"[${NODE_IP}]\" ]]; then\n            # echo the error message to stderr\n            echo \"Expected node IP to be ${NODE_IP} got ${NODE_NODE_ENVVAR_NAME_IP}\" \u003e\u00262\n            exit 1\n          fi\n\n          # check for ipv4 addresses as well as ipv6 addresses with extra square brackets\n          if [[ \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" != \"${NODE_IP}\" \u0026\u0026 \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" != \"[${NODE_IP}]\" ]]; then\n            # echo the error message to stderr\n            echo \"Expected etcd url host to be ${NODE_IP} got ${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" \u003e\u00262\n            exit 1\n          fi\n\n      resources:\n        requests:\n          memory: 60Mi\n          cpu: 10m\n      securityContext:\n        privileged: true\n      env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"1000\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"100\"\n      - name: \"ETCD_IMAGE\"\n        value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n        value: \"10.0.0.6\"\n      - name: NODE_IP\n        valueFrom:\n          fieldRef:\n            fieldPath: status.podIP\n    - name: etcd-resources-copy\n      image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          set -euo pipefail\n\n          rm -f $(grep -l '^### Created by cluster-etcd-operator' /usr/local/bin/*)\n          cp -p /etc/kubernetes/static-pod-certs/configmaps/etcd-scripts/*.sh /usr/local/bin\n\n      resources:\n        requests:\n          memory: 60Mi\n          cpu: 10m\n      securityContext:\n        privileged: true\n      volumeMounts:\n        - mountPath: /etc/kubernetes/static-pod-resources\n          name: resource-dir\n        - mountPath: /etc/kubernetes/static-pod-certs\n          name: cert-dir\n        - mountPath: /usr/local/bin\n          name: usr-local-bin\n  containers:\n  # The etcdctl container should always be first. It is intended to be used\n  # to open a remote shell via `oc rsh` that is ready to run `etcdctl`.\n  - name: etcdctl\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - \"/bin/bash\"\n      - \"-c\"\n      - \"trap TERM INT; sleep infinity \u0026 wait\"\n    resources:\n      requests:\n        memory: 60Mi\n        cpu: 10m\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n    env:\n    - name: \"ALL_ETCD_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_API\"\n      value: \"3\"\n    - name: \"ETCDCTL_CACERT\"\n      value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n    - name: \"ETCDCTL_CERT\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n    - name: \"ETCDCTL_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_KEY\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n    - name: \"ETCD_CIPHER_SUITES\"\n      value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n    - name: \"ETCD_DATA_DIR\"\n      value: \"/var/lib/etcd\"\n    - name: \"ETCD_ELECTION_TIMEOUT\"\n      value: \"1000\"\n    - name: \"ETCD_ENABLE_PPROF\"\n      value: \"true\"\n    - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n      value: \"3\"\n    - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n      value: \"200ms\"\n    - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n      value: \"5s\"\n    - name: \"ETCD_HEARTBEAT_INTERVAL\"\n      value: \"100\"\n    - name: \"ETCD_IMAGE\"\n      value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n    - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n      value: \"existing\"\n    - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n      value: \"8589934592\"\n    - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n      value: \"true\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n      value: \"10.0.0.6\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n      value: \"10.0.0.6\"\n    - name: \"ETCD_STATIC_POD_VERSION\"\n      value: \"REVISION\"\n  - name: etcd\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n\n        etcdctl member list || true\n\n        # this has a non-zero return code if the command is non-zero.  If you use an export first, it doesn't and you\n        # will succeed when you should fail.\n        ETCD_INITIAL_CLUSTER=$(discover-etcd-initial-cluster \\\n          --cacert=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --cert=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --key=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --endpoints=${ALL_ETCD_ENDPOINTS} \\\n          --data-dir=/var/lib/etcd \\\n          --target-peer-url-host=${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST} \\\n          --target-name=NODE_NAME)\n        export ETCD_INITIAL_CLUSTER\n\n        # we cannot use the \"normal\" port conflict initcontainer because when we upgrade, the existing static pod will never yield,\n        # so we do the detection in etcd container itself.\n        echo -n \"Waiting for ports 2379, 2380 and 9978 to be released.\"\n        time while [ -n \"$(ss -Htan '( sport = 2379 or sport = 2380 or sport = 9978 )')\" ]; do\n          echo -n \".\"\n          sleep 1\n        done\n\n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n        env | grep ETCD | grep -v NODE\n\n        set -x\n        # See https://etcd.io/docs/v3.4.0/tuning/ for why we use ionice\n        exec nice -n -19 ionice -c2 -n0 etcd \\\n          --logger=zap \\\n          --log-level=info \\\n          --experimental-initial-corrupt-check=true \\\n          --snapshot-count=10000 \\\n          --initial-advertise-peer-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2380 \\\n          --cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --client-cert-auth=true \\\n          --peer-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --peer-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --peer-trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --peer-client-cert-auth=true \\\n          --advertise-client-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2379 \\\n          --listen-client-urls=https://0.0.0.0:2379,unixs://${NODE_NODE_ENVVAR_NAME_IP}:0 \\\n          --listen-peer-urls=https://0.0.0.0:2380 \\\n          --metrics=extensive \\\n          --listen-metrics-urls=https://0.0.0.0:9978 ||  mv /etc/kubernetes/etcd-backup-dir/etcd-member.yaml /etc/kubernetes/manifests\n    env:\n    - name: \"ALL_ETCD_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_API\"\n      value: \"3\"\n    - name: \"ETCDCTL_CACERT\"\n      value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n    - name: \"ETCDCTL_CERT\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n    - name: \"ETCDCTL_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_KEY\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n    - name: \"ETCD_CIPHER_SUITES\"\n      value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n    - name: \"ETCD_DATA_DIR\"\n      value: \"/var/lib/etcd\"\n    - name: \"ETCD_ELECTION_TIMEOUT\"\n      value: \"1000\"\n    - name: \"ETCD_ENABLE_PPROF\"\n      value: \"true\"\n    - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n      value: \"3\"\n    - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n      value: \"200ms\"\n    - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n      value: \"5s\"\n    - name: \"ETCD_HEARTBEAT_INTERVAL\"\n      value: \"100\"\n    - name: \"ETCD_IMAGE\"\n      value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n    - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n      value: \"existing\"\n    - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n      value: \"8589934592\"\n    - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n      value: \"true\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n      value: \"10.0.0.6\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n      value: \"10.0.0.6\"\n    - name: \"ETCD_STATIC_POD_VERSION\"\n      value: \"REVISION\"\n    resources:\n      requests:\n        memory: 600Mi\n        cpu: 300m\n    readinessProbe:\n      httpGet:\n        port: 9980\n        path: readyz\n        scheme: HTTPS\n      timeoutSeconds: 30\n      failureThreshold: 5\n      periodSeconds: 5\n      successThreshold: 1\n    livenessProbe:\n      httpGet:\n        path: healthz\n        port: 9980\n        scheme: HTTPS\n      timeoutSeconds: 30\n      periodSeconds: 5\n      successThreshold: 1\n      failureThreshold: 5\n    startupProbe:\n      httpGet:\n        port: 9980\n        path: readyz\n        scheme: HTTPS\n      initialDelaySeconds: 10\n      timeoutSeconds: 1\n      periodSeconds: 10\n      successThreshold: 1\n      failureThreshold: 18\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n  - name: etcd-metrics\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n\n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n\n        exec nice -n -18 etcd grpc-proxy start \\\n          --endpoints https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:9978 \\\n          --metrics-addr https://0.0.0.0:9979 \\\n          --listen-addr 127.0.0.1:9977 \\\n          --advertise-client-url \"\"  \\\n          --key /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --key-file /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-metrics-NODE_NAME.key \\\n          --cert /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --cert-file /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-metrics-NODE_NAME.crt \\\n          --cacert /etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --trusted-ca-file /etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/metrics-ca-bundle.crt \\\n          --listen-cipher-suites ${ETCD_CIPHER_SUITES}\n    env:\n    - name: \"ALL_ETCD_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_API\"\n      value: \"3\"\n    - name: \"ETCDCTL_CACERT\"\n      value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n    - name: \"ETCDCTL_CERT\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n    - name: \"ETCDCTL_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_KEY\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n    - name: \"ETCD_CIPHER_SUITES\"\n      value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n    - name: \"ETCD_DATA_DIR\"\n      value: \"/var/lib/etcd\"\n    - name: \"ETCD_ELECTION_TIMEOUT\"\n      value: \"1000\"\n    - name: \"ETCD_ENABLE_PPROF\"\n      value: \"true\"\n    - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n      value: \"3\"\n    - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n      value: \"200ms\"\n    - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n      value: \"5s\"\n    - name: \"ETCD_HEARTBEAT_INTERVAL\"\n      value: \"100\"\n    - name: \"ETCD_IMAGE\"\n      value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n    - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n      value: \"existing\"\n    - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n      value: \"8589934592\"\n    - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n      value: \"true\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n      value: \"10.0.0.6\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n      value: \"10.0.0.6\"\n    - name: \"ETCD_STATIC_POD_VERSION\"\n      value: \"REVISION\"\n    resources:\n      requests:\n        memory: 200Mi\n        cpu: 40m\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n  - name: etcd-readyz\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:f99379698faa42b7db0e7367c8e7f738a69f699f414a7567a5593a530fb6723d\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n        \n        exec nice -n -18 cluster-etcd-operator readyz \\\n          --target=https://localhost:2379 \\\n          --listen-port=9980 \\\n          --serving-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --serving-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --client-cert-file=$(ETCDCTL_CERT) \\\n          --client-key-file=$(ETCDCTL_KEY) \\\n          --client-cacert-file=$(ETCDCTL_CACERT) \\\n          --listen-cipher-suites=$(ETCD_CIPHER_SUITES)\n    securityContext:\n      privileged: true\n    ports:\n    - containerPort: 9980\n      name: readyz\n      protocol: TCP\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    env:\n    - name: \"ALL_ETCD_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_API\"\n      value: \"3\"\n    - name: \"ETCDCTL_CACERT\"\n      value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n    - name: \"ETCDCTL_CERT\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n    - name: \"ETCDCTL_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_KEY\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n    - name: \"ETCD_CIPHER_SUITES\"\n      value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n    - name: \"ETCD_DATA_DIR\"\n      value: \"/var/lib/etcd\"\n    - name: \"ETCD_ELECTION_TIMEOUT\"\n      value: \"1000\"\n    - name: \"ETCD_ENABLE_PPROF\"\n      value: \"true\"\n    - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n      value: \"3\"\n    - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n      value: \"200ms\"\n    - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n      value: \"5s\"\n    - name: \"ETCD_HEARTBEAT_INTERVAL\"\n      value: \"100\"\n    - name: \"ETCD_IMAGE\"\n      value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n    - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n      value: \"existing\"\n    - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n      value: \"8589934592\"\n    - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n      value: \"true\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n      value: \"10.0.0.6\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n      value: \"10.0.0.6\"\n    volumeMounts:\n      - mountPath: /var/log/etcd/\n        name: log-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n  - name: etcd-rev\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:f99379698faa42b7db0e7367c8e7f738a69f699f414a7567a5593a530fb6723d\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n        \n        cluster-etcd-operator rev \\\n          --endpoints=$(ALL_ETCD_ENDPOINTS) \\\n          --client-cert-file=$(ETCDCTL_CERT) \\\n          --client-key-file=$(ETCDCTL_KEY) \\\n          --client-cacert-file=$(ETCDCTL_CACERT)\n    securityContext:\n      privileged: true\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    env:\n    - name: \"ALL_ETCD_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_API\"\n      value: \"3\"\n    - name: \"ETCDCTL_CACERT\"\n      value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n    - name: \"ETCDCTL_CERT\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n    - name: \"ETCDCTL_ENDPOINTS\"\n      value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n    - name: \"ETCDCTL_KEY\"\n      value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n    - name: \"ETCD_CIPHER_SUITES\"\n      value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n    - name: \"ETCD_DATA_DIR\"\n      value: \"/var/lib/etcd\"\n    - name: \"ETCD_ELECTION_TIMEOUT\"\n      value: \"1000\"\n    - name: \"ETCD_ENABLE_PPROF\"\n      value: \"true\"\n    - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n      value: \"3\"\n    - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n      value: \"200ms\"\n    - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n      value: \"5s\"\n    - name: \"ETCD_HEARTBEAT_INTERVAL\"\n      value: \"100\"\n    - name: \"ETCD_IMAGE\"\n      value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n    - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n      value: \"existing\"\n    - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n      value: \"8589934592\"\n    - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n      value: \"true\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n      value: \"10.0.0.3\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n      value: \"10.0.0.4\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n      value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n      value: \"10.0.0.6\"\n    - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n      value: \"10.0.0.6\"\n    volumeMounts:\n    - mountPath: /var/lib/etcd\n      name: data-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n  hostNetwork: true\n  priorityClassName: system-node-critical\n  tolerations:\n  - operator: \"Exists\"\n  volumes:\n    - hostPath:\n        path: /etc/kubernetes/manifests\n      name: static-pod-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-pod-REVISION\n      name: resource-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-certs\n      name: cert-dir\n    - hostPath:\n        path: /var/lib/etcd\n        type: \"\"\n      name: data-dir\n    - hostPath:\n        path: /usr/local/bin\n      name: usr-local-bin\n    - hostPath:\n        path: /var/log/etcd\n      name: log-dir\n    - hostPath:\n        path: /etc/kubernetes\n      name: config-dir\n    - hostPath:\n        path: /var/lib/etcd-auto-backup\n      name: etcd-auto-backup-dir\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:27:32.945088811Z I1024 13:27:32.945054       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-pod -n openshift-etcd:
2024-10-24T13:27:32.945088811Z cause by changes in data.pod.yaml
2024-10-24T13:27:32.946045181Z E1024 13:27:32.945987       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3309593037038193071 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-0\" peerURLs:\"https://10.0.0.3:2380\" clientURLs:\"https://10.0.0.3:2379\"  Healthy:true Took:5.05586ms Error:<nil>} {Member:ID:5953405296437866173 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-2\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:4.80342ms Error:<nil>} {Member:ID:15496572367184033116 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-1\" peerURLs:\"https://10.0.0.4:2380\" clientURLs:\"https://10.0.0.4:2379\"  Healthy:false Took:29.989495775s Error:health check failed: context deadline exceeded}]"
2024-10-24T13:27:32.946261971Z I1024 13:27:32.946207       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:27:33.123467490Z I1024 13:27:33.123382       1 request.go:700] Waited for 1.193311833s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:27:33.331015219Z I1024 13:27:33.330940       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:27:33.331015219Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:27:33.331015219Z  CurrentRevision: (int32) 12,
2024-10-24T13:27:33.331015219Z  TargetRevision: (int32) 0,
2024-10-24T13:27:33.331015219Z  LastFailedRevision: (int32) 0,
2024-10-24T13:27:33.331015219Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:27:33.331015219Z  LastFailedReason: (string) "",
2024-10-24T13:27:33.331015219Z  LastFailedCount: (int) 0,
2024-10-24T13:27:33.331015219Z  LastFallbackCount: (int) 0,
2024-10-24T13:27:33.331015219Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:27:33.331015219Z }
2024-10-24T13:27:33.331015219Z  because static pod is ready
2024-10-24T13:27:33.540342507Z I1024 13:27:33.540264       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:27:33.540616728Z I1024 13:27:33.540512       1 core.go:352] ConfigMap "openshift-etcd/etcd-scripts" changes: {"apiVersion":"v1","data":{"etcd.env":"export ALL_ETCD_ENDPOINTS=\"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\nexport ETCDCTL_API=\"3\"\nexport ETCDCTL_CACERT=\"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\nexport ETCDCTL_CERT=\"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\nexport ETCDCTL_ENDPOINTS=\"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\nexport ETCDCTL_KEY=\"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\nexport ETCD_CIPHER_SUITES=\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\nexport ETCD_DATA_DIR=\"/var/lib/etcd\"\nexport ETCD_ELECTION_TIMEOUT=\"1000\"\nexport ETCD_ENABLE_PPROF=\"true\"\nexport ETCD_EXPERIMENTAL_MAX_LEARNERS=\"3\"\nexport ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION=\"200ms\"\nexport ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL=\"5s\"\nexport ETCD_HEARTBEAT_INTERVAL=\"100\"\nexport ETCD_IMAGE=\"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\nexport ETCD_INITIAL_CLUSTER_STATE=\"existing\"\nexport ETCD_QUOTA_BACKEND_BYTES=\"8589934592\"\nexport ETCD_SOCKET_REUSE_ADDRESS=\"true\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME=\"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST=\"10.0.0.3\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP=\"10.0.0.3\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME=\"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST=\"10.0.0.4\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP=\"10.0.0.4\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME=\"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST=\"10.0.0.6\"\nexport NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP=\"10.0.0.6\"\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:27:33.540911107Z I1024 13:27:33.540832       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-scripts -n openshift-etcd:
2024-10-24T13:27:33.540911107Z cause by changes in data.etcd.env
2024-10-24T13:27:33.541380367Z E1024 13:27:33.541321       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3309593037038193071 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-0\" peerURLs:\"https://10.0.0.3:2380\" clientURLs:\"https://10.0.0.3:2379\"  Healthy:true Took:5.05586ms Error:<nil>} {Member:ID:5953405296437866173 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-2\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:4.80342ms Error:<nil>} {Member:ID:15496572367184033116 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-1\" peerURLs:\"https://10.0.0.4:2380\" clientURLs:\"https://10.0.0.4:2379\"  Healthy:false Took:29.989495775s Error:health check failed: context deadline exceeded}]"
2024-10-24T13:27:34.123817594Z I1024 13:27:34.123721       1 request.go:700] Waited for 1.392938001s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:27:35.017078408Z E1024 13:27:35.017013       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3309593037038193071 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-0\" peerURLs:\"https://10.0.0.3:2380\" clientURLs:\"https://10.0.0.3:2379\"  Healthy:true Took:5.05586ms Error:<nil>} {Member:ID:5953405296437866173 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-2\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:4.80342ms Error:<nil>} {Member:ID:15496572367184033116 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-1\" peerURLs:\"https://10.0.0.4:2380\" clientURLs:\"https://10.0.0.4:2379\"  Healthy:false Took:29.989495775s Error:health check failed: context deadline exceeded}]"
2024-10-24T13:27:35.323763806Z I1024 13:27:35.323682       1 request.go:700] Waited for 1.191622992s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:27:35.540775155Z I1024 13:27:35.540685       1 core.go:352] ConfigMap "openshift-etcd/restore-etcd-pod" changes: {"apiVersion":"v1","data":{"pod.yaml":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: etcd\n  namespace: openshift-etcd\n  labels:\n    app: etcd\n    k8s-app: etcd\n    etcd: \"true\"\n    revision: \"REVISION\"\nspec:\n  containers:\n  - name: etcd\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n               \n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n        export ETCD_INITIAL_CLUSTER=\"${ETCD_NAME}=https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:2380\"\n        env | grep ETCD | grep -v NODE\n        export ETCD_NODE_PEER_URL=https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:2380\n        export REV_JSON=\"/var/lib/etcd-backup/revision.json\"\n        export SNAPSHOT_FILE=\"/var/lib/etcd-backup/snapshot.db\"\n\n        # checking if data directory is empty, if not etcdctl restore will fail         \n        if [ -n \"$(ls -A \"/var/lib/etcd\")\" ]; then\n          echo \"please delete the contents of the /var/lib/etcd directory before restoring, running the restore script will do this for you\"\n          exit 1\n        fi\n        \n        ETCD_ETCDCTL_BIN=\"etcdctl\"\n        if [ -x \"$(command -v etcdutl)\" ]; then\n          echo \"found etcdutl, using that instead of etcdctl for local operations\"\n          ETCD_ETCDCTL_BIN=\"etcdutl\"\n        fi      \n\n        # check if we have backup file to be restored\n        # if the file exist, check if it has not changed size in last 5 seconds\n        if [ ! -f \"${SNAPSHOT_FILE}\" ]; then\n          echo \"please make a copy of the snapshot db file, then move that copy to ${SNAPSHOT_FILE}\"\n          exit 1\n        else\n          filesize=$(stat --format=%s \"${SNAPSHOT_FILE}\")\n          sleep 5\n          newfilesize=$(stat --format=%s \"${SNAPSHOT_FILE}\")\n          if [ \"$filesize\" != \"$newfilesize\" ]; then\n            echo \"file size has changed since last 5 seconds, retry sometime after copying is complete\"\n            exit 1\n          fi\n        fi\n        \n        SNAPSHOT_REV=$(etcdutl snapshot status -wjson \"$SNAPSHOT_FILE\" | jq -r \".revision\")\n        echo \"snapshot is at revision ${SNAPSHOT_REV}\"\n        \n        if [ -n \"$(ls -A \"${REV_JSON}\")\" ]; then\n           # this will bump by the amount of the last known live revision + 20% slack.\n           # Note: the bump amount is an addition to the current revision stored in the snapshot.\n           # We're avoiding to do any math with SNAPSHOT_REV, uint64 has plenty of space to double revisions\n           # and we're assuming that full disaster restores are a very rare occurrence anyway.\n           BUMP_REV=$(jq -r \"(.maxRaftIndex*1.2|floor)\" \"${REV_JSON}\")\n           echo \"bumping revisions by ${BUMP_REV}\"\n        else\n           # we can't take SNAPSHOT_REV as an indicator here, because the snapshot might be much older\n           # than any currently live served revision. \n           # 1bn would be an etcd running at 1000 writes/s for about eleven days.\n           echo \"no revision.json found, assuming a 1bn revision bump\"\n           BUMP_REV=1000000000\n        fi\n        \n        UUID=$(uuidgen)\n        echo \"restoring to a single node cluster\"\n        ${ETCD_ETCDCTL_BIN} snapshot restore \"${SNAPSHOT_FILE}\" \\\n         --name $ETCD_NAME \\\n         --initial-cluster=$ETCD_INITIAL_CLUSTER \\\n         --initial-cluster-token \"openshift-etcd-${UUID}\" \\\n         --initial-advertise-peer-urls $ETCD_NODE_PEER_URL \\\n         --data-dir=\"/var/lib/etcd/restore-${UUID}\" \\\n         --mark-compacted \\\n         --bump-revision \"${BUMP_REV}\"\n\n        mv /var/lib/etcd/restore-${UUID}/* /var/lib/etcd/\n        # copy the revision.json back in case a second restore needs to be run afterwards\n        if [ -n \"$(ls -A \"${REV_JSON}\")\" ]; then\n           cp ${REV_JSON} /var/lib/etcd/\n        fi\n\n        rmdir /var/lib/etcd/restore-${UUID}\n        rm /var/lib/etcd-backup/snapshot.db\n\n        set -x\n        exec etcd \\\n          --logger=zap \\\n          --log-level=info \\\n          --initial-advertise-peer-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2380 \\\n          --cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --client-cert-auth=true \\\n          --peer-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --peer-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --peer-trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --peer-client-cert-auth=true \\\n          --advertise-client-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2379 \\\n          --listen-client-urls=https://0.0.0.0:2379 \\\n          --listen-peer-urls=https://0.0.0.0:2380 \\\n          --metrics=extensive \\\n          --listen-metrics-urls=https://0.0.0.0:9978\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"1000\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"100\"\n      - name: \"ETCD_IMAGE\"\n        value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n        value: \"10.0.0.6\"\n      - name: \"ETCD_STATIC_POD_REV\"\n        value: \"REVISION\"\n    resources:\n      requests:\n        memory: 600Mi\n        cpu: 300m\n    readinessProbe:\n      tcpSocket:\n        port: 2380\n      failureThreshold: 3\n      initialDelaySeconds: 3\n      periodSeconds: 5\n      successThreshold: 1\n      timeoutSeconds: 5\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n      - mountPath: /var/lib/etcd-backup/\n        name: backup-dir\n  hostNetwork: true\n  priorityClassName: system-node-critical\n  tolerations:\n  - operator: \"Exists\"\n  volumes:\n    - hostPath:\n        path: /etc/kubernetes/manifests\n      name: static-pod-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-certs\n      name: cert-dir\n    - hostPath:\n        path: /var/lib/etcd\n        type: \"\"\n      name: data-dir\n    - hostPath:\n        path: /var/lib/etcd-backup\n        type: \"\"\n      name: backup-dir\n","quorum-restore-pod.yaml":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: etcd\n  namespace: openshift-etcd\n  labels:\n    app: etcd\n    k8s-app: etcd\n    etcd: \"true\"\n    revision: \"REVISION\"\nspec:\n  containers:\n  - name: etcd\n    image: registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n        \n        set -x\n        exec etcd \\\n          --logger=zap \\\n          --log-level=info \\\n          --force-new-cluster \\\n          --name=\"${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\" \\\n          --initial-cluster=\"${NODE_NODE_ENVVAR_NAME_ETCD_NAME}=https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:2380\" \\\n          --initial-advertise-peer-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2380 \\\n          --cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --client-cert-auth=true \\\n          --peer-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --peer-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --peer-trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt \\\n          --peer-client-cert-auth=true \\\n          --advertise-client-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2379 \\\n          --listen-client-urls=https://0.0.0.0:2379 \\\n          --listen-peer-urls=https://0.0.0.0:2380 \\\n          --metrics=extensive \\\n          --listen-metrics-urls=https://0.0.0.0:9978\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-all-bundles/server-ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.3:2379,https://10.0.0.4:2379,https://10.0.0.6:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"1000\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"100\"\n      - name: \"ETCD_IMAGE\"\n        value: \"registry.build02.ci.openshift.org/ci-op-2fcpj5j6/stable@sha256:a5ffe3489a5c049cb2bae31ba55fa7e3a7654d93d833a78f6c0506d2d7c1b272\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-0\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_0_IP\"\n        value: \"10.0.0.3\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-1\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_1_IP\"\n        value: \"10.0.0.4\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_NAME\"\n        value: \"ci-op-2fcpj5j6-f6035-2lklf-master-2\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_2fcpj5j6_f6035_2lklf_master_2_IP\"\n        value: \"10.0.0.6\"\n      - name: \"ETCD_STATIC_POD_REV\"\n        value: \"REVISION\"\n    resources:\n      requests:\n        memory: 600Mi\n        cpu: 300m\n    readinessProbe:\n      tcpSocket:\n        port: 2380\n      failureThreshold: 3\n      initialDelaySeconds: 3\n      periodSeconds: 5\n      successThreshold: 1\n      timeoutSeconds: 5\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n      - mountPath: /var/lib/etcd-backup/\n        name: backup-dir\n  hostNetwork: true\n  priorityClassName: system-node-critical\n  tolerations:\n  - operator: \"Exists\"\n  volumes:\n    - hostPath:\n        path: /etc/kubernetes/manifests\n      name: static-pod-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-certs\n      name: cert-dir\n    - hostPath:\n        path: /var/lib/etcd\n        type: \"\"\n      name: data-dir\n    - hostPath:\n        path: /var/lib/etcd-backup\n        type: \"\"\n      name: backup-dir\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-10-24T13:27:35.541338365Z I1024 13:27:35.541139       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:27:35.541627105Z E1024 13:27:35.541575       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3309593037038193071 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-0\" peerURLs:\"https://10.0.0.3:2380\" clientURLs:\"https://10.0.0.3:2379\"  Healthy:true Took:5.05586ms Error:<nil>} {Member:ID:5953405296437866173 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-2\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:4.80342ms Error:<nil>} {Member:ID:15496572367184033116 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-1\" peerURLs:\"https://10.0.0.4:2380\" clientURLs:\"https://10.0.0.4:2379\"  Healthy:false Took:29.989495775s Error:health check failed: context deadline exceeded}]"
2024-10-24T13:27:35.541881795Z I1024 13:27:35.541841       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/restore-etcd-pod -n openshift-etcd:
2024-10-24T13:27:35.541881795Z cause by changes in data.pod.yaml,data.quorum-restore-pod.yaml
2024-10-24T13:27:38.728441226Z E1024 13:27:38.728373       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy"
2024-10-24T13:27:48.268881057Z E1024 13:27:48.268803       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-2fcpj5j6-f6035-2lklf-master-1, took=29.989495775s, err=health check failed: context deadline exceeded
2024-10-24T13:27:48.284305427Z E1024 13:27:48.284258       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client query returned empty vector"
2024-10-24T13:27:48.382475626Z E1024 13:27:48.382407       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:48.382521415Z I1024 13:27:48.382490       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:48.402236956Z E1024 13:27:48.402171       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:48.402303476Z I1024 13:27:48.402247       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:48.425339075Z E1024 13:27:48.425271       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:48.425405595Z I1024 13:27:48.425328       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:48.458393715Z E1024 13:27:48.458315       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:48.458465895Z I1024 13:27:48.458396       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:48.512419545Z E1024 13:27:48.512358       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:48.512503875Z I1024 13:27:48.512444       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:48.607700154Z E1024 13:27:48.607617       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:48.607785654Z I1024 13:27:48.607709       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:48.780673063Z E1024 13:27:48.780609       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:48.780723023Z I1024 13:27:48.780676       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:48.969802192Z E1024 13:27:48.969733       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:48.972473522Z E1024 13:27:48.972421       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:48.977220022Z E1024 13:27:48.977166       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:48.983503002Z E1024 13:27:48.983450       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:48.992477102Z E1024 13:27:48.992443       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:49.114734721Z E1024 13:27:49.114670       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:49.114843661Z I1024 13:27:49.114744       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:49.370691849Z E1024 13:27:49.370626       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:49.570388668Z E1024 13:27:49.570280       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3309593037038193071 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-0\" peerURLs:\"https://10.0.0.3:2380\" clientURLs:\"https://10.0.0.3:2379\"  Healthy:true Took:5.05586ms Error:<nil>} {Member:ID:5953405296437866173 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-2\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:4.80342ms Error:<nil>} {Member:ID:15496572367184033116 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-1\" peerURLs:\"https://10.0.0.4:2380\" clientURLs:\"https://10.0.0.4:2379\"  Healthy:false Took:29.989495775s Error:health check failed: context deadline exceeded}]"
2024-10-24T13:27:49.570968278Z E1024 13:27:49.570915       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:49.573048668Z E1024 13:27:49.573004       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:49.578366228Z E1024 13:27:49.578318       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:49.590623478Z E1024 13:27:49.590578       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:49.613269908Z E1024 13:27:49.613198       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:49.656021017Z E1024 13:27:49.655957       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:49.738584037Z E1024 13:27:49.738525       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:49.766481647Z E1024 13:27:49.766407       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:49.766560167Z I1024 13:27:49.766510       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:49.769967407Z E1024 13:27:49.769925       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:49.900687316Z E1024 13:27:49.900631       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:50.172271394Z E1024 13:27:50.172085       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:50.172271394Z I1024 13:27:50.172172       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:50.223785084Z E1024 13:27:50.223703       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:50.570788972Z E1024 13:27:50.570723       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:50.866551330Z E1024 13:27:50.866501       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:50.973528539Z E1024 13:27:50.973472       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:51.060352669Z E1024 13:27:51.060296       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:51.060408359Z I1024 13:27:51.060369       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:51.169693978Z I1024 13:27:51.169637       1 request.go:700] Waited for 1.198658132s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:27:51.371959757Z E1024 13:27:51.371902       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:51.371997677Z I1024 13:27:51.371972       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:51.573092086Z E1024 13:27:51.573031       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:51.770268604Z E1024 13:27:51.770212       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:52.149713402Z E1024 13:27:52.149641       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:52.170128652Z I1024 13:27:52.170071       1 request.go:700] Waited for 1.189850643s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:27:52.173734332Z E1024 13:27:52.173697       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:52.359242861Z E1024 13:27:52.359167       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:27:52.360246291Z E1024 13:27:52.360180       1 leaderelection.go:436] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:52.372137721Z E1024 13:27:52.372087       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:52.573397530Z E1024 13:27:52.573323       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:52.573472700Z I1024 13:27:52.573383       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:53.171129016Z E1024 13:27:53.171059       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:53.369932205Z I1024 13:27:53.369860       1 request.go:700] Waited for 1.184397682s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:27:53.373468844Z E1024 13:27:53.373402       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:53.632845153Z E1024 13:27:53.632780       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:53.632845153Z I1024 13:27:53.632806       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:53.772239582Z E1024 13:27:53.772173       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:53.772239582Z I1024 13:27:53.772216       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:53.971234091Z E1024 13:27:53.971165       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:54.180711929Z E1024 13:27:54.180643       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:54.373649589Z E1024 13:27:54.373594       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:54.712913316Z E1024 13:27:54.712832       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:54.770009166Z E1024 13:27:54.769948       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:54.969955345Z I1024 13:27:54.969887       1 request.go:700] Waited for 1.155730333s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:27:54.972572584Z E1024 13:27:54.972529       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:54.972652434Z I1024 13:27:54.972597       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:55.572598941Z E1024 13:27:55.572552       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:55.772600540Z E1024 13:27:55.772545       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:55.971542208Z E1024 13:27:55.971486       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:55.971632488Z I1024 13:27:55.971568       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:56.172191857Z E1024 13:27:56.172129       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:56.573076934Z E1024 13:27:56.573022       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:56.970097182Z E1024 13:27:56.970043       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:57.169624191Z I1024 13:27:57.169566       1 request.go:700] Waited for 1.035352814s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:27:57.171686151Z E1024 13:27:57.171657       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:57.171730551Z I1024 13:27:57.171699       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:57.773651637Z E1024 13:27:57.773596       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:58.172242175Z E1024 13:27:58.172194       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:58.372516853Z E1024 13:27:58.372466       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:58.372643183Z I1024 13:27:58.372576       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:58.574138692Z E1024 13:27:58.574084       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:58.765794321Z E1024 13:27:58.765696       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:58.765871411Z I1024 13:27:58.765783       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:58.772296041Z E1024 13:27:58.772238       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:58.972959939Z E1024 13:27:58.972915       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:27:59.771673415Z E1024 13:27:59.771613       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:59.771673415Z I1024 13:27:59.771650       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:27:59.835526844Z E1024 13:27:59.835463       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:27:59.972538844Z E1024 13:27:59.972475       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:00.370535591Z E1024 13:28:00.370492       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:00.769897019Z I1024 13:28:00.769835       1 request.go:700] Waited for 1.154963023s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:28:00.773642949Z E1024 13:28:00.773606       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:01.373441555Z E1024 13:28:01.373379       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:01.572157813Z E1024 13:28:01.572096       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:01.772067592Z E1024 13:28:01.771979       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:01.772133532Z I1024 13:28:01.772075       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:01.975621671Z E1024 13:28:01.975553       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:02.772538796Z E1024 13:28:02.772474       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:02.972353184Z E1024 13:28:02.972286       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:03.771818190Z E1024 13:28:03.771770       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:04.172047727Z E1024 13:28:04.171982       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:04.373656366Z E1024 13:28:04.373590       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:04.771793543Z E1024 13:28:04.771699       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:04.771793543Z I1024 13:28:04.771772       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:05.371282360Z E1024 13:28:05.371225       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:05.973243256Z E1024 13:28:05.973192       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:06.370379343Z E1024 13:28:06.370320       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:06.571893402Z E1024 13:28:06.571838       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:06.972202600Z E1024 13:28:06.972137       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:07.174611748Z E1024 13:28:07.174552       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:07.771540925Z E1024 13:28:07.771493       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:08.772484099Z E1024 13:28:08.772410       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:09.018014977Z E1024 13:28:09.017952       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:09.018080817Z I1024 13:28:09.018018       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:09.173913736Z E1024 13:28:09.173859       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:09.572656594Z E1024 13:28:09.572601       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:09.972276452Z E1024 13:28:09.972216       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:10.078836931Z E1024 13:28:10.078771       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:10.372555209Z E1024 13:28:10.372491       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:10.372624799Z I1024 13:28:10.372558       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:10.971664516Z E1024 13:28:10.971604       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:11.175005574Z E1024 13:28:11.174941       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:11.573911842Z E1024 13:28:11.573853       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:11.771786591Z E1024 13:28:11.771715       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:12.771808516Z E1024 13:28:12.771737       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:13.577447001Z E1024 13:28:13.577381       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:13.772417440Z E1024 13:28:13.772348       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:13.971594018Z E1024 13:28:13.971535       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:14.371460186Z E1024 13:28:14.371400       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:15.172253621Z E1024 13:28:15.172198       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:15.773604107Z E1024 13:28:15.773546       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:15.972445116Z E1024 13:28:15.972363       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:15.979794236Z E1024 13:28:15.979690       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3309593037038193071 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-0\" peerURLs:\"https://10.0.0.3:2380\" clientURLs:\"https://10.0.0.3:2379\"  Healthy:true Took:5.05586ms Error:<nil>} {Member:ID:5953405296437866173 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-2\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:4.80342ms Error:<nil>} {Member:ID:15496572367184033116 name:\"ci-op-2fcpj5j6-f6035-2lklf-master-1\" peerURLs:\"https://10.0.0.4:2380\" clientURLs:\"https://10.0.0.4:2379\"  Healthy:false Took:29.989495775s Error:health check failed: context deadline exceeded}]"
2024-10-24T13:28:16.372363633Z E1024 13:28:16.372318       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:16.771565981Z E1024 13:28:16.771511       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:16.970616950Z E1024 13:28:16.970548       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:17.571055596Z E1024 13:28:17.570997       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:18.362183271Z E1024 13:28:18.362120       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:28:18.363328231Z E1024 13:28:18.363265       1 leaderelection.go:436] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:18.372380601Z E1024 13:28:18.372314       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:18.575710860Z E1024 13:28:18.575618       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:18.972253997Z E1024 13:28:18.972205       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:19.772129982Z E1024 13:28:19.772072       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:19.971932441Z E1024 13:28:19.971877       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:20.372871969Z E1024 13:28:20.372726       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:20.771335216Z E1024 13:28:20.771260       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:20.971663065Z E1024 13:28:20.971602       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:20.971705195Z I1024 13:28:20.971657       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:21.571692481Z E1024 13:28:21.571622       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:22.373157716Z E1024 13:28:22.373097       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:22.573053925Z E1024 13:28:22.572986       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:22.773717844Z E1024 13:28:22.773663       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:23.172537932Z E1024 13:28:23.172466       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:23.571815059Z E1024 13:28:23.571715       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:23.972190546Z E1024 13:28:23.972128       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:24.371627784Z E1024 13:28:24.371568       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:24.771735411Z E1024 13:28:24.771651       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:25.171701989Z E1024 13:28:25.171641       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:25.571681677Z E1024 13:28:25.571626       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:25.972019754Z E1024 13:28:25.971947       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:26.372204121Z E1024 13:28:26.372136       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:26.771171608Z E1024 13:28:26.771126       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:27.172229616Z E1024 13:28:27.172167       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:27.572601843Z E1024 13:28:27.572536       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:27.971453151Z E1024 13:28:27.971395       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:28.771785186Z E1024 13:28:28.771703       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:29.374152232Z E1024 13:28:29.374083       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:29.515868491Z E1024 13:28:29.515811       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:29.515956631Z I1024 13:28:29.515900       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:29.576560951Z E1024 13:28:29.576504       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:29.972407118Z E1024 13:28:29.972362       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:30.372050656Z E1024 13:28:30.371986       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:30.561710135Z E1024 13:28:30.561670       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:31.171704901Z E1024 13:28:31.171648       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:31.372094220Z E1024 13:28:31.372032       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:31.771726647Z E1024 13:28:31.771665       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:32.171777825Z E1024 13:28:32.171699       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:32.571227062Z E1024 13:28:32.571167       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:32.971497490Z E1024 13:28:32.971427       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:33.371887207Z E1024 13:28:33.371835       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:33.772204225Z E1024 13:28:33.772138       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:34.171608952Z E1024 13:28:34.171525       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:34.571857520Z E1024 13:28:34.571804       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:34.972713488Z E1024 13:28:34.972644       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:35.372277945Z E1024 13:28:35.372228       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:35.771630643Z E1024 13:28:35.771570       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:36.171661610Z E1024 13:28:36.171604       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:36.571505777Z E1024 13:28:36.571452       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:36.971955795Z E1024 13:28:36.971900       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:37.372256422Z E1024 13:28:37.372195       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:37.770443930Z E1024 13:28:37.770388       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:37.971184579Z E1024 13:28:37.971130       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:38.371779777Z E1024 13:28:38.371712       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:38.771962924Z E1024 13:28:38.771904       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:39.171005612Z E1024 13:28:39.170947       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:39.571215328Z E1024 13:28:39.571152       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:40.171848735Z E1024 13:28:40.171795       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:40.971739131Z E1024 13:28:40.971687       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:41.172900809Z E1024 13:28:41.172850       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:41.570985507Z E1024 13:28:41.570942       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:41.770979985Z E1024 13:28:41.770922       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:41.771075835Z I1024 13:28:41.770994       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:42.171552233Z E1024 13:28:42.171504       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:42.571951541Z E1024 13:28:42.571898       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:42.972250298Z E1024 13:28:42.972190       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:43.173184387Z E1024 13:28:43.173128       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:43.571737555Z E1024 13:28:43.571681       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:43.972104322Z E1024 13:28:43.972048       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:44.362162350Z E1024 13:28:44.362075       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:28:44.362927260Z E1024 13:28:44.362887       1 leaderelection.go:436] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:44.371216410Z E1024 13:28:44.371171       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:44.771334308Z E1024 13:28:44.771283       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:45.171781895Z E1024 13:28:45.171693       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:45.572586823Z E1024 13:28:45.572517       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:45.972710620Z E1024 13:28:45.972640       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:46.372151078Z E1024 13:28:46.372091       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:46.771263236Z E1024 13:28:46.771211       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:47.171858033Z E1024 13:28:47.171792       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:47.572243791Z E1024 13:28:47.572188       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:47.972257209Z E1024 13:28:47.972196       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:48.285417567Z E1024 13:28:48.285347       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client_error: client error: 401"
2024-10-24T13:28:48.290832277Z I1024 13:28:48.290730       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:48.292047037Z E1024 13:28:48.291998       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.180166519bed17ab\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.180166519bed17ab  openshift-etcd-operator   27259 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-10-24 13:23:52 +0000 UTC,LastTimestamp:2024-10-24 13:28:48.290534527 +0000 UTC m=+641.067387179,Count:27,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-10-24T13:28:48.294571827Z I1024 13:28:48.294521       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:48.295566207Z E1024 13:28:48.295522       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:48.295618737Z I1024 13:28:48.295561       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:48.303876227Z I1024 13:28:48.303801       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:48.305287297Z I1024 13:28:48.305244       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:48.306158277Z E1024 13:28:48.306120       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:48.306158277Z I1024 13:28:48.306148       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:48.319374487Z I1024 13:28:48.319301       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:48.321168097Z I1024 13:28:48.321094       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:48.322423777Z E1024 13:28:48.322343       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:48.322474637Z I1024 13:28:48.322406       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:48.345726006Z I1024 13:28:48.345655       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:48.491623136Z I1024 13:28:48.491554       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:48.691223764Z E1024 13:28:48.691161       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:48.890440823Z E1024 13:28:48.890366       1 base_controller.go:271] "Unhandled Error" err="EtcdEndpointsController reconciliation failed: applying configmap update failed :Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:48.890502063Z I1024 13:28:48.890438       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:48.891241224Z E1024 13:28:48.891202       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.18016650a1555b11\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.18016650a1555b11  openshift-etcd-operator   27214 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-10-24 13:23:48 +0000 UTC,LastTimestamp:2024-10-24 13:28:48.890319503 +0000 UTC m=+641.667172135,Count:29,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-10-24T13:28:48.970605963Z E1024 13:28:48.970545       1 base_controller.go:271] "Unhandled Error" err="etcd-InstallerState reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:49.090805052Z E1024 13:28:49.090681       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:49.090805052Z I1024 13:28:49.090732       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:49.291961631Z E1024 13:28:49.291874       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:49.490820940Z I1024 13:28:49.490722       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:49.570852259Z E1024 13:28:49.570800       1 base_controller.go:271] "Unhandled Error" err="EtcdCertSignerController reconciliation failed: could not get current etcd-all-bundles configmap Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-all-bundles\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:49.576937959Z I1024 13:28:49.576876       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 13 triggered by "required configmap/etcd-pod has changed"
2024-10-24T13:28:49.577657799Z E1024 13:28:49.577614       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.18016696c23aa6b3  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:StartingNewRevision,Message:new revision 13 triggered by \"required configmap/etcd-pod has changed\",Source:EventSource{Component:openshift-cluster-etcd-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:28:49.576732339 +0000 UTC m=+642.353584981,LastTimestamp:2024-10-24 13:28:49.576732339 +0000 UTC m=+642.353584981,Count:1,Type:Normal,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:28:49.690953498Z I1024 13:28:49.690871       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:49.891023357Z E1024 13:28:49.890961       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:49.891090657Z I1024 13:28:49.891012       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:50.090811126Z E1024 13:28:50.090714       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:50.290786315Z E1024 13:28:50.290712       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:50.490495304Z I1024 13:28:50.490429       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:50.691184862Z E1024 13:28:50.691126       1 base_controller.go:271] "Unhandled Error" err="RevisionController reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-RevisionController\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-RevisionController&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:50.691236173Z I1024 13:28:50.691164       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 13: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:50.890886821Z E1024 13:28:50.890824       1 base_controller.go:271] "Unhandled Error" err="ScriptController reconciliation failed: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:50.891027081Z I1024 13:28:50.890944       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:50.891826531Z E1024 13:28:50.891770       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.180166510c22b409\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.180166510c22b409  openshift-etcd-operator   27269 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-10-24 13:23:50 +0000 UTC,LastTimestamp:2024-10-24 13:28:50.890781781 +0000 UTC m=+643.667634423,Count:28,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-10-24T13:28:51.016324381Z E1024 13:28:51.016268       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.180166519bed17ab\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.180166519bed17ab  openshift-etcd-operator   27259 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-10-24 13:23:52 +0000 UTC,LastTimestamp:2024-10-24 13:28:48.290534527 +0000 UTC m=+641.067387179,Count:27,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-10-24T13:28:51.091463120Z I1024 13:28:51.091389       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:51.291517099Z E1024 13:28:51.291444       1 base_controller.go:271] "Unhandled Error" err="BackingResourceController-StaticResources reconciliation failed: [\"manifests/installer-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"manifests/installer-cluster-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"BackingResourceController-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=BackingResourceController-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:51.490526238Z E1024 13:28:51.490453       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:51.490526238Z I1024 13:28:51.490500       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:51.690620846Z E1024 13:28:51.690531       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:51.891149515Z I1024 13:28:51.891095       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:52.090965014Z E1024 13:28:52.090917       1 base_controller.go:271] "Unhandled Error" err="EtcdStaticResources-StaticResources reconciliation failed: [\"etcd/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/svc.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/minimal-sm.yaml\" (string): Get \"https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-role.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/prometheus-rolebinding.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-sa.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-cr.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role\": dial tcp 172.30.0.1:443: connect: connection refused, \"etcd/backups-crb.yaml\" (string): Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb\": dial tcp 172.30.0.1:443: connect: connection refused, unable to ApplyStatus for operator using fieldManager \"EtcdStaticResources-StaticResources\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=EtcdStaticResources-StaticResources&force=true\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:28:52.291129443Z I1024 13:28:52.291037       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:52.491248661Z E1024 13:28:52.491203       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:52.491279351Z I1024 13:28:52.491244       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:52.691636920Z E1024 13:28:52.691579       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:52.891562969Z E1024 13:28:52.891513       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:53.091334397Z I1024 13:28:53.091263       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:53.291417386Z I1024 13:28:53.291351       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:53.490992325Z E1024 13:28:53.490924       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:53.691443484Z E1024 13:28:53.691378       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:53.691493494Z I1024 13:28:53.691429       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:53.890725063Z E1024 13:28:53.890664       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:54.090933322Z E1024 13:28:54.090870       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:54.335206660Z I1024 13:28:54.335130       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:54.491570959Z I1024 13:28:54.491499       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:54.566877709Z E1024 13:28:54.566825       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.18016650a1555b11\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.18016650a1555b11  openshift-etcd-operator   27214 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-10-24 13:23:48 +0000 UTC,LastTimestamp:2024-10-24 13:28:48.890319503 +0000 UTC m=+641.667172135,Count:29,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-10-24T13:28:54.691120538Z E1024 13:28:54.691040       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:54.891582666Z E1024 13:28:54.891509       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:54.891582666Z I1024 13:28:54.891561       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:55.091151105Z E1024 13:28:55.091098       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:55.291488344Z E1024 13:28:55.291427       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:55.571936172Z E1024 13:28:55.571876       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:55.972871750Z E1024 13:28:55.972799       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:56.174838939Z I1024 13:28:56.174770       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:56.176316699Z I1024 13:28:56.176252       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:56.291188738Z E1024 13:28:56.291130       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:56.291269748Z I1024 13:28:56.291184       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:56.491134957Z E1024 13:28:56.491072       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:56.771380795Z E1024 13:28:56.771323       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:57.172370013Z E1024 13:28:57.172306       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:57.571852980Z E1024 13:28:57.571812       1 base_controller.go:271] "Unhandled Error" err="TargetConfigController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:57.972849498Z E1024 13:28:57.972789       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:58.076283107Z E1024 13:28:58.076229       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.18016696c23aa6b3  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:StartingNewRevision,Message:new revision 13 triggered by \"required configmap/etcd-pod has changed\",Source:EventSource{Component:openshift-cluster-etcd-operator-revisioncontroller,Host:,},FirstTimestamp:2024-10-24 13:28:49.576732339 +0000 UTC m=+642.353584981,LastTimestamp:2024-10-24 13:28:49.576732339 +0000 UTC m=+642.353584981,Count:1,Type:Normal,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-revisioncontroller,ReportingInstance:,}"
2024-10-24T13:28:58.373521815Z E1024 13:28:58.373414       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:58.772316793Z E1024 13:28:58.772248       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:58.854314173Z I1024 13:28:58.854250       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:58.855527673Z I1024 13:28:58.855478       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:58.856898052Z E1024 13:28:58.856832       1 base_controller.go:271] "Unhandled Error" err="EtcdMembersController reconciliation failed: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:58.856898052Z I1024 13:28:58.856862       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:28:59.172312481Z E1024 13:28:59.172258       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:59.571730448Z E1024 13:28:59.571675       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:28:59.971614625Z E1024 13:28:59.971532       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:29:00.332855884Z E1024 13:29:00.332805       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.180166510c22b409\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.180166510c22b409  openshift-etcd-operator   27269 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-10-24 13:23:50 +0000 UTC,LastTimestamp:2024-10-24 13:28:50.890781781 +0000 UTC m=+643.667634423,Count:28,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-10-24T13:29:00.371991653Z E1024 13:29:00.371927       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:29:00.697788361Z I1024 13:29:00.697693       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 42.89 %, dbSize: 114200576
2024-10-24T13:29:00.697788361Z I1024 13:29:00.697715       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 42.55 %, dbSize: 113631232
2024-10-24T13:29:00.697788361Z I1024 13:29:00.697721       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 42.79 %, dbSize: 114241536
2024-10-24T13:29:00.771628951Z E1024 13:29:00.771566       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:29:01.017923140Z E1024 13:29:01.017867       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.180166519bed17ab\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.180166519bed17ab  openshift-etcd-operator   27259 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-10-24 13:23:52 +0000 UTC,LastTimestamp:2024-10-24 13:28:48.290534527 +0000 UTC m=+641.067387179,Count:27,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-10-24T13:29:01.172586628Z E1024 13:29:01.172515       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:29:01.615857366Z E1024 13:29:01.615786       1 base_controller.go:269] "Unhandled Error" err="\"TargetConfigController\" controller failed to sync \"\", err: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:29:04.019463391Z I1024 13:29:04.019381       1 helpers.go:184] lister was stale at resourceVersion=29460, live get showed resourceVersion=29685
2024-10-24T13:29:04.089149321Z I1024 13:29:04.089079       1 helpers.go:184] lister was stale at resourceVersion=29460, live get showed resourceVersion=29723
2024-10-24T13:29:33.950062101Z I1024 13:29:33.950012       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:42.065601659Z I1024 13:29:42.065544       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:42.954231084Z I1024 13:29:42.954167       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:43.889678138Z I1024 13:29:43.889608       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:45.138448749Z I1024 13:29:45.138378       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:47.074642927Z I1024 13:29:47.074593       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:48.308276199Z E1024 13:29:48.308201       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client query returned empty vector"
2024-10-24T13:29:48.310577219Z I1024 13:29:48.310512       1 helpers.go:184] lister was stale at resourceVersion=29460, live get showed resourceVersion=29725
2024-10-24T13:29:48.348516909Z I1024 13:29:48.348456       1 helpers.go:184] lister was stale at resourceVersion=29460, live get showed resourceVersion=29725
2024-10-24T13:29:49.499140842Z I1024 13:29:49.499073       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:49.600952911Z I1024 13:29:49.600883       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 13 triggered by "required configmap/etcd-pod has changed"
2024-10-24T13:29:50.548520875Z I1024 13:29:50.548438       1 reflector.go:368] Caches populated for *v1.Role from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:50.669624934Z I1024 13:29:50.669573       1 request.go:700] Waited for 1.068736263s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps
2024-10-24T13:29:51.869404176Z I1024 13:29:51.869350       1 request.go:700] Waited for 1.591825889s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:29:52.287249373Z I1024 13:29:52.287195       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-pod-13 -n openshift-etcd because it was missing
2024-10-24T13:29:52.869556360Z I1024 13:29:52.869505       1 request.go:700] Waited for 1.190911883s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:29:53.477555676Z I1024 13:29:53.477486       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-endpoints-13 -n openshift-etcd because it was missing
2024-10-24T13:29:53.869714934Z I1024 13:29:53.869661       1 request.go:700] Waited for 1.082620734s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets?resourceVersion=28808
2024-10-24T13:29:53.873317214Z I1024 13:29:53.873245       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:54.680534479Z I1024 13:29:54.680463       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-all-bundles-13 -n openshift-etcd because it was missing
2024-10-24T13:29:54.872674868Z I1024 13:29:54.872611       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:55.069620636Z I1024 13:29:55.069534       1 request.go:700] Waited for 1.363057891s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa
2024-10-24T13:29:55.690513132Z I1024 13:29:55.690456       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-all-certs-13 -n openshift-etcd because it was missing
2024-10-24T13:29:56.478310437Z I1024 13:29:56.478235       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 13 triggered by "required configmap/etcd-pod has changed"
2024-10-24T13:29:56.479650877Z W1024 13:29:56.479613       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:29:56.479650877Z W1024 13:29:56.479642       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:29:57.564498430Z I1024 13:29:57.564454       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:57.577037950Z I1024 13:29:57.576998       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:29:57.673129809Z I1024 13:29:57.673066       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:58.075462617Z I1024 13:29:58.075385       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:29:58.272394455Z I1024 13:29:58.272331       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:00.588440441Z I1024 13:30:00.588053       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:30:01.456108005Z I1024 13:30:01.456059       1 reflector.go:368] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:01.904684892Z I1024 13:30:01.904616       1 reflector.go:368] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:02.471868329Z I1024 13:30:02.471809       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:03.710072521Z I1024 13:30:03.708396       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:03.835738400Z I1024 13:30:03.835688       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:03.836675340Z I1024 13:30:03.836619       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.838351250Z I1024 13:30:03.838270       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.838931050Z I1024 13:30:03.838900       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.839264840Z I1024 13:30:03.839247       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.839985110Z I1024 13:30:03.839965       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.840338160Z I1024 13:30:03.840321       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.840856020Z I1024 13:30:03.840793       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.841883870Z I1024 13:30:03.841839       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.842352960Z I1024 13:30:03.842329       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.842936780Z I1024 13:30:03.842903       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.843307540Z I1024 13:30:03.843263       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.843470100Z I1024 13:30:03.843441       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.843943720Z I1024 13:30:03.843910       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.844415650Z I1024 13:30:03.844396       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.844806740Z I1024 13:30:03.844790       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.845248780Z I1024 13:30:03.845230       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.845511860Z I1024 13:30:03.845496       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.845795140Z I1024 13:30:03.845779       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.846087770Z I1024 13:30:03.846052       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.846342920Z I1024 13:30:03.846325       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.846579320Z I1024 13:30:03.846562       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.846851820Z I1024 13:30:03.846835       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.847097650Z I1024 13:30:03.847080       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.847293700Z I1024 13:30:03.847276       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.847493860Z I1024 13:30:03.847478       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.847687230Z I1024 13:30:03.847671       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.847910280Z I1024 13:30:03.847892       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.848018900Z I1024 13:30:03.847076       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 13 triggered by "required configmap/etcd-pod has changed"
2024-10-24T13:30:03.848161320Z I1024 13:30:03.848135       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.849013040Z I1024 13:30:03.848969       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.849173160Z I1024 13:30:03.849129       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.849363300Z I1024 13:30:03.849289       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.849467470Z I1024 13:30:03.849444       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.849625870Z I1024 13:30:03.849599       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.849869340Z I1024 13:30:03.849816       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:03.862237670Z I1024 13:30:03.862213       1 revision_controller.go:274] down the branch indicating that our cache was out of date and we're trying to recreate a revision.
2024-10-24T13:30:03.865319380Z W1024 13:30:03.865294       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:30:03.865378950Z W1024 13:30:03.865363       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:30:03.881057210Z I1024 13:30:03.881011       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:30:03.903573949Z W1024 13:30:03.903529       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:30:03.903573949Z W1024 13:30:03.903548       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:30:03.915348449Z I1024 13:30:03.915271       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:30:03.942194879Z W1024 13:30:03.942133       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:30:03.942194879Z W1024 13:30:03.942153       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:30:03.984671419Z W1024 13:30:03.984604       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:30:03.984671419Z W1024 13:30:03.984626       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:30:04.049921239Z W1024 13:30:04.049852       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:30:04.049921239Z W1024 13:30:04.049885       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:30:04.162418648Z W1024 13:30:04.162345       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:30:04.162418648Z W1024 13:30:04.162375       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:30:04.307888487Z I1024 13:30:04.307829       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:04.345870407Z W1024 13:30:04.345794       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:30:04.345870407Z W1024 13:30:04.345829       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:30:04.415107166Z I1024 13:30:04.415048       1 reflector.go:368] Caches populated for *v1.Etcd from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:04.689515145Z W1024 13:30:04.689458       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:30:04.689515145Z W1024 13:30:04.689484       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:30:04.893502123Z I1024 13:30:04.893434       1 reflector.go:368] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:05.354412580Z W1024 13:30:05.354356       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:30:05.354412580Z W1024 13:30:05.354376       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:30:06.660535602Z W1024 13:30:06.660460       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:30:06.660535602Z W1024 13:30:06.660494       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:30:07.895150884Z I1024 13:30:07.895083       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:30:09.246484395Z W1024 13:30:09.246418       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:30:09.246484395Z W1024 13:30:09.246441       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:30:09.820832602Z I1024 13:30:09.820766       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:09.822882982Z W1024 13:30:09.822831       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:30:09.822882982Z W1024 13:30:09.822852       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:30:09.849447111Z W1024 13:30:09.849340       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:30:09.849447111Z W1024 13:30:09.849363       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:30:09.853043021Z I1024 13:30:09.853007       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:30:09.880306621Z I1024 13:30:09.880273       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:30:10.364149338Z I1024 13:30:10.364089       1 reflector.go:368] Caches populated for *v1.Job from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:10.744500306Z I1024 13:30:10.744433       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:30:11.210946913Z I1024 13:30:11.210794       1 reflector.go:368] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:13.442589409Z I1024 13:30:13.442528       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:14.396842543Z W1024 13:30:14.396787       1 dynamic_operator_client.go:343] .status.conditions["RevisionControllerDegraded"].reason is missing; this will eventually be fatal
2024-10-24T13:30:14.396842543Z W1024 13:30:14.396811       1 dynamic_operator_client.go:346] .status.conditions["RevisionControllerDegraded"].message is missing; this will eventually be fatal
2024-10-24T13:30:17.975386020Z I1024 13:30:17.975344       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:30:20.956943391Z I1024 13:30:20.956891       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:30:24.087345182Z I1024 13:30:24.087267       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:26.250107418Z I1024 13:30:26.250060       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:29.355954828Z I1024 13:30:29.355914       1 reflector.go:368] Caches populated for *v1beta1.Machine from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:30.249877192Z I1024 13:30:30.249799       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=etcds from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:30.251182242Z I1024 13:30:30.251129       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:30.252946352Z I1024 13:30:30.252908       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nTargetConfigControllerDegraded: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod\": dial tcp 172.30.0.1:443: connect: connection refused\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:27:29Z","message":"NodeInstallerProgressing: 3 nodes are at revision 12\nEtcdMembersProgressing: No unstarted etcd members found","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 12\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:30:30.276410372Z I1024 13:30:30.276362       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy" to "NodeControllerDegraded: All master nodes are ready\nTargetConfigControllerDegraded: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod\": dial tcp 172.30.0.1:443: connect: connection refused\nEtcdMembersDegraded: No unhealthy members found",Available message changed from "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 12\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-1 is unhealthy" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 12\nEtcdMembersAvailable: 3 members are available"
2024-10-24T13:30:30.291119102Z I1024 13:30:30.290067       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:30:30.305366152Z I1024 13:30:30.305314       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:30.305507272Z I1024 13:30:30.305482       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:27:29Z","message":"NodeInstallerProgressing: 3 nodes are at revision 12\nEtcdMembersProgressing: No unstarted etcd members found","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 12\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:30:30.314074192Z I1024 13:30:30.313799       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 38.05 %, dbSize: 114200576
2024-10-24T13:30:30.314147092Z I1024 13:30:30.314119       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 37.72 %, dbSize: 113631232
2024-10-24T13:30:30.314184282Z I1024 13:30:30.314169       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 37.97 %, dbSize: 114241536
2024-10-24T13:30:30.324778212Z I1024 13:30:30.324298       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nTargetConfigControllerDegraded: \"configmap/etcd-pod\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod\": dial tcp 172.30.0.1:443: connect: connection refused\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found"
2024-10-24T13:30:30.338518322Z I1024 13:30:30.338465       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:30:30.367856491Z I1024 13:30:30.367795       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 38.03 %, dbSize: 114200576
2024-10-24T13:30:30.367856491Z I1024 13:30:30.367821       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 37.69 %, dbSize: 113631232
2024-10-24T13:30:30.367856491Z I1024 13:30:30.367828       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 37.97 %, dbSize: 114241536
2024-10-24T13:30:31.371390545Z I1024 13:30:31.371323       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:30:31.451076974Z I1024 13:30:31.451018       1 request.go:700] Waited for 1.144265332s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-10-24T13:30:32.651743177Z I1024 13:30:32.651669       1 request.go:700] Waited for 1.079923003s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/configmaps?resourceVersion=29240
2024-10-24T13:30:32.670698967Z I1024 13:30:32.670650       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:34.261490717Z I1024 13:30:34.261418       1 installer_controller.go:534] node ci-op-2fcpj5j6-f6035-2lklf-master-2 with revision 12 is the oldest and needs new revision 13
2024-10-24T13:30:34.261557307Z I1024 13:30:34.261516       1 installer_controller.go:542] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:30:34.261557307Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:30:34.261557307Z  CurrentRevision: (int32) 12,
2024-10-24T13:30:34.261557307Z  TargetRevision: (int32) 13,
2024-10-24T13:30:34.261557307Z  LastFailedRevision: (int32) 5,
2024-10-24T13:30:34.261557307Z  LastFailedTime: (*v1.Time)(0xc002797638)(2024-10-24 13:11:34 +0000 UTC),
2024-10-24T13:30:34.261557307Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:30:34.261557307Z  LastFailedCount: (int) 1,
2024-10-24T13:30:34.261557307Z  LastFallbackCount: (int) 0,
2024-10-24T13:30:34.261557307Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:30:34.261557307Z   (string) (len=2059) "installer:  172.30.0.1:443: connect: connection refused\nW1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:30:34.261557307Z  }
2024-10-24T13:30:34.261557307Z }
2024-10-24T13:30:34.284248387Z I1024 13:30:34.284173       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 12 to 13 because node ci-op-2fcpj5j6-f6035-2lklf-master-2 with revision 12 is the oldest
2024-10-24T13:30:34.285782876Z I1024 13:30:34.285738       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:30:34.286069526Z I1024 13:30:34.286042       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 3 nodes are at revision 12; 0 nodes have achieved new revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 12; 0 nodes have achieved new revision 13\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:30:34.300468496Z I1024 13:30:34.300430       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing changed from False to True ("NodeInstallerProgressing: 3 nodes are at revision 12; 0 nodes have achieved new revision 13"),Available message changed from "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 12\nEtcdMembersAvailable: 3 members are available" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 12; 0 nodes have achieved new revision 13\nEtcdMembersAvailable: 3 members are available"
2024-10-24T13:30:34.319058416Z I1024 13:30:34.318999       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:30:34.334792756Z I1024 13:30:34.334699       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 37.74 %, dbSize: 114200576
2024-10-24T13:30:34.334792756Z I1024 13:30:34.334719       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 37.41 %, dbSize: 113631232
2024-10-24T13:30:34.334792756Z I1024 13:30:34.334725       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 37.68 %, dbSize: 114241536
2024-10-24T13:30:34.476673465Z I1024 13:30:34.476571       1 reflector.go:368] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:35.451706009Z I1024 13:30:35.451648       1 request.go:700] Waited for 1.164947912s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-10-24T13:30:36.678979072Z I1024 13:30:36.678926       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2 -n openshift-etcd because it was missing
2024-10-24T13:30:37.251818938Z I1024 13:30:37.251715       1 request.go:700] Waited for 1.124351233s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config/configmaps?resourceVersion=28852
2024-10-24T13:30:37.255691628Z I1024 13:30:37.255632       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:38.060171552Z I1024 13:30:38.060101       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 13, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:30:39.857933971Z I1024 13:30:39.857869       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 13, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:30:40.360670618Z I1024 13:30:40.360609       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:42.253684836Z I1024 13:30:42.253639       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:44.724515810Z I1024 13:30:44.724449       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:30:48.289220358Z E1024 13:30:48.289148       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client query returned empty vector"
2024-10-24T13:30:48.868277804Z I1024 13:30:48.868233       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:30:49.607902129Z I1024 13:30:49.607858       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:31:09.463108191Z I1024 13:31:09.463021       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:31:10.346060096Z I1024 13:31:10.345991       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 13, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:31:12.651664421Z I1024 13:31:12.651594       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 13, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:31:19.643675496Z I1024 13:31:19.643614       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:31:42.570982068Z I1024 13:31:42.570929       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 13, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:31:44.755190906Z I1024 13:31:44.755125       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 13, but has not made progress because waiting for static pod of revision 13, found 12
2024-10-24T13:31:48.316959986Z I1024 13:31:48.316896       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:31:48.349064065Z I1024 13:31:48.349008       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:31:49.554803628Z I1024 13:31:49.554726       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 13, but has not made progress because waiting for static pod of revision 13, found 12
2024-10-24T13:31:49.594924238Z I1024 13:31:49.594860       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:31:55.838435069Z I1024 13:31:55.838361       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 13, but has not made progress because waiting for static pod of revision 13, found 12
2024-10-24T13:32:12.552007360Z E1024 13:32:12.551943       1 health.go:115] health check for member (ci-op-2fcpj5j6-f6035-2lklf-master-2) failed: err(context deadline exceeded)
2024-10-24T13:32:12.552175611Z W1024 13:32:12.552120       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-2fcpj5j6-f6035-2lklf-master-2]
2024-10-24T13:32:18.275558878Z E1024 13:32:18.275483       1 health.go:115] health check for member (ci-op-2fcpj5j6-f6035-2lklf-master-2) failed: err(context deadline exceeded)
2024-10-24T13:32:18.275692569Z E1024 13:32:18.275655       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-2fcpj5j6-f6035-2lklf-master-2, took=29.991748363s, err=health check failed: context deadline exceeded
2024-10-24T13:32:18.275951809Z E1024 13:32:18.275903       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy"
2024-10-24T13:32:18.283493869Z E1024 13:32:18.283462       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy"
2024-10-24T13:32:18.295121108Z E1024 13:32:18.295087       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy"
2024-10-24T13:32:18.302483828Z I1024 13:32:18.302458       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:32:18.302715288Z E1024 13:32:18.302689       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy"
2024-10-24T13:32:18.303366958Z I1024 13:32:18.303343       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 3 nodes are at revision 12; 0 nodes have achieved new revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 12; 0 nodes have achieved new revision 13\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:32:18.315920768Z I1024 13:32:18.314606       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy"
2024-10-24T13:32:18.317285718Z E1024 13:32:18.316678       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy"
2024-10-24T13:32:18.335530228Z I1024 13:32:18.335462       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:32:18.356085528Z E1024 13:32:18.356026       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy"
2024-10-24T13:32:18.357927847Z I1024 13:32:18.357846       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 3 nodes are at revision 12; 0 nodes have achieved new revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 12; 0 nodes have achieved new revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:32:18.358386018Z I1024 13:32:18.358366       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:32:18.373260107Z I1024 13:32:18.373193       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Available message changed from "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 12; 0 nodes have achieved new revision 13\nEtcdMembersAvailable: 3 members are available" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 12; 0 nodes have achieved new revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy"
2024-10-24T13:32:18.385504207Z I1024 13:32:18.385453       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:32:18.399088727Z E1024 13:32:18.399034       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy"
2024-10-24T13:32:18.714193222Z I1024 13:32:18.714121       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 13, but has not made progress because waiting for static pod of revision 13, found 12
2024-10-24T13:32:18.721326702Z E1024 13:32:18.721287       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy"
2024-10-24T13:32:19.362987383Z E1024 13:32:19.362925       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy"
2024-10-24T13:32:19.501997841Z I1024 13:32:19.501930       1 request.go:700] Waited for 1.142993074s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-10-24T13:32:20.645325025Z E1024 13:32:20.645264       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy"
2024-10-24T13:32:20.902091382Z I1024 13:32:20.902020       1 request.go:700] Waited for 1.024675435s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:32:22.102139344Z I1024 13:32:22.102071       1 request.go:700] Waited for 1.38762593s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-10-24T13:32:22.715236895Z I1024 13:32:22.715191       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 13, but has not made progress because static pod is pending
2024-10-24T13:32:23.207874438Z E1024 13:32:23.207786       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy"
2024-10-24T13:32:23.302834837Z I1024 13:32:23.302784       1 request.go:700] Waited for 1.390608s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:32:24.502001380Z I1024 13:32:24.501928       1 request.go:700] Waited for 1.185194223s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:32:25.502606045Z I1024 13:32:25.502551       1 request.go:700] Waited for 1.194419073s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-10-24T13:32:26.312215914Z I1024 13:32:26.312154       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-2" is in transition to 13, but has not made progress because static pod is pending
2024-10-24T13:32:26.703274679Z E1024 13:32:26.703199       1 guard_controller.go:366] Unable to apply pod etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2 changes: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:26.705089528Z W1024 13:32:26.705053       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:26.705124079Z E1024 13:32:26.705106       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: Unable to apply pod etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2 changes: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:26.903786346Z I1024 13:32:26.903664       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 13 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:26.904419156Z E1024 13:32:26.904386       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.180166c95bea42b6  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 13 count 1 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:32:26.903519926 +0000 UTC m=+859.680372568,LastTimestamp:2024-10-24 13:32:26.903519926 +0000 UTC m=+859.680372568,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:32:26.905021116Z E1024 13:32:26.904987       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:27.503220088Z I1024 13:32:27.503153       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 13 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:27.504462777Z E1024 13:32:27.504430       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:27.704613444Z E1024 13:32:27.704557       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:28.103617339Z I1024 13:32:28.103539       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 13 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:28.105024299Z E1024 13:32:28.104959       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:28.329660356Z E1024 13:32:28.329604       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy"
2024-10-24T13:32:28.505614733Z W1024 13:32:28.505548       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:28.505614733Z E1024 13:32:28.505598       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:28.703635600Z I1024 13:32:28.703538       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 13 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:28.704955710Z E1024 13:32:28.704901       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:29.303905552Z I1024 13:32:29.303744       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 13 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:29.305253442Z E1024 13:32:29.305185       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:29.453664380Z E1024 13:32:29.453588       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.180166c95bea42b6  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 13 count 1 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:32:26.903519926 +0000 UTC m=+859.680372568,LastTimestamp:2024-10-24 13:32:26.903519926 +0000 UTC m=+859.680372568,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:32:29.505915659Z E1024 13:32:29.505805       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:29.903514173Z I1024 13:32:29.903452       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 13 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:29.904931483Z E1024 13:32:29.904891       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:30.303992737Z W1024 13:32:30.303953       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:30.304053237Z E1024 13:32:30.303993       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:30.503494995Z I1024 13:32:30.503410       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 13 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:30.505001575Z E1024 13:32:30.504965       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:31.104485456Z E1024 13:32:31.104429       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:31.303178683Z I1024 13:32:31.303101       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 13 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:31.304231313Z E1024 13:32:31.304196       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:31.905278275Z W1024 13:32:31.905216       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:31.905360375Z E1024 13:32:31.905282       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:32.503577966Z I1024 13:32:32.503508       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 13 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:32.504828667Z E1024 13:32:32.504773       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:32.705037954Z E1024 13:32:32.704971       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:33.305423895Z W1024 13:32:33.305356       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:33.305482325Z E1024 13:32:33.305421       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:33.904386107Z E1024 13:32:33.904291       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:34.303058121Z I1024 13:32:34.302975       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 13 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:34.304230061Z E1024 13:32:34.304194       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:34.705075485Z W1024 13:32:34.705020       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:34.705125565Z E1024 13:32:34.705069       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:35.304418887Z E1024 13:32:35.304347       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:35.905915918Z W1024 13:32:35.905854       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:35.905971938Z E1024 13:32:35.905927       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:36.505355039Z E1024 13:32:36.505275       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:36.904831554Z W1024 13:32:36.904746       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:36.904885214Z E1024 13:32:36.904831       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:37.302818338Z I1024 13:32:37.302708       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 13 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:37.303987358Z E1024 13:32:37.303948       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:38.104987717Z E1024 13:32:38.104922       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:38.304826014Z W1024 13:32:38.304779       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:38.304878364Z E1024 13:32:38.304837       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:38.446890272Z E1024 13:32:38.446803       1 leaderelection.go:429] Failed to update lock optimitically: Put "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused, falling back to slow path
2024-10-24T13:32:38.447580002Z E1024 13:32:38.447534       1 leaderelection.go:436] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:38.571596810Z E1024 13:32:38.571526       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy"
2024-10-24T13:32:38.904405275Z W1024 13:32:38.904342       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:38.904459856Z E1024 13:32:38.904398       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:39.455017288Z E1024 13:32:39.454957       1 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.180166c95bea42b6  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:bff212df-2809-4dd6-8cc1-b1e11e66ac01,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 13 count 1 on node \"ci-op-2fcpj5j6-f6035-2lklf-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-10-24 13:32:26.903519926 +0000 UTC m=+859.680372568,LastTimestamp:2024-10-24 13:32:26.903519926 +0000 UTC m=+859.680372568,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-10-24T13:32:39.504282657Z E1024 13:32:39.504232       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:40.105656039Z W1024 13:32:40.105586       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:40.105720989Z E1024 13:32:40.105654       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:40.790145219Z E1024 13:32:40.790083       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:42.427671526Z I1024 13:32:42.427614       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 13 count 1 on node "ci-op-2fcpj5j6-f6035-2lklf-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:42.428908726Z E1024 13:32:42.428876       1 base_controller.go:271] "Unhandled Error" err="InstallerController reconciliation failed: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:42.558360394Z E1024 13:32:42.558283       1 health.go:115] health check for member (ci-op-2fcpj5j6-f6035-2lklf-master-2) failed: err(context deadline exceeded)
2024-10-24T13:32:42.558514594Z W1024 13:32:42.558452       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-2fcpj5j6-f6035-2lklf-master-2]
2024-10-24T13:32:43.355979643Z E1024 13:32:43.355933       1 base_controller.go:271] "Unhandled Error" err="etcd-StaticPodState reconciliation failed: unable to ApplyStatus for operator using fieldManager \"etcd-StaticPodState\": Patch \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=etcd-StaticPodState&force=true\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-10-24T13:32:45.232858666Z W1024 13:32:45.232804       1 base_controller.go:234] Updating status of "GuardController" failed: unable to ApplyStatus for operator using fieldManager "GuardController-reportDegraded": Patch "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status?fieldManager=GuardController-reportDegraded&force=true": dial tcp 172.30.0.1:443: connect: connection refused
2024-10-24T13:32:45.233003616Z E1024 13:32:45.232977       1 base_controller.go:271] "Unhandled Error" err="GuardController reconciliation failed: [Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-1\": dial tcp 172.30.0.1:443: connect: connection refused, Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-2\": dial tcp 172.30.0.1:443: connect: connection refused]"
2024-10-24T13:32:48.270974263Z E1024 13:32:48.270915       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-2fcpj5j6-f6035-2lklf-master-2, took=29.991748363s, err=health check failed: context deadline exceeded
2024-10-24T13:32:48.286811382Z E1024 13:32:48.286772       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client_error: client error: 401"
2024-10-24T13:32:48.307053792Z E1024 13:32:48.307020       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client_error: client error: 401"
2024-10-24T13:32:48.332416972Z E1024 13:32:48.332379       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client_error: client error: 401"
2024-10-24T13:32:48.365551511Z E1024 13:32:48.365512       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client_error: client error: 401"
2024-10-24T13:32:48.365865411Z E1024 13:32:48.365826       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy"
2024-10-24T13:32:48.420479451Z E1024 13:32:48.420408       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client_error: client error: 401"
2024-10-24T13:32:48.513836219Z E1024 13:32:48.513788       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client_error: client error: 401"
2024-10-24T13:32:48.686509307Z E1024 13:32:48.686460       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client_error: client error: 401"
2024-10-24T13:32:49.020473282Z E1024 13:32:49.020428       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client_error: client error: 401"
2024-10-24T13:32:49.641929713Z I1024 13:32:49.641855       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:32:49.673509583Z E1024 13:32:49.673472       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client_error: client error: 401"
2024-10-24T13:32:50.966658384Z E1024 13:32:50.966602       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client_error: client error: 401"
2024-10-24T13:32:52.690441850Z I1024 13:32:52.690363       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:32:52.690441850Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:32:52.690441850Z  CurrentRevision: (int32) 13,
2024-10-24T13:32:52.690441850Z  TargetRevision: (int32) 0,
2024-10-24T13:32:52.690441850Z  LastFailedRevision: (int32) 5,
2024-10-24T13:32:52.690441850Z  LastFailedTime: (*v1.Time)(0xc001f36c18)(2024-10-24 13:11:34 +0000 UTC),
2024-10-24T13:32:52.690441850Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:32:52.690441850Z  LastFailedCount: (int) 1,
2024-10-24T13:32:52.690441850Z  LastFallbackCount: (int) 0,
2024-10-24T13:32:52.690441850Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:32:52.690441850Z   (string) (len=2059) "installer:  172.30.0.1:443: connect: connection refused\nW1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:32:52.690441850Z  }
2024-10-24T13:32:52.690441850Z }
2024-10-24T13:32:52.690441850Z  because static pod is ready
2024-10-24T13:32:52.713858070Z I1024 13:32:52.713801       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-2" from revision 12 to 13 because static pod is ready
2024-10-24T13:32:53.540896728Z E1024 13:32:53.540830       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client_error: client error: 401"
2024-10-24T13:32:58.674613415Z E1024 13:32:58.674542       1 base_controller.go:271] "Unhandled Error" err="FSyncController reconciliation failed: client_error: client error: 401"
2024-10-24T13:32:59.054015710Z E1024 13:32:59.053943       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy"
2024-10-24T13:33:01.910888879Z I1024 13:33:01.910823       1 reflector.go:368] Caches populated for *v1.Pod from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:02.113000466Z I1024 13:33:02.112943       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:33:02.113000466Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:33:02.113000466Z  CurrentRevision: (int32) 13,
2024-10-24T13:33:02.113000466Z  TargetRevision: (int32) 0,
2024-10-24T13:33:02.113000466Z  LastFailedRevision: (int32) 5,
2024-10-24T13:33:02.113000466Z  LastFailedTime: (*v1.Time)(0xc0038a1170)(2024-10-24 13:11:34 +0000 UTC),
2024-10-24T13:33:02.113000466Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:33:02.113000466Z  LastFailedCount: (int) 1,
2024-10-24T13:33:02.113000466Z  LastFallbackCount: (int) 0,
2024-10-24T13:33:02.113000466Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:33:02.113000466Z   (string) (len=2059) "installer:  172.30.0.1:443: connect: connection refused\nW1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:33:02.113000466Z  }
2024-10-24T13:33:02.113000466Z }
2024-10-24T13:33:02.113000466Z  because static pod is ready
2024-10-24T13:33:02.153663095Z I1024 13:33:02.153606       1 helpers.go:260] lister was stale at resourceVersion=31764, live get showed resourceVersion=31979
2024-10-24T13:33:03.914595910Z I1024 13:33:03.914515       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-2" moving to (v1.NodeStatus) {
2024-10-24T13:33:03.914595910Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-2",
2024-10-24T13:33:03.914595910Z  CurrentRevision: (int32) 13,
2024-10-24T13:33:03.914595910Z  TargetRevision: (int32) 0,
2024-10-24T13:33:03.914595910Z  LastFailedRevision: (int32) 5,
2024-10-24T13:33:03.914595910Z  LastFailedTime: (*v1.Time)(0xc0019d8198)(2024-10-24 13:11:34 +0000 UTC),
2024-10-24T13:33:03.914595910Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-10-24T13:33:03.914595910Z  LastFailedCount: (int) 1,
2024-10-24T13:33:03.914595910Z  LastFallbackCount: (int) 0,
2024-10-24T13:33:03.914595910Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-10-24T13:33:03.914595910Z   (string) (len=2059) "installer:  172.30.0.1:443: connect: connection refused\nW1024 13:09:11.245859       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:21.246355       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:31.244720       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:41.245006       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:09:51.245434       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.245005       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW1024 13:10:01.246460       1 cmd.go:466] Error getting installer pods on current node ci-op-2fcpj5j6-f6035-2lklf-master-2: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF1024 13:10:01.246502       1 cmd.go:105] timed out waiting for the condition\n"
2024-10-24T13:33:03.914595910Z  }
2024-10-24T13:33:03.914595910Z }
2024-10-24T13:33:03.914595910Z  because static pod is ready
2024-10-24T13:33:03.948940020Z I1024 13:33:03.948850       1 helpers.go:260] lister was stale at resourceVersion=31764, live get showed resourceVersion=31979
2024-10-24T13:33:04.125026737Z I1024 13:33:04.124948       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:05.740025814Z I1024 13:33:05.739977       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:05.770810194Z I1024 13:33:05.770762       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:33:05.799389643Z I1024 13:33:05.799317       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:33:06.228268547Z I1024 13:33:06.228212       1 reflector.go:368] Caches populated for *v1.Job from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:07.669355747Z I1024 13:33:07.669292       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:08.656667993Z I1024 13:33:08.656611       1 reflector.go:368] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:09.267132394Z I1024 13:33:09.267064       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:09.576287540Z I1024 13:33:09.576141       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:09.600365340Z I1024 13:33:09.600291       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:33:09.627786049Z I1024 13:33:09.627677       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:33:09.657943969Z I1024 13:33:09.657862       1 reflector.go:368] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:09.725638598Z I1024 13:33:09.725570       1 reflector.go:368] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:11.217807067Z I1024 13:33:11.217734       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:33:12.821528654Z I1024 13:33:12.821455       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:13.815708960Z I1024 13:33:13.815651       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:13.847816919Z I1024 13:33:13.847731       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:33:13.869518199Z I1024 13:33:13.869471       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:33:14.522148130Z I1024 13:33:14.522090       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:33:15.465548876Z I1024 13:33:15.465495       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:21.469236391Z I1024 13:33:21.469179       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:33:29.637702275Z I1024 13:33:29.637643       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=etcds from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:29.638057325Z I1024 13:33:29.638008       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:29.640304815Z I1024 13:33:29.640261       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:29.654924445Z I1024 13:33:29.654881       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 12; 0 nodes have achieved new revision 13" to "NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13",Available message changed from "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 12; 0 nodes have achieved new revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy" to "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy"
2024-10-24T13:33:29.672479874Z I1024 13:33:29.672414       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:33:29.708037344Z I1024 13:33:29.707992       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 32.11 %, dbSize: 114241536
2024-10-24T13:33:29.708037344Z I1024 13:33:29.708012       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 31.75 %, dbSize: 113631232
2024-10-24T13:33:29.708037344Z I1024 13:33:29.708019       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 32.13 %, dbSize: 114200576
2024-10-24T13:33:30.048981709Z I1024 13:33:30.048911       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:30.055554599Z E1024 13:33:30.055526       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:30.057251949Z I1024 13:33:30.057210       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:30.064529309Z E1024 13:33:30.064459       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:30.066120799Z I1024 13:33:30.066096       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:30.075446259Z E1024 13:33:30.075405       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:30.076873409Z I1024 13:33:30.076842       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:30.086836279Z E1024 13:33:30.086793       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:30.097876238Z I1024 13:33:30.097833       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:30.105039448Z E1024 13:33:30.104990       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:30.187102567Z I1024 13:33:30.187024       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:30.195180187Z E1024 13:33:30.195118       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:30.357967455Z I1024 13:33:30.357901       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:30.367086295Z E1024 13:33:30.367033       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:30.689453240Z I1024 13:33:30.689333       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:30.700422420Z E1024 13:33:30.700362       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:30.709713130Z I1024 13:33:30.709665       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:31.047983545Z I1024 13:33:31.047913       1 installer_controller.go:534] node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 12 is the oldest and needs new revision 13
2024-10-24T13:33:31.047983545Z I1024 13:33:31.047953       1 installer_controller.go:542] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:33:31.047983545Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:33:31.047983545Z  CurrentRevision: (int32) 12,
2024-10-24T13:33:31.047983545Z  TargetRevision: (int32) 13,
2024-10-24T13:33:31.047983545Z  LastFailedRevision: (int32) 0,
2024-10-24T13:33:31.047983545Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:33:31.047983545Z  LastFailedReason: (string) "",
2024-10-24T13:33:31.047983545Z  LastFailedCount: (int) 0,
2024-10-24T13:33:31.047983545Z  LastFallbackCount: (int) 0,
2024-10-24T13:33:31.047983545Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:33:31.047983545Z }
2024-10-24T13:33:31.074873414Z I1024 13:33:31.074786       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 12 to 13 because node ci-op-2fcpj5j6-f6035-2lklf-master-0 with revision 12 is the oldest
2024-10-24T13:33:31.077744494Z I1024 13:33:31.077684       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:31.078241094Z I1024 13:33:31.078200       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:31.087060404Z E1024 13:33:31.086991       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:31.107625374Z I1024 13:33:31.107565       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:33:31.127043304Z I1024 13:33:31.126982       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 32.07 %, dbSize: 114241536
2024-10-24T13:33:31.127043304Z I1024 13:33:31.127005       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 31.71 %, dbSize: 113631232
2024-10-24T13:33:31.127043304Z I1024 13:33:31.127022       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 32.10 %, dbSize: 114200576
2024-10-24T13:33:31.342364871Z I1024 13:33:31.342306       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:31.349325760Z E1024 13:33:31.349281       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:32.239219468Z I1024 13:33:32.239144       1 request.go:700] Waited for 1.157315224s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-10-24T13:33:32.860571309Z I1024 13:33:32.860505       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-0 -n openshift-etcd because it was missing
2024-10-24T13:33:33.246044033Z I1024 13:33:33.245995       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:33.260430883Z E1024 13:33:33.260364       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:33.262601993Z I1024 13:33:33.262553       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:33.271259453Z E1024 13:33:33.271212       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:33.645314738Z I1024 13:33:33.645265       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:33:33.911165044Z I1024 13:33:33.911111       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:33.924304754Z E1024 13:33:33.924248       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:34.039188772Z I1024 13:33:34.039105       1 request.go:700] Waited for 1.177971814s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:33:35.042839148Z I1024 13:33:35.042653       1 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:35.238605355Z I1024 13:33:35.238537       1 request.go:700] Waited for 1.188931443s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:33:35.644012320Z I1024 13:33:35.643963       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:33:35.760449968Z I1024 13:33:35.760392       1 reflector.go:368] Caches populated for *v1beta1.Machine from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:36.246408621Z I1024 13:33:36.246276       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:36.257045791Z E1024 13:33:36.257001       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:36.259007841Z I1024 13:33:36.258966       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:36.271254191Z E1024 13:33:36.271221       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:36.973583901Z I1024 13:33:36.973512       1 reflector.go:368] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:37.045516710Z I1024 13:33:37.045458       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:33:38.049776255Z I1024 13:33:38.049687       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:38.059063195Z E1024 13:33:38.059019       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:38.060731045Z I1024 13:33:38.060701       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:38.070561575Z E1024 13:33:38.070468       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:38.642670857Z I1024 13:33:38.642606       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:38.645675437Z I1024 13:33:38.645647       1 reflector.go:368] Caches populated for *v1.Role from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:41.055220763Z I1024 13:33:41.055141       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:41.897651111Z I1024 13:33:41.897588       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:33:42.337262894Z I1024 13:33:42.337199       1 reflector.go:368] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:42.818382508Z I1024 13:33:42.818288       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:42.981840755Z I1024 13:33:42.981772       1 reflector.go:368] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:45.705367926Z I1024 13:33:45.705301       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:45.706536127Z I1024 13:33:45.706464       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.711845446Z I1024 13:33:45.709065       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.712209376Z I1024 13:33:45.712164       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.712523456Z I1024 13:33:45.712485       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.713093156Z I1024 13:33:45.713051       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.715297596Z I1024 13:33:45.715255       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.715721306Z I1024 13:33:45.715668       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.715934486Z I1024 13:33:45.715908       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.716383706Z I1024 13:33:45.716253       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.716770796Z I1024 13:33:45.716730       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.717139636Z I1024 13:33:45.717097       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.717524776Z I1024 13:33:45.717454       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.717853396Z I1024 13:33:45.717833       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.721241516Z I1024 13:33:45.721203       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.721469616Z I1024 13:33:45.721441       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.723644156Z I1024 13:33:45.723610       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.724286346Z I1024 13:33:45.724228       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.727814056Z I1024 13:33:45.727704       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.728158876Z I1024 13:33:45.728125       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.729041226Z I1024 13:33:45.728382       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.729041226Z I1024 13:33:45.728578       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.729041226Z I1024 13:33:45.728715       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.735887306Z I1024 13:33:45.734836       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.741049656Z I1024 13:33:45.741009       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.743568216Z I1024 13:33:45.743547       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.746538576Z I1024 13:33:45.746493       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:33:45.747082396Z I1024 13:33:45.747062       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.748271136Z I1024 13:33:45.748250       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.750347096Z I1024 13:33:45.750326       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.756709386Z I1024 13:33:45.756683       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.758285216Z I1024 13:33:45.758246       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.770565276Z I1024 13:33:45.770528       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:33:45.774119355Z I1024 13:33:45.774081       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:33:45.774274325Z I1024 13:33:45.774241       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.774433395Z I1024 13:33:45.774400       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:45.806616725Z I1024 13:33:45.803338       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:33:46.104275961Z I1024 13:33:46.104221       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:33:48.296900340Z I1024 13:33:48.296856       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:48.297016419Z I1024 13:33:48.296868       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:48.308455459Z E1024 13:33:48.308398       1 base_controller.go:271] "Unhandled Error" err="StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io \"etcd\": the object has been modified; please apply your changes to the latest version and try again"
2024-10-24T13:33:48.308455459Z I1024 13:33:48.308414       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:33:48.328826619Z I1024 13:33:48.328790       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:33:48.343351239Z I1024 13:33:48.343307       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:48.344021859Z I1024 13:33:48.343983       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:48.346707099Z I1024 13:33:48.346648       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:33:48.348590449Z I1024 13:33:48.348556       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 31.29 %, dbSize: 114241536
2024-10-24T13:33:48.348590449Z I1024 13:33:48.348569       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 30.94 %, dbSize: 113631232
2024-10-24T13:33:48.348590449Z I1024 13:33:48.348575       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 31.33 %, dbSize: 114200576
2024-10-24T13:33:48.363245428Z I1024 13:33:48.357271       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:33:48.363245428Z I1024 13:33:48.357564       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy" to "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found"
2024-10-24T13:33:48.371032008Z I1024 13:33:48.370971       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Available message changed from "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-2 is unhealthy" to "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 3 members are available"
2024-10-24T13:33:48.378745788Z I1024 13:33:48.378683       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:33:48.403520138Z I1024 13:33:48.403444       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 31.29 %, dbSize: 114241536
2024-10-24T13:33:48.403520138Z I1024 13:33:48.403475       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 30.90 %, dbSize: 113631232
2024-10-24T13:33:48.403520138Z I1024 13:33:48.403480       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 31.33 %, dbSize: 114200576
2024-10-24T13:33:49.497269233Z I1024 13:33:49.497203       1 request.go:700] Waited for 1.148980773s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:33:49.608795791Z I1024 13:33:49.607714       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:33:50.006431755Z I1024 13:33:50.006355       1 reflector.go:368] Caches populated for *v1.Etcd from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:50.499877718Z I1024 13:33:50.499782       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:50.697288615Z I1024 13:33:50.697236       1 request.go:700] Waited for 1.191919484s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:33:50.704866255Z I1024 13:33:50.704817       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:33:52.206300194Z I1024 13:33:52.206243       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:53.330199838Z I1024 13:33:53.330128       1 reflector.go:368] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:54.115854437Z I1024 13:33:54.115805       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:54.137918136Z I1024 13:33:54.137858       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:33:54.162547046Z I1024 13:33:54.162458       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:33:54.301478994Z I1024 13:33:54.301426       1 reflector.go:368] Caches populated for *v1.Namespace from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:54.653577829Z I1024 13:33:54.653502       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:55.299528210Z I1024 13:33:55.299469       1 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:55.501876097Z I1024 13:33:55.501820       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:33:56.707807600Z I1024 13:33:56.707737       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:33:58.344876367Z I1024 13:33:58.344728       1 reflector.go:368] Caches populated for *v1.Secret from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:33:59.101015896Z I1024 13:33:59.100958       1 reflector.go:368] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:34:06.014311177Z I1024 13:34:06.014242       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:34:08.007098609Z I1024 13:34:08.007023       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because waiting for static pod of revision 13, found 12
2024-10-24T13:34:12.292623668Z I1024 13:34:12.292558       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:34:15.758441709Z I1024 13:34:15.758298       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because waiting for static pod of revision 13, found 12
2024-10-24T13:34:35.982895301Z E1024 13:34:35.982825       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: failed to dial endpoint https://10.0.0.3:2379 with maintenance client: context deadline exceeded"
2024-10-24T13:34:36.006903991Z E1024 13:34:36.006856       1 health.go:115] health check for member (ci-op-2fcpj5j6-f6035-2lklf-master-0) failed: err(context deadline exceeded)
2024-10-24T13:34:36.007050061Z W1024 13:34:36.007007       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-2fcpj5j6-f6035-2lklf-master-0]
2024-10-24T13:34:41.371441425Z I1024 13:34:41.371370       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because static pod is pending
2024-10-24T13:34:42.365498251Z I1024 13:34:42.365430       1 request.go:700] Waited for 1.097342674s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-10-24T13:34:44.373110892Z I1024 13:34:44.373029       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because static pod is pending
2024-10-24T13:34:46.374859864Z I1024 13:34:46.374792       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because static pod is pending
2024-10-24T13:34:48.314618396Z I1024 13:34:48.314561       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdLeaderChangeMetrics' Detected leader change increase of 2.4834222222222224 over 5 minutes on "GCP"; disk metrics are: etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0=0.007520,etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1=0.006640,etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2=0.007580. Most often this is as a result of inadequate storage or sometimes due to networking issues.
2024-10-24T13:34:49.616090877Z I1024 13:34:49.616035       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:34:51.168017105Z I1024 13:34:51.167951       1 request.go:700] Waited for 1.184136863s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:34:53.621900340Z I1024 13:34:53.621831       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:35:03.329271222Z I1024 13:35:03.329192       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:35:03.684883737Z I1024 13:35:03.684823       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:35:05.992959544Z E1024 13:35:05.992902       1 health.go:115] health check for member (ci-op-2fcpj5j6-f6035-2lklf-master-0) failed: err(context deadline exceeded)
2024-10-24T13:35:05.993344814Z E1024 13:35:05.993323       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy"
2024-10-24T13:35:05.993483334Z E1024 13:35:05.993417       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-2fcpj5j6-f6035-2lklf-master-0, took=29.984686763s, err=health check failed: context deadline exceeded
2024-10-24T13:35:06.005459724Z E1024 13:35:06.005410       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy"
2024-10-24T13:35:06.013830924Z E1024 13:35:06.013801       1 health.go:115] health check for member (ci-op-2fcpj5j6-f6035-2lklf-master-0) failed: err(context deadline exceeded)
2024-10-24T13:35:06.013994624Z W1024 13:35:06.013970       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-2fcpj5j6-f6035-2lklf-master-0]
2024-10-24T13:35:06.023326534Z I1024 13:35:06.023302       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:35:06.024200413Z E1024 13:35:06.024168       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy"
2024-10-24T13:35:06.025000294Z I1024 13:35:06.024978       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:35:06.026918344Z E1024 13:35:06.026859       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy"
2024-10-24T13:35:06.042390303Z I1024 13:35:06.042329       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy"
2024-10-24T13:35:06.059851653Z I1024 13:35:06.059822       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:35:06.076683133Z E1024 13:35:06.076619       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy"
2024-10-24T13:35:06.076941543Z I1024 13:35:06.076888       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:35:06.077325823Z I1024 13:35:06.077291       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:35:06.096187512Z I1024 13:35:06.096115       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Available message changed from "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 3 members are available" to "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy"
2024-10-24T13:35:06.109037903Z E1024 13:35:06.108985       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy"
2024-10-24T13:35:06.110352182Z I1024 13:35:06.110307       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:35:06.430959798Z E1024 13:35:06.430899       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy"
2024-10-24T13:35:07.073336148Z E1024 13:35:07.073272       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy"
2024-10-24T13:35:07.093801368Z I1024 13:35:07.093726       1 request.go:700] Waited for 1.015958656s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:35:07.500119123Z I1024 13:35:07.500064       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because static pod is pending
2024-10-24T13:35:08.355581870Z E1024 13:35:08.355506       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy"
2024-10-24T13:35:09.713870291Z I1024 13:35:09.713737       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-0" is in transition to 13, but has not made progress because static pod is pending
2024-10-24T13:35:10.918039834Z E1024 13:35:10.917981       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy"
2024-10-24T13:35:12.504876231Z I1024 13:35:12.504821       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:35:12.504876231Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:35:12.504876231Z  CurrentRevision: (int32) 13,
2024-10-24T13:35:12.504876231Z  TargetRevision: (int32) 0,
2024-10-24T13:35:12.504876231Z  LastFailedRevision: (int32) 0,
2024-10-24T13:35:12.504876231Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:35:12.504876231Z  LastFailedReason: (string) "",
2024-10-24T13:35:12.504876231Z  LastFailedCount: (int) 0,
2024-10-24T13:35:12.504876231Z  LastFallbackCount: (int) 0,
2024-10-24T13:35:12.504876231Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:35:12.504876231Z }
2024-10-24T13:35:12.504876231Z  because static pod is ready
2024-10-24T13:35:12.537533241Z E1024 13:35:12.537463       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy"
2024-10-24T13:35:12.537885461Z I1024 13:35:12.537824       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-0" from revision 12 to 13 because static pod is ready
2024-10-24T13:35:12.538028001Z I1024 13:35:12.537907       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:35:12.541589621Z I1024 13:35:12.541542       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:30:34Z","message":"NodeInstallerProgressing: 1 node is at revision 12; 2 nodes are at revision 13","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 12; 2 nodes are at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:35:12.555076761Z I1024 13:35:12.554979       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 12; 1 node is at revision 13" to "NodeInstallerProgressing: 1 node is at revision 12; 2 nodes are at revision 13",Available message changed from "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 12; 1 node is at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 12; 2 nodes are at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy"
2024-10-24T13:35:12.571427820Z I1024 13:35:12.571329       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:35:13.535039887Z I1024 13:35:13.534981       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:35:13.693387624Z I1024 13:35:13.693318       1 request.go:700] Waited for 1.153233884s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-10-24T13:35:14.893095567Z I1024 13:35:14.893026       1 request.go:700] Waited for 1.193271233s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-10-24T13:35:15.502488049Z I1024 13:35:15.502430       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-0" moving to (v1.NodeStatus) {
2024-10-24T13:35:15.502488049Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-0",
2024-10-24T13:35:15.502488049Z  CurrentRevision: (int32) 13,
2024-10-24T13:35:15.502488049Z  TargetRevision: (int32) 0,
2024-10-24T13:35:15.502488049Z  LastFailedRevision: (int32) 0,
2024-10-24T13:35:15.502488049Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:35:15.502488049Z  LastFailedReason: (string) "",
2024-10-24T13:35:15.502488049Z  LastFailedCount: (int) 0,
2024-10-24T13:35:15.502488049Z  LastFallbackCount: (int) 0,
2024-10-24T13:35:15.502488049Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:35:15.502488049Z }
2024-10-24T13:35:15.502488049Z  because static pod is ready
2024-10-24T13:35:16.039874311Z E1024 13:35:16.039808       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy"
2024-10-24T13:35:17.265871104Z I1024 13:35:17.265804       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:35:17.293653364Z I1024 13:35:17.293581       1 request.go:700] Waited for 1.173216214s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:35:20.303812591Z I1024 13:35:20.303734       1 installer_controller.go:534] node ci-op-2fcpj5j6-f6035-2lklf-master-1 with revision 12 is the oldest and needs new revision 13
2024-10-24T13:35:20.303890001Z I1024 13:35:20.303825       1 installer_controller.go:542] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:35:20.303890001Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:35:20.303890001Z  CurrentRevision: (int32) 12,
2024-10-24T13:35:20.303890001Z  TargetRevision: (int32) 13,
2024-10-24T13:35:20.303890001Z  LastFailedRevision: (int32) 0,
2024-10-24T13:35:20.303890001Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:35:20.303890001Z  LastFailedReason: (string) "",
2024-10-24T13:35:20.303890001Z  LastFailedCount: (int) 0,
2024-10-24T13:35:20.303890001Z  LastFallbackCount: (int) 0,
2024-10-24T13:35:20.303890001Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:35:20.303890001Z }
2024-10-24T13:35:20.328420891Z I1024 13:35:20.328311       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 12 to 13 because node ci-op-2fcpj5j6-f6035-2lklf-master-1 with revision 12 is the oldest
2024-10-24T13:35:20.333400060Z I1024 13:35:20.333353       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:35:20.333694150Z E1024 13:35:20.333671       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy"
2024-10-24T13:35:20.364653080Z I1024 13:35:20.364600       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:35:21.493435394Z I1024 13:35:21.493333       1 request.go:700] Waited for 1.159919523s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2
2024-10-24T13:35:22.322209002Z I1024 13:35:22.322139       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-13-ci-op-2fcpj5j6-f6035-2lklf-master-1 -n openshift-etcd because it was missing
2024-10-24T13:35:23.301538208Z I1024 13:35:23.301426       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because installer is not finished, but in Pending phase
2024-10-24T13:35:23.493301065Z I1024 13:35:23.493233       1 request.go:700] Waited for 1.168546173s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-10-24T13:35:25.101265713Z I1024 13:35:25.101141       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:35:26.499982712Z I1024 13:35:26.499920       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:35:27.333470521Z I1024 13:35:27.333392       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:35:36.521409451Z E1024 13:35:36.521349       1 base_controller.go:271] "Unhandled Error" err="DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy"
2024-10-24T13:35:48.102108286Z I1024 13:35:48.102012       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:35:48.271988663Z E1024 13:35:48.271899       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-2fcpj5j6-f6035-2lklf-master-0, took=29.984686763s, err=health check failed: context deadline exceeded
2024-10-24T13:35:48.332729042Z I1024 13:35:48.332654       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdLeaderChangeMetrics' Detected leader change increase of 2.5 over 5 minutes on "GCP"; disk metrics are: etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0=0.007520,etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1=0.006640,etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2=0.007580. Most often this is as a result of inadequate storage or sometimes due to networking issues.
2024-10-24T13:35:49.603371765Z I1024 13:35:49.603307       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:35:56.237445637Z I1024 13:35:56.237325       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because installer is not finished, but in Running phase
2024-10-24T13:35:58.429922680Z I1024 13:35:58.429854       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because waiting for static pod of revision 13, found 12
2024-10-24T13:36:04.861595076Z I1024 13:36:04.861541       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:36:07.675042212Z I1024 13:36:07.674970       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because waiting for static pod of revision 13, found 12
2024-10-24T13:36:08.566839783Z I1024 13:36:08.566742       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:36:15.532275365Z I1024 13:36:15.532209       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:36:25.503285655Z I1024 13:36:25.503233       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:36:25.873561369Z I1024 13:36:25.873506       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:36:26.228604893Z E1024 13:36:26.228544       1 health.go:115] health check for member (ci-op-2fcpj5j6-f6035-2lklf-master-1) failed: err(context deadline exceeded)
2024-10-24T13:36:26.228807283Z W1024 13:36:26.228777       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-2fcpj5j6-f6035-2lklf-master-1]
2024-10-24T13:36:32.813835983Z I1024 13:36:32.813737       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because static pod is pending
2024-10-24T13:36:34.603048794Z I1024 13:36:34.602982       1 request.go:700] Waited for 1.14111658s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-10-24T13:36:36.011538452Z I1024 13:36:36.011467       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because static pod is pending
2024-10-24T13:36:38.212003664Z I1024 13:36:38.211911       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because static pod is pending
2024-10-24T13:36:39.048514398Z I1024 13:36:39.048469       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:36:40.213048396Z I1024 13:36:40.212977       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because static pod is pending
2024-10-24T13:36:48.340554597Z I1024 13:36:48.340475       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdLeaderChangeMetrics' Detected leader change increase of 2.2222222222222223 over 5 minutes on "GCP"; disk metrics are: etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0=0.007520,etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1=0.006640,etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2=0.007580. Most often this is as a result of inadequate storage or sometimes due to networking issues.
2024-10-24T13:36:49.395070451Z I1024 13:36:49.394978       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:36:49.602276012Z I1024 13:36:49.602218       1 etcdcertsignercontroller.go:241] skipping EtcdCertSignerController can't get current revision. Err=revision rollout in progress, can't establish current revision
2024-10-24T13:36:56.237923560Z E1024 13:36:56.237857       1 health.go:115] health check for member (ci-op-2fcpj5j6-f6035-2lklf-master-1) failed: err(context deadline exceeded)
2024-10-24T13:36:56.238125939Z W1024 13:36:56.238098       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-2fcpj5j6-f6035-2lklf-master-1]
2024-10-24T13:36:58.093047008Z I1024 13:36:58.092997       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because static pod is pending
2024-10-24T13:37:02.455922105Z I1024 13:37:02.455870       1 installer_controller.go:522] "ci-op-2fcpj5j6-f6035-2lklf-master-1" is in transition to 13, but has not made progress because static pod is pending
2024-10-24T13:37:03.626505873Z I1024 13:37:03.626448       1 request.go:700] Waited for 1.13385495s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-10-24T13:37:05.036809781Z I1024 13:37:05.036709       1 installer_controller.go:510] "ci-op-2fcpj5j6-f6035-2lklf-master-1" moving to (v1.NodeStatus) {
2024-10-24T13:37:05.036809781Z  NodeName: (string) (len=35) "ci-op-2fcpj5j6-f6035-2lklf-master-1",
2024-10-24T13:37:05.036809781Z  CurrentRevision: (int32) 13,
2024-10-24T13:37:05.036809781Z  TargetRevision: (int32) 0,
2024-10-24T13:37:05.036809781Z  LastFailedRevision: (int32) 0,
2024-10-24T13:37:05.036809781Z  LastFailedTime: (*v1.Time)(<nil>),
2024-10-24T13:37:05.036809781Z  LastFailedReason: (string) "",
2024-10-24T13:37:05.036809781Z  LastFailedCount: (int) 0,
2024-10-24T13:37:05.036809781Z  LastFallbackCount: (int) 0,
2024-10-24T13:37:05.036809781Z  LastFailedRevisionErrors: ([]string) <nil>
2024-10-24T13:37:05.036809781Z }
2024-10-24T13:37:05.036809781Z  because static pod is ready
2024-10-24T13:37:05.058821400Z I1024 13:37:05.058782       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-2fcpj5j6-f6035-2lklf-master-1" from revision 12 to 13 because static pod is ready
2024-10-24T13:37:05.060996660Z I1024 13:37:05.060970       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:37:05.061797580Z I1024 13:37:05.061706       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:37:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 13\nEtcdMembersProgressing: No unstarted etcd members found","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:37:05.071662649Z I1024 13:37:05.071617       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing changed from True to False ("NodeInstallerProgressing: 3 nodes are at revision 13\nEtcdMembersProgressing: No unstarted etcd members found"),Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 12; 2 nodes are at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy"
2024-10-24T13:37:06.226404338Z I1024 13:37:06.226328       1 request.go:700] Waited for 1.165031849s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:37:07.226728324Z I1024 13:37:07.226684       1 request.go:700] Waited for 1.191594777s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-10-24T13:37:08.882895151Z I1024 13:37:08.882830       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:37:08.883855191Z I1024 13:37:08.883480       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:37:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 13\nEtcdMembersProgressing: No unstarted etcd members found","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:37:08.901159110Z I1024 13:37:08.899145       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy" to "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found"
2024-10-24T13:37:08.903470500Z I1024 13:37:08.903418       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 47.38 %, dbSize: 114200576
2024-10-24T13:37:08.903675570Z I1024 13:37:08.903645       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'DefragControllerDefragmentAttempt' Attempting defrag on member: ci-op-2fcpj5j6-f6035-2lklf-master-0, memberID: 2dee09550bc489af, dbSize: 114200576, dbInUse: 60092416, leader ID: 5953405296437866173
2024-10-24T13:37:09.465064866Z I1024 13:37:09.464997       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'DefragControllerDefragmentSuccess' etcd member has been defragmented: ci-op-2fcpj5j6-f6035-2lklf-master-0, memberID: 3309593037038193071
2024-10-24T13:37:09.475941695Z I1024 13:37:09.474181       1 status_controller.go:225] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-10-24T13:22:18Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-10-24T13:37:05Z","message":"NodeInstallerProgressing: 3 nodes are at revision 13\nEtcdMembersProgressing: No unstarted etcd members found","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-10-24T13:04:53Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 13\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-10-24T13:03:29Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-10-24T13:03:29Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-10-24T13:37:09.475941695Z I1024 13:37:09.475859       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:37:09.489268095Z I1024 13:37:09.489196       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Available message changed from "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 13\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-2fcpj5j6-f6035-2lklf-master-0 is unhealthy" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 13\nEtcdMembersAvailable: 3 members are available"
2024-10-24T13:37:10.026606301Z I1024 13:37:10.026533       1 request.go:700] Waited for 1.14241955s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-10-24T13:37:11.027105006Z I1024 13:37:11.026993       1 request.go:700] Waited for 1.391863638s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0
2024-10-24T13:37:12.226736273Z I1024 13:37:12.226660       1 request.go:700] Waited for 1.392391598s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1
2024-10-24T13:37:47.466672669Z I1024 13:37:47.466218       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 47.17 %, dbSize: 113631232
2024-10-24T13:37:47.467060459Z I1024 13:37:47.467001       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'DefragControllerDefragmentAttempt' Attempting defrag on member: ci-op-2fcpj5j6-f6035-2lklf-master-1, memberID: d70ee276ae23755c, dbSize: 113631232, dbInUse: 60035072, leader ID: 5953405296437866173
2024-10-24T13:37:47.949029728Z I1024 13:37:47.948954       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'DefragControllerDefragmentSuccess' etcd member has been defragmented: ci-op-2fcpj5j6-f6035-2lklf-master-1, memberID: 15496572367184033116
2024-10-24T13:37:48.321183802Z I1024 13:37:48.321099       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdLeaderChangeMetrics' Detected leader change increase of 2.2222222222222223 over 5 minutes on "GCP"; disk metrics are: etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0=0.007168,etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1=0.006104,etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2=0.007580. Most often this is as a result of inadequate storage or sometimes due to networking issues.
2024-10-24T13:38:25.977317421Z I1024 13:38:25.977243       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 47.43 %, dbSize: 114241536
2024-10-24T13:38:25.977994031Z I1024 13:38:25.977955       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'DefragControllerDefragmentAttempt' Attempting defrag on member: ci-op-2fcpj5j6-f6035-2lklf-master-2, memberID: 529ebe931a1baebd, dbSize: 114241536, dbInUse: 60059648, leader ID: 5953405296437866173
2024-10-24T13:38:26.460322360Z I1024 13:38:26.460238       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'DefragControllerDefragmentSuccess' etcd member has been defragmented: ci-op-2fcpj5j6-f6035-2lklf-master-2, memberID: 5953405296437866173
2024-10-24T13:38:48.329513095Z I1024 13:38:48.329429       1 event.go:377] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"bff212df-2809-4dd6-8cc1-b1e11e66ac01", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdLeaderChangeMetrics' Detected leader change increase of 2.2222222222222223 over 5 minutes on "GCP"; disk metrics are: etcd-ci-op-2fcpj5j6-f6035-2lklf-master-0=0.007740,etcd-ci-op-2fcpj5j6-f6035-2lklf-master-1=0.005000,etcd-ci-op-2fcpj5j6-f6035-2lklf-master-2=0.007016. Most often this is as a result of inadequate storage or sometimes due to networking issues.
2024-10-24T13:39:04.499425903Z I1024 13:39:04.499370       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.06 %, dbSize: 62316544
2024-10-24T13:39:04.499425903Z I1024 13:39:04.499397       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 0.08 %, dbSize: 62287872
2024-10-24T13:39:04.499425903Z I1024 13:39:04.499404       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.09 %, dbSize: 62279680
2024-10-24T13:43:45.707718456Z I1024 13:43:45.707646       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.708113306Z I1024 13:43:45.708083       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.708916106Z I1024 13:43:45.708888       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.709234096Z I1024 13:43:45.709202       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.709582455Z I1024 13:43:45.709561       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.710037235Z I1024 13:43:45.710014       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.710246466Z I1024 13:43:45.710228       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.710442765Z I1024 13:43:45.710423       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.710652315Z I1024 13:43:45.710633       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.711020296Z I1024 13:43:45.711002       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.711337576Z I1024 13:43:45.711315       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.711671675Z I1024 13:43:45.711603       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.712025176Z I1024 13:43:45.712004       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.712270975Z I1024 13:43:45.712255       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.712460705Z I1024 13:43:45.712446       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.713417055Z I1024 13:43:45.713384       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.713626445Z I1024 13:43:45.713611       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.713860646Z I1024 13:43:45.713843       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.714128905Z I1024 13:43:45.714069       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.714341335Z I1024 13:43:45.714325       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.714613845Z I1024 13:43:45.714595       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.714951735Z I1024 13:43:45.714879       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.715798136Z I1024 13:43:45.715777       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:45.716217525Z I1024 13:43:45.716188       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:43:48.433468443Z I1024 13:43:48.433410       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 11.07 %, dbSize: 65445888
2024-10-24T13:43:48.433468443Z I1024 13:43:48.433434       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 11.12 %, dbSize: 65421312
2024-10-24T13:43:48.433468443Z I1024 13:43:48.433441       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 11.06 %, dbSize: 65392640
2024-10-24T13:46:21.798201659Z I1024 13:46:21.798112       1 tlsconfig.go:181] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"admin-kubeconfig-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:31 +0000 UTC to 2034-10-22 12:49:31 +0000 UTC (now=2024-10-24 13:46:21.798068639 +0000 UTC))"
2024-10-24T13:46:21.799058739Z I1024 13:46:21.798332       1 tlsconfig.go:181] "Loaded client CA" index=1 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2024-10-25 12:49:34 +0000 UTC (now=2024-10-24 13:46:21.79830862 +0000 UTC))"
2024-10-24T13:46:21.799139010Z I1024 13:46:21.799120       1 tlsconfig.go:181] "Loaded client CA" index=2 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-control-plane-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2025-10-24 12:49:34 +0000 UTC (now=2024-10-24 13:46:21.799095239 +0000 UTC))"
2024-10-24T13:46:21.799204599Z I1024 13:46:21.799189       1 tlsconfig.go:181] "Loaded client CA" index=3 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-apiserver-to-kubelet-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2025-10-24 12:49:34 +0000 UTC (now=2024-10-24 13:46:21.79916999 +0000 UTC))"
2024-10-24T13:46:21.799262310Z I1024 13:46:21.799248       1 tlsconfig.go:181] "Loaded client CA" index=4 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-bootstrap-kubeconfig-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:32 +0000 UTC to 2034-10-22 12:49:32 +0000 UTC (now=2024-10-24 13:46:21.79922799 +0000 UTC))"
2024-10-24T13:46:21.799317790Z I1024 13:46:21.799303       1 tlsconfig.go:181] "Loaded client CA" index=5 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-csr-signer_@1729775012\" [] issuer=\"kubelet-signer\" (2024-10-24 13:03:31 +0000 UTC to 2024-10-25 12:49:34 +0000 UTC (now=2024-10-24 13:46:21.799285399 +0000 UTC))"
2024-10-24T13:46:21.799376640Z I1024 13:46:21.799359       1 tlsconfig.go:181] "Loaded client CA" index=6 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_node-system-admin-signer@1729775011\" [] issuer=\"<self>\" (2024-10-24 13:03:30 +0000 UTC to 2025-10-24 13:03:31 +0000 UTC (now=2024-10-24 13:46:21.799339849 +0000 UTC))"
2024-10-24T13:46:21.799441260Z I1024 13:46:21.799426       1 tlsconfig.go:181] "Loaded client CA" index=7 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"aggregator-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:32 +0000 UTC to 2024-10-25 12:49:32 +0000 UTC (now=2024-10-24 13:46:21.799407229 +0000 UTC))"
2024-10-24T13:46:21.799504400Z I1024 13:46:21.799486       1 tlsconfig.go:181] "Loaded client CA" index=8 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_aggregator-client-signer@1729777579\" [] issuer=\"<self>\" (2024-10-24 13:46:18 +0000 UTC to 2024-10-25 01:46:19 +0000 UTC (now=2024-10-24 13:46:21.799463569 +0000 UTC))"
2024-10-24T13:46:21.799815930Z I1024 13:46:21.799797       1 tlsconfig.go:203] "Loaded serving cert" certName="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key" certDetail="\"metrics.openshift-etcd-operator.svc\" [serving] validServingFor=[metrics.openshift-etcd-operator.svc,metrics.openshift-etcd-operator.svc.cluster.local] issuer=\"openshift-service-serving-signer@1729775010\" (2024-10-24 13:03:39 +0000 UTC to 2026-10-24 13:03:40 +0000 UTC (now=2024-10-24 13:46:21.799774559 +0000 UTC))"
2024-10-24T13:46:21.800121860Z I1024 13:46:21.800034       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1729775940\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1729775940\" (2024-10-24 12:19:00 +0000 UTC to 2025-10-24 12:19:00 +0000 UTC (now=2024-10-24 13:46:21.8000094 +0000 UTC))"
2024-10-24T13:50:50.194338177Z I1024 13:50:50.194272       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:50:50.346002086Z I1024 13:50:50.345934       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:50:50.567320843Z I1024 13:50:50.567193       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:50:50.782795661Z I1024 13:50:50.780631       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=etcds from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:50:50.789486861Z I1024 13:50:50.789424       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:50:50.862452880Z I1024 13:50:50.861010       1 reflector.go:368] Caches populated for *v1.Etcd from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:50:50.866181281Z I1024 13:50:50.866121       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 3.19 %, dbSize: 65445888
2024-10-24T13:50:50.866276760Z I1024 13:50:50.866256       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 3.14 %, dbSize: 65421312
2024-10-24T13:50:50.866333271Z I1024 13:50:50.866304       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 3.08 %, dbSize: 65392640
2024-10-24T13:50:51.571799773Z I1024 13:50:51.571714       1 reflector.go:368] Caches populated for *v1beta1.Machine from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:50:51.736816792Z I1024 13:50:51.736744       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T13:53:45.708374647Z I1024 13:53:45.708305       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.708791507Z I1024 13:53:45.708742       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.714069267Z I1024 13:53:45.714017       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.714410107Z I1024 13:53:45.714385       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.715032788Z I1024 13:53:45.714964       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.715452557Z I1024 13:53:45.715421       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.715988387Z I1024 13:53:45.715885       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.716493087Z I1024 13:53:45.716468       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.716946618Z I1024 13:53:45.716923       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.717545567Z I1024 13:53:45.717354       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.717706567Z I1024 13:53:45.717677       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.718176867Z I1024 13:53:45.718129       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.718628827Z I1024 13:53:45.718517       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.719179758Z I1024 13:53:45.719117       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.719523788Z I1024 13:53:45.719466       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.719984788Z I1024 13:53:45.719886       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.720247247Z I1024 13:53:45.720207       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.720521437Z I1024 13:53:45.720492       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.722726708Z I1024 13:53:45.721137       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.722726708Z I1024 13:53:45.721580       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.722726708Z I1024 13:53:45.721866       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.722726708Z I1024 13:53:45.722172       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.722726708Z I1024 13:53:45.722547       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.723192638Z I1024 13:53:45.723155       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.726575588Z I1024 13:53:45.726520       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.726949287Z I1024 13:53:45.726925       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.727236588Z I1024 13:53:45.727161       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.727386778Z I1024 13:53:45.727345       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.727628048Z I1024 13:53:45.727555       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:53:45.727798057Z I1024 13:53:45.727731       1 prune_controller.go:277] Nothing to prune
2024-10-24T13:54:48.410166575Z I1024 13:54:48.410099       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 0.06 %, dbSize: 65564672
2024-10-24T13:54:48.410166575Z I1024 13:54:48.410131       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 0.04 %, dbSize: 65568768
2024-10-24T13:54:48.410166575Z I1024 13:54:48.410138       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 0.11 %, dbSize: 65634304
2024-10-24T14:01:14.844412760Z I1024 14:01:14.844300       1 reflector.go:368] Caches populated for *v1.Etcd from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:01:14.924846989Z I1024 14:01:14.924707       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=etcds from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:01:14.926508959Z I1024 14:01:14.926463       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:01:14.959126259Z I1024 14:01:14.958657       1 etcdcli_pool.go:70] creating a new cached client
2024-10-24T14:01:15.049468099Z I1024 14:01:15.049377       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 3.98 %, dbSize: 67784704
2024-10-24T14:01:15.049468099Z I1024 14:01:15.049405       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 4.25 %, dbSize: 67940352
2024-10-24T14:01:15.049468099Z I1024 14:01:15.049411       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 4.24 %, dbSize: 67981312
2024-10-24T14:03:45.708952197Z I1024 14:03:45.708874       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.709404796Z I1024 14:03:45.709383       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.709929187Z I1024 14:03:45.709906       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.710242546Z I1024 14:03:45.710224       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.710530096Z I1024 14:03:45.710508       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.710972377Z I1024 14:03:45.710949       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.711178307Z I1024 14:03:45.711156       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.711375417Z I1024 14:03:45.711358       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.711575367Z I1024 14:03:45.711557       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.711776086Z I1024 14:03:45.711741       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.711980197Z I1024 14:03:45.711960       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.712193036Z I1024 14:03:45.712173       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.712381886Z I1024 14:03:45.712365       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.712933706Z I1024 14:03:45.712572       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.713145727Z I1024 14:03:45.713126       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.713431126Z I1024 14:03:45.713403       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.713661587Z I1024 14:03:45.713642       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.713882077Z I1024 14:03:45.713861       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.714075826Z I1024 14:03:45.714057       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.714257227Z I1024 14:03:45.714240       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.714517637Z I1024 14:03:45.714436       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.714742247Z I1024 14:03:45.714724       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.714963197Z I1024 14:03:45.714944       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.715157286Z I1024 14:03:45.715137       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.715393347Z I1024 14:03:45.715374       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.715602206Z I1024 14:03:45.715585       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.715802667Z I1024 14:03:45.715786       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.716043327Z I1024 14:03:45.715980       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:03:45.716241866Z I1024 14:03:45.716221       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:04:28.026294263Z I1024 14:04:28.026223       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:04:28.050936733Z I1024 14:04:28.050851       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=etcds from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:04:28.053207823Z I1024 14:04:28.053166       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:04:28.077341983Z I1024 14:04:28.077266       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:04:28.110437562Z I1024 14:04:28.110378       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 10.50 %, dbSize: 67784704
2024-10-24T14:04:28.110437562Z I1024 14:04:28.110403       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 10.76 %, dbSize: 67940352
2024-10-24T14:04:28.110437562Z I1024 14:04:28.110409       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 10.79 %, dbSize: 67981312
2024-10-24T14:04:28.224796132Z I1024 14:04:28.224471       1 reflector.go:368] Caches populated for *v1.Etcd from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:04:28.328221122Z I1024 14:04:28.328137       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:04:28.660227681Z I1024 14:04:28.660176       1 reflector.go:368] Caches populated for *v1beta1.Machine from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:04:28.878145880Z I1024 14:04:28.878094       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:04:29.882619407Z I1024 14:04:29.882554       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:05:48.413915083Z I1024 14:05:48.413725       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 5.69 %, dbSize: 67784704
2024-10-24T14:05:48.413915083Z I1024 14:05:48.413810       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 5.93 %, dbSize: 67940352
2024-10-24T14:05:48.413915083Z I1024 14:05:48.413820       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 6.00 %, dbSize: 67981312
2024-10-24T14:07:56.653892361Z I1024 14:07:56.651924       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:56.687978721Z I1024 14:07:56.687866       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:56.721844231Z I1024 14:07:56.721770       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:56.734370051Z I1024 14:07:56.734303       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:56.745072651Z I1024 14:07:56.744998       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:56.769124120Z I1024 14:07:56.769041       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:56.778100450Z I1024 14:07:56.778034       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:56.802905880Z I1024 14:07:56.802829       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:56.816209941Z I1024 14:07:56.815067       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:56.831320090Z I1024 14:07:56.831240       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:56.855097411Z I1024 14:07:56.855004       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:56.868475210Z I1024 14:07:56.868410       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:56.888018950Z I1024 14:07:56.887976       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:56.917325400Z I1024 14:07:56.917015       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:56.927301030Z I1024 14:07:56.927236       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:56.941728370Z I1024 14:07:56.941678       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:56.956834630Z I1024 14:07:56.955958       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:56.974110330Z I1024 14:07:56.974036       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:56.985806970Z I1024 14:07:56.984679       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:56.999855630Z I1024 14:07:56.999741       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.014731350Z I1024 14:07:57.014655       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.036298240Z I1024 14:07:57.036223       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.050557230Z I1024 14:07:57.050314       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.065079390Z I1024 14:07:57.064994       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.079134750Z I1024 14:07:57.079082       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.091742250Z I1024 14:07:57.091652       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.125240340Z I1024 14:07:57.125161       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.136820770Z I1024 14:07:57.136741       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.152865349Z I1024 14:07:57.152806       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.163613680Z I1024 14:07:57.163561       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.184850020Z I1024 14:07:57.182972       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.201084389Z I1024 14:07:57.201030       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.227883200Z I1024 14:07:57.227242       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.265816589Z I1024 14:07:57.262870       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.275838829Z I1024 14:07:57.274907       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.305877129Z I1024 14:07:57.305774       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.309665779Z I1024 14:07:57.309026       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.335062659Z I1024 14:07:57.334859       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.368928359Z I1024 14:07:57.368769       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.419525219Z I1024 14:07:57.418071       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.455708148Z I1024 14:07:57.454175       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.496601859Z I1024 14:07:57.495641       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.521787449Z I1024 14:07:57.521116       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.536474898Z I1024 14:07:57.536397       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.553969518Z I1024 14:07:57.553913       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.579775718Z I1024 14:07:57.579123       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.598066448Z I1024 14:07:57.598012       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.623808248Z I1024 14:07:57.618579       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.639550598Z I1024 14:07:57.639481       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.646455708Z I1024 14:07:57.646220       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.666238128Z I1024 14:07:57.666170       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.679896618Z I1024 14:07:57.677325       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.692391838Z I1024 14:07:57.691588       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.708106348Z I1024 14:07:57.707981       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.725543548Z I1024 14:07:57.725482       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.737836698Z I1024 14:07:57.737731       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.758828878Z I1024 14:07:57.757408       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.788367378Z I1024 14:07:57.787468       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.798458008Z I1024 14:07:57.798076       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.809176678Z I1024 14:07:57.809104       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:07:57.820306618Z I1024 14:07:57.820250       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:26.736041241Z I1024 14:13:26.735965       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=etcds from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:13:26.740158911Z I1024 14:13:26.740131       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:26.754065051Z I1024 14:13:26.752275       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:13:26.795022491Z I1024 14:13:26.794947       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 8.82 %, dbSize: 90279936
2024-10-24T14:13:26.795022491Z I1024 14:13:26.794975       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 8.86 %, dbSize: 90259456
2024-10-24T14:13:26.795022491Z I1024 14:13:26.794981       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 8.86 %, dbSize: 90292224
2024-10-24T14:13:26.888992980Z I1024 14:13:26.888900       1 reflector.go:368] Caches populated for *v1.Etcd from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:13:26.897137311Z I1024 14:13:26.897002       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:13:27.302672779Z I1024 14:13:27.302583       1 reflector.go:368] Caches populated for *v1beta1.Machine from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:13:27.341467889Z I1024 14:13:27.341298       1 reflector.go:368] Caches populated for *v1.Network from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:13:27.381728209Z I1024 14:13:27.381603       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:13:28.260577675Z I1024 14:13:28.260499       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:13:45.710714248Z I1024 14:13:45.710036       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.711050188Z I1024 14:13:45.711024       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.711264378Z I1024 14:13:45.711243       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.711475218Z I1024 14:13:45.711455       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.711723728Z I1024 14:13:45.711704       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.711936128Z I1024 14:13:45.711917       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.712157458Z I1024 14:13:45.712140       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.712484968Z I1024 14:13:45.712438       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.712912358Z I1024 14:13:45.712863       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.713279408Z I1024 14:13:45.713142       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.713496198Z I1024 14:13:45.713477       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.713681638Z I1024 14:13:45.713667       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.713903098Z I1024 14:13:45.713888       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.716265238Z I1024 14:13:45.715581       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.716265238Z I1024 14:13:45.715766       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.716265238Z I1024 14:13:45.716002       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.716265238Z I1024 14:13:45.716239       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.716471858Z I1024 14:13:45.716437       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.716631558Z I1024 14:13:45.716601       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.716801348Z I1024 14:13:45.716772       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.717444068Z I1024 14:13:45.717220       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.717444068Z I1024 14:13:45.717383       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.717663488Z I1024 14:13:45.717642       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.718084768Z I1024 14:13:45.718018       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.718343668Z I1024 14:13:45.718312       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.718624098Z I1024 14:13:45.718593       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:13:45.718920898Z I1024 14:13:45.718891       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:16:48.437126446Z I1024 14:16:48.436995       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 2.55 %, dbSize: 90279936
2024-10-24T14:16:48.437126446Z I1024 14:16:48.437036       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 2.59 %, dbSize: 90259456
2024-10-24T14:16:48.437126446Z I1024 14:16:48.437042       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 2.56 %, dbSize: 90292224
2024-10-24T14:19:22.156574336Z I1024 14:19:22.156499       1 reflector.go:368] Caches populated for *v1beta1.Machine from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.178897526Z I1024 14:19:22.178745       1 reflector.go:368] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.331130465Z I1024 14:19:22.328784       1 reflector.go:368] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.417545955Z I1024 14:19:22.417342       1 reflector.go:368] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.455870415Z I1024 14:19:22.455340       1 reflector.go:368] Caches populated for *v1.APIServer from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.471796155Z I1024 14:19:22.471346       1 reflector.go:368] Caches populated for operator.openshift.io/v1, Resource=etcds from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:19:22.471858075Z I1024 14:19:22.471740       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:19:22.576354844Z I1024 14:19:22.576278       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 31.50 %, dbSize: 90279936
2024-10-24T14:19:22.576354844Z I1024 14:19:22.576322       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 31.57 %, dbSize: 90259456
2024-10-24T14:19:22.576354844Z I1024 14:19:22.576330       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 31.56 %, dbSize: 90292224
2024-10-24T14:19:23.125473042Z I1024 14:19:23.125402       1 reflector.go:368] Caches populated for *v1.Etcd from k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
2024-10-24T14:21:48.267788616Z I1024 14:21:48.267667       1 etcd_cert_cleaner_controller.go:126] unused secret [etcd-serving-metrics-ci-op-2fcpj5j6-f6035-2lklf-master-0] became used again, removing label for grace period
2024-10-24T14:21:48.279180666Z I1024 14:21:48.279075       1 etcd_cert_cleaner_controller.go:126] unused secret [etcd-serving-ci-op-2fcpj5j6-f6035-2lklf-master-0] became used again, removing label for grace period
2024-10-24T14:21:48.287566265Z I1024 14:21:48.287486       1 etcd_cert_cleaner_controller.go:126] unused secret [etcd-peer-ci-op-2fcpj5j6-f6035-2lklf-master-0] became used again, removing label for grace period
2024-10-24T14:21:48.298120566Z I1024 14:21:48.298043       1 etcd_cert_cleaner_controller.go:126] unused secret [etcd-serving-metrics-ci-op-2fcpj5j6-f6035-2lklf-master-1] became used again, removing label for grace period
2024-10-24T14:21:48.384278165Z I1024 14:21:48.384173       1 etcd_cert_cleaner_controller.go:126] unused secret [etcd-peer-ci-op-2fcpj5j6-f6035-2lklf-master-1] became used again, removing label for grace period
2024-10-24T14:21:48.581947225Z I1024 14:21:48.581868       1 etcd_cert_cleaner_controller.go:126] unused secret [etcd-serving-ci-op-2fcpj5j6-f6035-2lklf-master-1] became used again, removing label for grace period
2024-10-24T14:21:48.984234583Z I1024 14:21:48.984157       1 etcd_cert_cleaner_controller.go:126] unused secret [etcd-serving-ci-op-2fcpj5j6-f6035-2lklf-master-2] became used again, removing label for grace period
2024-10-24T14:21:49.181640012Z I1024 14:21:49.181557       1 etcd_cert_cleaner_controller.go:126] unused secret [etcd-serving-metrics-ci-op-2fcpj5j6-f6035-2lklf-master-2] became used again, removing label for grace period
2024-10-24T14:21:49.383245101Z I1024 14:21:49.383114       1 etcd_cert_cleaner_controller.go:126] unused secret [etcd-peer-ci-op-2fcpj5j6-f6035-2lklf-master-2] became used again, removing label for grace period
2024-10-24T14:21:49.583068221Z I1024 14:21:49.582969       1 etcd_cert_cleaner_controller.go:155] unused secret [etcd-serving-ci-op-2fcpj5j6-f6035-2lklf-bootstrap] detected, label for grace period of 72h0m0s
2024-10-24T14:21:49.790035830Z I1024 14:21:49.789934       1 etcd_cert_cleaner_controller.go:155] unused secret [etcd-peer-ci-op-2fcpj5j6-f6035-2lklf-bootstrap] detected, label for grace period of 72h0m0s
2024-10-24T14:21:50.186277018Z I1024 14:21:50.186188       1 etcd_cert_cleaner_controller.go:155] unused secret [etcd-serving-metrics-ci-op-2fcpj5j6-f6035-2lklf-bootstrap] detected, label for grace period of 72h0m0s
2024-10-24T14:23:45.710694798Z I1024 14:23:45.710606       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.711604178Z I1024 14:23:45.711355       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.712281869Z I1024 14:23:45.712244       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.713041218Z I1024 14:23:45.712635       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.713041218Z I1024 14:23:45.712856       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.713041218Z I1024 14:23:45.713006       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.713223118Z I1024 14:23:45.713194       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.713568738Z I1024 14:23:45.713367       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.713568738Z I1024 14:23:45.713522       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.713712148Z I1024 14:23:45.713689       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.714088338Z I1024 14:23:45.714062       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.714278508Z I1024 14:23:45.714255       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.714473169Z I1024 14:23:45.714427       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.714610078Z I1024 14:23:45.714588       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.714788588Z I1024 14:23:45.714767       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.715476348Z I1024 14:23:45.714975       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.715476348Z I1024 14:23:45.715157       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.715476348Z I1024 14:23:45.715311       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.715476348Z I1024 14:23:45.715470       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.716150498Z I1024 14:23:45.715634       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.716150498Z I1024 14:23:45.715823       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.716150498Z I1024 14:23:45.715977       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.716182918Z I1024 14:23:45.716143       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.716352488Z I1024 14:23:45.716327       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.716505578Z I1024 14:23:45.716485       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.716943408Z I1024 14:23:45.716716       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.716943408Z I1024 14:23:45.716898       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.717130388Z I1024 14:23:45.717105       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.717281838Z I1024 14:23:45.717258       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.717430768Z I1024 14:23:45.717404       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.717613928Z I1024 14:23:45.717590       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.717770169Z I1024 14:23:45.717734       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:23:45.717930338Z I1024 14:23:45.717911       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:27:48.427366028Z I1024 14:27:48.427268       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 28.22 %, dbSize: 90279936
2024-10-24T14:27:48.427366028Z I1024 14:27:48.427302       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 28.37 %, dbSize: 90259456
2024-10-24T14:27:48.427366028Z I1024 14:27:48.427309       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 28.31 %, dbSize: 90292224
2024-10-24T14:33:45.711508680Z I1024 14:33:45.711135       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.712599420Z I1024 14:33:45.712082       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.712599420Z I1024 14:33:45.712435       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.712831540Z I1024 14:33:45.712809       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.713412910Z I1024 14:33:45.713349       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.713606410Z I1024 14:33:45.713578       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.713819390Z I1024 14:33:45.713802       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.714016280Z I1024 14:33:45.713998       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.714248730Z I1024 14:33:45.714202       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.714389270Z I1024 14:33:45.714356       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.714525880Z I1024 14:33:45.714503       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.715275830Z I1024 14:33:45.714681       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.715275830Z I1024 14:33:45.714888       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.715275830Z I1024 14:33:45.715037       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.715275830Z I1024 14:33:45.715193       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.715391050Z I1024 14:33:45.715337       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.715498760Z I1024 14:33:45.715470       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.715653320Z I1024 14:33:45.715627       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.715819190Z I1024 14:33:45.715793       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.716842760Z I1024 14:33:45.716027       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.716842760Z I1024 14:33:45.716181       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.716842760Z I1024 14:33:45.716330       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.716842760Z I1024 14:33:45.716478       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.716842760Z I1024 14:33:45.716615       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.716842760Z I1024 14:33:45.716779       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.717040030Z I1024 14:33:45.716999       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.717235190Z I1024 14:33:45.717174       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.717572920Z I1024 14:33:45.717551       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.717833820Z I1024 14:33:45.717812       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.718049180Z I1024 14:33:45.718030       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.718431550Z I1024 14:33:45.718387       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:33:45.718631750Z I1024 14:33:45.718612       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:38:48.434095148Z I1024 14:38:48.434009       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-0" backend store fragmented: 30.12 %, dbSize: 90279936
2024-10-24T14:38:48.434095148Z I1024 14:38:48.434042       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-1" backend store fragmented: 30.20 %, dbSize: 90259456
2024-10-24T14:38:48.434095148Z I1024 14:38:48.434050       1 defragcontroller.go:300] etcd member "ci-op-2fcpj5j6-f6035-2lklf-master-2" backend store fragmented: 30.24 %, dbSize: 90292224
2024-10-24T14:42:20.081348463Z I1024 14:42:20.081245       1 tlsconfig.go:181] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"admin-kubeconfig-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:31 +0000 UTC to 2034-10-22 12:49:31 +0000 UTC (now=2024-10-24 14:42:19.822061675 +0000 UTC))"
2024-10-24T14:42:20.081348463Z I1024 14:42:20.081314       1 tlsconfig.go:181] "Loaded client CA" index=1 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2024-10-25 12:49:34 +0000 UTC (now=2024-10-24 14:42:20.081286123 +0000 UTC))"
2024-10-24T14:42:20.081348463Z I1024 14:42:20.081339       1 tlsconfig.go:181] "Loaded client CA" index=2 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-control-plane-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2025-10-24 12:49:34 +0000 UTC (now=2024-10-24 14:42:20.081324583 +0000 UTC))"
2024-10-24T14:42:20.081443923Z I1024 14:42:20.081363       1 tlsconfig.go:181] "Loaded client CA" index=3 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-apiserver-to-kubelet-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:34 +0000 UTC to 2025-10-24 12:49:34 +0000 UTC (now=2024-10-24 14:42:20.081346713 +0000 UTC))"
2024-10-24T14:42:20.081443923Z I1024 14:42:20.081388       1 tlsconfig.go:181] "Loaded client CA" index=4 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-bootstrap-kubeconfig-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:32 +0000 UTC to 2034-10-22 12:49:32 +0000 UTC (now=2024-10-24 14:42:20.081370303 +0000 UTC))"
2024-10-24T14:42:20.081443923Z I1024 14:42:20.081414       1 tlsconfig.go:181] "Loaded client CA" index=5 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-csr-signer_@1729775012\" [] issuer=\"kubelet-signer\" (2024-10-24 13:03:31 +0000 UTC to 2024-10-25 12:49:34 +0000 UTC (now=2024-10-24 14:42:20.081399943 +0000 UTC))"
2024-10-24T14:42:20.081443923Z I1024 14:42:20.081438       1 tlsconfig.go:181] "Loaded client CA" index=6 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_node-system-admin-signer@1729775011\" [] issuer=\"<self>\" (2024-10-24 13:03:30 +0000 UTC to 2025-10-24 13:03:31 +0000 UTC (now=2024-10-24 14:42:20.081421093 +0000 UTC))"
2024-10-24T14:42:20.081468993Z I1024 14:42:20.081459       1 tlsconfig.go:181] "Loaded client CA" index=7 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"TestUserClientCABundleRootCA_3120422217834922768\" [] issuer=\"<self>\" (2023-10-24 14:42:09 +0000 UTC to 2025-10-24 14:42:09 +0000 UTC (now=2024-10-24 14:42:20.081445953 +0000 UTC))"
2024-10-24T14:42:20.081505003Z I1024 14:42:20.081480       1 tlsconfig.go:181] "Loaded client CA" index=8 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"aggregator-signer\" [] issuer=\"<self>\" (2024-10-24 12:49:32 +0000 UTC to 2024-10-25 12:49:32 +0000 UTC (now=2024-10-24 14:42:20.081465542 +0000 UTC))"
2024-10-24T14:42:20.081553833Z I1024 14:42:20.081519       1 tlsconfig.go:181] "Loaded client CA" index=9 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_aggregator-client-signer@1729777579\" [] issuer=\"<self>\" (2024-10-24 13:46:18 +0000 UTC to 2024-10-25 01:46:19 +0000 UTC (now=2024-10-24 14:42:20.081500213 +0000 UTC))"
2024-10-24T14:42:20.081835433Z I1024 14:42:20.081772       1 tlsconfig.go:203] "Loaded serving cert" certName="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key" certDetail="\"metrics.openshift-etcd-operator.svc\" [serving] validServingFor=[metrics.openshift-etcd-operator.svc,metrics.openshift-etcd-operator.svc.cluster.local] issuer=\"openshift-service-serving-signer@1729775010\" (2024-10-24 13:03:39 +0000 UTC to 2026-10-24 13:03:40 +0000 UTC (now=2024-10-24 14:42:20.081723503 +0000 UTC))"
2024-10-24T14:42:20.081984363Z I1024 14:42:20.081918       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1729775940\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1729775940\" (2024-10-24 12:19:00 +0000 UTC to 2025-10-24 12:19:00 +0000 UTC (now=2024-10-24 14:42:20.081899113 +0000 UTC))"
2024-10-24T14:43:45.713769524Z I1024 14:43:45.713660       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:43:45.716544533Z I1024 14:43:45.716483       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:43:45.717152173Z I1024 14:43:45.717117       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:43:45.717836414Z I1024 14:43:45.717811       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:43:45.718384303Z I1024 14:43:45.718274       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:43:45.718779964Z I1024 14:43:45.718744       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:43:45.719487643Z I1024 14:43:45.719441       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:43:45.720602734Z I1024 14:43:45.720577       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:43:45.721125743Z I1024 14:43:45.721101       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:43:45.721584453Z I1024 14:43:45.721563       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:43:45.722209743Z I1024 14:43:45.722188       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:43:45.722810603Z I1024 14:43:45.722738       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:43:45.723723024Z I1024 14:43:45.723705       1 prune_controller.go:277] Nothing to prune
2024-10-24T14:43:45.724452774Z I1024 14:43:45.724433       1 prune_controller.go:277] Nothing to prune
